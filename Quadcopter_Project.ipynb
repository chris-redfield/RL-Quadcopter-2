{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Train a Quadcopter How to Fly\n",
    "\n",
    "Design an agent to fly a quadcopter, and then train it using a reinforcement learning algorithm of your choice! \n",
    "\n",
    "Try to apply the techniques you have learnt, but also feel free to come up with innovative ideas and test them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Take a look at the files in the directory to better understand the structure of the project. \n",
    "\n",
    "- `task.py`: Define your task (environment) in this file.\n",
    "- `agents/`: Folder containing reinforcement learning agents.\n",
    "    - `policy_search.py`: A sample agent has been provided here.\n",
    "    - `agent.py`: Develop your agent here.\n",
    "- `physics_sim.py`: This file contains the simulator for the quadcopter.  **DO NOT MODIFY THIS FILE**.\n",
    "\n",
    "For this project, you will define your own task in `task.py`.  Although we have provided a example task to get you started, you are encouraged to change it.  Later in this notebook, you will learn more about how to amend this file.\n",
    "\n",
    "You will also design a reinforcement learning agent in `agent.py` to complete your chosen task.  \n",
    "\n",
    "You are welcome to create any additional files to help you to organize your code.  For instance, you may find it useful to define a `model.py` file defining any needed neural network architectures.\n",
    "\n",
    "## Controlling the Quadcopter\n",
    "\n",
    "We provide a sample agent in the code cell below to show you how to use the sim to control the quadcopter.  This agent is even simpler than the sample agent that you'll examine (in `agents/policy_search.py`) later in this notebook!\n",
    "\n",
    "The agent controls the quadcopter by setting the revolutions per second on each of its four rotors.  The provided agent in the `Basic_Agent` class below always selects a random action for each of the four rotors.  These four speeds are returned by the `act` method as a list of four floating-point numbers.  \n",
    "\n",
    "For this project, the agent that you will implement in `agents/agent.py` will have a far more intelligent method for selecting actions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Basic_Agent():\n",
    "    def __init__(self, task):\n",
    "        self.task = task\n",
    "    \n",
    "    def act(self):\n",
    "        new_thrust = random.gauss(450., 25.)\n",
    "        return [new_thrust + random.gauss(0., 1.) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to have the agent select actions to control the quadcopter.  \n",
    "\n",
    "Feel free to change the provided values of `runtime`, `init_pose`, `init_velocities`, and `init_angle_velocities` below to change the starting conditions of the quadcopter.\n",
    "\n",
    "The `labels` list below annotates statistics that are saved while running the simulation.  All of this information is saved in a text file `data.txt` and stored in the dictionary `results`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [  0.           0.          10.00037857] 1.0\n",
      "positions (x,y,z), reward: [  6.81919038e-04   1.08355537e-03   1.01224270e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.18103997e-03   1.47599650e-03   1.01596337e+01] 1.0\n",
      "positions (x,y,z), reward: [  3.77349685e-03   2.86694288e-03   1.02851067e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.57343778e-02   6.12655278e-03   1.06203601e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.73689495e-02   6.45410757e-03   1.06554831e+01] 1.0\n",
      "positions (x,y,z), reward: [  3.64381688e-02   8.96754453e-03   1.09939995e+01] 1.0\n",
      "positions (x,y,z), reward: [  9.82336433e-02  -3.08162033e-04   1.18868546e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.23435273  -0.10108518  13.53860298] 1.0\n",
      "positions (x,y,z), reward: [  0.29612613  -0.16240519  14.15201743] 1.0\n",
      "positions (x,y,z), reward: [  0.82457739  -0.79523301  18.07356067] 1.0\n",
      "positions (x,y,z), reward: [  1.40549037  -1.64227226  21.72672076] 1.0\n",
      "positions (x,y,z), reward: [  1.77643566  -2.19602394  23.77671123] 1.0\n",
      "positions (x,y,z), reward: [  1.84738808  -2.30106897  24.13991769] 1.0\n",
      "positions (x,y,z), reward: [  2.25924029  -2.8951486   26.08120314] 1.0\n",
      "positions (x,y,z), reward: [  2.6782155   -3.45530463  27.79601197] 1.0\n",
      "positions (x,y,z), reward: [  3.16874729  -4.04272292  29.5382553 ] 1.0\n",
      "positions (x,y,z), reward: [  3.24553288  -4.12803801  29.79042333] 1.0\n",
      "positions (x,y,z), reward: [  3.40383048  -4.29923334  30.29015088] 1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "# Modify the values below to give the quadcopter a different starting position.\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0., 0., 10., 0., 0., 0.])  # initial pose\n",
    "init_velocities = np.array([0., 0., 0.])         # initial velocities\n",
    "init_angle_velocities = np.array([0., 0., 0.])   # initial angle velocities\n",
    "file_output = 'data.txt'                         # file name for saved results\n",
    "\n",
    "# Setup\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "agent = Basic_Agent(task)\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    while True:\n",
    "        rotor_speeds = agent.act()\n",
    "        _, _, done = task.step(rotor_speeds)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "        writer.writerow(to_write)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize how the position of the quadcopter evolved during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8XNWd9/HPGc1II416ly3LkgtykcHGAoIdeMABsrCUwAOEaogNXpKwcQL7LDzJbjZls2kQg18OxTiEEogTEiCAqcE4wEPi3otc5CZbvY+k6ef5415ZcsOWNaM7mvm9X6/zumXu3PkN4C/H5565V2mtEUIIETtsVhcghBAivCTYhRAixkiwCyFEjJFgF0KIGCPBLoQQMUaCXQghYowEuxBCxBgJdiGEiDES7EIIEWPsVnxobm6uLi0tteKjhRBi2Fq7dm2T1jrvVMdZEuylpaWsWbPGio8WQohhSym1/3SOk6EYIYSIMRLsQggRYyTYhRAixlgyxn4ifr+fmpoaPB6P1aWclNPppLi4GIfDYXUpQghxUlET7DU1NaSlpVFaWopSyupyjqO1prm5mZqaGsrKyqwuRwghTipqhmI8Hg85OTlRGeoASilycnKi+m8UQggBURTsQNSGeq9or08IISDKgl0IIWJVU08TP1/1czp9nRH/rKgZYxdCiFjkCXh4cduLLNm8BF/QxwVFF3DJqEsi+pkS7EIIEQEhHeKdve/w2LrHqOuqY9aoWXxn+ncozSiN+GfLUIxp9erVnH322Xg8Hrq6upg8eTJbtmyxuiwhxDC0vmE9d7x9Bw9/8jBZSVk8++VneXzW40MS6hClPfYfvrmVbYc7wnrOSSPS+a9rJp/09fPOO49rr72W//iP/6Cnp4c77riDioqKsNYghIhtBzsOsmDdAj7Y/wH5Kfn85Is/4eoxV2NTQ9uHPu1gV0o5gY+BJPN9f9Ja/5dSqgxYCmQD64A7tda+SBQbad///vc577zzcDqdLFy40OpyhBDDRLu3ncWbFvPyjpdx2Bx8c+o3uWvyXSTbky2pZyA9di8wS2vtVko5gE+VUu8ADwALtNZLlVJPAXOBJwdT1Of1rCOppaUFt9uN3+/H4/HgcrksqUMIMTz4Q37+WPVHntz4JB3eDr4y7ivcP+1+8lPyLa3rtINda60Bt7npMJsGZgG3mfufB37AIIPdKvPmzePHP/4xe/fu5aGHHmLRokVWlySEiEJaaz6u+ZhH1jzCvo59XFB0Af+n8v9Qnl1udWnAAMfYlVIJwFpgHPBrYA/QprUOmIfUACNP8t55wDyAkpKSM603Yl544QXsdju33XYbwWCQGTNmsHz5cmbNmmV1aUKIKFLVUsUv1/ySlbUrKU0vZdGsRVxcfHFU/YBxQMGutQ4CU5VSmcBrwMQTHXaS9y4GFgNUVlae8BgrzZ49m9mzZwOQkJDAypUrLa5ICBFNmnuaWbRhEa/uepW0xDQePv9hbi6/GYct+m4KeEazYrTWbUqpFcAXgEyllN3stRcDh8NYnxBCWMoX9PHy9pd5etPTeAIebptwG/edcx8ZSRlWl3ZSA5kVkwf4zVBPBi4Dfg58BNyIMTPmLuAvkShUCCGGktaa5QeX8+iaRznYeZCLiy/m3yr/jbKM6L+760B67EXA8+Y4uw34o9b6LaXUNmCpUuq/gfXAbyJQpxBCDJmqlip+sfoXrKpbxdiMsTx92dPMGDnD6rJO20BmxWwCpp1gfzVwfjiLEkIIKzT1NLFovTGOnp6Uzncv+C43nXUTdltU/pbzpIZXtUIIEQHeoJcXt73IM5uewRf0cfvE26N+HP3zSLALIeKW1pr39r3HgrULONx1mEtHXcqDlQ8yOn201aUNigS7ECIubWjYwC/X/JJNjZsozypnycwlXFB0gdVlhYUEuxAirhzsOMhj6x7j/f3vk5ecx49m/Ihrx15Lgi3B6tLCRoLd9J//+Z/k5uYyf/58AL73ve9RUFDAt771LYsrE0KEQ5unjac3Pc3SqqU4bA6+fs7XuXvy3aQ4UqwuLeyiM9jfeRjqNof3nIVT4MqfnfTluXPncsMNNzB//nxCoRBLly5l1apV4a1BCDHkvEEvL29/mWc2PUNXoIvrx13PN6d+k7yUPKtLi5joDHYLlJaWkpOTw/r166mvr2fatGnk5ORYXZYQ4gz1PsFo4bqFHO46zEUjL+KB6Q8wLmuc1aVFXHQG++f0rCPpnnvu4bnnnqOuro45c+ZYUoMQYvBW163m0TWPsrV5KxOyJ/DDmT/kC0VfsLqsIROdwW6R66+/nu9///v4/X5efvllq8sRQgxQdXs1C9YuYMXBFRSkFFj2BCOrSbD3k5iYyKWXXkpmZiYJCbFzhVyIWNfc08yTG5/kTzv/hNPuZP6587lj4h047U6rS7OEBHs/oVCIf/zjH7zyyitWlyKEOA2egIffbf8dSzYvwRPwcONZN/L1c75OTnJ8Xx+TYDdt27aNq6++muuvv57x48dbXY4Q4nOEdIhl1ctYuH4hdV11XDLqEr4z/TuMyRhjdWlRQYLdNGnSJKqrq60uQwhxCqvrVvPL1b9ke8t2JuVM4n+++D+cV3ie1WVFFQl2IcSwUN1mXhitWUGhq5CfXvRTriq7Ku4ujJ4OCXYhRFRr6mniiQ1P8OquV0m2J/Ptc7/N7RNvj9sLo6dDgl0IEZW6/d08v/V5frv1t/iDfm6ZcAvzzp5HtjPb6tKingS7ECKqBEIBXtv9Gk9seIKmniauGH0F88+dT0l6idWlDRsS7EKIqKC15pNDn/Domkepbq/m3PxzefzSxzk772yrSxt2BvIw61HAC0AhEAIWa60fV0r9ALgXaDQP/a7W+u1wFyqEiF3bmrfx6JpHWVW3itHpo3ns0seYNWoWSimrSxuWBtJjDwAPaq3XKaXSgLVKqQ/M1xZorR8Jf3lD56mnnuKpp54CoL29ndLSUj766COLqxIith12H2bh+oUsq15GZlImD5//MDeX34zD5rC6tGFtIA+zrgVqzfVOpdR2YGQkivr5qp+zo2VHWM85IXsCD53/0Elfv++++7jvvvvw+/3MmjWLBx54IKyfL4To0+HrYMmmJby0/SUA5lTM4Z4p95CWmGZxZbHhjMbYlVKlwDRgJTATuF8pNRtYg9Grbw1XgUNt/vz5zJo1i2uuucbqUoSIOb6gjz9U/YGnNz1Nh7eDa8Zew/1T76cotcjq0mLKgINdKZUK/Bn4tta6Qyn1JPBjQJvLR4Hj7nmrlJoHzAMoKfn8q9uf17OOpOeee479+/ezaNEiSz5fiFgV0iHe3fsuC9cv5JD7EDNGzOA707/DhOwJVpcWkwYU7EopB0aov6S1fhVAa13f7/VngLdO9F6t9WJgMUBlZaU+04IjZe3atTzyyCN88skn2GzySzYhwmVl7UoWrF3A1uatlGeV8/RlTzNj5Ayry4ppA5kVo4DfANu11r/qt7/IHH8HuB7YEt4Sh8aiRYtoaWnh0ksvBaCyspIlS5ZYXJUQw9fO1p0sWLuATw99SqGrMG7vjW6FgfTYZwJ3ApuVUhvMfd8FblVKTcUYitkH/EtYKxwiv/3tb60uQYiYUNdVx6L1i3hjzxukJqby4PQHuXXirSQlJFldWtwYyKyYT4ETTSqVOetCCGOmy+YlvLTNmOly1+S7uGfKPWQkZVhcWfyRX54KIQbFF/SxdMdSFm9efGSmyzenfpMRqSOsLi1uRVWwa62j+pdmWkfdNV8hLBPSId7f9z6PrXuMQ+5DXFh0IQ9UPiAzXaJA1AS70+mkubmZnJycqAx3rTXNzc04nXKrUCFW163mV2t+xZbmLZyVdZbMdIkyURPsxcXF1NTU0NjYeOqDLeJ0OikuLra6DCEss7t1NwvWLeDjmo8pdBXy3zP/m6vHXE2CTR7+Hk2iJtgdDgdlZWVWlyGEOIH6rnqe2PgEr+9+HZfdJQ+7iHJRE+xCiOjj9rl5dsuzvLjtRYI6yO0Tb2felHlkOjOtLk18Dgl2IcRx/CE/r1S9wlMbn6LV28qVZVfyrWnfojhNhiKHAwl2IcQRWms+2P8Bj697nAOdBziv8DwenP4gk3MnW12aGAAJdiEEAGvr1/Krtb9iU+MmxmWO49df+jUXjbwoKmepic8nwS5EnNvTtofH1j7GipoV5Cfn88MZP+S6sdfJTJdhTIJdiDjVf6ZLij2F+efO5/aJt5NsT7a6NDFIEuxCxJl2bzvPbnmWl7a/RFAHuW3Cbcw7ex5ZziyrSxNhIsEuRJzwBDz8fsfvWbJ5CZ2+Tq4acxX3T71fZrrEIAl2IWJcIBTgzT1v8usNv6a+u56ZI2fy7XO/Lfd0iWES7ELEKK01Hx74kIXrF7K3fS9Tcqfw04t+ynmF51ldmogwCXYhYtDfD/+dhesWsqV5C2UZZTx2yWPMKpklUxfjhAS7EDFkU+MmFq5byMq6lRS5ivjRjB9xzdhrsNvkj3o8kX/bQsSAXa27WLR+EcsPLicrKYt/P+/fubn8ZnkcXZySYBdiGNvfsZ8nNjzBO3vfweVw8Y2p32D2pNm4HC6rSxMWOu1gV0qNAl4ACoEQsFhr/bhSKhv4A1CK8TDrm7XWreEvVQjRq6azhqc3Pc2be97EYXPwtYqv8bXJX5O7LgpgYD32APCg1nqdUioNWKuU+gC4G/hQa/0zpdTDwMPAQ+EvVQhR665l8ebFvL7rdWzKxq0TbmXulLnkJudaXZqIIqcd7FrrWqDWXO9USm0HRgLXAZeYhz0PrECCXYiwquuqY8nmJfx5159RKG4qv4m5FXMpcBVYXZqIQmc0xq6UKgWmASuBAjP00VrXKqXyT/KeecA8gJKSkjP5WCHiTm+gv7rrVTSaG8bdwL1n30uhq9Dq0kQUG3CwK6VSgT8D39Zad5zuvFit9WJgMUBlZaUe6OcKEU9q3bVGoO9+FYDrx13PvVPupSi1yOLKxHAwoGBXSjkwQv0lrfWr5u56pVSR2VsvAhrCXaQQ8aKms4Ylm5fwlz1/AeCGcTdwz5R7JNDFgAxkVowCfgNs11r/qt9LbwB3AT8zl38Ja4VCxIGDHQd5ZvMzvLnnTZRS3Dj+RuZOmStDLuKMDKTHPhO4E9islNpg7vsuRqD/USk1FzgA3BTeEoWIXXvb9/LMpmdYtncZDpuDr074Kl+b/DW5KCoGZSCzYj4FTjag/qXwlCNEfKhqqWLJ5iW8t+89nHYnd0y8g7sn301eSp7VpYkYIL88FWIIbW7czOLNi1lxcAUuh4s5FXOYPXk22c5sq0sTMUSCXYgI01qzsm4lSzYvYWXtStIT0/nGOd/gtom3kZGUYXV5IgZJsAsRIcFQkA8PfMizW55la/NWcpNzeXD6g9xUfpPcy0VElAS7EGHmCXh4Y88bPL/1eQ50HmBU2ii+f+H3uXbstXK3RTEkJNiFCJNWTytLq5aydMdSWjwtVORU8Oj/epQvlXyJBFuC1eWJOCLBLsQg7W3fy4vbXuSNPW/gDXq5pPgSZk+eTWVBpTyxSFhCgl2IM6C1ZnXdal7Y9gJ/q/kbibZErhl7DbMnzWZM5hiryxNxToJdiAHwB/28s+8dXtj6AlWtVWQ7s/n6OV/n5vKb5da5ImpIsAtxGlo8LbxS9QpLq5bS1NPEuMxx/ODCH3D12KvlgqiIOhLsQnyOna07eWn7SyyrXoY36GXmyJn8ZOJPuHDEhTJ+LqKWBLsQxwjpEJ/UfMKL219kZe1KnAlOrhl7DXdOvFPGz8WwIMEuhKnb383ru1/n5R0vs79jPwUpBcw/dz43nXWT/EJUDCsS7CLuHXIf4vfbf8+ru16l09/JlNwp/OLiX3DZ6Mtw2BxWlyfEgEmwi7iktWZV3Spe3v4yK2pWoFBcNvoy7px0J+fknWN1eUIMigS7iCtd/i7e2vMWS6uWsrttN5lJmcypmMNXy78qD7UQMUOCXcSFna07eaXqFd6sfpMufxcTsyfy45k/5sqyK2W6oog5EuwiZnkCHt7f/z5/2vkn1jesJ9GWyJdLv8wtE25hSu4Uma4oYpYEu4g525u389ru13ir+i06fZ2MTh/Nv1X+G9eOvZYsZ5bV5QkRcQN5mPWzwNVAg9a6wtz3A+BeoNE87Lta67fDXaQQp9LmaWPZ3mW8tus1qlqrSLQlctnoy7jxrBvlZlwi7gykx/4csAh44Zj9C7TWj4StIiFOUyAU4LPDn/H67tdZcXAF/pCfSTmT+N4F3+PKsitl7rmIWwN5mPXHSqnSyJUixOnZ1bqLN/a8wbLqZTT2NJKVlMVXy7/KV8Z9hfLscqvLE8Jy4Rhjv18pNRtYAzyotW4NwzmFOEpTTxNvV7/NW9Vvsb1lO3Zl56Lii7hu3HVcPPJiHAnyQyIheg022J8Efgxoc/koMOdEByql5gHzAEpKSgb5sSIeuH1uPjzwIcuql7GybiUhHWJyzmQeOu8hrhpzFdnObKtLFCIqDSrYtdb1vetKqWeAtz7n2MXAYoDKyko9mM8VscsX9PHJoU94u/pt/lbzN7xBLyNTRzK3Yi5Xj7labsIlxGkYVLArpYq01rXm5vXAlsGXJOJNSIdYW7+WZdXLeH//+3T6Osl2ZnPD+Bu4quwqzsk7R2a1CDEAA5nu+HvgEiBXKVUD/BdwiVJqKsZQzD7gXyJQo4hBWmt2tu5k2d5lvF39NvXd9STbk/lSyZf45zH/zBeKvoDdJj+zEOJMDGRWzK0n2P2bMNYi4kBNZw3v7H2Ht/e+ze623diVnQtHXMgD0x/gklGXkOJIsbpEIYY96RKJiGvqaeK9fe/x9t632dS4CYBp+dP43gXf44rSK+QiqBBhJsEuIqLV08pfD/yVd/e+y5r6NYR0iPKscuafO5+ryq5iROoIq0sUImZJsIuwafO0sfzgct7b9x4ra1cS1EFK00u5d8q9XFl2JWMzx1pdohBxQYJdDEqrp5XlB5bz/v73WVW7ioAOUJxazN2T7+bLpV9mQvYEmdEixBCTYBcD1tDdwPIDy/nr/r+ypn4NQR1kVNoo7pp8F1eUXsHE7IkS5kJYSIJdnJZ97fv48MCHLD+4/MgF0NL0UuZUzOGK0isozyqXMBciSkiwixMKhoJsatrEioMr+OjgR+xt3wvApJxJ3D/1fi4bfZmMmQsRpSTYxREdvg4+O/QZH9d8zKeHPqXV24pd2ZleOJ1bym/h0lGXUpRaZHWZQohTkGCPY1prqlqr+PTQp3xS8wkbGzcS1EEykjL44sgvcknxJcwcOZO0xDSrSxVCDIAEe5xp7mnmH7X/4LPDn/HZ4c9o6mkCYGL2ROZUzOHi4ouZkjuFBFuCxZUKIc6UBHuM6/Z3s65hHStrV/L3w3+nqrUKgMykTC4supAvFn+RGSNmkJuca3GlQohwkWCPMd3+bjY0bGB1/WpW161ma9NWAjqAw+ZgWv40/nXavzJzxEwm5kzEpmxWlyuEiAAJ9mGu3dvOhoYNrK1fy9r6tWxt3kpQB7ErO5NyJ3F3xd2cX3g+U/OnkmxPtrpcIcQQkGAfRrTW1HbVsr5h/ZG2q3UXGo3dZqcip4I5FXOoLKhkav5UuVOiEHFKgj2K9QR62NGyg02Nm9jYuJGNjRtp6G4AIMWewtT8qVw++nKmF0ynIrdCeuRCCECCPWp0+7vZ1baL7c3b2d6ynW3N29jVuougDgIwMnUk0wumMy1/GlPzpjI+a7w8iEIIcUKSDEMsGApysPMge9r2sKttF7tad7GzdSf7O/ajMR4Fm5mUyaScScydMpcpuVOoyK2QWStCiNMmwR4hwVCQw+7D7G7bzZ72PcaybQ/VbdX4Qr4jx41KG8X4zPFcVXYV5dnlTMyeSKGrUO67IoQ4YxLsg9Th6+BAxwH2dexjX/s+9nXsY2/7Xva17zsqwAtdhYzNHMsFhRcwNnMs4zLHMSZzDC6Hy8LqhRCxaCAPs34WuBpo0FpXmPuygT8ApRgPs75Za90a/jKt4wv6qO+up9Zdy+GuwxxyH+JQ5yEOdB7gQMcBWr19X9embBSnFlOaUcqMETMYkzGGsowyxmWOIzUx1cJvIYSIJwPpsT8HLAJe6LfvYeBDrfXPlFIPm9sPha+8yAiEArR522jztNHiaaHF00Kzp5nmnmZaPC009jTS2N1IQ3cDzZ7mo96rUBS6CilOK2ZWySxGp49mdPpoStNLKU4rJjEh0aJvJYQQhtMOdq31x0qp0mN2XwdcYq4/D6wggsG+pm4Nu9t2E9RBQjpESIcIhAIEQgH8IT/+kB9v0Isn4MEb9NIT6KEn0EO3v5uuQBdun5tOXyduv/uE57cpG1lJWeSl5JGXnMeknEkUuAooTCmkKLWIEa4RFLmKcCQ4IvUVhRBi0AY7xl6gta4F0FrXKqXyT3agUmoeMA+gpKTkjD7s3X3v8oeqP5z0dYfNgTPBSWJCIk67k2R7Msn2ZFIcKWQ7s0lNTCU9MZ30xHSynFlkOjPJceaQlZRFdnI2mUmZ8jN7IcSwp7TWp3+w0WN/q98Ye5vWOrPf661a66xTnaeyslKvWbNmwMW6fW68QS82ZcOmbNhtdhJUAgm2BOzKLjNJhBAxTSm1VmtdearjBttjr1dKFZm99SKgYZDn+1ypiamkIhchhRDi8wx23OEN4C5z/S7gL4M8nxBCiEE67WBXSv0e+DtQrpSqUUrNBX4GXK6U2gVcbm4LIYSw0EBmxdx6kpe+FKZahBBChIFMARFCiBgjwS6EEDFGgl0IIWKMBLsQQsQYCXYhhIgxEuxCCBFjJNiFECLGSLALIUSMkWAXQogYI8EuhBAxRoJdCCFijAS7EELEGAl2IYSIMRLsQggRYyTYhRAixkiwCyFEjJFgF0KIGCPBLoQQMea0H433eZRS+4BOIAgEtNaV4TivEEKIgQtLsJsu1Vo3hfF8QgghzoAMxQghRIwJV7Br4H2l1Fql1LwwnVMIIcQZCNdQzEyt9WGlVD7wgVJqh9b64/4HmIE/D6CkpCRMHyuEEOJYYemxa60Pm8sG4DXg/BMcs1hrXam1rszLywvHxwohhDiBQQe7UsqllErrXQeuALYM9rxCCCHOTDiGYgqA15RSved7WWv9bhjOK4QQ4gwMOti11tXAOWGoRQghRBjIdEchhBgigWCIQDAU8c8J5w+UhBBCmLyBILvq3Ww51M6Ww+1sPtTBjtoOXphzPheMyYnoZ0uwCyHEILV2+dhe28G22g6213ay9XA7uxvcBEIagLQkO5NHpnPnF0aTk5oU8Xok2IUQ4jT5AiH2NLqpqutkR10nVXVGkNd1eI4ck5uaxOQR6Vw6IZ+KERlUjExnVFYKNpsasjol2IUQ4hj+YIj9zd3squ9kZ72bnQ2d7KzrZG9T15FeuCNBMTYvlQvH5jChMI2JRelMLEonLy3yPfJTkWAXQsStbl+A6sYu9jS62dPgZnejm90NbvY2deEP6iPHlWSncFZBKldMLqC8MJ3ygjTG5LlwJETn/BMJdiFETAsEQxxq62FvU9eRVt3YRXWjm8PtfUMoNgWjslMYn5/GrAkFnFWQyvj8NMbmu0hJHF5RObyqFUKIE/AFjPDe19zFgeZu9jV3sb+5m31NXRxs7T6q952WZGdMnovzy7IZm5fKmLxUxuWnMjonBacjwcJvET4S7EKIqKe1prnLx8GWbg629hjLlm4OtHSzv7mb2vYeQn3ZTUpiAqNzXJQXpvHlikLKclyU5bkozXGRm5qI+Uv5mCXBLoSwXCikaXJ7qWnr4VBrD4faeqhp7eZQaw81ZuvxB496T25qIsVZKVSWZjE6eyQlOS5Kc1IoyUkhLzUp5sP780iwCyEirtPjp7bdw+G2niPLw20eatt7jqz7jvlFZkayg+KsZMpyXVx8Vh7FWcmMykphVHYKxVnJuJIkvk5G/skIIc6Y1pqWLh91HR7qOzzUtXup6/BQ124EeF27h9p2D25v4Kj32RTkpzkZmZXMlOJMvlzhpDgzmRGZyRRnpTAyK5lUCe4zJv/khBDH0VrT0ROgodNDQ6eX+o5+y47e8PbQ2Ok9rqdtU5CXlkRhupMxeS5mjsulKMNJUWYyI8xlQVoS9iidKhgLJNiFiCO+QIgmt5cmt5fGTqM1dPatN7q9Rph3ePEGjr9ZlSsxgYIMJwVpTs4vyyY/3QjwwnQnBRlOijKc5KVKaFtNgl2IYUxrTac3QLPbR0uXlya3j2a3jya3l2a3sd0b5E1uH+09/hOeJyPZQX5aEnlpSUwvySI/3Ul+WtKRZYG5lHHt4UH+LQkRRXyBEG3dPlq6fbR0+Wjt8tPS7aO1y9jubc1dRpC3dPmOmqPdX7rTTm5qErmpSZQXpjEzNYm81CRy04x9eWlJ5KYmkpeWRJI9NuZvC4MEuxAREAppOjx+2rr9tPX4aes2esutXT5au43t1m4/rd0+2sxla5ePLl/wpOdMc9rJdiWS7UpkZKaTihHp5KQmkeNKJCfV2N8b5NmuRBLtMhwSryTYhTiJYEjj9gTo8Php7/HT0eM/EtbtPSdvbd3GcfrEHWnA6E1nuRLJTDFCeVx+KlkpiWSlOMh0JZJtrmenGuuZKRLU4vRJsIuY5A0EcXsCdHmDuL0B3N4AnR6/uext/mOWRoh3egJ09PjpPGaK3rESbIqMZMeRlpWSSGmOi6wUYzszJZHMfuvGMca2XFwUkRSWYFdK/RPwOJAALNFa/ywc5xWxLRTSeAMhevxBo/mCePxBun292wG6fea2uez2BejyBej2BunyGcFtLI9eP9m4c38JNkVqkp30ZDvpTgdpTjsl2SmkOR1H7ctIdpBuhne600GGGc6uxIS4/nWjiF6DDnalVALwa+ByoAZYrZR6Q2u9bbDnFuGltSYQ0gSCGn8ohD8Qwh/U+IMhsx297guE8AWD+AIaX9A43hcMGfvNda+57g0E+62H8PqDeI5d+oN4/EaQe/zBE06nOxWnw0ZKop2UxARSEhNwJdlJTbIfmbHhSrSb+xJITbKT6nSY6w5cSQlGaDvtpDrtJDskmEVsCkeP/Xxgt9a6GkAptRS4Dgh7sO9Y/Vc6ak59WnWiwc1++3rXFMfvQ2tj3Tz+6P2672CtCfVuaG0ers2GgNp6AAALIElEQVSXzG0dIqTNc/Rb1yFtrodAQ0hDyHyPsdTH7evdDmqjpxvSEOxtIQiaxwRCENSKgLkeCCn85ro/ZCOEIoiNEDZzqQiSQNDcDugEAhzf/Njxa3OJHZ+5DGEj0W4jKcFGkiOBJLvNaI4EEu02nHYbGckOnGlJOB0JOB02c2m0ZHNfSqKxnZJoP7Kd7OgL8ORE47WEIXwKjRDDVTiCfSRwsN92DXDBsQcppeYB8wBKSkrO6IPaV77EBU2vntF745YyW4SGdLWyoRKSwG62I+vOo5eOZGPd4QR7stlS+pYJyWZzQULKMctUY6nkkpAQpyMcf1JO1IU6rsustV4MLAaorKw89QDoCZTf8lNqux4ecFlH/rp9wr929z+ud2kz8vDIDlAo83V15FibUsb+BHXkeJuyoVTvusJms2Ez33/izz8DR/72oc31Y5Y6ZK6H+rZ7WyhorgfNdXMZCkIoYLYghPzGerB36TObuR7yQ8CHCnoh4DX2BXrXvRDwQaDH2O5phc46Y9vvMZc9EPCc/DueiEqApFRINFtSWr+W3rfuTDe2nengzDBbptkyIEH+ByFiWzj+C68BRvXbLgYOh+G8x8nMLSQztzASpxZWCIWMcPd3G83Xfcx6F3jdxra301y6wec2tr2dxnpnHXg7+vYd3684WmIaJGdBcqa5zIKUbEjONpYpOWbrXc+FRFf4/scsRISFI9hXA+OVUmXAIeAW4LYwnFfEOpsNElOMFi6hkBH2nnYj7D0d4Gkztnt6l61G87RBdwt0HIaeFmOfPskFXbsTXHlG0LvywJVrtnxjOzUPUgvM7VywyS85hXUGHexa64BS6n7gPYzpjs9qrbcOujIhzoTNZg7BpA/8vaEQeNuNsO9uhq4mI/C7mqC7CbqaoavRWG/cAe4GY9jpWMpm9PJTCyCtAFILjWVaEaQVmssi43UZFhIREJb/qrTWbwNvh+NcQljGZusbmskZe+rjtTaGfroajZDvajCW7gZw1xnLzjqo3wbueuN6xlEUpOZD+ghIH2kue9dHQsZISBsB9sSIfF0Ru6S7IMSZUqrvbwen+h9BKGj0/N110FELnWbrOGRsN++BfZ8YQ0VHf4jRs88o7muZJZAxylhmjjIuCAvRjwS7EEPBlmAOxxRA0TknP87rNsP+ELT3Lg9Cew3Ub4Gd7x4/m8iZYYb86L5lVilkmduJroh+NRF9JNiFiCZJqZBXbrQT0doY+mk7CO0HjGXbfmPZvBv2LDdmD/XnyofsMjPsy8z1MsgeY1zoldk+MUeCXYjhRJnj8qn5UDz9+Ne1NoZ8WvcZgd+6F1r3G9v7P4NNf+So6aCJaUbQZ48xWs5YyB5rLF15EvrDlAS7ELFEKXPqZR6MOu/41wNeaDsALXuhpdoI/pZqqNsMO94yfozWK8m8dpAzrl8zt5PShu47iQGTYBcintiTIHe80Y4V9JuhX21czG3eDS174OBK2PwnjurppxWZ5znLbOMhZ7xxcVd6+ZaTYBdCGBIcZo98LIy//OjX/B4z8HdB0y4j9Jt2waZXjLn/vRwuyB0HueV91wryJhhj+jJnf8jIP2khxKk5nFAwyWj99V7MbayCpioj7BurYP//g81/7DvO5jCGcPInGEGfVw55E43/iSQ4hva7xAEJdiHEmet/MbfsoqNf83ZC005o3Gn8UrexCg5vgK2vc2RY50jgT4T8SeZyojGDR27LcMYk2IUQkZGUBiOnG60/X7cZ+DugYbuxPLQWtva7Jbc92ejVF0w2Ar9gkrFMLZAx/NMgwS6EGFqJKTBiqtH687r7wr5hm9F2fQAbXuo7JiXHDPoKI/QLJhs9fEfy0H6HKCfBLoSIDkmpUFxptP66moyQr98GDVuhfiuse77vh1jKZgznFEw2A78CCiuM++3Eae9egl0IEd1cuVB2sdF6hULGHPz6LUbQ12+FQ+tg62t9xyRnmSE/pW+ZNyEubqomwS6EGH5str6pmZOu69vv6TB693WbjVa/Bdb81nhqFxgXa/MmGCHfvyVnWvM9IkSCXQgRO5zpUPIFo/UKBY0fXNVvhtpNRtjv+RA2vtx3TGYJFJ5ttKKzjbAfxkM5EuxCiNhmS4C8s4xW8b/79nfW94V93SbztgrLODIVMyWnX9CfDUVTjfvp2CL0ZPgwkmAXQsSn3tsoj7usb5+307hIW7cJajca7e9PGA9vB+Mh6gUVxq2XewM/CsftJdiFEKJXUhqUXGC0XgGfMQ2zdqMZ+Jtg/e9gVZfxekKiMQWz6Gwz8KcaM3QsnII5qGBXSv0AuBdoNHd913xMnhBCxAZ7ohnaZ/ftCwWNe+f09uprN8L2N2HdC8brKsG4OVrROf1691OG7GlX4eixL9BaPxKG8wghxPBgS+i7S+aUG419WhtPu6rdaPTqazfC3r/BpqV978seA9csPP72C2EmQzFCCBEOSpmPJiyBidf07e+sN4dwNhiBn5of8VLCEez3K6VmA2uAB7XWrWE4pxBCxIa0Aki7/PhbIUfQKeftKKX+qpTacoJ2HfAkMBaYCtQCj37OeeYppdYopdY0Njae7DAhhBCDpLTWpz7qdE6kVCnwlta64lTHVlZW6jVr1oTlc4UQIl4opdZqrStPddygZtorpYr6bV4PbBnM+YQQQgzeYMfYf6GUmorxU619wL8MuiIhhBCDMqhg11rfGa5ChBBChEf03/RACCHEgEiwCyFEjJFgF0KIGBO26Y4D+lClGoH9A3xbLtAUgXKiWbx953j7viDfOV6E6zuP1lrnneogS4L9TCil1pzO/M1YEm/fOd6+L8h3jhdD/Z1lKEYIIWKMBLsQQsSY4RTsi60uwALx9p3j7fuCfOd4MaTfediMsQshhDg9w6nHLoQQ4jREfbArpf5JKVWllNqtlHrY6nqGglLqWaVUg1IqLm6qppQapZT6SCm1XSm1VSk13+qaIk0p5VRKrVJKbTS/8w+trmmoKKUSlFLrlVJvWV3LUFBK7VNKbVZKbVBKDcltbaN6KEYplQDsBC4HaoDVwK1a622WFhZhSqmLATfwwuncBnm4M+8SWqS1XqeUSgPWAl+J5X/PSikFuLTWbqWUA/gUmK+1/ofFpUWcUuoBoBJI11pfbXU9kaaU2gdUaq2HbO5+tPfYzwd2a62rtdY+YClwncU1RZzW+mOgxeo6horWulZrvc5c7wS2AyOtrSqytMFtbjrMFr29rDBRShUD/wwssbqWWBbtwT4SONhvu4YY/wMf78wHtkwDVlpbSeSZQxIbgAbgA611zH9n4DHg34GQ1YUMIQ28r5Raq5SaNxQfGO3Brk6wL+Z7NfFKKZUK/Bn4tta6w+p6Ik1rHdRaTwWKgfOVUjE97KaUuhpo0FqvtbqWITZTa30ucCXwTXOoNaKiPdhrgFH9touBwxbVIiLIHGf+M/CS1vpVq+sZSlrrNmAF8E8WlxJpM4FrzTHnpcAspdTvrC0p8rTWh81lA/AaxhBzREV7sK8GxiulypRSicAtwBsW1yTCzLyQ+Btgu9b6V1bXMxSUUnlKqUxzPRm4DNhhbVWRpbX+v1rrYq11Kcaf5eVa6zssLiuilFIuc0IASikXcAVD8AjRqA52rXUAuB94D+OC2h+11lutrSrylFK/B/4OlCulapRSc62uKcJmAndi9OA2mO0qq4uKsCLgI6XUJowOzAda67iY/hdnCoBPlVIbgVXAMq31u5H+0Kie7iiEEGLgorrHLoQQYuAk2IUQIsZIsAshRIyRYBdCiBgjwS6EEDFGgl0IIWKMBLsQQsQYCXYhhIgx/x8sas8yZN9rRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe974e76390>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell visualizes the velocity of the quadcopter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe98413aa90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe961dbb8d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting the velocities (in radians per second) corresponding to each of the Euler angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe98413ab38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the code cell below to print the agent's choice of actions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe961d0b358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a task, you will derive the environment state from the simulator.  Run the code cell below to print the values of the following variables at the end of the simulation:\n",
    "- `task.sim.pose` (the position of the quadcopter in ($x,y,z$) dimensions and the Euler angles),\n",
    "- `task.sim.v` (the velocity of the quadcopter in ($x,y,z$) dimensions), and\n",
    "- `task.sim.angular_v` (radians/second for each of the three Euler angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.74217229e+00  -4.64296534e+00   3.12834785e+01   1.35754194e-02\n",
      "   6.14890897e+00   0.00000000e+00]\n",
      "[ 2.21336942 -2.15026443  6.2080224 ]\n",
      "[ 0.08393107 -0.08812107  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample task in `task.py`, we use the 6-dimensional pose of the quadcopter to construct the state of the environment at each timestep.  However, when amending the task for your purposes, you are welcome to expand the size of the state vector by including the velocity information.  You can use any combination of the pose, velocity, and angular velocity - feel free to tinker here, and construct the state to suit your task.\n",
    "\n",
    "## The Task\n",
    "\n",
    "A sample task has been provided for you in `task.py`.  Open this file in a new window now. \n",
    "\n",
    "The `__init__()` method is used to initialize several variables that are needed to specify the task.  \n",
    "- The simulator is initialized as an instance of the `PhysicsSim` class (from `physics_sim.py`).  \n",
    "- Inspired by the methodology in the original DDPG paper, we make use of action repeats.  For each timestep of the agent, we step the simulation `action_repeats` timesteps.  If you are not familiar with action repeats, please read the **Results** section in [the DDPG paper](https://arxiv.org/abs/1509.02971).\n",
    "- We set the number of elements in the state vector.  For the sample task, we only work with the 6-dimensional pose information.  To set the size of the state (`state_size`), we must take action repeats into account.  \n",
    "- The environment will always have a 4-dimensional action space, with one entry for each rotor (`action_size=4`). You can set the minimum (`action_low`) and maximum (`action_high`) values of each entry here.\n",
    "- The sample task in this provided file is for the agent to reach a target position.  We specify that target position as a variable.\n",
    "\n",
    "The `reset()` method resets the simulator.  The agent should call this method every time the episode ends.  You can see an example of this in the code cell below.\n",
    "\n",
    "The `step()` method is perhaps the most important.  It accepts the agent's choice of action `rotor_speeds`, which is used to prepare the next state to pass on to the agent.  Then, the reward is computed from `get_reward()`.  The episode is considered done if the time limit has been exceeded, or the quadcopter has travelled outside of the bounds of the simulation.\n",
    "\n",
    "In the next section, you will learn how to test the performance of an agent on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "The sample agent given in `agents/policy_search.py` uses a very simplistic linear policy to directly compute the action vector as a dot product of the state vector and a matrix of weights. Then, it randomly perturbs the parameters by adding some Gaussian noise, to produce a different policy. Based on the average reward obtained in each episode (`score`), it keeps track of the best set of parameters found so far, how the score is changing, and accordingly tweaks a scaling factor to widen or tighten the noise.\n",
    "\n",
    "Run the code cell below to see how the agent performs on the sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [ -5.52994617e-02   2.20347003e-03   1.00350364e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.24268402 -0.18664949  8.91608411] 1.0\n",
      "positions (x,y,z), reward: [ 2.95206126 -0.26844833  7.7189301 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.10614296 -0.39466242  6.87087103] 1.0\n",
      "positions (x,y,z), reward: [ 6.2288882  -0.73081163  4.99583693] 1.0\n",
      "positions (x,y,z), reward: [ 6.60551334 -0.77708584  4.60235079] 1.0\n",
      "positions (x,y,z), reward: [ 6.79283538 -0.79722831  4.39592308] 1.0\n",
      "positions (x,y,z), reward: [ 8.96574721 -1.08866101  1.65149915] 1.0\n",
      "Episode =    1, score =   2.000 (best =   2.000), noise_scale = 0.05positions (x,y,z), reward: [ 0.03315579 -0.03035077  9.95843989] 1.0\n",
      "positions (x,y,z), reward: [ 1.0923942   0.19883944  8.68547433] 1.0\n",
      "positions (x,y,z), reward: [ 3.22807432  1.6326073   5.07513718] 1.0\n",
      "Episode =    2, score =   2.000 (best =   2.000), noise_scale = 0.1positions (x,y,z), reward: [-0.37581177 -2.04171098  8.7264775 ] 1.0\n",
      "positions (x,y,z), reward: [-1.30957366 -3.07187122  7.60255825] 1.0\n",
      "positions (x,y,z), reward: [-4.94260119 -6.87638449  1.27052374] 1.0\n",
      "Episode =    3, score =   2.000 (best =   2.000), noise_scale = 0.2positions (x,y,z), reward: [ 0.16910639 -2.3072787   6.13111708] 1.0\n",
      "positions (x,y,z), reward: [-1.75240863 -3.26879266  2.46130739] 1.0\n",
      "Episode =    4, score =   2.000 (best =   2.000), noise_scale = 0.4positions (x,y,z), reward: [ -0.19796048   0.01042867  10.00042352] 1.0\n",
      "positions (x,y,z), reward: [-0.08898239 -0.04174569  9.77558729] 1.0\n",
      "Episode =    5, score =   2.000 (best =   2.000), noise_scale = 0.8positions (x,y,z), reward: [ 1.03515829 -0.26974008  9.38814802] 1.0\n",
      "positions (x,y,z), reward: [ 2.57678575 -0.54328419  8.47162389] 1.0\n",
      "positions (x,y,z), reward: [ 12.51438357  -2.02039301   1.09337272] 1.0\n",
      "Episode =    6, score =   2.000 (best =   2.000), noise_scale = 1.6positions (x,y,z), reward: [ -0.1649899    0.09865472  10.0028689 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.21460514  0.02001965  9.77467034] 1.0\n",
      "positions (x,y,z), reward: [-5.4349124  -5.20402978  0.5838135 ] 1.0\n",
      "Episode =    7, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.68830406 -1.50251199  7.40027822] 1.0\n",
      "Episode =    8, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.13464512  0.13300192  9.89422496] 1.0\n",
      "positions (x,y,z), reward: [-0.6691543   0.0412522   9.32554621] 1.0\n",
      "positions (x,y,z), reward: [-1.80621111 -0.58878125  8.37127429] 1.0\n",
      "positions (x,y,z), reward: [-7.58947285 -2.42531442  2.6426794 ] 1.0\n",
      "Episode =    9, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.22721887  0.82020396  8.78312457] 1.0\n",
      "positions (x,y,z), reward: [ 0.14054793  1.05093581  8.56657821] 1.0\n",
      "positions (x,y,z), reward: [-0.03789924  1.62831201  7.96689871] 1.0\n",
      "positions (x,y,z), reward: [-0.10717407  2.47231409  6.4075275 ] 1.0\n",
      "Episode =   10, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.68693023 -0.33359438  9.87681836] 1.0\n",
      "positions (x,y,z), reward: [ 6.16241246 -2.32670965  6.19115767] 1.0\n",
      "Episode =   11, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07858755  -0.03835282  10.05845312] 1.0\n",
      "positions (x,y,z), reward: [-0.38126872 -0.20611148  9.28643836] 1.0\n",
      "positions (x,y,z), reward: [-0.92832868 -0.01383778  9.15683258] 1.0\n",
      "positions (x,y,z), reward: [-5.77607434  2.69591778  7.08473495] 1.0\n",
      "Episode =   12, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04518395  -0.01185226  10.05089766] 1.0\n",
      "positions (x,y,z), reward: [  8.28933270e-01   1.91323525e-03   9.83964154e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.15024667  0.19024034  9.59930502] 1.0\n",
      "positions (x,y,z), reward: [ 1.66209747  0.43290035  9.16536342] 1.0\n",
      "Episode =   13, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.22579985 -0.0308923   9.22712522] 1.0\n",
      "positions (x,y,z), reward: [ 0.95571164 -0.40651175  8.18902675] 1.0\n",
      "positions (x,y,z), reward: [ 1.00000667 -0.50514032  7.98877832] 1.0\n",
      "positions (x,y,z), reward: [ 1.04203778 -0.98185465  6.63619988] 1.0\n",
      "positions (x,y,z), reward: [ 0.72753473 -1.41162602  4.80728235] 1.0\n",
      "Episode =   14, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.44824484  0.19439164  7.38327011] 1.0\n",
      "positions (x,y,z), reward: [ 0.2394859   1.23186723  0.23570105] 1.0\n",
      "Episode =   15, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.65429637 -2.08849405  8.44641614] 1.0\n",
      "positions (x,y,z), reward: [ 0.63297442 -2.23574859  8.30309995] 1.0\n",
      "Episode =   16, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.47342671 -0.05218133  9.76823228] 1.0\n",
      "positions (x,y,z), reward: [ 10.2669439   -0.60869127   3.88407925] 1.0\n",
      "Episode =   17, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00572328] 1.0\n",
      "positions (x,y,z), reward: [ 0.15477122 -0.19077245  9.88964872] 1.0\n",
      "positions (x,y,z), reward: [ 1.39317009 -1.46467141  8.99776056] 1.0\n",
      "positions (x,y,z), reward: [ 1.33214268 -1.83587621  8.65801841] 1.0\n",
      "positions (x,y,z), reward: [ 1.30013416 -2.03205146  8.44239507] 1.0\n",
      "positions (x,y,z), reward: [ 0.97782062 -3.06311004  7.11530581] 1.0\n",
      "positions (x,y,z), reward: [-0.48115491 -5.58279542  2.29549331] 1.0\n",
      "Episode =   18, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00555616] 1.0\n",
      "positions (x,y,z), reward: [ 0.82385938 -0.31598738  9.30665181] 1.0\n",
      "positions (x,y,z), reward: [ 0.82127851 -0.37871103  9.24905393] 1.0\n",
      "positions (x,y,z), reward: [-1.7584246  -2.05745368  6.6759243 ] 1.0\n",
      "positions (x,y,z), reward: [-4.48991471 -3.1154542   3.43633407] 1.0\n",
      "Episode =   19, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.61235556 -0.15412258  9.41426175] 1.0\n",
      "positions (x,y,z), reward: [ 2.30108718 -0.25916276  7.57703991] 1.0\n",
      "Episode =   20, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.01537237  -0.13446404  10.08143866] 1.0\n",
      "positions (x,y,z), reward: [ 0.53170736 -2.18329485  9.37532074] 1.0\n",
      "Episode =   21, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00493859] 1.0\n",
      "positions (x,y,z), reward: [ 6.81357188  0.10299735  3.96851727] 1.0\n",
      "positions (x,y,z), reward: [ 7.60351438  0.11899293  2.80183689] 1.0\n",
      "Episode =   22, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.61979233e-03  -2.63559469e-03   1.00107492e+01] 1.0\n",
      "positions (x,y,z), reward: [ 4.21162134  2.26893005  1.84906249] 1.0\n",
      "Episode =   23, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.39157243 -0.01153844  9.9982316 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.58932719  -0.1175442   10.02887784] 1.0\n",
      "positions (x,y,z), reward: [-4.13166968 -1.46942748  9.53490618] 1.0\n",
      "positions (x,y,z), reward: [-5.39747659 -1.99492391  8.89856847] 1.0\n",
      "positions (x,y,z), reward: [-9.31952963 -3.35477565  6.54716662] 1.0\n",
      "Episode =   24, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.28584117  1.00831481  9.7660031 ] 1.0\n",
      "positions (x,y,z), reward: [-4.03465558  3.05360772  9.22124597] 1.0\n",
      "positions (x,y,z), reward: [-10.57173101   6.2059898    5.85803364] 1.0\n",
      "positions (x,y,z), reward: [-16.37704608   9.31513773   0.48411805] 1.0\n",
      "Episode =   25, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.872038   -4.64925098  2.37889638] 1.0\n",
      "Episode =   26, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.37431446  0.34325603  9.96464642] 1.0\n",
      "positions (x,y,z), reward: [-0.25425779  0.86983277  9.79289592] 1.0\n",
      "positions (x,y,z), reward: [-2.09063193  3.13421872  9.0610573 ] 1.0\n",
      "positions (x,y,z), reward: [-2.77789403  3.59921392  8.83261435] 1.0\n",
      "positions (x,y,z), reward: [-3.90846897  4.2049269   8.29387476] 1.0\n",
      "positions (x,y,z), reward: [-9.45072507  7.07131362  3.14163939] 1.0\n",
      "positions (x,y,z), reward: [-10.98663858   7.97359493   1.14646146] 1.0\n",
      "Episode =   27, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0051822] 1.0\n",
      "positions (x,y,z), reward: [ -0.21878879   0.02315194  10.00163059] 1.0\n",
      "positions (x,y,z), reward: [-2.45943735  0.26907289  8.37027935] 1.0\n",
      "Episode =   28, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.21308762 -0.61293158  9.95998031] 1.0\n",
      "positions (x,y,z), reward: [  1.01630665  -0.45082163  10.08784615] 1.0\n",
      "positions (x,y,z), reward: [  2.00462410e-01  -3.83407002e-03   1.01288190e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.19862532   0.223214    10.06423686] 1.0\n",
      "positions (x,y,z), reward: [-1.47949049  0.88444842  9.8050143 ] 1.0\n",
      "positions (x,y,z), reward: [-3.63654239  1.58193571  9.14507618] 1.0\n",
      "positions (x,y,z), reward: [-4.83197561  2.02026131  8.77268061] 1.0\n",
      "positions (x,y,z), reward: [-8.37508616  3.05059494  7.46145435] 1.0\n",
      "positions (x,y,z), reward: [-12.13469954   3.9605326    5.55230338] 1.0\n",
      "positions (x,y,z), reward: [-12.42819237   4.01453059   5.37576753] 1.0\n",
      "positions (x,y,z), reward: [-15.31618564   4.55193755   3.28007674] 1.0\n",
      "Episode =   29, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0116104    0.01866118  10.02101518] 1.0\n",
      "positions (x,y,z), reward: [ 2.33477578 -0.37352623  8.77215449] 1.0\n",
      "positions (x,y,z), reward: [ 4.21569711 -1.1856886   6.57827238] 1.0\n",
      "positions (x,y,z), reward: [ 4.50231792 -1.34007321  6.07976462] 1.0\n",
      "Episode =   30, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04310302   0.0102165   10.0121572 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.03537721 -0.09839601  9.7143472 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.92254712 -2.08926252  6.60206413] 1.0\n",
      "positions (x,y,z), reward: [ 2.08146018 -2.76986055  5.25343988] 1.0\n",
      "Episode =   31, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.07431913e-02   1.29009022e-03   1.00204354e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.22078195 -0.23017563  9.89118764] 1.0\n",
      "positions (x,y,z), reward: [ 0.67397534 -0.48599724  9.62075084] 1.0\n",
      "positions (x,y,z), reward: [ 1.61660325 -3.08721843  7.54580184] 1.0\n",
      "positions (x,y,z), reward: [-0.03942418 -5.9853308   1.9741802 ] 1.0\n",
      "Episode =   32, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.1994869   0.75007691  0.30755584] 1.0\n",
      "Episode =   33, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04629807  -0.07563298  10.00407167] 1.0\n",
      "positions (x,y,z), reward: [ 0.67673983 -0.49471636  8.88673719] 1.0\n",
      "Episode =   34, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05757788  0.01182442  9.95186989] 1.0\n",
      "positions (x,y,z), reward: [ 0.54404449 -0.28883007  9.53726067] 1.0\n",
      "positions (x,y,z), reward: [ 0.40833676 -0.37173606  9.47813711] 1.0\n",
      "positions (x,y,z), reward: [-2.27755255 -1.64771772  3.36984885] 1.0\n",
      "positions (x,y,z), reward: [-2.52713095 -1.63482536  2.18163645] 1.0\n",
      "Episode =   35, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.97322693 -0.57344551  9.65894627] 1.0\n",
      "Episode =   36, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02046053 -0.01325235  9.94771684] 1.0\n",
      "positions (x,y,z), reward: [ 1.76395782  0.42734363  8.61493841] 1.0\n",
      "Episode =   37, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04892883  0.0288826   9.92633182] 1.0\n",
      "positions (x,y,z), reward: [ 0.64514257 -0.87012285  8.55987518] 1.0\n",
      "positions (x,y,z), reward: [ 0.20826049 -1.17094676  8.05135517] 1.0\n",
      "positions (x,y,z), reward: [-0.36633068 -1.50272345  7.14172252] 1.0\n",
      "positions (x,y,z), reward: [-1.14939911 -1.84336787  5.8673917 ] 1.0\n",
      "positions (x,y,z), reward: [-2.32184171 -2.16278934  3.73418458] 1.0\n",
      "positions (x,y,z), reward: [-2.97896511 -2.31359819  2.40503588] 1.0\n",
      "positions (x,y,z), reward: [-3.08947564 -2.33914753  2.16685209] 1.0\n",
      "Episode =   38, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.01253617 -0.1964923   8.81337783] 1.0\n",
      "positions (x,y,z), reward: [-0.74942769 -0.25596978  7.72717521] 1.0\n",
      "positions (x,y,z), reward: [-1.51702908 -0.28456114  6.85809184] 1.0\n",
      "positions (x,y,z), reward: [-1.74715874 -0.28887126  6.60717526] 1.0\n",
      "positions (x,y,z), reward: [-4.48065217 -0.0256583   2.96142417] 1.0\n",
      "Episode =   39, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.03803869 -0.04293602  9.95992456] 1.0\n",
      "positions (x,y,z), reward: [-1.96513241 -2.58789756  7.62351737] 1.0\n",
      "positions (x,y,z), reward: [-2.08251003 -2.66527712  7.46752163] 1.0\n",
      "positions (x,y,z), reward: [-4.28805721 -4.01952665  4.35903178] 1.0\n",
      "Episode =   40, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.24553445  0.04349968  9.78951421] 1.0\n",
      "Episode =   41, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.2669031   1.03882693  9.11560428] 1.0\n",
      "positions (x,y,z), reward: [-3.22341748  4.48787896  6.97861362] 1.0\n",
      "positions (x,y,z), reward: [-7.04843978  9.51640984  1.85599235] 1.0\n",
      "Episode =   42, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03663423   0.01749245  10.03087739] 1.0\n",
      "positions (x,y,z), reward: [  6.52017712e-03  -1.83982397e-01   9.57044927e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.99433932 -0.86518665  8.61016425] 1.0\n",
      "positions (x,y,z), reward: [-1.3886078  -1.03112052  8.35057589] 1.0\n",
      "positions (x,y,z), reward: [-1.65013286 -1.14800026  8.15720435] 1.0\n",
      "positions (x,y,z), reward: [-4.96765584 -2.05129919  5.11564245] 1.0\n",
      "positions (x,y,z), reward: [-6.50485378 -2.39623868  3.25220305] 1.0\n",
      "Episode =   43, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.01254423 -0.54555131  9.58289788] 1.0\n",
      "positions (x,y,z), reward: [ 0.86489286 -1.0640225   8.648307  ] 1.0\n",
      "positions (x,y,z), reward: [ 1.31125607 -1.23649515  8.14360452] 1.0\n",
      "positions (x,y,z), reward: [ 3.13892418 -1.47348634  4.50967794] 1.0\n",
      "Episode =   44, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11523205 -0.37232908  9.75584369] 1.0\n",
      "positions (x,y,z), reward: [-0.83636986 -2.22095951  5.67738441] 1.0\n",
      "positions (x,y,z), reward: [-1.20222669 -2.59779498  4.667668  ] 1.0\n",
      "positions (x,y,z), reward: [-1.78865611 -3.14931436  3.09700825] 1.0\n",
      "Episode =   45, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.08193597 -1.33375759  8.19781408] 1.0\n",
      "positions (x,y,z), reward: [ 0.80020694 -2.58885304  5.97978193] 1.0\n",
      "Episode =   46, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.18454497e-02  -3.02658825e-03   1.00465100e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.1324254   -0.04024799  10.07364601] 1.0\n",
      "positions (x,y,z), reward: [-0.95809134  0.09738477  8.09350351] 1.0\n",
      "positions (x,y,z), reward: [-2.48242481  0.08337136  4.80509946] 1.0\n",
      "positions (x,y,z), reward: [-3.0042986   0.01412749  3.44563951] 1.0\n",
      "positions (x,y,z), reward: [-3.52412957 -0.07604448  1.90088968] 1.0\n",
      "positions (x,y,z), reward: [-4.10691262 -0.19494251  0.        ] 1.0\n",
      "Episode =   47, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.18611518 -0.86953703  8.54823782] 1.0\n",
      "positions (x,y,z), reward: [-5.92252457 -2.52038555  2.15264017] 1.0\n",
      "Episode =   48, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.21621919 -0.25833067  9.68947205] 1.0\n",
      "positions (x,y,z), reward: [-0.34135264 -0.36127014  9.59566546] 1.0\n",
      "positions (x,y,z), reward: [-4.35033371 -1.6600895   7.62341217] 1.0\n",
      "positions (x,y,z), reward: [-7.71865964 -2.30621068  5.67148647] 1.0\n",
      "positions (x,y,z), reward: [-8.6454227  -2.46906818  5.0129571 ] 1.0\n",
      "positions (x,y,z), reward: [-11.06169148  -2.79408389   3.12782434] 1.0\n",
      "positions (x,y,z), reward: [-12.29909799  -2.93898307   2.05315595] 1.0\n",
      "positions (x,y,z), reward: [-12.78863213  -2.99800045   1.59443793] 1.0\n",
      "Episode =   49, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00472728] 1.0\n",
      "positions (x,y,z), reward: [-2.65397211 -1.20404804  9.89579631] 1.0\n",
      "positions (x,y,z), reward: [-5.84346802 -2.75019487  7.50964986] 1.0\n",
      "Episode =   50, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.15926207  0.13519967  9.93695703] 1.0\n",
      "positions (x,y,z), reward: [-0.1126566   0.28225469  9.71098503] 1.0\n",
      "positions (x,y,z), reward: [ 0.37723956  0.44751423  9.23013524] 1.0\n",
      "positions (x,y,z), reward: [ 3.36051507  0.81881078  7.05185736] 1.0\n",
      "positions (x,y,z), reward: [ 8.27393389  0.39688135  1.4222439 ] 1.0\n",
      "Episode =   51, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.72190523  0.17440257  7.65710241] 1.0\n",
      "positions (x,y,z), reward: [-1.05876299  0.37999941  7.27071887] 1.0\n",
      "positions (x,y,z), reward: [-1.40201654  0.61595879  6.87975761] 1.0\n",
      "positions (x,y,z), reward: [-2.62099822  1.43365826  5.29386358] 1.0\n",
      "positions (x,y,z), reward: [-3.28958488  1.83765463  4.3667885 ] 1.0\n",
      "Episode =   52, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01667571  -0.01886386  10.04099448] 1.0\n",
      "positions (x,y,z), reward: [  3.74225369e+00   5.85907481e-03   8.35199506e+00] 1.0\n",
      "positions (x,y,z), reward: [ 5.73826152 -0.09223004  6.99265311] 1.0\n",
      "positions (x,y,z), reward: [ 8.77735561 -0.33387276  4.41224467] 1.0\n",
      "Episode =   53, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.54600524e-02  -2.16494153e-03   1.00357740e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.92850248  2.75454253  7.39389471] 1.0\n",
      "Episode =   54, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.1250213   0.58148148  8.08227357] 1.0\n",
      "positions (x,y,z), reward: [ 1.72142583  0.47658512  6.48535493] 1.0\n",
      "positions (x,y,z), reward: [ 1.71127349  0.70983991  2.71757211] 1.0\n",
      "positions (x,y,z), reward: [ 1.68995633  0.74108286  2.0828286 ] 1.0\n",
      "Episode =   55, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02527473 -0.0703311   9.76982807] 1.0\n",
      "positions (x,y,z), reward: [ 0.21998103 -0.1275655   9.55671167] 1.0\n",
      "positions (x,y,z), reward: [ 1.19325541 -0.70750989  8.83898169] 1.0\n",
      "positions (x,y,z), reward: [ 1.64663087 -1.5692166   7.76286251] 1.0\n",
      "positions (x,y,z), reward: [ 1.6846824  -1.67738792  7.63899943] 1.0\n",
      "positions (x,y,z), reward: [ 1.78509628 -2.24636545  6.96249   ] 1.0\n",
      "positions (x,y,z), reward: [ 1.78962519 -2.47392853  6.67150533] 1.0\n",
      "positions (x,y,z), reward: [ 1.41788554 -5.34874533  1.70975952] 1.0\n",
      "Episode =   57, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.58906894  0.48600237  7.82588822] 1.0\n",
      "positions (x,y,z), reward: [ 4.31042279  1.22678629  4.5247882 ] 1.0\n",
      "Episode =   58, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.82878701 -0.01135401  8.46304657] 1.0\n",
      "Episode =   59, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04547933  -0.02600952  10.01354026] 1.0\n",
      "positions (x,y,z), reward: [-0.15390881 -0.07620073  9.99843191] 1.0\n",
      "positions (x,y,z), reward: [-2.87093995 -0.19128094  8.70960693] 1.0\n",
      "positions (x,y,z), reward: [-6.65558408  0.84028729  6.70891099] 1.0\n",
      "positions (x,y,z), reward: [-7.28448969  1.07636774  6.32835766] 1.0\n",
      "positions (x,y,z), reward: [-10.64402589   2.14502952   3.67161813] 1.0\n",
      "Episode =   60, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.04626157 -0.20204746  7.96551661] 1.0\n",
      "Episode =   61, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.27056981e-03  -4.26516525e-03   1.00204928e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.03644614  -0.02147178  10.0459221 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.22270199 -0.16959591  9.95129417] 1.0\n",
      "positions (x,y,z), reward: [-0.847621   -0.37785933  8.98050954] 1.0\n",
      "Episode =   62, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.91788600e-02  -3.00390166e-03   1.00229910e+01] 1.0\n",
      "positions (x,y,z), reward: [ -7.53029063e-03  -6.83362936e-02   1.00018711e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.70625681 -0.49984791  8.1882607 ] 1.0\n",
      "positions (x,y,z), reward: [-0.78322276 -0.4951782   8.07872656] 1.0\n",
      "positions (x,y,z), reward: [-4.09870382  0.36219344  1.2378623 ] 1.0\n",
      "Episode =   63, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00560889] 1.0\n",
      "positions (x,y,z), reward: [ -0.13214289   0.04910435  10.10015955] 1.0\n",
      "positions (x,y,z), reward: [-0.49287302 -3.22328898  8.99925048] 1.0\n",
      "positions (x,y,z), reward: [-1.0554706  -4.29251213  8.26944471] 1.0\n",
      "positions (x,y,z), reward: [-2.94016316 -7.71218321  5.55924909] 1.0\n",
      "Episode =   64, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.97816562  0.48486843  8.50063768] 1.0\n",
      "positions (x,y,z), reward: [-0.92950666  0.62884412  7.74766949] 1.0\n",
      "positions (x,y,z), reward: [ 0.58174125  1.24639878  3.39903586] 1.0\n",
      "Episode =   65, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.12081006   0.14460531  10.05110489] 1.0\n",
      "positions (x,y,z), reward: [ -1.98232747   0.75207016  10.68256294] 1.0\n",
      "positions (x,y,z), reward: [-10.62375397   2.66115469   9.20350894] 1.0\n",
      "positions (x,y,z), reward: [-12.08104841   2.91691312   8.74538721] 1.0\n",
      "positions (x,y,z), reward: [-17.73582001   3.91322903   6.25458549] 1.0\n",
      "positions (x,y,z), reward: [-23.28490993   4.71900887   2.84026017] 1.0\n",
      "Episode =   66, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02891009  -0.02350231  10.03986147] 1.0\n",
      "positions (x,y,z), reward: [-0.0401282  -0.0624491   9.98364846] 1.0\n",
      "positions (x,y,z), reward: [ 2.53476777 -4.08638615  4.00538393] 1.0\n",
      "positions (x,y,z), reward: [ 3.12682534 -5.25811857  1.625391  ] 1.0\n",
      "positions (x,y,z), reward: [ 3.45896953 -5.94979926  0.12180208] 1.0\n",
      "Episode =   67, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.26563531e-03  -2.89260261e-03   1.00096682e+01] 1.0\n",
      "positions (x,y,z), reward: [-1.97958033 -2.01926551  8.50887055] 1.0\n",
      "positions (x,y,z), reward: [-7.12038803 -5.40622176  2.3671737 ] 1.0\n",
      "positions (x,y,z), reward: [-7.28901126 -5.49938725  2.11227114] 1.0\n",
      "Episode =   68, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.45011864   0.52878975  10.26087848] 1.0\n",
      "positions (x,y,z), reward: [  0.45094314   0.55020385  10.29632554] 1.0\n",
      "positions (x,y,z), reward: [ -0.13889577   0.86612154  10.53684672] 1.0\n",
      "positions (x,y,z), reward: [ -0.23336336   0.93601189  10.57617493] 1.0\n",
      "positions (x,y,z), reward: [-3.13612166  3.48350944  9.61507017] 1.0\n",
      "positions (x,y,z), reward: [-4.20301897  4.09168232  8.88532224] 1.0\n",
      "positions (x,y,z), reward: [-5.80736757  5.1414613   7.51108353] 1.0\n",
      "positions (x,y,z), reward: [-7.36056453  6.23825237  6.12298332] 1.0\n",
      "positions (x,y,z), reward: [-10.13225429   8.12644969   3.60350628] 1.0\n",
      "Episode =   69, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.08693529  -0.06922171  10.04788693] 1.0\n",
      "positions (x,y,z), reward: [ -0.6761243   -0.82956945  10.65074211] 1.0\n",
      "positions (x,y,z), reward: [-5.52554787 -2.35254985  8.16821353] 1.0\n",
      "positions (x,y,z), reward: [-6.15342488 -2.74512614  7.50681027] 1.0\n",
      "positions (x,y,z), reward: [-6.30271271 -2.84794444  7.33514425] 1.0\n",
      "positions (x,y,z), reward: [-8.85272243 -4.90546625  3.20904671] 1.0\n",
      "positions (x,y,z), reward: [-10.42482199  -6.21478404   0.01140962] 1.0\n",
      "Episode =   70, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.73196942e-02   3.73205733e-03   9.93148279e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.69835276 -0.10236226  9.37940984] 1.0\n",
      "positions (x,y,z), reward: [ 0.75962896 -1.60391609  7.64256146] 1.0\n",
      "positions (x,y,z), reward: [-1.08293388 -3.82422609  3.1726578 ] 1.0\n",
      "positions (x,y,z), reward: [-1.6983609  -4.50076148  1.34730446] 1.0\n",
      "Episode =   71, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08429896  0.0640865   9.91557256] 1.0\n",
      "positions (x,y,z), reward: [ 5.0344563   0.18482541  6.08335728] 1.0\n",
      "positions (x,y,z), reward: [ 5.22480471  0.19909074  5.9061336 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.41336881  0.28555926  4.77577309] 1.0\n",
      "positions (x,y,z), reward: [ 7.62448768  0.36084286  3.52295142] 1.0\n",
      "Episode =   72, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.83534633 -0.43543918  8.88997205] 1.0\n",
      "positions (x,y,z), reward: [ 0.98639942 -0.58664457  8.70834366] 1.0\n",
      "positions (x,y,z), reward: [ 1.05218964 -0.6690549   8.60365742] 1.0\n",
      "positions (x,y,z), reward: [ 1.59998592 -3.15055789  3.70739894] 1.0\n",
      "positions (x,y,z), reward: [ 1.59649234 -3.39834887  3.00736486] 1.0\n",
      "positions (x,y,z), reward: [ 1.56825922 -3.86917361  1.53905068] 1.0\n",
      "Episode =   73, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.45834596e-02   3.27997598e-03   1.00537847e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.24364321 -0.42262565  9.67842226] 1.0\n",
      "positions (x,y,z), reward: [ 0.68730931 -0.76008689  9.36078846] 1.0\n",
      "positions (x,y,z), reward: [ 1.93222387 -1.51264893  8.33160099] 1.0\n",
      "positions (x,y,z), reward: [ 5.606851   -2.44472309  4.45745397] 1.0\n",
      "positions (x,y,z), reward: [ 5.76347678 -2.47426628  4.27007753] 1.0\n",
      "Episode =   74, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15629633  0.06023891  9.73402921] 1.0\n",
      "positions (x,y,z), reward: [ 1.0127269  -0.62181907  8.74615169] 1.0\n",
      "positions (x,y,z), reward: [-0.48713016 -2.19464797  5.48400466] 1.0\n",
      "Episode =   75, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0780751  -0.01145908  9.96409937] 1.0\n",
      "positions (x,y,z), reward: [ 0.14388584 -0.47329129  9.99684757] 1.0\n",
      "positions (x,y,z), reward: [-6.2762607  -3.80840461  5.47801969] 1.0\n",
      "Episode =   76, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.80909675  0.65214021  5.29659558] 1.0\n",
      "positions (x,y,z), reward: [ 0.89969851  0.55596204  4.72274954] 1.0\n",
      "positions (x,y,z), reward: [ 1.20842178  0.13793628  2.26937634] 1.0\n",
      "positions (x,y,z), reward: [ 1.43064413 -0.19698021  0.2001426 ] 1.0\n",
      "Episode =   77, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.87437094e-03  -1.43997194e-02   1.00217338e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.16411148 -0.75036801  7.64708128] 1.0\n",
      "Episode =   78, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02481407 -0.01729351  9.91209228] 1.0\n",
      "positions (x,y,z), reward: [ 1.12766266 -0.27585812  8.45726997] 1.0\n",
      "positions (x,y,z), reward: [ 1.36859066 -0.61203348  7.69096608] 1.0\n",
      "positions (x,y,z), reward: [ 1.3911495  -0.71218862  7.44996011] 1.0\n",
      "positions (x,y,z), reward: [ 1.40257526 -1.03834541  6.6202674 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.27910632 -1.6408256   3.75615037] 1.0\n",
      "positions (x,y,z), reward: [ 1.1941918  -1.84625378  1.88716386] 1.0\n",
      "Episode =   79, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.49887856e-03   3.25752771e-03   1.00185080e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.0444406   0.0232064  10.0277861] 1.0\n",
      "positions (x,y,z), reward: [  2.79671335e-03   2.79767598e-02   1.00035233e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.35990347  0.01196304  9.90490794] 1.0\n",
      "positions (x,y,z), reward: [ 1.69455581 -0.12788851  8.92816351] 1.0\n",
      "positions (x,y,z), reward: [ 3.39293317  0.15858513  7.80449204] 1.0\n",
      "Episode =   80, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-4.09506047 -0.79361226  4.78206166] 1.0\n",
      "positions (x,y,z), reward: [-6.60582052 -0.39344934  1.07180687] 1.0\n",
      "positions (x,y,z), reward: [-7.40798457 -0.23075355  0.        ] 1.0\n",
      "Episode =   81, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.         0.        10.004648] 1.0\n",
      "positions (x,y,z), reward: [ -0.05211341  -0.03065376  10.01318902] 1.0\n",
      "positions (x,y,z), reward: [ 0.12313175 -0.25418146  9.62939739] 1.0\n",
      "positions (x,y,z), reward: [ 0.87917461 -0.53826041  8.99764694] 1.0\n",
      "positions (x,y,z), reward: [ 2.70745585 -2.36406004  3.57563679] 1.0\n",
      "Episode =   82, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06031303 -0.03654719  9.98442836] 1.0\n",
      "positions (x,y,z), reward: [ 0.23577384 -3.10106201  2.96478082] 1.0\n",
      "positions (x,y,z), reward: [ 0.1999225  -3.16902542  2.71658164] 1.0\n",
      "Episode =   83, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10775479 -0.02910804  9.97001359] 1.0\n",
      "positions (x,y,z), reward: [-0.20150917  0.01672057  9.90505997] 1.0\n",
      "positions (x,y,z), reward: [-0.25868777  0.07310867  9.87390366] 1.0\n",
      "positions (x,y,z), reward: [-1.22342191  0.3563724   9.69937054] 1.0\n",
      "positions (x,y,z), reward: [-1.62406949  0.57068205  9.64257997] 1.0\n",
      "positions (x,y,z), reward: [-2.94800862  1.15850567  9.35844357] 1.0\n",
      "positions (x,y,z), reward: [-4.90369891  2.08772197  9.05188172] 1.0\n",
      "positions (x,y,z), reward: [-5.26949405  2.23719801  8.98231873] 1.0\n",
      "positions (x,y,z), reward: [-14.73391348   6.02481033   0.16697261] 1.0\n",
      "Episode =   84, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00543442] 1.0\n",
      "positions (x,y,z), reward: [ 0.09259647  0.02973906  9.9960537 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.85581833 -0.71299399  8.8237573 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.31679408 -1.11599317  7.85010236] 1.0\n",
      "positions (x,y,z), reward: [ 2.35958533 -1.16807216  7.69463538] 1.0\n",
      "Episode =   85, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10456095 -0.03492534  9.94362508] 1.0\n",
      "positions (x,y,z), reward: [-0.1388777  -0.15073155  9.77478548] 1.0\n",
      "Episode =   86, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06769313  -0.05090198  10.02302123] 1.0\n",
      "positions (x,y,z), reward: [ 0.72468955 -1.73345234  9.49284231] 1.0\n",
      "positions (x,y,z), reward: [ 1.59842859 -3.13903287  8.41237787] 1.0\n",
      "positions (x,y,z), reward: [ 1.96748526 -4.01979518  7.71277933] 1.0\n",
      "Episode =   87, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.27412757  0.03534605  9.79574352] 1.0\n",
      "positions (x,y,z), reward: [ 1.13353077  0.05189442  8.83056519] 1.0\n",
      "positions (x,y,z), reward: [ 1.54504623  0.12488489  8.32148172] 1.0\n",
      "positions (x,y,z), reward: [ 2.14102885  0.17649616  7.11318855] 1.0\n",
      "positions (x,y,z), reward: [ 2.31331575  0.18426475  6.70544281] 1.0\n",
      "positions (x,y,z), reward: [ 2.40320021  0.18683109  6.49565685] 1.0\n",
      "positions (x,y,z), reward: [ 2.92368511  0.18551815  5.4078914 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.58039979  0.18308416  4.01603732] 1.0\n",
      "positions (x,y,z), reward: [ 5.17624667  0.22551753  0.24752489] 1.0\n",
      "Episode =   88, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00579936] 1.0\n",
      "positions (x,y,z), reward: [-0.22647748  0.21499942  9.68543576] 1.0\n",
      "positions (x,y,z), reward: [-0.33812758  0.36537436  9.63233552] 1.0\n",
      "positions (x,y,z), reward: [-2.21866387  1.61443165  9.15399167] 1.0\n",
      "positions (x,y,z), reward: [-4.45159993  2.97288842  8.68810837] 1.0\n",
      "positions (x,y,z), reward: [-11.39263164   7.5897671    2.45714585] 1.0\n",
      "positions (x,y,z), reward: [-12.37018373   8.11396754   0.96993396] 1.0\n",
      "Episode =   89, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.01206345  0.02767651  9.33069752] 1.0\n",
      "positions (x,y,z), reward: [ 6.23424066 -0.71636672  5.35716899] 1.0\n",
      "positions (x,y,z), reward: [ 11.30488459  -1.80495776   0.        ] 1.0\n",
      "Episode =   90, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 8.39686961 -2.30920564  3.0742919 ] 1.0\n",
      "Episode =   91, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.08095823  -0.03467256  10.02804615] 1.0\n",
      "positions (x,y,z), reward: [ -0.20807075   0.04289202  10.02300421] 1.0\n",
      "positions (x,y,z), reward: [ -0.20677255   0.06649782  10.02874686] 1.0\n",
      "positions (x,y,z), reward: [-9.00140865  0.51423413  8.06987761] 1.0\n",
      "positions (x,y,z), reward: [-10.37234714   0.52835999   7.2565803 ] 1.0\n",
      "positions (x,y,z), reward: [-13.64167923   0.58728511   4.94334844] 1.0\n",
      "Episode =   92, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.09879043   1.382067    10.5048477 ] 1.0\n",
      "positions (x,y,z), reward: [ -3.83234212   1.7576313   10.44780052] 1.0\n",
      "positions (x,y,z), reward: [-11.25416105   3.99506317   8.04021949] 1.0\n",
      "positions (x,y,z), reward: [-14.10182323   4.74465363   6.10112496] 1.0\n",
      "positions (x,y,z), reward: [-14.5339435    4.83930329   5.69947914] 1.0\n",
      "positions (x,y,z), reward: [-18.7740585    5.69056782   0.72995635] 1.0\n",
      "Episode =   93, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.98527074 -1.27456066  8.82906642] 1.0\n",
      "positions (x,y,z), reward: [ 0.9984337  -1.37945468  8.72353734] 1.0\n",
      "positions (x,y,z), reward: [ 0.78275863 -2.4065667   7.44293363] 1.0\n",
      "positions (x,y,z), reward: [ 0.38570477 -3.04617836  6.18402183] 1.0\n",
      "Episode =   94, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.77011229 -0.18800738  9.6589615 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.03140538 -0.28551509  9.61760976] 1.0\n",
      "positions (x,y,z), reward: [ 1.1550121  -0.53652363  9.44226781] 1.0\n",
      "positions (x,y,z), reward: [ 0.7418671  -0.96185694  9.13094233] 1.0\n",
      "positions (x,y,z), reward: [-2.27534126 -2.35040514  6.81960817] 1.0\n",
      "Episode =   95, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.45398578e-02   8.96587320e-03   1.00016236e+01] 1.0\n",
      "positions (x,y,z), reward: [ 2.8216364  -2.5037794   5.97010547] 1.0\n",
      "Episode =   96, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.20582442 -1.07110188  9.22767644] 1.0\n",
      "positions (x,y,z), reward: [-1.32337428 -1.16868538  9.13707724] 1.0\n",
      "positions (x,y,z), reward: [-1.44605935 -1.26359882  9.04333497] 1.0\n",
      "positions (x,y,z), reward: [-2.88883216 -2.1868625   7.8412377 ] 1.0\n",
      "positions (x,y,z), reward: [-3.50767267 -2.50939358  7.19800834] 1.0\n",
      "positions (x,y,z), reward: [-6.14419893 -3.89323522  4.08770864] 1.0\n",
      "Episode =   97, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06569469  0.04963384  9.89067841] 1.0\n",
      "positions (x,y,z), reward: [-0.99144872  0.42219958  9.37722919] 1.0\n",
      "positions (x,y,z), reward: [-1.83322145  0.59242288  9.14851522] 1.0\n",
      "positions (x,y,z), reward: [-10.3951469    3.44860883   4.7601685 ] 1.0\n",
      "Episode =   98, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13749754 -0.23456862  9.91547764] 1.0\n",
      "positions (x,y,z), reward: [ 0.26790907 -0.27040644  9.84966518] 1.0\n",
      "positions (x,y,z), reward: [ 2.95442145  0.24965827  7.34202551] 1.0\n",
      "positions (x,y,z), reward: [ 4.15434526  0.44310129  6.00245063] 1.0\n",
      "positions (x,y,z), reward: [ 4.89769058  0.54030804  5.1799859 ] 1.0\n",
      "Episode =   99, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.71587771  0.24469741  9.86835587] 1.0\n",
      "positions (x,y,z), reward: [-1.03217194  0.35677763  9.82968894] 1.0\n",
      "positions (x,y,z), reward: [-1.6697636   0.68103031  9.60353706] 1.0\n",
      "positions (x,y,z), reward: [-3.20119588  2.2803715   8.70678097] 1.0\n",
      "positions (x,y,z), reward: [-4.40262258  3.29738719  8.0524828 ] 1.0\n",
      "positions (x,y,z), reward: [-11.23704526   7.66629264   3.62153773] 1.0\n",
      "positions (x,y,z), reward: [-11.75037354   7.95778408   3.20571769] 1.0\n",
      "Episode =  100, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.24693375 -4.4789606   1.43675418] 1.0\n",
      "Episode =  101, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.41632374 -0.02507163  9.43741891] 1.0\n",
      "positions (x,y,z), reward: [ 0.10545892  0.95116719  7.76261164] 1.0\n",
      "positions (x,y,z), reward: [-0.99947157  2.4069563   5.3673239 ] 1.0\n",
      "positions (x,y,z), reward: [-1.35278562  2.82792056  4.66407383] 1.0\n",
      "positions (x,y,z), reward: [-1.72700664  3.25594179  3.92520787] 1.0\n",
      "Episode =  102, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.76119544 -0.4265031   9.52713957] 1.0\n",
      "positions (x,y,z), reward: [ 1.20263315 -0.84830665  9.28627714] 1.0\n",
      "positions (x,y,z), reward: [ 1.62520071 -3.27100789  7.21977972] 1.0\n",
      "Episode =  103, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.78178000e-03   1.53417974e-03   1.00102733e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.25367542  0.19094999  9.65708962] 1.0\n",
      "positions (x,y,z), reward: [-1.95931833 -1.32788014  6.88823481] 1.0\n",
      "positions (x,y,z), reward: [-3.58694031 -2.32920078  3.39088394] 1.0\n",
      "positions (x,y,z), reward: [-3.77408244 -2.43406023  2.95108915] 1.0\n",
      "Episode =  104, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 4.56281952  1.02250033  7.28342495] 1.0\n",
      "positions (x,y,z), reward: [ 8.5793661   1.97085603  3.88638628] 1.0\n",
      "Episode =  105, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.12873609 -0.10227965  9.5667584 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.31104498  1.57314423  5.79931706] 1.0\n",
      "positions (x,y,z), reward: [ 0.06354102  2.0700629   4.64231089] 1.0\n",
      "positions (x,y,z), reward: [ 0.02068767  2.1536353   4.432952  ] 1.0\n",
      "positions (x,y,z), reward: [-0.29724251  2.87478384  2.69541192] 1.0\n",
      "Episode =  106, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06662635  -0.1160049   10.05523974] 1.0\n",
      "positions (x,y,z), reward: [ 0.18127304 -1.10457413  9.99207272] 1.0\n",
      "positions (x,y,z), reward: [-3.00646175 -6.71702895  5.62609998] 1.0\n",
      "positions (x,y,z), reward: [-3.10497124 -6.85982592  5.45170487] 1.0\n",
      "positions (x,y,z), reward: [-3.50857795 -7.42787427  4.71982362] 1.0\n",
      "positions (x,y,z), reward: [-3.92505145 -8.00309449  3.91905366] 1.0\n",
      "positions (x,y,z), reward: [ -5.28455127 -10.24422879   0.19046699] 1.0\n",
      "Episode =  107, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.69746835  0.95658749  9.08826623] 1.0\n",
      "positions (x,y,z), reward: [-4.84683564  2.00314226  7.60557112] 1.0\n",
      "positions (x,y,z), reward: [-10.99125527   4.61037062   2.76615121] 1.0\n",
      "Episode =  108, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.10447781e-03   2.93319417e-02   1.00030197e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.10471397  0.62562609  9.32229686] 1.0\n",
      "positions (x,y,z), reward: [ 2.20031135  0.89855884  8.59868036] 1.0\n",
      "Episode =  109, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02581491 -0.14967284  9.9855995 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.12203848 -0.66635863  9.40579381] 1.0\n",
      "positions (x,y,z), reward: [ 0.82659129 -1.23420175  7.43553054] 1.0\n",
      "positions (x,y,z), reward: [ 1.21080734 -1.58476128  4.01647587] 1.0\n",
      "positions (x,y,z), reward: [ 1.614951   -1.69962193  0.72314982] 1.0\n",
      "Episode =  110, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.51395668  0.06864053  9.66482004] 1.0\n",
      "positions (x,y,z), reward: [ 3.53162285  1.25629014  1.98692563] 1.0\n",
      "positions (x,y,z), reward: [ 3.79103385  1.31862318  1.16374021] 1.0\n",
      "Episode =  111, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02980793  0.01905184  9.99285025] 1.0\n",
      "positions (x,y,z), reward: [ 3.76046112 -2.05287567  5.59814847] 1.0\n",
      "positions (x,y,z), reward: [ 4.55414657 -4.1683067   1.37465303] 1.0\n",
      "positions (x,y,z), reward: [ 4.58785849 -4.2866034   1.10743677] 1.0\n",
      "Episode =  113, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05577343  -0.0405336   10.03800031] 1.0\n",
      "positions (x,y,z), reward: [ 1.08884891 -0.57244854  9.50013865] 1.0\n",
      "positions (x,y,z), reward: [ 1.80279437 -1.07509934  8.79916002] 1.0\n",
      "positions (x,y,z), reward: [ 4.96662711 -2.6908843   5.3526704 ] 1.0\n",
      "Episode =  114, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11843919  0.06432349  9.91169866] 1.0\n",
      "positions (x,y,z), reward: [-0.74247321  0.49351657  9.97571097] 1.0\n",
      "positions (x,y,z), reward: [-3.56903218  2.18856536  9.13970118] 1.0\n",
      "positions (x,y,z), reward: [-3.75344391  2.29344297  9.05251962] 1.0\n",
      "positions (x,y,z), reward: [-7.1766916   3.52374338  7.55016672] 1.0\n",
      "positions (x,y,z), reward: [-7.76361207  3.70683814  7.22935087] 1.0\n",
      "positions (x,y,z), reward: [-11.96169178   4.85787832   3.99067625] 1.0\n",
      "positions (x,y,z), reward: [-13.41223883   5.21511178   2.24600686] 1.0\n",
      "Episode =  115, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.86123642  1.21814696  8.51832762] 1.0\n",
      "positions (x,y,z), reward: [ 7.97233479  1.86907441  4.10008344] 1.0\n",
      "Episode =  116, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  1.79858614e-01   5.21018381e-03   9.91918040e+00] 1.0\n",
      "positions (x,y,z), reward: [ 2.29607762 -1.41346709  7.7158442 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.39978465 -1.63728277  7.24874948] 1.0\n",
      "positions (x,y,z), reward: [ 2.57274141 -2.41281729  4.9501781 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.58076318 -2.8182461   3.35000225] 1.0\n",
      "positions (x,y,z), reward: [ 2.58151171 -3.03495158  2.36896021] 1.0\n",
      "Episode =  117, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.12552112  0.02323325  9.99213829] 1.0\n",
      "positions (x,y,z), reward: [-3.43036479 -1.21696001  7.31904019] 1.0\n",
      "positions (x,y,z), reward: [-6.80567167 -2.78781511  2.30506184] 1.0\n",
      "Episode =  118, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.14523988 -0.11575458  9.55937699] 1.0\n",
      "positions (x,y,z), reward: [ 0.60040682  0.47976059  7.51210952] 1.0\n",
      "positions (x,y,z), reward: [ 0.35284947  0.85652345  6.51798727] 1.0\n",
      "positions (x,y,z), reward: [-0.02613426  2.17934879  3.0022007 ] 1.0\n",
      "positions (x,y,z), reward: [-0.2948112   2.78920711  1.11414359] 1.0\n",
      "Episode =  119, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.13626556   0.02925861  10.07662659] 1.0\n",
      "positions (x,y,z), reward: [-3.88299374 -1.06633615  6.76090221] 1.0\n",
      "Episode =  120, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07562518  -0.01674181  10.05821092] 1.0\n",
      "positions (x,y,z), reward: [ -1.62646505  -0.66430533  10.02348879] 1.0\n",
      "positions (x,y,z), reward: [-5.15308741 -0.79259364  8.99097802] 1.0\n",
      "positions (x,y,z), reward: [-6.25782148 -0.9264133   8.40850878] 1.0\n",
      "positions (x,y,z), reward: [-6.8914968  -1.00549058  8.01938736] 1.0\n",
      "positions (x,y,z), reward: [-7.52223489 -1.08210469  7.59532587] 1.0\n",
      "positions (x,y,z), reward: [-8.34566772 -1.14984962  6.99353152] 1.0\n",
      "positions (x,y,z), reward: [-11.30890462  -1.44619421   4.36166601] 1.0\n",
      "positions (x,y,z), reward: [-13.9821602   -1.80427053   1.33713331] 1.0\n",
      "Episode =  121, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.47237957  0.21012987  9.93556267] 1.0\n",
      "positions (x,y,z), reward: [-0.89711491  0.46084479  9.28080725] 1.0\n",
      "positions (x,y,z), reward: [-1.95855245  0.56207723  7.84557781] 1.0\n",
      "positions (x,y,z), reward: [-5.47717074  1.45358631  2.63290323] 1.0\n",
      "positions (x,y,z), reward: [-6.30994864  1.64825381  0.93867554] 1.0\n",
      "positions (x,y,z), reward: [-6.78613104  1.75870227  0.        ] 1.0\n",
      "Episode =  122, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02506766 -0.12393524  9.83819143] 1.0\n",
      "positions (x,y,z), reward: [ 0.15570405 -0.1759033   9.68511927] 1.0\n",
      "positions (x,y,z), reward: [ 3.28112978 -3.06847254  3.0805041 ] 1.0\n",
      "Episode =  123, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-11.8878466    7.82769148   3.64115035] 1.0\n",
      "Episode =  124, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.418138     0.21701263  10.04855889] 1.0\n",
      "positions (x,y,z), reward: [-13.05319941   2.30105996   6.02297318] 1.0\n",
      "Episode =  125, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.09116918  0.379734    9.55228191] 1.0\n",
      "positions (x,y,z), reward: [-3.1119165   0.80421793  9.23060521] 1.0\n",
      "positions (x,y,z), reward: [-10.33526682   2.65170449   5.179475  ] 1.0\n",
      "Episode =  126, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 4.42193499 -2.68193359  4.74783115] 1.0\n",
      "positions (x,y,z), reward: [ 5.56463815 -4.13440968  0.70739557] 1.0\n",
      "Episode =  127, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06218146  -0.05074529  10.01540854] 1.0\n",
      "positions (x,y,z), reward: [ 1.16436202 -1.9856939   6.74540558] 1.0\n",
      "Episode =  128, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.31306611  0.80275278  8.98028016] 1.0\n",
      "positions (x,y,z), reward: [ 8.81289551  2.94842136  2.01895382] 1.0\n",
      "Episode =  129, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.17204956  0.58738353  8.75391946] 1.0\n",
      "positions (x,y,z), reward: [ 6.06327743  1.86515755  0.95599912] 1.0\n",
      "Episode =  130, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05610918  0.04659871  9.99015161] 1.0\n",
      "positions (x,y,z), reward: [ 0.73336898  0.0847497   8.74102033] 1.0\n",
      "positions (x,y,z), reward: [ 0.9988099  -0.32468538  7.6943928 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.36891928 -1.15242344  4.73214305] 1.0\n",
      "positions (x,y,z), reward: [ 1.6726656  -2.31775893  0.        ] 1.0\n",
      "Episode =  131, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.49796089  -2.18856697  10.17377645] 1.0\n",
      "positions (x,y,z), reward: [-5.87983251 -5.26622031  6.77853251] 1.0\n",
      "positions (x,y,z), reward: [-10.1773058   -7.19547279   1.77709915] 1.0\n",
      "Episode =  132, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.11254578e-03  -2.83421962e-03   1.00182133e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.07723985 -0.05360454  9.98377677] 1.0\n",
      "positions (x,y,z), reward: [ 1.59000179  0.25236137  6.85803779] 1.0\n",
      "positions (x,y,z), reward: [ 2.71479791  0.33239127  2.60038187] 1.0\n",
      "positions (x,y,z), reward: [ 3.38241409  0.35002486  0.3771894 ] 1.0\n",
      "Episode =  133, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.08527743  0.06279797  9.84346519] 1.0\n",
      "positions (x,y,z), reward: [ 0.34063657  0.72692058  6.04225331] 1.0\n",
      "Episode =  134, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.49156232 -0.19436965  8.59807534] 1.0\n",
      "positions (x,y,z), reward: [ 6.15519873 -0.71395097  4.28327751] 1.0\n",
      "positions (x,y,z), reward: [ 7.76090899 -0.79484158  1.90010592] 1.0\n",
      "Episode =  135, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.21026661 -1.47919181  7.54644756] 1.0\n",
      "positions (x,y,z), reward: [ 6.41532883 -2.75592865  2.86460262] 1.0\n",
      "positions (x,y,z), reward: [ 7.85706757 -3.33336148  0.        ] 1.0\n",
      "Episode =  136, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.41831910e-03  -3.28617799e-03   1.00102117e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.48592411 -0.10764993  7.89216836] 1.0\n",
      "positions (x,y,z), reward: [-1.05918114  0.42627879  6.06615011] 1.0\n",
      "positions (x,y,z), reward: [-1.74211343  1.05148457  4.38651127] 1.0\n",
      "positions (x,y,z), reward: [-2.62734072  1.76472177  2.19350715] 1.0\n",
      "Episode =  137, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0701816   -0.10545974  10.02283259] 1.0\n",
      "positions (x,y,z), reward: [ 0.4621157  -0.27901325  9.73584913] 1.0\n",
      "positions (x,y,z), reward: [-0.02933883 -0.87043044  9.29341615] 1.0\n",
      "positions (x,y,z), reward: [-3.536235    0.01365446  5.03751656] 1.0\n",
      "positions (x,y,z), reward: [-4.7072417   0.34196617  3.07254892] 1.0\n",
      "positions (x,y,z), reward: [-5.10109208  0.47637795  2.37653354] 1.0\n",
      "positions (x,y,z), reward: [-5.76171233  0.7224848   1.17070712] 1.0\n",
      "Episode =  138, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.1020444   0.51894682  7.86277817] 1.0\n",
      "positions (x,y,z), reward: [ 4.39408818  0.88672689  6.85888274] 1.0\n",
      "positions (x,y,z), reward: [ 8.24489426  1.52546743  2.69841483] 1.0\n",
      "Episode =  139, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-4.48503077 -1.28804769  5.4452387 ] 1.0\n",
      "positions (x,y,z), reward: [-6.09302056 -1.82596894  3.39561378] 1.0\n",
      "positions (x,y,z), reward: [-7.88019235 -2.37840179  0.69392058] 1.0\n",
      "Episode =  140, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.43004445 -0.02078418  9.68562771] 1.0\n",
      "positions (x,y,z), reward: [-0.49737285 -0.09803071  9.69046081] 1.0\n",
      "positions (x,y,z), reward: [-4.76703412 -0.41831596  9.35643657] 1.0\n",
      "Episode =  141, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15772391 -0.0808964   9.35024269] 1.0\n",
      "positions (x,y,z), reward: [-0.41989221  0.26235142  8.18492338] 1.0\n",
      "positions (x,y,z), reward: [-1.98932205  1.26603171  6.52046805] 1.0\n",
      "Episode =  142, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00576914] 1.0\n",
      "positions (x,y,z), reward: [ 1.01839724 -0.10930562  9.41873769] 1.0\n",
      "positions (x,y,z), reward: [ 3.07238155 -0.28157648  8.56696707] 1.0\n",
      "positions (x,y,z), reward: [ 4.15482922 -0.29739333  8.01060337] 1.0\n",
      "positions (x,y,z), reward: [ 4.93279687 -0.30240287  7.62074703] 1.0\n",
      "positions (x,y,z), reward: [ 7.80436625 -0.05814847  6.09014176] 1.0\n",
      "positions (x,y,z), reward: [ 13.57171943   1.40343436   0.23925483] 1.0\n",
      "Episode =  143, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05530247  -0.04748916  10.03061303] 1.0\n",
      "positions (x,y,z), reward: [-0.02895178 -0.15459153  9.91279056] 1.0\n",
      "positions (x,y,z), reward: [-0.91927799  1.16665467  8.17805409] 1.0\n",
      "positions (x,y,z), reward: [-4.06366483  3.58045164  5.38044622] 1.0\n",
      "positions (x,y,z), reward: [-5.93741496  4.88812866  3.15801059] 1.0\n",
      "Episode =  144, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 4.07115922 -3.14445321  4.70550777] 1.0\n",
      "Episode =  145, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.15850270e-02   3.55920239e-03   1.00203789e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.03713554 -0.03779523  9.88073741] 1.0\n",
      "positions (x,y,z), reward: [ 0.76508348  0.01357799  9.24373055] 1.0\n",
      "positions (x,y,z), reward: [ 1.03125877  0.09655887  9.01003999] 1.0\n",
      "positions (x,y,z), reward: [ 1.58929632  0.31954108  8.37452156] 1.0\n",
      "positions (x,y,z), reward: [ 1.67011918  0.39782703  8.18623904] 1.0\n",
      "positions (x,y,z), reward: [ 1.82360773  0.61477436  7.82235353] 1.0\n",
      "Episode =  146, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.18737115  0.22717692  9.1838255 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.69015595  1.36553369  7.23895373] 1.0\n",
      "positions (x,y,z), reward: [ 5.34990532  1.9987807   5.68802802] 1.0\n",
      "positions (x,y,z), reward: [ 6.41568904  2.29105918  4.48969799] 1.0\n",
      "Episode =  147, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.28896248e-02   7.47211927e-03   1.00673798e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.54044317  0.47598738  7.85341382] 1.0\n",
      "positions (x,y,z), reward: [ 4.26791628  0.75361484  4.00178144] 1.0\n",
      "positions (x,y,z), reward: [ 4.76712089  0.79725116  3.26310065] 1.0\n",
      "Episode =  148, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.1215567  -1.39441021  8.17787516] 1.0\n",
      "positions (x,y,z), reward: [ 5.75162347 -4.5785929   2.31735179] 1.0\n",
      "Episode =  149, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11336656  0.06505859  9.98595362] 1.0\n",
      "positions (x,y,z), reward: [-0.30608439  0.03270917  9.8292228 ] 1.0\n",
      "positions (x,y,z), reward: [-1.2539135   0.74040517  7.94092819] 1.0\n",
      "positions (x,y,z), reward: [-1.44685598  0.84079551  7.43974964] 1.0\n",
      "positions (x,y,z), reward: [-1.73739965  0.97837162  6.70494229] 1.0\n",
      "Episode =  150, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.29963105e-02   4.18509395e-03   1.00184693e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.05019183   0.02550909  10.02989495] 1.0\n",
      "positions (x,y,z), reward: [ -7.49631931e-03   9.91494598e-03   9.96475429e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.15000734 -0.03324819  9.80131861] 1.0\n",
      "positions (x,y,z), reward: [ 0.96226397 -4.80547709  1.90236767] 1.0\n",
      "Episode =  151, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.10097913  0.61101543  9.26001854] 1.0\n",
      "positions (x,y,z), reward: [ 0.1099297   0.66491616  9.21541737] 1.0\n",
      "positions (x,y,z), reward: [ 0.10981967  0.76830744  9.12455883] 1.0\n",
      "positions (x,y,z), reward: [-0.45940873  1.77580048  8.20171898] 1.0\n",
      "positions (x,y,z), reward: [-1.84491666  3.13493807  6.51241372] 1.0\n",
      "positions (x,y,z), reward: [-2.28057165  3.43732481  5.99456073] 1.0\n",
      "positions (x,y,z), reward: [-6.43689764  5.79702667  0.32457835] 1.0\n",
      "Episode =  152, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.07726060e-03   3.85348441e-01   8.81781416e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.73962531  1.1865034   7.12596586] 1.0\n",
      "positions (x,y,z), reward: [-1.70932103  2.00981531  5.48954018] 1.0\n",
      "positions (x,y,z), reward: [-3.30431438  3.13116322  2.93053067] 1.0\n",
      "positions (x,y,z), reward: [-4.73881844  4.11751726  0.34246556] 1.0\n",
      "Episode =  153, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.85543927  -0.98111883  10.65329462] 1.0\n",
      "positions (x,y,z), reward: [ -5.44622151  -1.64228443  10.47131465] 1.0\n",
      "positions (x,y,z), reward: [ -6.18510069  -1.77635997  10.34876068] 1.0\n",
      "positions (x,y,z), reward: [-8.13282288 -2.09691906  9.94566089] 1.0\n",
      "positions (x,y,z), reward: [-10.51193136  -2.57616028   9.11567566] 1.0\n",
      "positions (x,y,z), reward: [-11.39131892  -2.74921807   8.75205944] 1.0\n",
      "positions (x,y,z), reward: [-18.9852812   -4.1449338    3.88184115] 1.0\n",
      "positions (x,y,z), reward: [-20.77911181  -4.41418392   2.25219223] 1.0\n",
      "Episode =  154, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.16561683 -0.08051631  9.72935707] 1.0\n",
      "positions (x,y,z), reward: [ 1.2975555  -1.14472152  8.53883311] 1.0\n",
      "positions (x,y,z), reward: [ 4.3247838  -3.66196571  4.78053319] 1.0\n",
      "Episode =  155, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05661706  -0.06817227  10.05279756] 1.0\n",
      "positions (x,y,z), reward: [ -0.02046456  -0.14981106  10.06468273] 1.0\n",
      "positions (x,y,z), reward: [ -0.02651376  -0.16037413  10.05074709] 1.0\n",
      "positions (x,y,z), reward: [-2.46154949 -0.01238795  7.29846805] 1.0\n",
      "positions (x,y,z), reward: [-5.72686406 -0.3545605   1.36257191] 1.0\n",
      "Episode =  156, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.31010978 -0.05713094  9.95230744] 1.0\n",
      "positions (x,y,z), reward: [-5.64532687 -1.59717959  8.45996703] 1.0\n",
      "positions (x,y,z), reward: [-14.29737552  -1.88290287   2.96560116] 1.0\n",
      "Episode =  157, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06126403 -0.06385743  9.93766676] 1.0\n",
      "positions (x,y,z), reward: [ 0.09114099 -0.07746683  9.91602874] 1.0\n",
      "positions (x,y,z), reward: [-1.27105366  2.06234187  6.49664865] 1.0\n",
      "positions (x,y,z), reward: [-4.38067847  5.12417484  2.30363002] 1.0\n",
      "Episode =  158, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.35593173  0.29947619  9.93199824] 1.0\n",
      "positions (x,y,z), reward: [-0.54896521  0.40845684  9.90906542] 1.0\n",
      "positions (x,y,z), reward: [-1.46673945  0.40205361  9.81342681] 1.0\n",
      "positions (x,y,z), reward: [-5.1292357  -0.29553655  7.98784192] 1.0\n",
      "positions (x,y,z), reward: [-5.90089566 -0.61011183  5.13777592] 1.0\n",
      "positions (x,y,z), reward: [-5.99822674 -0.61501758  4.74668273] 1.0\n",
      "Episode =  159, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.26649379 -0.08696577  9.53280302] 1.0\n",
      "positions (x,y,z), reward: [-0.23312192 -0.11672711  9.27802576] 1.0\n",
      "positions (x,y,z), reward: [-0.03454024 -0.15139494  8.75941891] 1.0\n",
      "Episode =  160, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.57149299e-03  -1.27161897e-03   1.00133046e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.37033093 -0.1265011   9.68203965] 1.0\n",
      "positions (x,y,z), reward: [ 0.45278167 -0.2133379   9.54753126] 1.0\n",
      "positions (x,y,z), reward: [-2.71781276  1.81900292  4.90424518] 1.0\n",
      "positions (x,y,z), reward: [-3.679473    2.14896747  3.25769945] 1.0\n",
      "Episode =  161, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00533337] 1.0\n",
      "positions (x,y,z), reward: [ 0.98533948  0.11769732  9.57165129] 1.0\n",
      "positions (x,y,z), reward: [ 0.33880849 -0.27958812  8.95165445] 1.0\n",
      "positions (x,y,z), reward: [-1.10158991 -0.89468212  7.146765  ] 1.0\n",
      "positions (x,y,z), reward: [-3.04825978 -2.6704805   2.60831825] 1.0\n",
      "Episode =  162, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02323231  -0.07837342  10.01612568] 1.0\n",
      "positions (x,y,z), reward: [ 0.18778129 -0.21201317  9.90082951] 1.0\n",
      "positions (x,y,z), reward: [ 0.78400221 -0.61583702  9.52008803] 1.0\n",
      "positions (x,y,z), reward: [ 2.43134458 -2.89262231  6.6425629 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.64734739 -3.42513426  5.78219832] 1.0\n",
      "positions (x,y,z), reward: [ 2.73526308 -3.65176837  5.41180838] 1.0\n",
      "positions (x,y,z), reward: [ 2.77932089 -3.76712433  5.22186903] 1.0\n",
      "positions (x,y,z), reward: [ 2.86772912 -3.99930223  4.83308459] 1.0\n",
      "positions (x,y,z), reward: [ 3.04580196 -4.46412171  4.01627768] 1.0\n",
      "Episode =  163, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07697621   0.03470406  10.0003614 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.30901489  0.47784666  9.69611243] 1.0\n",
      "positions (x,y,z), reward: [-0.0768353   0.75252159  9.59179088] 1.0\n",
      "positions (x,y,z), reward: [-6.19979311  0.32284586  5.79682974] 1.0\n",
      "Episode =  164, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02578517   0.01389995  10.03380738] 1.0\n",
      "positions (x,y,z), reward: [-0.07966459 -0.03561528  9.95183564] 1.0\n",
      "positions (x,y,z), reward: [-1.53099755 -1.82158536  9.89450023] 1.0\n",
      "positions (x,y,z), reward: [-1.67427408 -1.89252779  9.86734381] 1.0\n",
      "positions (x,y,z), reward: [-1.94678229 -2.01979071  9.81209539] 1.0\n",
      "positions (x,y,z), reward: [-2.57639869 -2.28752328  9.58959153] 1.0\n",
      "positions (x,y,z), reward: [-3.25000272 -2.37270742  9.26245321] 1.0\n",
      "positions (x,y,z), reward: [-4.43178892 -2.43780299  8.69764577] 1.0\n",
      "positions (x,y,z), reward: [-10.49180165  -2.44645421   4.75450447] 1.0\n",
      "Episode =  165, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06849808  -0.04939505  10.02167405] 1.0\n",
      "positions (x,y,z), reward: [ 1.14517419 -1.07564976  9.23063312] 1.0\n",
      "positions (x,y,z), reward: [ 0.70541959 -2.14640846  8.11176474] 1.0\n",
      "positions (x,y,z), reward: [ 0.57614045 -2.26075025  7.89325186] 1.0\n",
      "Episode =  166, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.37657272e-03   2.43620572e-03   1.00114654e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.0728557   0.07234417  9.9856751 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.83681986  1.6022731   6.77965827] 1.0\n",
      "positions (x,y,z), reward: [ 0.75376403  2.81390418  4.25196527] 1.0\n",
      "Episode =  167, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.36808581e-02   2.85767437e-04   9.97639804e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.42009027 -0.20080655  9.23817316] 1.0\n",
      "positions (x,y,z), reward: [ 0.27077229 -0.27036763  8.94334114] 1.0\n",
      "positions (x,y,z), reward: [ 0.14935659 -0.23709161  8.81247114] 1.0\n",
      "positions (x,y,z), reward: [ 0.17604699 -0.98207621  6.46672347] 1.0\n",
      "positions (x,y,z), reward: [ 1.28070747 -1.98261823  2.38668829] 1.0\n",
      "Episode =  168, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.73419502 -1.064096    9.0827983 ] 1.0\n",
      "positions (x,y,z), reward: [-3.30603877 -4.36257591  5.58495813] 1.0\n",
      "positions (x,y,z), reward: [-3.4539302  -4.48935122  5.40413094] 1.0\n",
      "positions (x,y,z), reward: [-3.90560536 -4.87081559  4.83916422] 1.0\n",
      "Episode =  169, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.3506331   -0.02826359  10.56091228] 1.0\n",
      "positions (x,y,z), reward: [ -2.52641709  -0.01189885  10.59737709] 1.0\n",
      "positions (x,y,z), reward: [ -4.10137928   0.10221106  10.74543874] 1.0\n",
      "positions (x,y,z), reward: [ -5.98912924   0.0929484   10.56848081] 1.0\n",
      "positions (x,y,z), reward: [ -7.74264414   0.06633124  10.00999504] 1.0\n",
      "positions (x,y,z), reward: [-9.12857107  0.04227323  9.51810829] 1.0\n",
      "positions (x,y,z), reward: [-11.07044851  -0.12088992   8.68505085] 1.0\n",
      "Episode =  170, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.13299074e-02  -7.09857623e-03   1.00156561e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.03896632  -0.02297197  10.01994168] 1.0\n",
      "positions (x,y,z), reward: [ 2.54356786 -1.73618041  7.64548539] 1.0\n",
      "positions (x,y,z), reward: [ 2.67557408 -1.95798508  7.38343808] 1.0\n",
      "Episode =  171, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05821453  -0.03250293  10.05742234] 1.0\n",
      "positions (x,y,z), reward: [ 0.36806343 -0.04939717  9.92250541] 1.0\n",
      "positions (x,y,z), reward: [ 1.40561268 -0.22952844  9.58095384] 1.0\n",
      "positions (x,y,z), reward: [ 3.2339809  -0.77694301  8.716726  ] 1.0\n",
      "positions (x,y,z), reward: [ 7.69687001 -1.82766006  5.79412816] 1.0\n",
      "positions (x,y,z), reward: [ 10.6085018   -2.32010398   3.61916563] 1.0\n",
      "Episode =  172, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.06493153 -1.15045886  8.31498229] 1.0\n",
      "positions (x,y,z), reward: [ 2.01973244 -2.87662392  3.21239197] 1.0\n",
      "Episode =  173, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02736292  0.36715434  9.61441678] 1.0\n",
      "positions (x,y,z), reward: [ 2.55094212  1.21144337  6.96441598] 1.0\n",
      "positions (x,y,z), reward: [ 3.9454521   1.4885241   5.30902106] 1.0\n",
      "positions (x,y,z), reward: [ 5.98290983  1.79954537  0.97860574] 1.0\n",
      "Episode =  174, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01940198  -0.01498548  10.01708846] 1.0\n",
      "positions (x,y,z), reward: [ -0.07882572  -0.09184446  10.01443761] 1.0\n",
      "positions (x,y,z), reward: [ 1.87183175 -1.00350403  8.48406871] 1.0\n",
      "positions (x,y,z), reward: [ 2.80915705 -1.04695139  7.80813469] 1.0\n",
      "positions (x,y,z), reward: [ 3.96353898 -1.10172132  6.82938921] 1.0\n",
      "Episode =  175, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.43654671 -1.20691187  8.33073227] 1.0\n",
      "positions (x,y,z), reward: [ 0.78747167 -2.72545597  6.3484155 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.96605921 -4.48647921  2.64309937] 1.0\n",
      "positions (x,y,z), reward: [ 0.89240591 -5.12531135  0.92455314] 1.0\n",
      "Episode =  176, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  6.85874799e-02   2.27748439e-03   9.99692208e+00] 1.0\n",
      "positions (x,y,z), reward: [  1.13249146e-01   8.88615750e-03   9.97750140e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.27866601  0.04780487  9.92131089] 1.0\n",
      "positions (x,y,z), reward: [ 0.72821259  0.16360138  9.90613604] 1.0\n",
      "positions (x,y,z), reward: [ 0.91028525  0.11339348  9.95111587] 1.0\n",
      "positions (x,y,z), reward: [  0.58755987   0.19497468  10.00422746] 1.0\n",
      "positions (x,y,z), reward: [-0.01649494  0.43712237  9.67256343] 1.0\n",
      "positions (x,y,z), reward: [-1.2587566   1.14305001  8.68722412] 1.0\n",
      "positions (x,y,z), reward: [-1.38693028  1.22170038  8.59806513] 1.0\n",
      "positions (x,y,z), reward: [-7.64817027  4.33263043  2.14188882] 1.0\n",
      "Episode =  177, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.51399888e-01   8.77492628e-03   9.92537132e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.51428845 -0.79542931  8.92287668] 1.0\n",
      "positions (x,y,z), reward: [-0.39801994 -2.93089569  3.04130859] 1.0\n",
      "Episode =  178, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.75995797 -0.08394286  9.72443159] 1.0\n",
      "positions (x,y,z), reward: [ 1.49887151 -0.2093862   9.35431587] 1.0\n",
      "positions (x,y,z), reward: [ 2.4226476  -0.37910702  8.59374642] 1.0\n",
      "positions (x,y,z), reward: [ 5.10867654 -0.78997476  3.77819683] 1.0\n",
      "positions (x,y,z), reward: [ 5.90014347 -1.06846217  0.86481467] 1.0\n",
      "Episode =  179, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.51289164   0.46258447  10.31264682] 1.0\n",
      "positions (x,y,z), reward: [ -1.75360944   0.96593287  10.51903494] 1.0\n",
      "positions (x,y,z), reward: [ -3.39348985   2.05734853  10.48345123] 1.0\n",
      "positions (x,y,z), reward: [ -4.33873349   3.67730075  10.17017731] 1.0\n",
      "positions (x,y,z), reward: [-5.4520124   6.19286951  7.30412722] 1.0\n",
      "Episode =  180, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.31531521  0.04199549  9.61175293] 1.0\n",
      "positions (x,y,z), reward: [ 0.87914517 -0.78627971  8.73198336] 1.0\n",
      "positions (x,y,z), reward: [-0.3901476  -1.74127071  6.4776478 ] 1.0\n",
      "positions (x,y,z), reward: [-3.67559894 -3.32465896  0.        ] 1.0\n",
      "Episode =  181, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.12866549 -0.14271359  9.83541089] 1.0\n",
      "positions (x,y,z), reward: [ 0.40079643 -0.28260613  9.21344855] 1.0\n",
      "positions (x,y,z), reward: [ 5.09621264 -4.62478069  0.87973377] 1.0\n",
      "positions (x,y,z), reward: [ 5.34086595 -4.90207958  0.09813871] 1.0\n",
      "positions (x,y,z), reward: [ 5.50522551 -5.08783894  0.        ] 1.0\n",
      "Episode =  182, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03664869  0.33781815  9.76649263] 1.0\n",
      "positions (x,y,z), reward: [-1.1422508   1.27890943  7.32710182] 1.0\n",
      "positions (x,y,z), reward: [-3.69520182  2.70741138  0.78220874] 1.0\n",
      "positions (x,y,z), reward: [-3.91539487  2.8322368   0.17883314] 1.0\n",
      "Episode =  183, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.27695446 -2.05246509  6.26336967] 1.0\n",
      "positions (x,y,z), reward: [-0.42388499 -2.58346237  4.34933776] 1.0\n",
      "Episode =  184, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-4.05657898  1.56703608  9.26301107] 1.0\n",
      "positions (x,y,z), reward: [-6.82578143  2.30061964  8.38849075] 1.0\n",
      "positions (x,y,z), reward: [-8.70947321  2.78345159  7.53538484] 1.0\n",
      "Episode =  185, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.34890653 -0.50412762  8.5609234 ] 1.0\n",
      "positions (x,y,z), reward: [-0.60573158 -0.52059673  7.99233933] 1.0\n",
      "positions (x,y,z), reward: [-1.81126371 -0.22026688  6.08624355] 1.0\n",
      "positions (x,y,z), reward: [-2.62128963 -0.109249    4.60374144] 1.0\n",
      "positions (x,y,z), reward: [-3.4073895  -0.04394708  3.07164641] 1.0\n",
      "positions (x,y,z), reward: [-3.94914383 -0.0109582   1.97041436] 1.0\n",
      "positions (x,y,z), reward: [-4.64815874  0.01994635  0.49035389] 1.0\n",
      "Episode =  186, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04361594  0.19778536  9.9863755 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.25599786  0.57575676  9.80912173] 1.0\n",
      "positions (x,y,z), reward: [-0.33559688  1.26946265  9.93973127] 1.0\n",
      "positions (x,y,z), reward: [-3.26838502  2.2795041   8.84828749] 1.0\n",
      "positions (x,y,z), reward: [-10.52299512   5.92929439   2.4721468 ] 1.0\n",
      "Episode =  187, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00542107] 1.0\n",
      "positions (x,y,z), reward: [-0.06203846  0.02561939  9.99774548] 1.0\n",
      "positions (x,y,z), reward: [-0.07546005  0.04286776  9.99004756] 1.0\n",
      "positions (x,y,z), reward: [-0.08187613  0.06229096  9.98026306] 1.0\n",
      "positions (x,y,z), reward: [-0.07240973  0.1070624   9.95518081] 1.0\n",
      "positions (x,y,z), reward: [ 0.34309202  0.39876082  9.96069379] 1.0\n",
      "positions (x,y,z), reward: [-0.1728965  -0.19404358  9.88016755] 1.0\n",
      "positions (x,y,z), reward: [ 1.6439004  -1.07631683  8.66348428] 1.0\n",
      "positions (x,y,z), reward: [ 2.5357094  -1.44631846  8.03031934] 1.0\n",
      "positions (x,y,z), reward: [ 5.23883635 -2.61212234  5.83644533] 1.0\n",
      "positions (x,y,z), reward: [ 8.0556669  -3.81997238  3.02493498] 1.0\n",
      "positions (x,y,z), reward: [  1.03350027e+01  -4.77204844e+00   7.53831589e-03] 1.0\n",
      "Episode =  188, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01893401   0.21113877  10.05919208] 1.0\n",
      "positions (x,y,z), reward: [ -7.31004666e-03   3.08748204e-01   1.00873095e+01] 1.0\n",
      "positions (x,y,z), reward: [ -2.50798956   2.6403245   10.15970007] 1.0\n",
      "positions (x,y,z), reward: [-5.55774005  4.08578245  9.76828467] 1.0\n",
      "positions (x,y,z), reward: [-9.52709231  5.63890365  9.25544121] 1.0\n",
      "positions (x,y,z), reward: [-20.69269409   8.98682882   5.00425591] 1.0\n",
      "positions (x,y,z), reward: [-28.62508771  11.11083083   0.        ] 1.0\n",
      "Episode =  189, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.87050199e-02   7.57977400e-03   1.00010800e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.25025865  0.46981238  8.5895137 ] 1.0\n",
      "positions (x,y,z), reward: [-1.12059978  1.06031284  6.58286173] 1.0\n",
      "Episode =  190, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.21226947  0.05260725  7.77558304] 1.0\n",
      "positions (x,y,z), reward: [ 2.51026445 -0.13416335  7.22048778] 1.0\n",
      "positions (x,y,z), reward: [ 2.92172556 -0.60799179  5.30051733] 1.0\n",
      "positions (x,y,z), reward: [ 3.19448921 -1.06361671  3.27295982] 1.0\n",
      "positions (x,y,z), reward: [ 3.37924856 -1.83979919  0.        ] 1.0\n",
      "Episode =  191, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03974216   0.02869767  10.07313272] 1.0\n",
      "positions (x,y,z), reward: [-0.15857483 -0.16338551  6.74420399] 1.0\n",
      "positions (x,y,z), reward: [-0.39138066 -0.22046662  5.5751856 ] 1.0\n",
      "positions (x,y,z), reward: [-0.98712915 -0.42054104  2.59545353] 1.0\n",
      "Episode =  192, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08509488  0.01077798  9.9888391 ] 1.0\n",
      "positions (x,y,z), reward: [ -5.61841257e-02   7.98803317e-04   9.77701694e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.68939573 -1.29147523  6.50447798] 1.0\n",
      "Episode =  193, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00629136] 1.0\n",
      "positions (x,y,z), reward: [ -0.07316865  -0.06316256  10.06059172] 1.0\n",
      "positions (x,y,z), reward: [  1.00864684e+00   4.20487063e-03   9.00321462e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.83101875  0.02612355  7.77304405] 1.0\n",
      "Episode =  194, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.22803721e-02  -4.83012026e-03   1.00103923e+01] 1.0\n",
      "positions (x,y,z), reward: [ -3.50591182e-01   6.54288444e-04   9.90127933e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.58291685 -0.0854075   9.80456655] 1.0\n",
      "positions (x,y,z), reward: [-11.42053376   0.53094858   2.23788136] 1.0\n",
      "positions (x,y,z), reward: [-11.81382782   0.56685439   1.78400006] 1.0\n",
      "Episode =  195, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06545268  0.5114451   9.22100302] 1.0\n",
      "positions (x,y,z), reward: [-0.28220142  0.5863514   9.02787871] 1.0\n",
      "positions (x,y,z), reward: [-0.92138907  0.79618994  8.55307247] 1.0\n",
      "positions (x,y,z), reward: [-2.09541371  1.12141018  7.06564588] 1.0\n",
      "positions (x,y,z), reward: [-3.42139308  1.84123083  5.35381133] 1.0\n",
      "positions (x,y,z), reward: [-3.99816107  2.16293972  4.49790361] 1.0\n",
      "positions (x,y,z), reward: [-4.11428085  2.22781948  4.3135244 ] 1.0\n",
      "Episode =  196, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.66351826  0.64209713  7.44712089] 1.0\n",
      "positions (x,y,z), reward: [-7.52424494  2.11888351  1.80080314] 1.0\n",
      "Episode =  197, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.45079943 -2.40367928  6.32486408] 1.0\n",
      "positions (x,y,z), reward: [ 0.61196598 -4.12405942  2.53720443] 1.0\n",
      "Episode =  198, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 8.43562683 -1.21227013  3.5592461 ] 1.0\n",
      "positions (x,y,z), reward: [ 11.15732849  -1.79193992   0.        ] 1.0\n",
      "Episode =  199, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.21776758e-03  -5.89306467e-02   9.96558961e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.72738347 -0.03646248  9.13992645] 1.0\n",
      "positions (x,y,z), reward: [ 0.78250304 -0.08499348  8.98944105] 1.0\n",
      "positions (x,y,z), reward: [ 1.31244544 -0.72819288  7.11388297] 1.0\n",
      "positions (x,y,z), reward: [ 1.30005939 -1.22800322  5.55456289] 1.0\n",
      "Episode =  200, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10314668 -0.04205917  9.98116375] 1.0\n",
      "positions (x,y,z), reward: [ 0.27869987 -0.26844858  9.91942841] 1.0\n",
      "positions (x,y,z), reward: [-5.65057749 -2.4933654   6.19797535] 1.0\n",
      "positions (x,y,z), reward: [-5.98834344 -2.59043458  5.85398806] 1.0\n",
      "positions (x,y,z), reward: [-6.82885698 -2.83244461  4.95305202] 1.0\n",
      "positions (x,y,z), reward: [-7.3345631  -2.9789915   4.37913051] 1.0\n",
      "Episode =  201, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04437118   0.01175049  10.02400419] 1.0\n",
      "positions (x,y,z), reward: [ 1.2463663   0.01641087  9.43073746] 1.0\n",
      "positions (x,y,z), reward: [ 1.65286142 -0.06469894  9.29886041] 1.0\n",
      "positions (x,y,z), reward: [ 2.35245311 -0.94411725  7.92016273] 1.0\n",
      "positions (x,y,z), reward: [ 2.1586005  -1.48959743  7.11942448] 1.0\n",
      "positions (x,y,z), reward: [ 1.98302756 -1.86444889  6.44783059] 1.0\n",
      "Episode =  202, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.18265987 -0.23188761  9.21769038] 1.0\n",
      "positions (x,y,z), reward: [ 1.30941317 -0.25958177  9.15861499] 1.0\n",
      "positions (x,y,z), reward: [ 4.97434369 -2.7389833   4.526044  ] 1.0\n",
      "positions (x,y,z), reward: [ 6.85849043 -4.4209016   0.        ] 1.0\n",
      "Episode =  203, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.33938375  0.40407567  5.27380471] 1.0\n",
      "Episode =  204, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.82504068e-03  -1.04062800e-02   9.99900550e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.09525257 -0.07156267  9.78989607] 1.0\n",
      "positions (x,y,z), reward: [ 0.13791781 -0.07763103  9.74657497] 1.0\n",
      "positions (x,y,z), reward: [ 0.30680748 -0.08720669  9.6098311 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.29580374 -0.90326116  8.57429101] 1.0\n",
      "positions (x,y,z), reward: [-0.82989021 -3.28369445  4.48564693] 1.0\n",
      "positions (x,y,z), reward: [-1.8684824  -3.95302052  2.43563299] 1.0\n",
      "positions (x,y,z), reward: [-2.28932725 -4.22280249  1.50871199] 1.0\n",
      "positions (x,y,z), reward: [-2.5035227  -4.36150409  1.01457923] 1.0\n",
      "Episode =  205, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.25734179 -0.10376148  9.81400633] 1.0\n",
      "positions (x,y,z), reward: [ 6.85615992 -0.49648045  3.40127085] 1.0\n",
      "positions (x,y,z), reward: [ 7.9440007  -0.54775708  2.1863704 ] 1.0\n",
      "Episode =  206, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  3.99978068e-01   6.48396998e-03   9.47795269e+00] 1.0\n",
      "Episode =  207, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.46938957  0.08235444  9.73562924] 1.0\n",
      "positions (x,y,z), reward: [-4.78169541  0.11925792  7.49455123] 1.0\n",
      "positions (x,y,z), reward: [-7.85665749  0.2690724   5.4822159 ] 1.0\n",
      "positions (x,y,z), reward: [-10.48294476   0.50122903   3.24588799] 1.0\n",
      "positions (x,y,z), reward: [-11.60238157   0.56437587   2.05440781] 1.0\n",
      "Episode =  208, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06206921  -0.0114459   10.05014087] 1.0\n",
      "positions (x,y,z), reward: [-1.20553934  1.53366113  9.77643612] 1.0\n",
      "positions (x,y,z), reward: [-2.83677608  2.37652053  8.66366325] 1.0\n",
      "Episode =  209, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.125193   -0.39252298  9.92995887] 1.0\n",
      "positions (x,y,z), reward: [ 1.32499123 -3.08416501  7.01276551] 1.0\n",
      "positions (x,y,z), reward: [ 1.45706803 -3.7469819   5.98130438] 1.0\n",
      "Episode =  210, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.29396422 -0.40237147  9.54079794] 1.0\n",
      "positions (x,y,z), reward: [ 1.00054369 -0.94005404  9.15531096] 1.0\n",
      "positions (x,y,z), reward: [ 1.08677092 -1.19604329  8.98143362] 1.0\n",
      "positions (x,y,z), reward: [ 1.10100653 -1.45286352  8.78352513] 1.0\n",
      "positions (x,y,z), reward: [ 1.07004094 -1.62252818  8.63103689] 1.0\n",
      "positions (x,y,z), reward: [ 0.63390904 -2.47978439  7.57374653] 1.0\n",
      "positions (x,y,z), reward: [-0.50914042 -3.5240147   5.87993773] 1.0\n",
      "positions (x,y,z), reward: [-0.67071601 -3.6506693   5.61502796] 1.0\n",
      "positions (x,y,z), reward: [-1.28534858 -4.07212564  4.56387747] 1.0\n",
      "positions (x,y,z), reward: [-2.49645537 -4.85836551  2.12258456] 1.0\n",
      "Episode =  211, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.34501786e-02   4.32331720e-03   9.98836077e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.01188047 -0.06530071  9.8794022 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.20076118 -0.2049406   9.6132023 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.71685172 -0.41480622  9.24509407] 1.0\n",
      "positions (x,y,z), reward: [ 0.9784911  -0.85156982  8.81096623] 1.0\n",
      "positions (x,y,z), reward: [ 0.97204038 -0.95794271  8.70089934] 1.0\n",
      "positions (x,y,z), reward: [ 0.56905634 -1.9679864   6.69441403] 1.0\n",
      "positions (x,y,z), reward: [ 0.33359665 -2.12210167  5.9140554 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.01494043 -2.27299753  4.8801599 ] 1.0\n",
      "positions (x,y,z), reward: [-1.22640325 -2.77037711  1.21489617] 1.0\n",
      "Episode =  212, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.15052549e-02  -1.28051781e-03   1.00371019e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.55830872 -0.20684551  9.83958483] 1.0\n",
      "positions (x,y,z), reward: [ 0.93765221 -0.32079496  9.83076579] 1.0\n",
      "positions (x,y,z), reward: [-6.10324977 -0.24825254  4.89496071] 1.0\n",
      "Episode =  213, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.04551681  0.03616353  9.92427315] 1.0\n",
      "positions (x,y,z), reward: [ 0.39534415  0.07631199  9.54797964] 1.0\n",
      "positions (x,y,z), reward: [ 0.58400766  0.04233321  9.28104149] 1.0\n",
      "positions (x,y,z), reward: [ 4.34150034 -1.41372452  3.24875375] 1.0\n",
      "Episode =  214, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.49010708 -0.57111149  7.91485181] 1.0\n",
      "positions (x,y,z), reward: [-3.63174028 -1.03961437  5.01543731] 1.0\n",
      "positions (x,y,z), reward: [-4.85855235 -1.17178518  3.21078173] 1.0\n",
      "Episode =  215, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.11273494  0.50532582  9.87634251] 1.0\n",
      "positions (x,y,z), reward: [ 0.12277635  0.52985334  9.90302044] 1.0\n",
      "positions (x,y,z), reward: [-0.91258448  1.11631866  9.93085036] 1.0\n",
      "positions (x,y,z), reward: [-1.19685862  1.12910575  9.75745429] 1.0\n",
      "positions (x,y,z), reward: [-4.38568109 -0.68526208  6.42533519] 1.0\n",
      "positions (x,y,z), reward: [-4.90366736 -1.07277909  5.63237789] 1.0\n",
      "Episode =  216, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.5426966   0.49935737  3.00208707] 1.0\n",
      "positions (x,y,z), reward: [-4.00751171  0.5547004   1.50594247] 1.0\n",
      "positions (x,y,z), reward: [-4.30807058  0.58998556  0.44572163] 1.0\n",
      "Episode =  217, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05841201  0.20939682  9.10834001] 1.0\n",
      "positions (x,y,z), reward: [-0.19075098  0.25608041  8.77788641] 1.0\n",
      "positions (x,y,z), reward: [-1.72791556  0.72005407  5.82643414] 1.0\n",
      "Episode =  218, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.03388365  0.02119967  9.99796159] 1.0\n",
      "positions (x,y,z), reward: [ 0.64951098 -0.10382745  9.44038741] 1.0\n",
      "positions (x,y,z), reward: [ 2.38724897 -1.18199144  6.78442147] 1.0\n",
      "positions (x,y,z), reward: [ 3.75598864 -2.54790721  1.7200162 ] 1.0\n",
      "Episode =  219, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.25069417 -2.93481338  7.70471305] 1.0\n",
      "positions (x,y,z), reward: [-2.61917173 -3.22461562  7.3475468 ] 1.0\n",
      "positions (x,y,z), reward: [-6.32619466 -5.30730869  2.30123446] 1.0\n",
      "Episode =  220, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.02638319  -0.15015394  10.08108895] 1.0\n",
      "positions (x,y,z), reward: [ 0.42076457 -2.09431601  9.79567574] 1.0\n",
      "positions (x,y,z), reward: [-0.71661561 -3.71480007  8.98087027] 1.0\n",
      "positions (x,y,z), reward: [-1.75804422 -4.56993345  8.39178797] 1.0\n",
      "positions (x,y,z), reward: [-3.30827864 -6.1396763   6.62819214] 1.0\n",
      "positions (x,y,z), reward: [-4.88867636 -7.26979141  4.15502087] 1.0\n",
      "Episode =  221, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04773779  -0.0315541   10.04229784] 1.0\n",
      "positions (x,y,z), reward: [-1.07701984  0.87215729  8.48584255] 1.0\n",
      "positions (x,y,z), reward: [-6.5832564   4.00237958  3.3333372 ] 1.0\n",
      "Episode =  222, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.12860981  1.05348572  8.74615357] 1.0\n",
      "positions (x,y,z), reward: [-0.63800476  2.29623313  7.22187663] 1.0\n",
      "positions (x,y,z), reward: [-2.40356593  4.07518622  3.71797948] 1.0\n",
      "positions (x,y,z), reward: [-2.9698738   4.5810362   2.34766518] 1.0\n",
      "Episode =  223, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.32152371  1.89607571  8.94015691] 1.0\n",
      "positions (x,y,z), reward: [-1.80400625  3.97352884  7.08251362] 1.0\n",
      "positions (x,y,z), reward: [-2.20447646  4.43156012  6.64430875] 1.0\n",
      "Episode =  224, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.08670685   0.23894006  10.02332008] 1.0\n",
      "positions (x,y,z), reward: [-4.16193322  2.76566366  7.71559439] 1.0\n",
      "positions (x,y,z), reward: [-6.38586898  3.96043513  6.54683565] 1.0\n",
      "positions (x,y,z), reward: [-6.84981399  4.1952754   6.27122665] 1.0\n",
      "positions (x,y,z), reward: [-10.93913924   6.1784453    3.26135523] 1.0\n",
      "Episode =  225, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06719689 -3.33186317  4.07563369] 1.0\n",
      "Episode =  226, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.18469817  0.09982814  9.85405581] 1.0\n",
      "positions (x,y,z), reward: [ 0.3892706   0.55616468  8.6608837 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.86104206  2.54606665  2.81767679] 1.0\n",
      "Episode =  227, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.45204549 -0.09527445  9.15702568] 1.0\n",
      "positions (x,y,z), reward: [ 0.78382266 -0.58984719  7.22206466] 1.0\n",
      "positions (x,y,z), reward: [ 0.85256625 -0.64205517  6.70217211] 1.0\n",
      "positions (x,y,z), reward: [ 0.89121594 -0.695258    6.14417187] 1.0\n",
      "Episode =  228, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.09535221 -0.12865921  9.78543957] 1.0\n",
      "positions (x,y,z), reward: [-3.472287    0.83224616  9.02588363] 1.0\n",
      "positions (x,y,z), reward: [-13.45143854   6.86692606   4.20975148] 1.0\n",
      "positions (x,y,z), reward: [-15.00250433   7.75942      3.17976973] 1.0\n",
      "Episode =  229, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.4990342  -0.36253906  8.94134816] 1.0\n",
      "positions (x,y,z), reward: [-1.40675052 -1.29856681  7.43020969] 1.0\n",
      "positions (x,y,z), reward: [-1.51358001 -1.38949753  7.27153321] 1.0\n",
      "positions (x,y,z), reward: [-3.88716566 -3.03274431  3.5479312 ] 1.0\n",
      "positions (x,y,z), reward: [-5.13367034 -3.79383611  1.22619557] 1.0\n",
      "Episode =  230, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05178575   0.05228316  10.07325905] 1.0\n",
      "positions (x,y,z), reward: [ -1.09042316   1.0770413   10.49090913] 1.0\n",
      "positions (x,y,z), reward: [ -1.26756494   1.17840601  10.49863047] 1.0\n",
      "positions (x,y,z), reward: [-13.52061966   7.57102211   8.1892689 ] 1.0\n",
      "positions (x,y,z), reward: [-14.60157557   8.03239622   7.79660865] 1.0\n",
      "positions (x,y,z), reward: [-17.19502357   9.13362388   6.76834978] 1.0\n",
      "positions (x,y,z), reward: [-24.32755156  12.05588645   3.49198261] 1.0\n",
      "Episode =  231, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.72083953  -0.20591632  10.13350304] 1.0\n",
      "positions (x,y,z), reward: [-6.84432157 -0.21604583  9.92075047] 1.0\n",
      "positions (x,y,z), reward: [-7.69821008 -0.20360082  9.82589334] 1.0\n",
      "positions (x,y,z), reward: [-11.32529323  -0.18384021   9.3913305 ] 1.0\n",
      "positions (x,y,z), reward: [-17.11303881  -0.37995938   7.09078073] 1.0\n",
      "positions (x,y,z), reward: [-20.61051424  -0.73649881   4.70706491] 1.0\n",
      "Episode =  232, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.41369582 -0.51293414  9.70152856] 1.0\n",
      "positions (x,y,z), reward: [ 2.65732355 -0.46259336  6.93438336] 1.0\n",
      "positions (x,y,z), reward: [ 3.65054963 -0.27263119  4.84682002] 1.0\n",
      "positions (x,y,z), reward: [ 3.90068853 -0.24807131  4.01839669] 1.0\n",
      "positions (x,y,z), reward: [ 3.95979819 -0.24122827  3.80416102] 1.0\n",
      "Episode =  233, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.14887201  0.15912731  9.6335872 ] 1.0\n",
      "positions (x,y,z), reward: [-0.77777735 -0.18590699  7.80860039] 1.0\n",
      "positions (x,y,z), reward: [-0.86186828 -0.26664229  7.44176945] 1.0\n",
      "positions (x,y,z), reward: [-0.90004138 -0.30357369  7.25339468] 1.0\n",
      "positions (x,y,z), reward: [-0.96922765 -0.3784044   6.86224995] 1.0\n",
      "Episode =  234, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04114346  0.03519918  9.84947274] 1.0\n",
      "positions (x,y,z), reward: [-0.21346674  0.557565    9.13700398] 1.0\n",
      "positions (x,y,z), reward: [-0.25284382  0.62266267  9.03945828] 1.0\n",
      "positions (x,y,z), reward: [-0.29140094  0.68932291  8.935463  ] 1.0\n",
      "Episode =  235, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.46022889e-02   2.28468429e-03   1.00198404e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.87663266e-01  -7.65231722e-03   9.75870411e+00] 1.0\n",
      "positions (x,y,z), reward: [  3.93579446e-01  -2.25242456e-03   9.64706178e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.12891158 -1.45258277  7.77338322] 1.0\n",
      "Episode =  236, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07420971  -0.05034768  10.01594259] 1.0\n",
      "positions (x,y,z), reward: [-0.22756897 -0.2026892   9.87654438] 1.0\n",
      "positions (x,y,z), reward: [-0.20427895 -0.5257923   8.95346041] 1.0\n",
      "positions (x,y,z), reward: [-0.04713288 -0.70711212  6.80151816] 1.0\n",
      "positions (x,y,z), reward: [-0.16299006 -0.75856288  5.95250867] 1.0\n",
      "Episode =  237, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04325278  -0.02879092  10.01725702] 1.0\n",
      "positions (x,y,z), reward: [-0.04415358 -0.39025527  9.72308025] 1.0\n",
      "positions (x,y,z), reward: [ -5.10040014e-03  -4.22617166e-01   9.66961110e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.2326765  -0.55024645  9.40948621] 1.0\n",
      "positions (x,y,z), reward: [ 1.98890172 -0.94101754  7.97266062] 1.0\n",
      "positions (x,y,z), reward: [ 4.71003414 -1.57263739  5.11127913] 1.0\n",
      "positions (x,y,z), reward: [ 6.67718507 -1.93149724  2.44273945] 1.0\n",
      "positions (x,y,z), reward: [ 7.89778184 -2.20171096  0.30119913] 1.0\n",
      "Episode =  238, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.20616456  0.03382308  9.20649603] 1.0\n",
      "positions (x,y,z), reward: [-0.44728177 -0.76033703  4.93863437] 1.0\n",
      "Episode =  239, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.61450559 -0.97601409  9.11054326] 1.0\n",
      "positions (x,y,z), reward: [-0.75247797 -0.99416435  9.06160798] 1.0\n",
      "positions (x,y,z), reward: [-0.89636572 -1.01178265  9.00883494] 1.0\n",
      "positions (x,y,z), reward: [-5.07983031 -1.72435018  6.1271014 ] 1.0\n",
      "positions (x,y,z), reward: [-7.06003377 -2.1362313   4.07885151] 1.0\n",
      "positions (x,y,z), reward: [-9.18036649 -2.61280841  1.38987927] 1.0\n",
      "Episode =  240, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.13567987  0.13964499  9.83508406] 1.0\n",
      "positions (x,y,z), reward: [ 1.39677422  0.56480744  3.02572473] 1.0\n",
      "positions (x,y,z), reward: [ 1.63501846  0.57357527  1.37736127] 1.0\n",
      "Episode =  241, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.34708119  1.99617279  9.73817609] 1.0\n",
      "positions (x,y,z), reward: [-6.20305571  4.2806096   2.62046046] 1.0\n",
      "Episode =  242, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05597607  0.1688071   9.90796514] 1.0\n",
      "positions (x,y,z), reward: [ 0.14488052 -0.02961605  9.92243344] 1.0\n",
      "positions (x,y,z), reward: [-0.11398095 -0.14499625  9.8750336 ] 1.0\n",
      "positions (x,y,z), reward: [-6.81951049 -2.81196942  2.60799101] 1.0\n",
      "positions (x,y,z), reward: [-7.78798157 -3.38481759  0.03013648] 1.0\n",
      "Episode =  243, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.21187742   0.03745724  10.25304096] 1.0\n",
      "positions (x,y,z), reward: [ -1.34860133   0.03992778  10.26135674] 1.0\n",
      "positions (x,y,z), reward: [ -2.14453502   0.16226397  10.31092338] 1.0\n",
      "positions (x,y,z), reward: [-8.39069177  1.62445263  8.9031697 ] 1.0\n",
      "positions (x,y,z), reward: [-21.73443514   3.06665547   0.41351021] 1.0\n",
      "positions (x,y,z), reward: [-22.01820814   3.07298247   0.13007432] 1.0\n",
      "Episode =  244, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  4.78951425e-01   8.35204852e-03   9.42107020e+00] 1.0\n",
      "positions (x,y,z), reward: [-1.24284332 -3.62361546  1.79241379] 1.0\n",
      "Episode =  245, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05228855 -0.18402732  9.88224205] 1.0\n",
      "positions (x,y,z), reward: [ 0.66693861 -0.68172229  9.4477424 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.91607662 -6.16894046  2.98135694] 1.0\n",
      "Episode =  246, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.14587833 -0.06458603  8.05160791] 1.0\n",
      "positions (x,y,z), reward: [-3.18947433  0.09851037  6.64351987] 1.0\n",
      "positions (x,y,z), reward: [-6.61292811  0.03111518  0.        ] 1.0\n",
      "Episode =  247, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.32825348 -0.53905675  9.47057429] 1.0\n",
      "positions (x,y,z), reward: [-15.30229558   0.41801619   5.25326785] 1.0\n",
      "positions (x,y,z), reward: [-16.56594882   0.62705223   4.55207052] 1.0\n",
      "positions (x,y,z), reward: [-21.33775497   1.4964285    1.88026868] 1.0\n",
      "Episode =  248, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.18323471  0.15877071  9.99000182] 1.0\n",
      "positions (x,y,z), reward: [ -3.94880464  -0.22153593  10.2461812 ] 1.0\n",
      "positions (x,y,z), reward: [-5.95516944 -0.47664436  9.83510012] 1.0\n",
      "positions (x,y,z), reward: [-9.76447231 -0.43797095  8.75974027] 1.0\n",
      "Episode =  249, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.44185913e-02   2.13893395e-03   1.00213634e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.59965209  0.02982693  9.92240118] 1.0\n",
      "positions (x,y,z), reward: [ 1.15168191 -0.69144405  9.4433052 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.67212222 -2.65357898  6.63564024] 1.0\n",
      "positions (x,y,z), reward: [ 0.08328797 -3.20125722  5.37474951] 1.0\n",
      "positions (x,y,z), reward: [-1.265496   -4.14318182  2.30025583] 1.0\n",
      "Episode =  250, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.24151546e-02   2.57734334e-03   1.00078357e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.05849051  0.02095498  9.99626318] 1.0\n",
      "positions (x,y,z), reward: [ 0.51988481  0.12658531  9.81428139] 1.0\n",
      "positions (x,y,z), reward: [ 0.07826665 -0.1142544   9.72317048] 1.0\n",
      "positions (x,y,z), reward: [-0.81479133 -0.4222812   9.47503361] 1.0\n",
      "positions (x,y,z), reward: [-1.34727809 -0.66377833  9.23135391] 1.0\n",
      "positions (x,y,z), reward: [-3.40590577 -1.68445866  7.56050718] 1.0\n",
      "positions (x,y,z), reward: [-3.5548238  -1.74686305  7.39768114] 1.0\n",
      "Episode =  251, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.47683412e-03  -4.98934601e-06   1.00146308e+01] 1.0\n",
      "positions (x,y,z), reward: [-2.89492635 -0.40511657  7.95770249] 1.0\n",
      "positions (x,y,z), reward: [-4.09079179 -0.59670528  7.03611872] 1.0\n",
      "positions (x,y,z), reward: [-6.65812223 -0.96051019  4.60695741] 1.0\n",
      "positions (x,y,z), reward: [-8.6516773  -1.2365241   2.19275189] 1.0\n",
      "Episode =  252, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.51918932  0.23814217  9.71499575] 1.0\n",
      "positions (x,y,z), reward: [ 0.93003172  0.4684506   9.25231168] 1.0\n",
      "Episode =  253, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07192178   0.01072424  10.04332561] 1.0\n",
      "positions (x,y,z), reward: [ -0.0731615    0.0158032   10.04153203] 1.0\n",
      "positions (x,y,z), reward: [ 0.17011387 -0.04598008  9.99985403] 1.0\n",
      "positions (x,y,z), reward: [ 1.34013321 -0.38543992  9.01780325] 1.0\n",
      "positions (x,y,z), reward: [ 3.18576119 -0.49529376  4.98832358] 1.0\n",
      "positions (x,y,z), reward: [ 3.41829882 -0.51211076  3.997765  ] 1.0\n",
      "positions (x,y,z), reward: [ 3.64663556 -0.531318    2.93800391] 1.0\n",
      "Episode =  254, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.27812571  0.42160502  9.6838748 ] 1.0\n",
      "positions (x,y,z), reward: [-4.21122639  3.83029594  1.74001283] 1.0\n",
      "positions (x,y,z), reward: [-4.29990371  3.90340185  1.49342256] 1.0\n",
      "positions (x,y,z), reward: [-4.65419815  4.19394017  0.48270039] 1.0\n",
      "Episode =  255, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.5744906   0.06475051  9.61771339] 1.0\n",
      "positions (x,y,z), reward: [ 1.1801633  -0.05146672  9.21628903] 1.0\n",
      "positions (x,y,z), reward: [ 1.80649503 -0.25351761  8.51218973] 1.0\n",
      "positions (x,y,z), reward: [ 2.88816399 -0.42570156  6.65535426] 1.0\n",
      "positions (x,y,z), reward: [ 4.4704851  -0.8056924   0.48691743] 1.0\n",
      "Episode =  256, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16214045  0.3318579   9.91079199] 1.0\n",
      "positions (x,y,z), reward: [ 0.19712542  0.27909173  9.62516466] 1.0\n",
      "positions (x,y,z), reward: [ 0.1765859   0.24821134  9.5888548 ] 1.0\n",
      "positions (x,y,z), reward: [-0.45579911 -0.08299174  9.16592916] 1.0\n",
      "positions (x,y,z), reward: [-6.18381482 -0.21960435  2.90710852] 1.0\n",
      "positions (x,y,z), reward: [-6.3286491  -0.20255542  2.68785448] 1.0\n",
      "Episode =  257, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.17675122  0.04956945  8.88413156] 1.0\n",
      "positions (x,y,z), reward: [ 0.20763284  0.06393881  8.76587857] 1.0\n",
      "positions (x,y,z), reward: [ 0.37707568 -0.15507666  6.65784045] 1.0\n",
      "positions (x,y,z), reward: [ 0.35026044 -0.20356563  6.28719258] 1.0\n",
      "positions (x,y,z), reward: [ 0.12253229 -0.4108162   4.44466793] 1.0\n",
      "Episode =  258, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07968117 -2.28326382  7.35177472] 1.0\n",
      "positions (x,y,z), reward: [-2.71646277 -5.71894088  0.98369075] 1.0\n",
      "Episode =  259, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02243458 -0.13459529  9.85695319] 1.0\n",
      "positions (x,y,z), reward: [ 0.19491464 -0.25266308  9.6669607 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.42612494 -0.46037851  9.30228557] 1.0\n",
      "positions (x,y,z), reward: [ 0.19363583 -0.57682852  8.48837047] 1.0\n",
      "positions (x,y,z), reward: [-0.24449782 -0.76698267  7.61405523] 1.0\n",
      "positions (x,y,z), reward: [-0.79715592 -0.99543518  6.49460339] 1.0\n",
      "positions (x,y,z), reward: [-1.52487283 -1.25422214  5.00277179] 1.0\n",
      "positions (x,y,z), reward: [-3.1523432  -1.70830406  1.07896297] 1.0\n",
      "Episode =  260, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.34963598e-03  -1.75829775e-04   1.00151719e+01] 1.0\n",
      "positions (x,y,z), reward: [ -2.32399407e-02   2.97259192e-03   1.00238765e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.87086035 -1.22954829  9.40963069] 1.0\n",
      "positions (x,y,z), reward: [ 0.86979496 -1.29464167  9.37676905] 1.0\n",
      "positions (x,y,z), reward: [-0.04062195 -2.14476114  6.9208045 ] 1.0\n",
      "positions (x,y,z), reward: [-0.3960585  -2.06514217  6.22572345] 1.0\n",
      "positions (x,y,z), reward: [-0.94715395 -1.91956616  5.13207819] 1.0\n",
      "positions (x,y,z), reward: [-1.47390681 -1.79246862  4.02243956] 1.0\n",
      "positions (x,y,z), reward: [-3.02216755 -1.41374347  0.42559818] 1.0\n",
      "Episode =  261, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0556892   -0.03710351  10.0810418 ] 1.0\n",
      "positions (x,y,z), reward: [-1.80488512 -3.17859976  7.56813969] 1.0\n",
      "positions (x,y,z), reward: [-2.66315651 -3.95020746  6.30312291] 1.0\n",
      "Episode =  262, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.44970486 -0.68978079  6.68365369] 1.0\n",
      "Episode =  263, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.0238521  -0.61005304  8.85777848] 1.0\n",
      "positions (x,y,z), reward: [-1.95846079 -3.04763069  1.78034826] 1.0\n",
      "Episode =  264, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.28172157 -0.54087276  7.30231602] 1.0\n",
      "positions (x,y,z), reward: [-5.87888991 -1.85398511  0.76706392] 1.0\n",
      "Episode =  265, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.3145157   0.46643977  9.80924499] 1.0\n",
      "positions (x,y,z), reward: [ 0.33749373  0.51414517  9.80538281] 1.0\n",
      "positions (x,y,z), reward: [ 0.35707903  0.68876798  9.78915698] 1.0\n",
      "positions (x,y,z), reward: [-6.4351295   7.44576227  5.47759519] 1.0\n",
      "Episode =  266, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06333689  -0.01223287  10.01900259] 1.0\n",
      "Episode =  268, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03663948  -0.02106653  10.07287923] 1.0\n",
      "positions (x,y,z), reward: [-0.33030343  0.75761079  9.72037122] 1.0\n",
      "positions (x,y,z), reward: [-0.70361474  1.27919304  9.37397161] 1.0\n",
      "positions (x,y,z), reward: [-5.84877116  7.22316187  2.60854165] 1.0\n",
      "Episode =  269, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.01822194e-03   3.77352995e-03   1.00215419e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.60063378 -0.06158767  9.78598943] 1.0\n",
      "positions (x,y,z), reward: [ 1.56803572 -0.1067296   9.03973426] 1.0\n",
      "positions (x,y,z), reward: [ 4.72100881 -0.44192531  6.53035099] 1.0\n",
      "positions (x,y,z), reward: [ 7.90591568 -0.9920877   3.07490604] 1.0\n",
      "positions (x,y,z), reward: [ 8.76507361 -1.12906368  2.00443915] 1.0\n",
      "positions (x,y,z), reward: [ 9.39676185 -1.22183954  1.17302038] 1.0\n",
      "positions (x,y,z), reward: [ 9.60482898 -1.24979354  0.88914443] 1.0\n",
      "Episode =  270, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00517236] 1.0\n",
      "positions (x,y,z), reward: [ -3.65346368e-02   7.30354236e-03   1.00160539e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.54025867  0.05937714  8.85829066] 1.0\n",
      "positions (x,y,z), reward: [ 2.33643028 -0.19320667  7.97203275] 1.0\n",
      "positions (x,y,z), reward: [ 4.99333618 -1.53076086  1.98708834] 1.0\n",
      "Episode =  271, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.026686   -0.01257103  9.92563248] 1.0\n",
      "positions (x,y,z), reward: [ 0.06777104 -0.01218824  9.90044048] 1.0\n",
      "positions (x,y,z), reward: [ 4.86209775 -3.1904764   4.42092702] 1.0\n",
      "positions (x,y,z), reward: [ 5.8251002  -3.66156678  3.0964519 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.31595932 -3.9112469   2.3774523 ] 1.0\n",
      "Episode =  272, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0671129   -0.33535797  10.14385597] 1.0\n",
      "positions (x,y,z), reward: [-2.87203838 -1.45506602  9.43472537] 1.0\n",
      "positions (x,y,z), reward: [-8.98753199 -1.32896706  5.22782502] 1.0\n",
      "positions (x,y,z), reward: [-13.23074879  -0.79626258   1.01561625] 1.0\n",
      "Episode =  273, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.79115566e-03  -2.86188737e-03   9.99497017e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.02025474  0.01857562  9.89007492] 1.0\n",
      "positions (x,y,z), reward: [-0.77765258  0.2096124   9.60214326] 1.0\n",
      "positions (x,y,z), reward: [-2.86279566  0.52775392  8.91518993] 1.0\n",
      "positions (x,y,z), reward: [-6.52148794  0.93736563  7.14015713] 1.0\n",
      "positions (x,y,z), reward: [-12.87563443   1.84975094   0.77365593] 1.0\n",
      "Episode =  274, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.51202032  0.92842755  8.55983423] 1.0\n",
      "positions (x,y,z), reward: [ 5.51610297  1.48720647  6.366847  ] 1.0\n",
      "positions (x,y,z), reward: [ 9.95704701  1.52467691  1.36919109] 1.0\n",
      "Episode =  275, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.77818706e-03  -3.18490995e-02   1.00510966e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.3450701  -0.09960485  9.89722755] 1.0\n",
      "positions (x,y,z), reward: [ 2.00233556 -0.04057935  8.65500577] 1.0\n",
      "positions (x,y,z), reward: [ 3.38038428  0.01342088  7.69543777] 1.0\n",
      "positions (x,y,z), reward: [ 7.32001222  0.03991963  3.68118845] 1.0\n",
      "positions (x,y,z), reward: [ 7.58954022  0.03092848  3.26362033] 1.0\n",
      "positions (x,y,z), reward: [  9.54395705e+00  -4.71401798e-03   0.00000000e+00] 1.0\n",
      "Episode =  276, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.43494986  0.14452362  9.72487587] 1.0\n",
      "positions (x,y,z), reward: [-0.19937282 -0.35898708  9.32703881] 1.0\n",
      "positions (x,y,z), reward: [-8.62986871 -0.19488009  4.20331103] 1.0\n",
      "positions (x,y,z), reward: [-11.00363609  -0.1959694    1.78091918] 1.0\n",
      "positions (x,y,z), reward: [-12.23880396  -0.23953163   0.28976873] 1.0\n",
      "Episode =  277, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11976219  0.02516383  9.96960378] 1.0\n",
      "Episode =  278, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.32557018e-01  -8.11326548e-03   9.98972800e+00] 1.0\n",
      "positions (x,y,z), reward: [ -0.38258277   0.01675779  10.07306972] 1.0\n",
      "positions (x,y,z), reward: [ -3.07653909   0.11853707  10.53177427] 1.0\n",
      "positions (x,y,z), reward: [-6.77925045  1.45916826  8.93573204] 1.0\n",
      "positions (x,y,z), reward: [-7.95479565  1.84275506  8.14160721] 1.0\n",
      "positions (x,y,z), reward: [-9.14147352  2.25474338  7.20973182] 1.0\n",
      "positions (x,y,z), reward: [-10.40531278   2.70128611   5.83874379] 1.0\n",
      "positions (x,y,z), reward: [-11.99689462   3.26889287   3.81565022] 1.0\n",
      "Episode =  280, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03606955  0.02585116  9.99910799] 1.0\n",
      "positions (x,y,z), reward: [ 0.23194626  0.54795449  9.51922469] 1.0\n",
      "positions (x,y,z), reward: [-2.06395106  3.27520118  7.61860562] 1.0\n",
      "positions (x,y,z), reward: [-6.8947201   6.93372266  3.72695303] 1.0\n",
      "positions (x,y,z), reward: [-7.89074668  7.53001447  2.5238623 ] 1.0\n",
      "positions (x,y,z), reward: [-8.38083122  7.83089801  1.87710282] 1.0\n",
      "Episode =  281, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.20011907   0.03688336  10.08273305] 1.0\n",
      "positions (x,y,z), reward: [ -0.87248794   0.05606111  10.28351609] 1.0\n",
      "positions (x,y,z), reward: [-3.20441404  1.05802218  9.87739273] 1.0\n",
      "positions (x,y,z), reward: [-4.28193372  1.56704745  9.50694431] 1.0\n",
      "positions (x,y,z), reward: [-5.84722996  2.34875999  8.89203907] 1.0\n",
      "positions (x,y,z), reward: [-11.29330546   5.5611427    5.14552029] 1.0\n",
      "Episode =  282, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.80962712 -3.69626957  4.42562547] 1.0\n",
      "Episode =  283, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.10238175 -1.5462415   8.43256832] 1.0\n",
      "positions (x,y,z), reward: [ 0.92182958 -1.93736798  7.81882252] 1.0\n",
      "positions (x,y,z), reward: [ 0.33905549 -2.53761524  6.44491839] 1.0\n",
      "positions (x,y,z), reward: [ 0.21996743 -2.64115018  6.13360447] 1.0\n",
      "positions (x,y,z), reward: [ 0.10300263 -2.73071065  5.80365053] 1.0\n",
      "positions (x,y,z), reward: [-0.34228001 -3.00207175  4.563664  ] 1.0\n",
      "Episode =  285, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06113409   0.01463265  10.00843019] 1.0\n",
      "positions (x,y,z), reward: [ 0.07925413 -0.06923197  9.76626689] 1.0\n",
      "positions (x,y,z), reward: [ 0.19169762 -0.08607748  9.66531815] 1.0\n",
      "positions (x,y,z), reward: [ 9.36608573 -0.41251181  0.        ] 1.0\n",
      "Episode =  286, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04862282  -0.02825478  10.05353825] 1.0\n",
      "positions (x,y,z), reward: [ 0.51862286 -0.29105641  9.76797854] 1.0\n",
      "positions (x,y,z), reward: [ 2.4588413  -4.06396368  5.73854497] 1.0\n",
      "Episode =  287, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  4.99686181e-03   7.60849430e-02   9.95350691e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.06681235  0.27545861  9.6936766 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.43376358  0.29968397  8.90862269] 1.0\n",
      "positions (x,y,z), reward: [ 0.47077771  0.28866128  8.77158821] 1.0\n",
      "positions (x,y,z), reward: [ 0.62203833  0.2221341   8.13285247] 1.0\n",
      "positions (x,y,z), reward: [ 0.50085703 -0.35614763  4.57164327] 1.0\n",
      "Episode =  288, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.57268308  2.82042879  9.47387124] 1.0\n",
      "positions (x,y,z), reward: [-7.19613968  3.51571885  8.7458364 ] 1.0\n",
      "positions (x,y,z), reward: [-9.46190194  4.13790999  7.29640326] 1.0\n",
      "Episode =  289, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  2.31592504e-02   7.60618247e-03   9.83090873e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.66953005 -1.82457604  6.93686157] 1.0\n",
      "positions (x,y,z), reward: [ 1.04245994 -4.13272061  0.97392296] 1.0\n",
      "Episode =  290, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.42543230e-03   2.99224714e-03   1.00122259e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.8245186  -0.46802043  9.14793013] 1.0\n",
      "positions (x,y,z), reward: [ 1.03219518 -3.17532846  3.09249209] 1.0\n",
      "Episode =  291, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.47796927e-02  -1.59354933e-04   9.99974715e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.41973961 -0.16755312  9.30518184] 1.0\n",
      "positions (x,y,z), reward: [ 0.91997995 -0.48079398  8.87157235] 1.0\n",
      "positions (x,y,z), reward: [ 1.01411242 -0.62195855  8.7025626 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.10864499 -1.5559089   7.09756699] 1.0\n",
      "positions (x,y,z), reward: [ 0.94683727 -2.04450873  5.97653111] 1.0\n",
      "Episode =  292, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.03287919 -0.01224458  9.93262027] 1.0\n",
      "positions (x,y,z), reward: [ 0.44111438 -0.14312613  9.5471017 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.78146903 -2.56617666  5.26376504] 1.0\n",
      "positions (x,y,z), reward: [ 1.75181797 -2.86415437  4.10179351] 1.0\n",
      "positions (x,y,z), reward: [ 1.72484937 -3.09237008  3.12138918] 1.0\n",
      "Episode =  293, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.13002637 -0.80127001  8.89987926] 1.0\n",
      "Episode =  294, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.55667263  0.13992378  9.6620063 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.57560003  0.12383406  9.61833763] 1.0\n",
      "positions (x,y,z), reward: [ 0.32375532 -0.04833295  9.08993536] 1.0\n",
      "positions (x,y,z), reward: [ 0.29050318 -0.08342235  9.02700149] 1.0\n",
      "positions (x,y,z), reward: [-1.02010533 -0.72674378  6.38726416] 1.0\n",
      "positions (x,y,z), reward: [-4.39131909 -0.87925688  1.16850606] 1.0\n",
      "Episode =  295, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 7.27746015 -1.39526089  2.71295649] 1.0\n",
      "positions (x,y,z), reward: [ 8.94419552 -1.49480964  0.        ] 1.0\n",
      "Episode =  296, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03064517   0.05952416  10.0052275 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.52709128  0.20642796  9.7201711 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.74626149  0.18806734  9.52968182] 1.0\n",
      "positions (x,y,z), reward: [ 1.74477832 -0.16835895  8.66505653] 1.0\n",
      "positions (x,y,z), reward: [ 4.4359     -0.8568623   6.40495112] 1.0\n",
      "Episode =  297, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08672666  0.13702988  9.93331162] 1.0\n",
      "positions (x,y,z), reward: [-0.4410792   0.89749613  9.96222652] 1.0\n",
      "positions (x,y,z), reward: [-2.55981458  0.99989027  8.11769413] 1.0\n",
      "Episode =  298, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.02026448 -2.43126766  5.16534532] 1.0\n",
      "positions (x,y,z), reward: [ 0.61435547 -4.01568232  0.05864346] 1.0\n",
      "Episode =  299, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.128993   -0.1991954   9.79374523] 1.0\n",
      "positions (x,y,z), reward: [ 1.5908202  -1.33691292  5.65702609] 1.0\n",
      "positions (x,y,z), reward: [ 1.65276314 -1.37918284  5.43423317] 1.0\n",
      "positions (x,y,z), reward: [ 2.2374295  -1.92542641  2.49345414] 1.0\n",
      "Episode =  300, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.04623441 -0.03613929  9.85663336] 1.0\n",
      "positions (x,y,z), reward: [ 0.43731884 -0.10407357  9.54026856] 1.0\n",
      "positions (x,y,z), reward: [ 2.75054044 -0.6876703   7.5952733 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.29639292 -1.39927598  4.21772394] 1.0\n",
      "Episode =  301, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.66520843  0.47661339  8.41134183] 1.0\n",
      "positions (x,y,z), reward: [ 4.27564802  1.42888072  2.70887215] 1.0\n",
      "positions (x,y,z), reward: [ 4.42140088  1.46295079  2.44208129] 1.0\n",
      "positions (x,y,z), reward: [ 4.56744132  1.4965645   2.17028378] 1.0\n",
      "Episode =  302, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.28730366e-03   1.82744145e-03   1.00154864e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.39836235 -0.44141217  9.43770615] 1.0\n",
      "positions (x,y,z), reward: [ 1.4168499  -0.6374813   9.30354402] 1.0\n",
      "Episode =  303, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.21126536 -0.04354234  9.90339586] 1.0\n",
      "positions (x,y,z), reward: [-0.29058807 -0.50706489  9.60352653] 1.0\n",
      "Episode =  304, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.31492417  0.11147254  9.892571  ] 1.0\n",
      "positions (x,y,z), reward: [-10.89339903   2.53182311   2.31210935] 1.0\n",
      "positions (x,y,z), reward: [-11.37256069   2.64658534   1.6066222 ] 1.0\n",
      "Episode =  305, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10533425 -0.01946328  9.95423101] 1.0\n",
      "positions (x,y,z), reward: [-0.32685555 -0.01729776  9.83846759] 1.0\n",
      "positions (x,y,z), reward: [-0.9095365  -0.02527338  9.53206844] 1.0\n",
      "positions (x,y,z), reward: [-2.81858702  0.32094225  8.14911132] 1.0\n",
      "positions (x,y,z), reward: [-4.60251669  0.62667394  6.54370142] 1.0\n",
      "positions (x,y,z), reward: [-7.48815964  1.17636529  3.04934955] 1.0\n",
      "Episode =  306, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -9.78471067e-03   6.82237874e-02   9.86527205e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.53496281  0.35010695  9.63498611] 1.0\n",
      "positions (x,y,z), reward: [-0.8445204   0.19945223  8.9889843 ] 1.0\n",
      "positions (x,y,z), reward: [-1.77403401  0.07733987  8.37084321] 1.0\n",
      "positions (x,y,z), reward: [-6.98573683 -0.74063553  3.27854622] 1.0\n",
      "positions (x,y,z), reward: [-8.00320301 -0.93289187  1.81036266] 1.0\n",
      "positions (x,y,z), reward: [-9.04761244 -1.12148277  0.15786007] 1.0\n",
      "Episode =  307, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.77403319  -0.14163691  10.51982831] 1.0\n",
      "positions (x,y,z), reward: [ -4.83404001  -0.11826354  10.36049723] 1.0\n",
      "positions (x,y,z), reward: [-9.42874046 -0.28447055  9.2711803 ] 1.0\n",
      "positions (x,y,z), reward: [-11.91923219  -0.46539055   8.26793203] 1.0\n",
      "positions (x,y,z), reward: [-18.70830932  -0.54567477   2.00490933] 1.0\n",
      "Episode =  308, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.55266087  1.59657521  9.68066332] 1.0\n",
      "positions (x,y,z), reward: [-4.68715319  2.2125495   8.57135534] 1.0\n",
      "positions (x,y,z), reward: [-5.65539718  2.45698255  7.81051262] 1.0\n",
      "positions (x,y,z), reward: [-8.22551476  2.83287207  5.26891681] 1.0\n",
      "positions (x,y,z), reward: [-11.51761583   3.26372086   1.16158184] 1.0\n",
      "Episode =  309, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.65583755  0.19714177  9.73219859] 1.0\n",
      "positions (x,y,z), reward: [ 1.00002643 -0.16470917  9.69574957] 1.0\n",
      "positions (x,y,z), reward: [-1.01510149 -1.32067807  8.43451049] 1.0\n",
      "positions (x,y,z), reward: [-2.52283803 -1.54477333  6.91627226] 1.0\n",
      "positions (x,y,z), reward: [-4.49937966 -1.98682526  4.00368763] 1.0\n",
      "positions (x,y,z), reward: [-5.12023226 -2.07965116  2.87495687] 1.0\n",
      "Episode =  310, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.29680899  0.6096553   7.59555611] 1.0\n",
      "positions (x,y,z), reward: [-2.28800139  0.55458639  1.02277777] 1.0\n",
      "Episode =  311, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.08537054e-02  -5.95370954e-03   9.98666013e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.1913121   0.2050576   9.74866795] 1.0\n",
      "positions (x,y,z), reward: [-0.25223501  0.44129119  9.70722888] 1.0\n",
      "positions (x,y,z), reward: [-5.13902176  0.40995098  9.43317568] 1.0\n",
      "positions (x,y,z), reward: [-14.59989803  -0.94365921   4.95276962] 1.0\n",
      "positions (x,y,z), reward: [-14.8498472   -1.00123844   4.75906667] 1.0\n",
      "positions (x,y,z), reward: [-16.93201966  -1.58739199   2.77982075] 1.0\n",
      "Episode =  312, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.07825041 -1.06752803  8.94966643] 1.0\n",
      "positions (x,y,z), reward: [ 0.95321643 -1.91189808  7.89878643] 1.0\n",
      "positions (x,y,z), reward: [ 0.62000036 -2.49993447  6.31597936] 1.0\n",
      "Episode =  313, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.4820625   0.41334979  9.91229122] 1.0\n",
      "positions (x,y,z), reward: [-0.56563359  0.43025194  9.90149082] 1.0\n",
      "positions (x,y,z), reward: [-0.97233036  0.55896831  9.85860895] 1.0\n",
      "positions (x,y,z), reward: [-7.51500151  3.6999675   8.35320623] 1.0\n",
      "Episode =  314, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.15922587 -0.27480933  9.55489548] 1.0\n",
      "positions (x,y,z), reward: [-0.53299651 -0.52326161  9.2348996 ] 1.0\n",
      "positions (x,y,z), reward: [-7.20367596 -2.11403958  2.98244542] 1.0\n",
      "positions (x,y,z), reward: [-8.41532196 -2.47615255  0.94221124] 1.0\n",
      "Episode =  316, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.88465025e-03  -3.30543427e-03   1.00155106e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.09805675  -0.14600076  10.03396248] 1.0\n",
      "Episode =  317, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.47818753 -0.35535193  9.5974566 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.73134599 -0.53387623  9.43295673] 1.0\n",
      "positions (x,y,z), reward: [ 0.46500999 -3.96906792  4.08454975] 1.0\n",
      "Episode =  318, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00494534] 1.0\n",
      "positions (x,y,z), reward: [ 0.43139503 -0.38266064  9.61890269] 1.0\n",
      "positions (x,y,z), reward: [ 1.36288101 -1.51857421  8.57945809] 1.0\n",
      "positions (x,y,z), reward: [ 1.35903923 -1.60213845  8.49278912] 1.0\n",
      "positions (x,y,z), reward: [ 1.2142515  -2.10232284  7.92099125] 1.0\n",
      "positions (x,y,z), reward: [ 0.84784573 -2.8617953   6.7044441 ] 1.0\n",
      "positions (x,y,z), reward: [-0.17741731 -3.80391441  3.38641158] 1.0\n",
      "positions (x,y,z), reward: [-0.47717968 -4.01287778  2.47177107] 1.0\n",
      "Episode =  319, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.28968586  0.16310117  9.45093294] 1.0\n",
      "Episode =  320, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.15326898 -0.02646411  9.06178271] 1.0\n",
      "positions (x,y,z), reward: [-8.76215548  3.72209906  0.        ] 1.0\n",
      "Episode =  321, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.24793106  -0.16653238  10.00783125] 1.0\n",
      "positions (x,y,z), reward: [ 2.52568507 -0.99678077  9.14766507] 1.0\n",
      "positions (x,y,z), reward: [ 4.31537636 -1.49159645  8.1792317 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.81458154 -1.59569528  7.93773059] 1.0\n",
      "positions (x,y,z), reward: [ 5.06017283 -1.65008523  7.82055145] 1.0\n",
      "positions (x,y,z), reward: [ 13.13924052  -4.02076718   1.86285836] 1.0\n",
      "Episode =  322, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.91462224  0.04700315  9.70874415] 1.0\n",
      "positions (x,y,z), reward: [-11.19524545   0.65294745   1.49733586] 1.0\n",
      "positions (x,y,z), reward: [-11.90810464   0.6828906    0.68451309] 1.0\n",
      "Episode =  323, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  9.80274570e-03  -2.39661172e-02   1.00719577e+01] 1.0\n",
      "positions (x,y,z), reward: [-2.97288385  2.24232791  8.82751035] 1.0\n",
      "positions (x,y,z), reward: [-3.13859749  2.36964909  8.73367903] 1.0\n",
      "positions (x,y,z), reward: [-4.09066501  3.13745556  8.05098376] 1.0\n",
      "positions (x,y,z), reward: [-11.74414956   8.605733     0.06710166] 1.0\n",
      "Episode =  324, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.32914329 -0.80719419  8.45346088] 1.0\n",
      "positions (x,y,z), reward: [ 2.09172235 -1.6541405   5.97895063] 1.0\n",
      "positions (x,y,z), reward: [ 2.67709043 -2.7815834   0.9216563 ] 1.0\n",
      "Episode =  325, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0345784   0.05116017  9.9922876 ] 1.0\n",
      "positions (x,y,z), reward: [  7.35004284e-03   7.10063163e-02   9.93546451e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.15735854  0.46368068  9.09687438] 1.0\n",
      "positions (x,y,z), reward: [ 4.17286125  2.19294382  7.45283705] 1.0\n",
      "positions (x,y,z), reward: [ 7.82080598  4.88312456  4.49638966] 1.0\n",
      "Episode =  326, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.06596263 -2.13250457  9.1275695 ] 1.0\n",
      "positions (x,y,z), reward: [-4.08292583 -2.4068716   8.88272061] 1.0\n",
      "positions (x,y,z), reward: [-5.58066099 -2.74572414  8.48979002] 1.0\n",
      "positions (x,y,z), reward: [-8.51061283 -3.07776827  7.68768938] 1.0\n",
      "positions (x,y,z), reward: [-19.47327368  -3.96813683   2.08105562] 1.0\n",
      "Episode =  327, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06577894  0.03428577  9.98051751] 1.0\n",
      "positions (x,y,z), reward: [-0.2767832  -1.01390576  9.26652229] 1.0\n",
      "positions (x,y,z), reward: [-3.39494823 -6.29493185  2.06153876] 1.0\n",
      "positions (x,y,z), reward: [-3.50112701 -6.44597396  1.79247107] 1.0\n",
      "Episode =  328, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07169671  0.4308887   9.45570738] 1.0\n",
      "positions (x,y,z), reward: [-0.35942287  0.5350634   8.31887996] 1.0\n",
      "positions (x,y,z), reward: [-0.57965776  0.61112695  7.42497703] 1.0\n",
      "positions (x,y,z), reward: [-1.99230343  1.14882021  0.97923149] 1.0\n",
      "positions (x,y,z), reward: [-2.18890751  1.17015639  0.16914869] 1.0\n",
      "Episode =  329, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.84975922  1.03094503  8.64421476] 1.0\n",
      "positions (x,y,z), reward: [-2.95389761  1.44403455  7.38178276] 1.0\n",
      "positions (x,y,z), reward: [-4.90761411  2.39235445  4.86863727] 1.0\n",
      "Episode =  330, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.47768558e-02   6.32543469e-03   1.00261520e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.49245342  0.04900175  9.60785016] 1.0\n",
      "positions (x,y,z), reward: [ 1.25876414 -0.11500455  8.77155491] 1.0\n",
      "positions (x,y,z), reward: [ 3.02745528  0.04024206  7.01062587] 1.0\n",
      "positions (x,y,z), reward: [ 6.46868174  0.33492009  2.89754626] 1.0\n",
      "Episode =  331, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03349892 -0.04031563  9.83810772] 1.0\n",
      "positions (x,y,z), reward: [ 0.01223579 -0.03871599  9.75332412] 1.0\n",
      "positions (x,y,z), reward: [ 1.61249864 -0.33511192  8.23789939] 1.0\n",
      "positions (x,y,z), reward: [ 2.34176265 -0.49003694  7.57720796] 1.0\n",
      "positions (x,y,z), reward: [ 4.34546762 -0.65601603  5.42678069] 1.0\n",
      "positions (x,y,z), reward: [ 5.76499656 -0.78455242  3.61163193] 1.0\n",
      "Episode =  332, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.15014149 -2.53590359  6.61947638] 1.0\n",
      "positions (x,y,z), reward: [ 4.38090541 -3.63298019  4.56651014] 1.0\n",
      "Episode =  333, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.75616571   0.44118384  10.56591414] 1.0\n",
      "positions (x,y,z), reward: [-15.83671203   4.66669726   7.87958674] 1.0\n",
      "positions (x,y,z), reward: [-23.6164962    7.05830317   4.30003058] 1.0\n",
      "positions (x,y,z), reward: [-26.07539956   7.88303524   2.67932636] 1.0\n",
      "positions (x,y,z), reward: [-29.17316699   8.9707092    0.24239625] 1.0\n",
      "Episode =  334, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.99352985e-02  -7.30526295e-03   1.00461852e+01] 1.0\n",
      "positions (x,y,z), reward: [-3.5268116   1.83841846  8.45587152] 1.0\n",
      "positions (x,y,z), reward: [-4.92358629  2.65787168  7.60878364] 1.0\n",
      "positions (x,y,z), reward: [-5.85796268  3.15505597  6.92068861] 1.0\n",
      "positions (x,y,z), reward: [-8.2936504   4.37270877  4.59986355] 1.0\n",
      "positions (x,y,z), reward: [-8.47442085  4.46035702  4.40220336] 1.0\n",
      "positions (x,y,z), reward: [-9.58271503  4.96634427  3.13419444] 1.0\n",
      "Episode =  335, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  1.02984189e-02  -9.45350855e-03   9.65370372e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.1243761  -0.09983172  8.78100259] 1.0\n",
      "positions (x,y,z), reward: [-0.27737687 -0.14105937  8.40723782] 1.0\n",
      "positions (x,y,z), reward: [-2.29806071 -0.1187111   1.08868836] 1.0\n",
      "Episode =  336, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.54279949 -1.85300708  7.9157927 ] 1.0\n",
      "positions (x,y,z), reward: [-1.69189091 -2.04046796  7.57199705] 1.0\n",
      "positions (x,y,z), reward: [-1.76457811 -2.13537866  7.39515473] 1.0\n",
      "positions (x,y,z), reward: [-2.32195115 -2.90141748  5.88339266] 1.0\n",
      "positions (x,y,z), reward: [-3.43792171 -5.00003909  1.14460804] 1.0\n",
      "Episode =  337, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0694343   0.15593188  9.92428976] 1.0\n",
      "positions (x,y,z), reward: [-2.43655917  0.83194411  9.60811159] 1.0\n",
      "positions (x,y,z), reward: [-4.55643698  0.90849397  7.98098497] 1.0\n",
      "positions (x,y,z), reward: [-7.94169469  0.95275523  5.04917227] 1.0\n",
      "positions (x,y,z), reward: [-9.23962809  1.04801573  3.76248463] 1.0\n",
      "Episode =  338, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.52749181 -1.00497978  7.76791332] 1.0\n",
      "positions (x,y,z), reward: [ 6.84670012 -2.41414709  3.74470779] 1.0\n",
      "Episode =  339, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.32053216e-02  -5.04395798e-03   1.00508286e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.07126388  -0.0116389   10.05041897] 1.0\n",
      "positions (x,y,z), reward: [ 0.19409925 -0.07656127  9.84557176] 1.0\n",
      "positions (x,y,z), reward: [-0.70573365  1.04091843  7.60805228] 1.0\n",
      "Episode =  340, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.01689318 -0.99832316  9.39432591] 1.0\n",
      "positions (x,y,z), reward: [ 0.95421048 -1.20148742  9.2763468 ] 1.0\n",
      "positions (x,y,z), reward: [-1.02177195 -1.21731288  6.34831585] 1.0\n",
      "positions (x,y,z), reward: [-1.8576429  -0.96539063  4.03651066] 1.0\n",
      "positions (x,y,z), reward: [-2.57871039 -0.81777571  1.59849365] 1.0\n",
      "positions (x,y,z), reward: [-2.64294088 -0.80641438  1.35219422] 1.0\n",
      "positions (x,y,z), reward: [-2.77453042 -0.78295507  0.84392363] 1.0\n",
      "Episode =  341, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.15049712 -0.46148288  9.42018973] 1.0\n",
      "positions (x,y,z), reward: [ 2.51989339 -0.58208809  9.3535527 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.64521394 -0.62751731  9.3381796 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.4320891  -1.08481739  9.25838048] 1.0\n",
      "positions (x,y,z), reward: [ 2.43464604 -4.35919204  5.56248742] 1.0\n",
      "positions (x,y,z), reward: [ 0.4111401  -6.01019388  1.14713389] 1.0\n",
      "Episode =  342, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.51509343 -0.087616    9.59284493] 1.0\n",
      "positions (x,y,z), reward: [-9.46513892  0.18043029  4.24593835] 1.0\n",
      "positions (x,y,z), reward: [-10.10340441   0.21712765   3.59188466] 1.0\n",
      "Episode =  343, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.21710383  0.05368414  9.98090852] 1.0\n",
      "Episode =  344, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00514253] 1.0\n",
      "positions (x,y,z), reward: [ -0.0613876   -0.05477752  10.0204784 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.06994543  -0.08406524  10.01618819] 1.0\n",
      "positions (x,y,z), reward: [ 2.65356592 -0.55149588  7.83978744] 1.0\n",
      "positions (x,y,z), reward: [ 6.26712584 -0.67343269  3.80305141] 1.0\n",
      "Episode =  345, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.15236704  0.01152785  9.84511933] 1.0\n",
      "positions (x,y,z), reward: [-0.14749609  0.05468821  9.29629443] 1.0\n",
      "positions (x,y,z), reward: [ 0.3841762   0.13788556  8.1162834 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.58803316  0.1752809   5.24592402] 1.0\n",
      "positions (x,y,z), reward: [ 0.24407723  0.19083671  3.60302394] 1.0\n",
      "positions (x,y,z), reward: [-0.01955776  0.21064123  2.35250928] 1.0\n",
      "Episode =  346, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.55697877e-03   1.02673383e-03   1.00172728e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.05475141e-03   5.03827639e-02   9.78062565e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.08437174  0.10593904  9.01383025] 1.0\n",
      "positions (x,y,z), reward: [ 0.61273069  0.28930445  6.72051717] 1.0\n",
      "positions (x,y,z), reward: [ 0.87555728  0.35129667  5.50675083] 1.0\n",
      "Episode =  347, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.74158130e-02   9.73768114e-03   1.00168659e+01] 1.0\n",
      "positions (x,y,z), reward: [ -4.74658372e-02   7.26328842e-03   1.00084622e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.88655705 -1.0466136   6.97272354] 1.0\n",
      "positions (x,y,z), reward: [ 2.08495896 -1.45058716  5.85333372] 1.0\n",
      "Episode =  348, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.59691229e-03  -6.01343547e-04   1.00156720e+01] 1.0\n",
      "positions (x,y,z), reward: [ 11.13773743  -0.95767975   2.57090154] 1.0\n",
      "Episode =  349, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10862526  0.02893337  9.92306643] 1.0\n",
      "positions (x,y,z), reward: [-0.11634886  0.03440241  9.69558334] 1.0\n",
      "positions (x,y,z), reward: [ 4.6913699  -0.35009013  4.78245815] 1.0\n",
      "Episode =  350, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.10606121  0.25817973  9.58936764] 1.0\n",
      "positions (x,y,z), reward: [ 0.01713754 -0.44029582  8.88085263] 1.0\n",
      "positions (x,y,z), reward: [-0.45302279 -1.80092116  7.69433988] 1.0\n",
      "positions (x,y,z), reward: [-0.66378618 -2.26753621  7.13058409] 1.0\n",
      "Episode =  351, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05115625   0.02369692  10.02271865] 1.0\n",
      "positions (x,y,z), reward: [-0.03850425  0.05007442  9.9491105 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.14675979  0.13984335  9.65218793] 1.0\n",
      "positions (x,y,z), reward: [ 1.46470328  0.37662212  8.60017006] 1.0\n",
      "positions (x,y,z), reward: [ 5.1033506   0.59582545  5.02113697] 1.0\n",
      "positions (x,y,z), reward: [ 5.68615696  0.57588869  4.33015801] 1.0\n",
      "Episode =  352, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.07655363  0.0388501   9.97915683] 1.0\n",
      "Episode =  353, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  1.50677954e+00   6.92669426e-03   9.25015549e+00] 1.0\n",
      "positions (x,y,z), reward: [ 3.63460681  0.27735858  7.95688172] 1.0\n",
      "positions (x,y,z), reward: [ 4.15077263  0.39512073  7.49640982] 1.0\n",
      "positions (x,y,z), reward: [ 4.88708782  0.65940076  6.62138797] 1.0\n",
      "positions (x,y,z), reward: [ 6.96571602  1.51385756  1.78029119] 1.0\n",
      "Episode =  354, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04977031  -0.02251023  10.05537109] 1.0\n",
      "positions (x,y,z), reward: [ 0.23160175  0.26708898  9.45546793] 1.0\n",
      "positions (x,y,z), reward: [ 0.26126551  0.31490719  9.3488839 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.06437274  3.11601206  5.11074666] 1.0\n",
      "positions (x,y,z), reward: [ 5.2606557   4.74969862  1.82415545] 1.0\n",
      "positions (x,y,z), reward: [ 6.56372498  5.58839676  0.        ] 1.0\n",
      "Episode =  355, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.40434808  0.3741687   8.58011978] 1.0\n",
      "positions (x,y,z), reward: [ 0.72637851  0.69978419  7.22007576] 1.0\n",
      "positions (x,y,z), reward: [ 1.59703086  0.82824766  1.19870729] 1.0\n",
      "Episode =  356, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.18235903 -0.10504653  9.91497613] 1.0\n",
      "positions (x,y,z), reward: [ 2.0943127  -1.97906727  7.81070886] 1.0\n",
      "positions (x,y,z), reward: [ 2.49633731 -2.46128139  6.67577015] 1.0\n",
      "positions (x,y,z), reward: [ 3.03497493 -2.9476323   5.21188875] 1.0\n",
      "positions (x,y,z), reward: [ 4.11152046 -4.10077711  0.69799939] 1.0\n",
      "Episode =  357, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.12869444e-03  -3.50028510e-05   1.00179845e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.54550161 -0.38482766  9.36282025] 1.0\n",
      "positions (x,y,z), reward: [ 2.09358624 -2.99712806  6.041413  ] 1.0\n",
      "Episode =  358, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.75399586e-03  -1.66091250e-03   1.00193772e+01] 1.0\n",
      "positions (x,y,z), reward: [ 3.29946929 -1.23757732  7.71133677] 1.0\n",
      "positions (x,y,z), reward: [ 5.16313336 -1.86131883  6.1209631 ] 1.0\n",
      "positions (x,y,z), reward: [ 5.35400906 -1.92122665  5.94090492] 1.0\n",
      "Episode =  359, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.11160111  0.77122278  6.97622799] 1.0\n",
      "positions (x,y,z), reward: [ 1.39325132  1.22203224  4.55400973] 1.0\n",
      "Episode =  360, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16195282  0.1598204   6.90092785] 1.0\n",
      "positions (x,y,z), reward: [-0.65044315  0.26616617  5.8845273 ] 1.0\n",
      "positions (x,y,z), reward: [-1.37228252  0.40891191  4.31058923] 1.0\n",
      "positions (x,y,z), reward: [-2.1908047   0.58022322  2.24954895] 1.0\n",
      "Episode =  361, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00544073] 1.0\n",
      "positions (x,y,z), reward: [ 0.09995406  0.78605553  8.97834728] 1.0\n",
      "positions (x,y,z), reward: [-0.01384666  1.03559409  8.72504278] 1.0\n",
      "Episode =  362, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08566173  0.0261175   9.95892923] 1.0\n",
      "positions (x,y,z), reward: [ 1.40651885 -0.16444266  6.95119461] 1.0\n",
      "positions (x,y,z), reward: [ 1.09816336 -0.60329477  3.73105826] 1.0\n",
      "Episode =  363, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05272313  -0.07075415  10.03597751] 1.0\n",
      "positions (x,y,z), reward: [ 0.02564304 -0.11454563  9.97969318] 1.0\n",
      "positions (x,y,z), reward: [ 1.41326386 -0.65635336  8.61295471] 1.0\n",
      "positions (x,y,z), reward: [ 1.38502842 -2.00947098  6.36079557] 1.0\n",
      "positions (x,y,z), reward: [ 0.85561931 -3.48491294  3.04010962] 1.0\n",
      "positions (x,y,z), reward: [ 0.56844047 -4.17648524  1.11121547] 1.0\n",
      "Episode =  364, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13115375 -0.08868901  9.88801012] 1.0\n",
      "positions (x,y,z), reward: [ 1.79814038 -4.08894569  1.98838138] 1.0\n",
      "positions (x,y,z), reward: [ 1.74767455 -4.40125701  0.98538353] 1.0\n",
      "Episode =  365, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.79000213  0.91498349  5.92325987] 1.0\n",
      "positions (x,y,z), reward: [ 4.04963615  1.03804108  5.54351367] 1.0\n",
      "positions (x,y,z), reward: [ 4.99153903  1.54085129  3.86388768] 1.0\n",
      "positions (x,y,z), reward: [ 5.21795454  1.65816153  3.38919121] 1.0\n",
      "positions (x,y,z), reward: [ 6.21639888  2.16959801  0.99475586] 1.0\n",
      "Episode =  366, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.14507853 -0.14389807  8.98335562] 1.0\n",
      "positions (x,y,z), reward: [ 5.15587938 -2.08461574  1.59123444] 1.0\n",
      "Episode =  367, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.63315014 -1.28670628  8.98681615] 1.0\n",
      "positions (x,y,z), reward: [ 2.35244728 -1.82424474  8.28622959] 1.0\n",
      "positions (x,y,z), reward: [ 2.59890723 -2.00442698  8.02011049] 1.0\n",
      "Episode =  368, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.0332131  -0.38311807  9.56257808] 1.0\n",
      "positions (x,y,z), reward: [ 3.7111701  -0.7040843   8.13350277] 1.0\n",
      "positions (x,y,z), reward: [ 4.81047286 -0.7117077   7.61164886] 1.0\n",
      "positions (x,y,z), reward: [ 5.93076493 -0.6497745   7.02773877] 1.0\n",
      "positions (x,y,z), reward: [ 6.60837579 -0.58648032  6.60008454] 1.0\n",
      "positions (x,y,z), reward: [ 9.01155851 -0.26498794  4.9228389 ] 1.0\n",
      "positions (x,y,z), reward: [ 13.3959756    0.35313621   1.59783136] 1.0\n",
      "Episode =  369, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.61612355 -0.46004419  9.95784682] 1.0\n",
      "Episode =  370, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06781308  0.03698557  9.97461808] 1.0\n",
      "positions (x,y,z), reward: [-11.23609974  -3.36110907   3.23223031] 1.0\n",
      "positions (x,y,z), reward: [-12.66818296  -3.65499926   1.85522855] 1.0\n",
      "Episode =  371, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.24413505  0.03768255  9.90018824] 1.0\n",
      "positions (x,y,z), reward: [ 0.31995262  2.59347229  6.34346679] 1.0\n",
      "positions (x,y,z), reward: [-1.63826424  3.65475866  1.57067233] 1.0\n",
      "positions (x,y,z), reward: [-2.16350852  3.94924442  0.19940154] 1.0\n",
      "Episode =  372, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00543558] 1.0\n",
      "positions (x,y,z), reward: [ 0.02568573  0.06445916  9.94243436] 1.0\n",
      "positions (x,y,z), reward: [ 0.07296965  0.12663649  9.8622624 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.19582593  1.45612191  5.92876824] 1.0\n",
      "positions (x,y,z), reward: [ 2.20932397  1.69902739  4.68304711] 1.0\n",
      "positions (x,y,z), reward: [ 2.14310083  2.1003547   2.81827512] 1.0\n",
      "Episode =  373, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.3982616  -0.12898264  9.49507882] 1.0\n",
      "positions (x,y,z), reward: [ 2.11287592 -0.22805549  9.24268314] 1.0\n",
      "positions (x,y,z), reward: [ 7.48057294 -0.34566467  5.23057455] 1.0\n",
      "Episode =  374, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07003547  -0.07569871  10.01614439] 1.0\n",
      "positions (x,y,z), reward: [ 0.52871076 -0.50965068  9.56040182] 1.0\n",
      "positions (x,y,z), reward: [ 0.63298816 -0.55065225  9.48678501] 1.0\n",
      "positions (x,y,z), reward: [ 0.74422665 -0.59189449  9.41046545] 1.0\n",
      "positions (x,y,z), reward: [ 3.27795586 -1.64708069  7.4591058 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.16871141 -2.68453549  4.42659539] 1.0\n",
      "Episode =  375, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.80816943e-03   3.52007969e-03   1.00153273e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.32610480e-01   9.18380876e-03   1.00124133e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.05932764 -0.33277494  7.90638684] 1.0\n",
      "Episode =  376, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.7234323   1.84118779  8.24141004] 1.0\n",
      "positions (x,y,z), reward: [-8.32159522  5.55685127  0.        ] 1.0\n",
      "Episode =  377, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.1705661  -0.22993174  9.2566802 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.61632093 -0.49064853  8.91609355] 1.0\n",
      "positions (x,y,z), reward: [ 2.18098125 -0.84206158  8.20591562] 1.0\n",
      "positions (x,y,z), reward: [ 2.46172314 -0.94298244  7.83523068] 1.0\n",
      "positions (x,y,z), reward: [ 4.16588887 -2.25168311  0.        ] 1.0\n",
      "Episode =  378, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.38820653 -0.01300686  9.83845032] 1.0\n",
      "positions (x,y,z), reward: [ 2.27602572 -1.98325524  5.94148018] 1.0\n",
      "Episode =  379, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.34052739  0.32021215  9.51820469] 1.0\n",
      "positions (x,y,z), reward: [ 5.80905946  0.78766363  3.08929907] 1.0\n",
      "positions (x,y,z), reward: [ 6.23760414  0.79745097  1.81532   ] 1.0\n",
      "Episode =  380, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05910146  0.05962838  9.90687045] 1.0\n",
      "positions (x,y,z), reward: [ 0.4212605   0.48010915  9.57255421] 1.0\n",
      "positions (x,y,z), reward: [ 0.84580365  1.0375021   9.08952653] 1.0\n",
      "positions (x,y,z), reward: [ 4.03006222  2.29730499  2.84993392] 1.0\n",
      "positions (x,y,z), reward: [ 4.31677193  2.32727535  1.17329776] 1.0\n",
      "Episode =  381, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.1375445   0.47735558  9.3599822 ] 1.0\n",
      "positions (x,y,z), reward: [-2.90762867  3.23066789  4.40727478] 1.0\n",
      "positions (x,y,z), reward: [-4.56269649  4.59131098  1.1866783 ] 1.0\n",
      "positions (x,y,z), reward: [-5.27506623  5.08427349  0.        ] 1.0\n",
      "Episode =  382, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0513353    0.01391291  10.01956869] 1.0\n",
      "positions (x,y,z), reward: [ 2.91756709 -1.14928446  6.67046718] 1.0\n",
      "positions (x,y,z), reward: [ 3.02536488 -1.30188748  6.02901216] 1.0\n",
      "positions (x,y,z), reward: [ 3.07642436 -1.38627164  5.68383669] 1.0\n",
      "positions (x,y,z), reward: [ 3.27404008 -1.76710795  4.08960336] 1.0\n",
      "positions (x,y,z), reward: [ 3.33764622 -1.9134252   3.40820898] 1.0\n",
      "positions (x,y,z), reward: [ 3.32614557 -2.69808768  0.        ] 1.0\n",
      "Episode =  383, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.48069566  -2.26617686  10.07296711] 1.0\n",
      "positions (x,y,z), reward: [-3.20923156 -6.38791397  8.10315385] 1.0\n",
      "positions (x,y,z), reward: [ -4.44957699 -12.04658463   3.42273226] 1.0\n",
      "Episode =  384, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.62789756 -1.1723944   2.6393651 ] 1.0\n",
      "Episode =  385, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.37311704e-02  -5.01158219e-03   1.00169295e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.6558501  -0.48443457  9.19557958] 1.0\n",
      "positions (x,y,z), reward: [ 0.69763429 -1.09426719  8.17169627] 1.0\n",
      "positions (x,y,z), reward: [ 0.82470244 -2.24810783  5.6081556 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.77854367 -2.34344334  5.16490697] 1.0\n",
      "Episode =  386, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.11137952  0.07596417  9.54650057] 1.0\n",
      "positions (x,y,z), reward: [-2.40228894 -0.22285958  7.92933974] 1.0\n",
      "positions (x,y,z), reward: [-8.66645948  0.63642393  3.46452211] 1.0\n",
      "positions (x,y,z), reward: [-9.95449561  0.84272668  2.1586137 ] 1.0\n",
      "Episode =  387, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.33827500e-03  -1.14226645e-03   1.00134229e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.99983022 -0.35188413  8.42105399] 1.0\n",
      "positions (x,y,z), reward: [ 3.22843209 -1.03538316  3.94250594] 1.0\n",
      "Episode =  388, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  8.32508676e-03  -2.87374210e-01   9.77412395e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.8951366  -1.14848595  8.9159496 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.61931344 -4.56291053  4.54621758] 1.0\n",
      "Episode =  389, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.79841972 -0.24499897  7.86311879] 1.0\n",
      "positions (x,y,z), reward: [ 5.81850275 -1.06256345  0.72321863] 1.0\n",
      "Episode =  390, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.23085762 -0.32230624  9.59231403] 1.0\n",
      "positions (x,y,z), reward: [ 3.73193753 -0.95911706  5.52805835] 1.0\n",
      "positions (x,y,z), reward: [ 5.93487824 -1.67126828  1.66356839] 1.0\n",
      "Episode =  391, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.47307082 -0.10605605  9.54862386] 1.0\n",
      "positions (x,y,z), reward: [ 0.6467987  -0.16751414  9.2947786 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.01413034 -0.40017369  8.72186132] 1.0\n",
      "positions (x,y,z), reward: [ 2.69000991 -1.10462003  6.34600241] 1.0\n",
      "positions (x,y,z), reward: [ 2.83737337 -1.15213856  6.1543683 ] 1.0\n",
      "Episode =  392, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.24680473  0.13255545  8.64395359] 1.0\n",
      "positions (x,y,z), reward: [-4.92137271  0.29788801  7.19919056] 1.0\n",
      "positions (x,y,z), reward: [-8.08133511  0.44706154  4.71914775] 1.0\n",
      "positions (x,y,z), reward: [-10.27120251   0.64333993   2.61626014] 1.0\n",
      "positions (x,y,z), reward: [-10.72235809   0.6940069    2.16437672] 1.0\n",
      "positions (x,y,z), reward: [-10.94955248   0.72082551   1.9348088 ] 1.0\n",
      "positions (x,y,z), reward: [-11.63396357   0.79824331   1.2297742 ] 1.0\n",
      "Episode =  393, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.08706434 -1.99904789  7.52997036] 1.0\n",
      "positions (x,y,z), reward: [-0.32855765 -2.68557171  6.03767297] 1.0\n",
      "Episode =  395, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.51023613 -0.02084408  9.74853582] 1.0\n",
      "positions (x,y,z), reward: [ 8.16949557 -2.9824721   3.51229654] 1.0\n",
      "positions (x,y,z), reward: [ 8.87406492 -3.24143948  2.80538897] 1.0\n",
      "Episode =  396, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.38922471e-03  -2.24221145e-03   1.00095638e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.31746112  0.01220213  7.78943945] 1.0\n",
      "positions (x,y,z), reward: [ 1.50360372  0.21643532  6.89860031] 1.0\n",
      "positions (x,y,z), reward: [ 1.53753578  0.59328447  4.60440299] 1.0\n",
      "positions (x,y,z), reward: [ 1.52746826  0.77353751  2.78366234] 1.0\n",
      "positions (x,y,z), reward: [ 1.50519354  0.85118489  1.80595048] 1.0\n",
      "positions (x,y,z), reward: [ 1.45260624  0.95661253  0.        ] 1.0\n",
      "Episode =  397, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.20318035 -0.99045076  9.82691042] 1.0\n",
      "positions (x,y,z), reward: [ 0.85660246 -1.53308036  9.71176168] 1.0\n",
      "positions (x,y,z), reward: [-1.13620161 -2.90620805  8.08839378] 1.0\n",
      "positions (x,y,z), reward: [-2.55877835 -5.14217539  2.946362  ] 1.0\n",
      "Episode =  398, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05696013 -0.20273517  9.8176899 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.21057626 -0.3024494   9.61903408] 1.0\n",
      "positions (x,y,z), reward: [ 0.28151099 -0.33606242  9.54627985] 1.0\n",
      "positions (x,y,z), reward: [ 3.03671537 -1.35023358  6.63745789] 1.0\n",
      "positions (x,y,z), reward: [ 5.55146655 -2.53523402  2.94716441] 1.0\n",
      "Episode =  399, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.53764591 -0.11231181  9.51333093] 1.0\n",
      "positions (x,y,z), reward: [-2.7991267   0.18983268  9.13950824] 1.0\n",
      "positions (x,y,z), reward: [-8.79064839  1.17971555  5.92402084] 1.0\n",
      "positions (x,y,z), reward: [-9.36374968  1.26571634  5.4252463 ] 1.0\n",
      "Episode =  400, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.21572757 -0.45413915  9.71070985] 1.0\n",
      "Episode =  401, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.72101670e-01  -8.94789534e-03   1.00272540e+01] 1.0\n",
      "positions (x,y,z), reward: [ 2.48319849 -0.79064855  7.72657999] 1.0\n",
      "positions (x,y,z), reward: [ 3.91484682 -3.02860257  2.52682636] 1.0\n",
      "positions (x,y,z), reward: [ 4.27639562 -3.94753752  0.06261275] 1.0\n",
      "Episode =  402, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.42101048 -3.36743409  4.23547257] 1.0\n",
      "Episode =  403, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.01813599 -0.0248965   9.9871255 ] 1.0\n",
      "positions (x,y,z), reward: [-3.13748116 -0.06178576  9.05926161] 1.0\n",
      "positions (x,y,z), reward: [-4.35744186  0.04505727  8.2918894 ] 1.0\n",
      "positions (x,y,z), reward: [-10.40056272   0.93752991   4.19193156] 1.0\n",
      "Episode =  404, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.62340323 -3.78382863  7.87209779] 1.0\n",
      "positions (x,y,z), reward: [ 1.59953065 -3.90653665  7.76080985] 1.0\n",
      "positions (x,y,z), reward: [ 1.19248312 -5.27593059  6.2727326 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.58906866 -6.56129219  4.33217152] 1.0\n",
      "positions (x,y,z), reward: [-0.09789048 -7.952405    1.64751338] 1.0\n",
      "Episode =  405, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11127518  0.12992408  9.97453718] 1.0\n",
      "positions (x,y,z), reward: [-0.22033971  0.2618909   9.90427473] 1.0\n",
      "positions (x,y,z), reward: [ 1.54594848  2.80993774  3.78646914] 1.0\n",
      "positions (x,y,z), reward: [ 2.53671761  3.31142927  1.35217196] 1.0\n",
      "Episode =  406, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-4.27950445  4.47248263  0.41785836] 1.0\n",
      "Episode =  407, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  9.54282631e-03  -7.16963987e-02   9.91901418e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.22450617 -0.64033326  8.94898841] 1.0\n",
      "positions (x,y,z), reward: [-0.4703754  -0.92346367  8.40483239] 1.0\n",
      "Episode =  408, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13749362  0.37123512  9.82821675] 1.0\n",
      "positions (x,y,z), reward: [ 0.13872237  0.50922351  9.81982597] 1.0\n",
      "positions (x,y,z), reward: [-0.58577641  0.68883307  9.80137193] 1.0\n",
      "positions (x,y,z), reward: [-3.52946823  0.96448252  8.33568631] 1.0\n",
      "positions (x,y,z), reward: [-4.99263705  0.99973083  7.37928995] 1.0\n",
      "positions (x,y,z), reward: [-8.54492655  1.12408513  4.47918288] 1.0\n",
      "positions (x,y,z), reward: [-12.47352303   1.44442267   0.85335656] 1.0\n",
      "Episode =  409, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.92910849 -1.92388066  7.69524052] 1.0\n",
      "positions (x,y,z), reward: [-2.88386302 -3.72603787  4.46501225] 1.0\n",
      "positions (x,y,z), reward: [-4.89078416 -5.40409902  0.81136175] 1.0\n",
      "positions (x,y,z), reward: [-5.03136429 -5.52486361  0.53195731] 1.0\n",
      "Episode =  410, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.03293818  0.17008195  7.36371795] 1.0\n",
      "positions (x,y,z), reward: [-2.68894714  0.4858246   3.24890868] 1.0\n",
      "Episode =  411, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00543245] 1.0\n",
      "positions (x,y,z), reward: [-1.80232497 -1.24381604  9.75324912] 1.0\n",
      "positions (x,y,z), reward: [-3.83175591 -2.40358215  8.80809483] 1.0\n",
      "Episode =  412, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.25350140e-03  -1.49372444e-03   1.00174023e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.37979849 -0.61928089  9.75922905] 1.0\n",
      "positions (x,y,z), reward: [ 1.12202429 -1.24608945  9.77475474] 1.0\n",
      "positions (x,y,z), reward: [-10.1886208    0.26440856   4.03306933] 1.0\n",
      "Episode =  413, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.94707286 -1.47536862  8.43109041] 1.0\n",
      "positions (x,y,z), reward: [-9.41525363 -2.2183765   6.41307667] 1.0\n",
      "positions (x,y,z), reward: [-10.90155847  -2.62307857   5.07455043] 1.0\n",
      "positions (x,y,z), reward: [-14.37020242  -3.64795424   1.09510858] 1.0\n",
      "Episode =  414, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.82271206  1.7411836   3.48292359] 1.0\n",
      "positions (x,y,z), reward: [ 4.10146857  1.83688421  3.03218579] 1.0\n",
      "positions (x,y,z), reward: [ 5.92231984  2.4568884   0.        ] 1.0\n",
      "Episode =  415, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0443173   0.03025249  9.98041153] 1.0\n",
      "Episode =  416, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.25727243 -0.0153909   9.77374705] 1.0\n",
      "positions (x,y,z), reward: [-0.30630337  0.03774721  9.68688078] 1.0\n",
      "positions (x,y,z), reward: [-0.50811052  0.15167137  9.45211756] 1.0\n",
      "positions (x,y,z), reward: [-1.74475944  0.42467241  8.59223961] 1.0\n",
      "positions (x,y,z), reward: [-2.90843627  0.66300565  7.62711521] 1.0\n",
      "positions (x,y,z), reward: [-3.21457459  0.71266286  7.33835311] 1.0\n",
      "positions (x,y,z), reward: [-6.28774159  1.30167943  3.66701036] 1.0\n",
      "positions (x,y,z), reward: [-8.50121591  1.86212218  0.3930014 ] 1.0\n",
      "Episode =  417, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.61974166e-02  -2.96777508e-03   9.66862854e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.96441474 -0.67590864  8.23821444] 1.0\n",
      "positions (x,y,z), reward: [ 1.39172827 -0.91072001  7.75902537] 1.0\n",
      "positions (x,y,z), reward: [ 1.86197759 -1.0913072   7.18912252] 1.0\n",
      "positions (x,y,z), reward: [ 2.79809363 -1.53740212  5.22849786] 1.0\n",
      "positions (x,y,z), reward: [ 2.88887963 -1.57504907  5.04597136] 1.0\n",
      "Episode =  418, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.33304389 -0.20965798  9.83758634] 1.0\n",
      "positions (x,y,z), reward: [ 2.51715298 -4.28511916  3.20183575] 1.0\n",
      "Episode =  419, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.68506609e-03  -3.05490837e-04   1.00163892e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.02185861  -0.06748482  10.030433  ] 1.0\n",
      "positions (x,y,z), reward: [ 1.08717706 -1.19686348  8.95290341] 1.0\n",
      "positions (x,y,z), reward: [ 1.46026309 -2.23022513  7.86580152] 1.0\n",
      "Episode =  420, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.15135444e-03   2.80431924e-03   1.00071845e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.16389573  0.17415516  9.77395778] 1.0\n",
      "positions (x,y,z), reward: [-0.46280544 -0.33965653  9.14402191] 1.0\n",
      "positions (x,y,z), reward: [-0.56769281 -0.37693274  9.07704526] 1.0\n",
      "positions (x,y,z), reward: [-3.12467593 -1.29413461  6.82260333] 1.0\n",
      "Episode =  421, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.44355011  4.16858654  6.92238809] 1.0\n",
      "positions (x,y,z), reward: [-4.70700049  6.83841654  3.95994027] 1.0\n",
      "positions (x,y,z), reward: [-5.44697744  7.67924422  2.76481855] 1.0\n",
      "Episode =  422, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02185298  0.04707759  9.93654419] 1.0\n",
      "positions (x,y,z), reward: [ 1.74837656  0.12263103  8.33293355] 1.0\n",
      "Episode =  423, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.1223976    0.11860076  10.03051733] 1.0\n",
      "positions (x,y,z), reward: [ -0.52196942   0.0731099   10.37679446] 1.0\n",
      "positions (x,y,z), reward: [ -1.18750893  -0.2270986   10.43371416] 1.0\n",
      "positions (x,y,z), reward: [-4.84566883 -0.88450037  7.79289309] 1.0\n",
      "positions (x,y,z), reward: [-5.27424176 -0.98468816  7.21468333] 1.0\n",
      "positions (x,y,z), reward: [-6.73219243 -1.32469639  4.99972594] 1.0\n",
      "positions (x,y,z), reward: [-7.63851199 -1.51637884  3.50264328] 1.0\n",
      "Episode =  424, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.87459346  0.66999321  7.57778016] 1.0\n",
      "positions (x,y,z), reward: [ 2.28448821  1.04688029  5.74790623] 1.0\n",
      "Episode =  425, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06833417  0.22284095  9.89878902] 1.0\n",
      "positions (x,y,z), reward: [ -0.29452081   0.11038426  10.09945713] 1.0\n",
      "positions (x,y,z), reward: [ -0.62049401   0.11071656  10.1704437 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.84712019   0.10702022  10.24282656] 1.0\n",
      "positions (x,y,z), reward: [ -1.06533379   0.09303357  10.31301517] 1.0\n",
      "positions (x,y,z), reward: [-2.93398153  0.6300262   9.51011539] 1.0\n",
      "positions (x,y,z), reward: [-3.12426827  0.88979086  8.19698871] 1.0\n",
      "positions (x,y,z), reward: [-3.27969062  0.92192089  7.66759539] 1.0\n",
      "Episode =  426, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.16114299 -0.17199782  9.40988763] 1.0\n",
      "positions (x,y,z), reward: [-0.36725479 -0.68432898  7.77161053] 1.0\n",
      "positions (x,y,z), reward: [-0.84260294 -0.92667216  5.5366078 ] 1.0\n",
      "positions (x,y,z), reward: [-1.59076585 -0.648377    2.15602318] 1.0\n",
      "positions (x,y,z), reward: [-1.95932674 -0.49284193  0.14237643] 1.0\n",
      "Episode =  427, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.09200113 -0.03349709  9.9327912 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.24444903 -0.13453742  9.04533445] 1.0\n",
      "positions (x,y,z), reward: [-0.18714209  0.31518878  8.53491892] 1.0\n",
      "Episode =  428, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00466793] 1.0\n",
      "positions (x,y,z), reward: [ 0.61447935  0.03853279  9.56637131] 1.0\n",
      "positions (x,y,z), reward: [ 0.76122609 -0.22957343  9.29045358] 1.0\n",
      "positions (x,y,z), reward: [ 1.02446345 -1.58294742  4.40378939] 1.0\n",
      "positions (x,y,z), reward: [ 1.31817096 -1.74806961  3.44266647] 1.0\n",
      "positions (x,y,z), reward: [ 1.51405266 -1.84605575  2.83692741] 1.0\n",
      "positions (x,y,z), reward: [ 1.84117625 -2.00962067  1.76768297] 1.0\n",
      "positions (x,y,z), reward: [ 2.38436743 -2.37425599  0.        ] 1.0\n",
      "Episode =  429, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  5.18675481e-03   4.58969704e-02   9.95738048e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.37316363  0.07871367  9.73592989] 1.0\n",
      "positions (x,y,z), reward: [ 6.50745415  0.45443721  3.68828706] 1.0\n",
      "Episode =  430, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-10.6902754    0.58065752   8.96288118] 1.0\n",
      "positions (x,y,z), reward: [-14.5425733    1.08377648   5.73558932] 1.0\n",
      "Episode =  431, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-11.78951088   2.1197647    3.44518383] 1.0\n",
      "Episode =  432, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02074469   0.01211261  10.01437359] 1.0\n",
      "positions (x,y,z), reward: [ 4.47021173 -3.31660215  2.1202652 ] 1.0\n",
      "positions (x,y,z), reward: [ 5.08344353 -4.08678849  0.        ] 1.0\n",
      "Episode =  433, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.07721769e-02   6.23736416e-03   9.93510173e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.29300915  0.30138071  9.74019245] 1.0\n",
      "positions (x,y,z), reward: [ 0.30780186  0.30456725  9.75063142] 1.0\n",
      "positions (x,y,z), reward: [-0.2330069   0.22288796  9.63469644] 1.0\n",
      "positions (x,y,z), reward: [-3.28752165  0.10340112  8.91753808] 1.0\n",
      "positions (x,y,z), reward: [-5.96674066  0.26076357  7.31708615] 1.0\n",
      "positions (x,y,z), reward: [-7.162936    0.26914186  6.24003544] 1.0\n",
      "positions (x,y,z), reward: [-7.36717425  0.26596034  6.04728897] 1.0\n",
      "positions (x,y,z), reward: [-11.02532359   0.21724319   2.02984652] 1.0\n",
      "Episode =  434, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.14711027  0.11771651  9.95605144] 1.0\n",
      "positions (x,y,z), reward: [ 0.498812   0.2303298  9.9228015] 1.0\n",
      "positions (x,y,z), reward: [ 1.5204594   0.53323201  9.98351822] 1.0\n",
      "positions (x,y,z), reward: [ 1.73713355  0.60753897  9.96543714] 1.0\n",
      "positions (x,y,z), reward: [ 4.91698995  0.1329837   6.96124267] 1.0\n",
      "Episode =  435, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.78004302 -0.33313805  9.6335867 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.49426196 -2.04566441  7.62978312] 1.0\n",
      "positions (x,y,z), reward: [ 1.35005733 -2.22315019  7.21777652] 1.0\n",
      "positions (x,y,z), reward: [ 1.29772612 -2.27332198  7.0732495 ] 1.0\n",
      "positions (x,y,z), reward: [-0.82991906 -3.42562985  1.07033817] 1.0\n",
      "positions (x,y,z), reward: [-1.30331891 -3.6241148   0.        ] 1.0\n",
      "Episode =  436, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05005679   0.01515082  10.02668408] 1.0\n",
      "positions (x,y,z), reward: [-0.29107782  0.43014837  8.2978232 ] 1.0\n",
      "positions (x,y,z), reward: [-2.30939582  0.28323842  5.29635654] 1.0\n",
      "positions (x,y,z), reward: [-4.6063744   0.17923979  0.6020155 ] 1.0\n",
      "Episode =  437, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03970804  0.13293068  9.87782595] 1.0\n",
      "positions (x,y,z), reward: [ 0.42344636  0.34198272  9.74693095] 1.0\n",
      "positions (x,y,z), reward: [-0.30868041  0.43327036  9.60002158] 1.0\n",
      "positions (x,y,z), reward: [-0.73815421  0.59349996  9.44778525] 1.0\n",
      "positions (x,y,z), reward: [-1.81711694  1.13154986  9.01892452] 1.0\n",
      "positions (x,y,z), reward: [-2.48060848  1.57293178  8.57303893] 1.0\n",
      "positions (x,y,z), reward: [-3.20319757  2.42103967  7.26457228] 1.0\n",
      "Episode =  438, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.79844746e-03   1.03775539e-03   1.00173179e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.24787784  0.04506088  9.43786593] 1.0\n",
      "positions (x,y,z), reward: [ 0.36331628  0.81266942  7.63998812] 1.0\n",
      "positions (x,y,z), reward: [-0.780096    2.1978858   3.78576721] 1.0\n",
      "positions (x,y,z), reward: [-0.8444926   2.26420515  3.59857611] 1.0\n",
      "positions (x,y,z), reward: [-0.97334898  2.39968751  3.21728275] 1.0\n",
      "Episode =  439, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.91037341 -1.15501317  5.37140971] 1.0\n",
      "positions (x,y,z), reward: [-1.66278602 -1.74377406  2.74355944] 1.0\n",
      "Episode =  440, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.22465838 -0.01858036  9.74125439] 1.0\n",
      "positions (x,y,z), reward: [-0.87003464 -0.31821192  9.39538567] 1.0\n",
      "positions (x,y,z), reward: [-1.08564781 -0.36045664  9.33753608] 1.0\n",
      "positions (x,y,z), reward: [-5.21490241 -0.8722512   8.12914375] 1.0\n",
      "Episode =  441, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02300354  0.02867165  9.98917541] 1.0\n",
      "positions (x,y,z), reward: [ 0.35270185 -0.11010295  9.89975967] 1.0\n",
      "positions (x,y,z), reward: [ 1.49921486 -1.42599496  7.63200933] 1.0\n",
      "positions (x,y,z), reward: [ 1.10077803 -2.54211513  3.92516684] 1.0\n",
      "positions (x,y,z), reward: [ 1.05324968 -2.65824542  3.4528017 ] 1.0\n",
      "Episode =  442, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.22882865 -0.87835366  8.68588877] 1.0\n",
      "positions (x,y,z), reward: [ 3.36420564 -2.85771164  4.56183353] 1.0\n",
      "Episode =  443, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.09701504e-03   9.48552133e-02   9.91210019e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.52386506 -0.45618961  9.36128146] 1.0\n",
      "positions (x,y,z), reward: [ 0.21424586 -1.035903    8.94920753] 1.0\n",
      "positions (x,y,z), reward: [-0.45155084 -1.46719799  8.42443747] 1.0\n",
      "positions (x,y,z), reward: [-4.36145874 -2.49681289  4.69501131] 1.0\n",
      "Episode =  444, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02715276 -0.15072473  9.91899963] 1.0\n",
      "positions (x,y,z), reward: [ 0.02223495 -0.15448633  9.8254818 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.39973975  0.07806446  9.25568133] 1.0\n",
      "positions (x,y,z), reward: [ 0.24650179  0.63748758  8.47393563] 1.0\n",
      "positions (x,y,z), reward: [-1.52234897  2.6203045   6.29790343] 1.0\n",
      "positions (x,y,z), reward: [-2.53669156  3.45860607  5.21293439] 1.0\n",
      "Episode =  445, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.15926548  0.22769448  9.77068079] 1.0\n",
      "positions (x,y,z), reward: [ 1.01875608 -0.01350687  7.60829935] 1.0\n",
      "positions (x,y,z), reward: [ 1.37792772 -1.42122005  3.26416473] 1.0\n",
      "Episode =  446, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03842908  -0.01276931  10.00321871] 1.0\n",
      "positions (x,y,z), reward: [-0.04551353 -0.19749924  9.72296533] 1.0\n",
      "positions (x,y,z), reward: [ 0.41384518 -0.58824283  9.07420876] 1.0\n",
      "positions (x,y,z), reward: [-0.65052917 -0.09865207  7.79720641] 1.0\n",
      "positions (x,y,z), reward: [-3.64237891  0.68618927  3.90283655] 1.0\n",
      "positions (x,y,z), reward: [-3.7717417   0.72821424  3.71047468] 1.0\n",
      "positions (x,y,z), reward: [-4.42534233  0.93809281  2.69390004] 1.0\n",
      "positions (x,y,z), reward: [-5.08446012  1.14396683  1.55520356] 1.0\n",
      "Episode =  447, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16266657  0.24345558  9.59233387] 1.0\n",
      "positions (x,y,z), reward: [-3.58461762  6.44008935  3.39644627] 1.0\n",
      "positions (x,y,z), reward: [-3.71687907  6.58815393  3.19280239] 1.0\n",
      "positions (x,y,z), reward: [-3.85099817  6.73573752  2.98667051] 1.0\n",
      "positions (x,y,z), reward: [-4.26717202  7.17466431  2.35168674] 1.0\n",
      "positions (x,y,z), reward: [-4.41015501  7.31985929  2.13428782] 1.0\n",
      "Episode =  448, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.60117425  -1.14013011  10.0686638 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.2689114  -4.31865768  7.41272269] 1.0\n",
      "positions (x,y,z), reward: [ 1.32555237 -4.46527289  7.22131698] 1.0\n",
      "positions (x,y,z), reward: [ 1.72119022 -5.48615044  5.75559904] 1.0\n",
      "positions (x,y,z), reward: [ 2.09776728 -6.50913949  4.10825005] 1.0\n",
      "positions (x,y,z), reward: [ 2.22286044 -6.93940672  3.34468665] 1.0\n",
      "Episode =  449, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.69533977e-03   2.53103263e-03   1.00155962e+01] 1.0\n",
      "Episode =  450, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00495989] 1.0\n",
      "positions (x,y,z), reward: [ 0.28296376 -0.56849847  9.28834946] 1.0\n",
      "positions (x,y,z), reward: [ 1.36974879 -1.17214794  8.20249977] 1.0\n",
      "positions (x,y,z), reward: [ 1.35015733 -4.91222707  0.        ] 1.0\n",
      "Episode =  451, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01665861   0.01950865  10.02067038] 1.0\n",
      "positions (x,y,z), reward: [ -0.31107755   0.40077473  10.04445414] 1.0\n",
      "positions (x,y,z), reward: [ -2.89161639   1.50209347  10.64835369] 1.0\n",
      "positions (x,y,z), reward: [-15.96085412   8.715882     6.33029648] 1.0\n",
      "positions (x,y,z), reward: [-20.9536586   12.14281635   2.27365735] 1.0\n",
      "Episode =  452, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.64880088 -0.26997742  9.47455578] 1.0\n",
      "positions (x,y,z), reward: [ 0.91689044 -0.56927304  8.21832883] 1.0\n",
      "positions (x,y,z), reward: [-0.87579344 -1.52905125  0.        ] 1.0\n",
      "Episode =  453, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04153976 -0.04131334  9.95469696] 1.0\n",
      "positions (x,y,z), reward: [ 1.03812251 -0.01862713  8.7404197 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.55216753 -0.38463625  2.61279096] 1.0\n",
      "Episode =  454, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02787068   0.02725146  10.05305175] 1.0\n",
      "positions (x,y,z), reward: [ 0.92407473  0.14174545  9.55715079] 1.0\n",
      "positions (x,y,z), reward: [ 5.55739967  0.80362233  6.02912857] 1.0\n",
      "Episode =  455, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.27502511 -0.15616465  9.56599385] 1.0\n",
      "positions (x,y,z), reward: [ 0.72823281 -0.31687626  9.06960643] 1.0\n",
      "positions (x,y,z), reward: [ 4.58541299 -0.45832051  1.84194407] 1.0\n",
      "positions (x,y,z), reward: [ 4.99295697 -0.42538972  0.55900862] 1.0\n",
      "Episode =  456, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.82411268 -0.06529806  9.78607803] 1.0\n",
      "positions (x,y,z), reward: [ 1.62700545 -0.40803304  9.49089422] 1.0\n",
      "positions (x,y,z), reward: [ 1.75014688 -0.48813708  9.39645669] 1.0\n",
      "positions (x,y,z), reward: [ 5.4952633  -3.11328858  5.029605  ] 1.0\n",
      "positions (x,y,z), reward: [ 7.19639207 -4.44072997  2.02923862] 1.0\n",
      "Episode =  457, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.24864235  0.17328374  9.88504292] 1.0\n",
      "positions (x,y,z), reward: [-0.78411644  2.29545158  8.97414367] 1.0\n",
      "positions (x,y,z), reward: [-0.86031797  2.49614801  8.87442875] 1.0\n",
      "positions (x,y,z), reward: [-1.2281549   3.56921194  8.30007652] 1.0\n",
      "positions (x,y,z), reward: [-1.96454431  4.70863188  7.50031822] 1.0\n",
      "Episode =  458, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.19855825 -0.10085153  9.78781145] 1.0\n",
      "positions (x,y,z), reward: [ 3.60900013 -0.59011105  6.09383882] 1.0\n",
      "Episode =  459, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05415827 -0.02310352  9.92495527] 1.0\n",
      "positions (x,y,z), reward: [ 0.39741416 -0.69228596  8.73180055] 1.0\n",
      "positions (x,y,z), reward: [ 0.21447187 -1.20607337  7.50982226] 1.0\n",
      "positions (x,y,z), reward: [ 0.05521658 -1.47640764  6.85536927] 1.0\n",
      "positions (x,y,z), reward: [-0.83239398 -2.15426769  4.32429652] 1.0\n",
      "Episode =  460, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06278648  0.05375832  9.99985257] 1.0\n",
      "positions (x,y,z), reward: [ 0.22862213 -0.02039119  9.9049678 ] 1.0\n",
      "positions (x,y,z), reward: [-1.30127267 -0.35508977  9.42606404] 1.0\n",
      "positions (x,y,z), reward: [-5.98251118 -0.77016153  6.12481707] 1.0\n",
      "positions (x,y,z), reward: [-6.74539252 -0.72244828  5.40235095] 1.0\n",
      "positions (x,y,z), reward: [-7.68483572 -0.67877135  4.43766268] 1.0\n",
      "Episode =  461, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.00553878e-03   2.62052421e-03   1.00109057e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.11497812 -0.03390272  9.55518961] 1.0\n",
      "positions (x,y,z), reward: [-1.35666694 -0.53322936  8.418619  ] 1.0\n",
      "positions (x,y,z), reward: [-2.87579724 -0.53317026  6.52965243] 1.0\n",
      "positions (x,y,z), reward: [-3.23376133 -0.48168353  6.09356027] 1.0\n",
      "positions (x,y,z), reward: [-3.47661709 -0.4453262   5.79351184] 1.0\n",
      "positions (x,y,z), reward: [-5.72107673 -0.05348943  2.33398978] 1.0\n",
      "Episode =  462, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.75493647 -1.04553383  8.62590117] 1.0\n",
      "positions (x,y,z), reward: [-0.42462508 -1.88331093  6.63678418] 1.0\n",
      "positions (x,y,z), reward: [-1.26289423 -2.35066319  5.20757604] 1.0\n",
      "positions (x,y,z), reward: [-1.76484218 -2.57938557  4.41395761] 1.0\n",
      "positions (x,y,z), reward: [-2.80581359 -3.03083311  2.6388119 ] 1.0\n",
      "Episode =  463, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13223786 -0.23609453  9.78109571] 1.0\n",
      "positions (x,y,z), reward: [-5.19638977 -0.4860937   6.48047162] 1.0\n",
      "positions (x,y,z), reward: [-5.91965191 -0.49725729  5.7800471 ] 1.0\n",
      "positions (x,y,z), reward: [-6.80716942 -0.51260821  4.83068319] 1.0\n",
      "positions (x,y,z), reward: [-6.98467845 -0.51519253  4.63123508] 1.0\n",
      "Episode =  464, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.23148493 -0.21423739  9.86241694] 1.0\n",
      "positions (x,y,z), reward: [ 4.77226537 -0.48477018  7.17560836] 1.0\n",
      "positions (x,y,z), reward: [ 11.74698808  -0.71023608   1.34937598] 1.0\n",
      "Episode =  465, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.6052862   -0.10010735  10.79585476] 1.0\n",
      "positions (x,y,z), reward: [ -1.72833488   0.06890113  10.80876055] 1.0\n",
      "positions (x,y,z), reward: [ -3.84443409   0.43024945  10.69409096] 1.0\n",
      "positions (x,y,z), reward: [ -4.11614947   0.47974977  10.66850539] 1.0\n",
      "positions (x,y,z), reward: [ -6.49960445   0.91835256  10.16591442] 1.0\n",
      "positions (x,y,z), reward: [-15.62790881   2.92414715   7.1116137 ] 1.0\n",
      "positions (x,y,z), reward: [-15.99761738   3.0119033    6.95003366] 1.0\n",
      "positions (x,y,z), reward: [-21.07242671   4.02821125   4.20691689] 1.0\n",
      "Episode =  466, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.09600903 -0.16602132  9.63149403] 1.0\n",
      "Episode =  467, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11890154  0.17771108  9.86951776] 1.0\n",
      "positions (x,y,z), reward: [-0.06827696  0.48938575  9.2046752 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.79712636  0.76990745  5.86407559] 1.0\n",
      "Episode =  468, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.48040974 -0.18763062  7.47850248] 1.0\n",
      "Episode =  469, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10504631 -0.11097629  9.92472333] 1.0\n",
      "positions (x,y,z), reward: [ 0.36486417 -0.60348483  9.35054479] 1.0\n",
      "positions (x,y,z), reward: [ 0.19762223 -0.70363692  9.1381109 ] 1.0\n",
      "positions (x,y,z), reward: [-3.20618001 -0.65530474  6.35276748] 1.0\n",
      "positions (x,y,z), reward: [-6.36168075 -1.07785904  1.5303722 ] 1.0\n",
      "Episode =  470, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.09377654  -0.05705932  10.03263602] 1.0\n",
      "positions (x,y,z), reward: [ 1.4647912   0.64228081  8.31327632] 1.0\n",
      "positions (x,y,z), reward: [ 1.59365346  0.66774911  7.83170905] 1.0\n",
      "positions (x,y,z), reward: [ 1.3924058   0.53047352  4.51054001] 1.0\n",
      "positions (x,y,z), reward: [ 1.24819395  0.42609843  2.94417174] 1.0\n",
      "positions (x,y,z), reward: [ 1.17950718  0.39065892  2.22045891] 1.0\n",
      "positions (x,y,z), reward: [ 1.13235153  0.36567832  1.72477043] 1.0\n",
      "positions (x,y,z), reward: [ 0.93077098  0.25395357  0.        ] 1.0\n",
      "Episode =  471, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0599352    0.18966187  10.05557346] 1.0\n",
      "positions (x,y,z), reward: [ 0.22128396  0.25891937  9.95474952] 1.0\n",
      "positions (x,y,z), reward: [ 0.83250856  0.31970118  9.69698921] 1.0\n",
      "positions (x,y,z), reward: [ 4.64385529  0.90441307  8.24040637] 1.0\n",
      "positions (x,y,z), reward: [ 13.536923     2.56731842   3.41425274] 1.0\n",
      "Episode =  472, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15735661 -0.05033774  9.29203783] 1.0\n",
      "positions (x,y,z), reward: [ 1.10693389 -1.53336752  5.82508185] 1.0\n",
      "Episode =  473, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.50295462  0.06982761  9.93938607] 1.0\n",
      "positions (x,y,z), reward: [-1.90877879  0.40896053  8.64069528] 1.0\n",
      "positions (x,y,z), reward: [-2.01718205  0.42804373  8.57832291] 1.0\n",
      "Episode =  474, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.51298801  0.06668125  6.71376264] 1.0\n",
      "positions (x,y,z), reward: [ 3.69661372 -0.06747737  4.93312723] 1.0\n",
      "Episode =  475, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.47086657 -3.32371517  6.0511137 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.22400698 -3.98493886  4.69139849] 1.0\n",
      "Episode =  476, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02809774  0.09433915  9.86887961] 1.0\n",
      "positions (x,y,z), reward: [-0.03632323  0.34235519  9.85195529] 1.0\n",
      "positions (x,y,z), reward: [-0.0773958   0.4235623   9.86887669] 1.0\n",
      "positions (x,y,z), reward: [-1.59267497  1.37419846  9.79292363] 1.0\n",
      "positions (x,y,z), reward: [-3.04622432  2.281723    9.69958166] 1.0\n",
      "positions (x,y,z), reward: [-3.88337985  2.70961992  9.58079919] 1.0\n",
      "positions (x,y,z), reward: [-12.53211843   6.63429257   7.27826574] 1.0\n",
      "positions (x,y,z), reward: [-13.74128171   7.19149089   6.71475393] 1.0\n",
      "positions (x,y,z), reward: [-19.40243797   9.86277067   2.88738638] 1.0\n",
      "Episode =  477, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03738926  -0.01211343  10.00282444] 1.0\n",
      "positions (x,y,z), reward: [-0.06312503 -0.05152952  9.94011288] 1.0\n",
      "positions (x,y,z), reward: [ 1.96740819 -5.20786202  0.20915087] 1.0\n",
      "Episode =  478, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.33076802  0.36743428  9.24514601] 1.0\n",
      "Episode =  479, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.98683443 -0.17511251  9.69621852] 1.0\n",
      "positions (x,y,z), reward: [ 1.20467088 -0.71115807  9.22185529] 1.0\n",
      "positions (x,y,z), reward: [ 0.9402985  -1.77180902  7.8920243 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.42962443 -2.33667431  6.8672882 ] 1.0\n",
      "positions (x,y,z), reward: [-2.66187424 -4.35665656  0.64938861] 1.0\n",
      "Episode =  480, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.13127366 -1.01573196  7.95472316] 1.0\n",
      "positions (x,y,z), reward: [ 0.88265825 -2.39373353  3.55737718] 1.0\n",
      "positions (x,y,z), reward: [ 0.86185326 -2.46132548  3.30834161] 1.0\n",
      "Episode =  481, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.66968235 -0.61089948  7.20270862] 1.0\n",
      "positions (x,y,z), reward: [ 0.76243537 -1.25628021  5.42625311] 1.0\n",
      "positions (x,y,z), reward: [ 0.7112216  -2.49332335  1.23366343] 1.0\n",
      "Episode =  482, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.1557422   -0.43358741  10.64953   ] 1.0\n",
      "positions (x,y,z), reward: [ -6.22912907  -0.6192957   11.11963281] 1.0\n",
      "positions (x,y,z), reward: [-13.79637122  -0.22434976   9.55576248] 1.0\n",
      "positions (x,y,z), reward: [-23.125739     0.08861109   4.97669834] 1.0\n",
      "positions (x,y,z), reward: [-29.12357912   0.14319002   0.20113436] 1.0\n",
      "Episode =  483, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  2.46230479e-02   8.43953149e-03   9.96025198e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.58757166  0.05290274  9.35509179] 1.0\n",
      "Episode =  484, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.24532678   0.06935334  10.05900304] 1.0\n",
      "positions (x,y,z), reward: [ -1.15340386   0.08945999  10.52066934] 1.0\n",
      "positions (x,y,z), reward: [ -1.27341623   0.11397409  10.56153194] 1.0\n",
      "positions (x,y,z), reward: [ -3.15320729   0.36943643  11.28690875] 1.0\n",
      "positions (x,y,z), reward: [ -3.61268685e+00   2.26811378e-04   1.10630096e+01] 1.0\n",
      "positions (x,y,z), reward: [ -4.59983274  -0.65211628  10.39466385] 1.0\n",
      "positions (x,y,z), reward: [-7.35896723 -2.64612071  8.08060914] 1.0\n",
      "positions (x,y,z), reward: [-8.70426849 -3.64628323  6.50978552] 1.0\n",
      "Episode =  485, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.34876806e-02   7.12750655e-03   9.94695950e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.21063199  0.20387687  9.91912233] 1.0\n",
      "positions (x,y,z), reward: [-0.33127828  0.26603387  9.95586117] 1.0\n",
      "positions (x,y,z), reward: [-10.30708511   3.42395329   7.25505794] 1.0\n",
      "positions (x,y,z), reward: [-11.20827372   3.60765725   6.81950124] 1.0\n",
      "positions (x,y,z), reward: [-13.26658917   3.99528006   5.67064579] 1.0\n",
      "positions (x,y,z), reward: [-19.09912742   5.08507713   0.63172163] 1.0\n",
      "Episode =  486, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.42476915 -0.30354129  9.35370821] 1.0\n",
      "positions (x,y,z), reward: [ 7.85613037 -0.42878818  0.49419976] 1.0\n",
      "Episode =  487, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03753019  -0.02583774  10.04500659] 1.0\n",
      "positions (x,y,z), reward: [  4.59321979e-01   4.27533444e-03   8.52192590e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.54278901  0.27229519  7.72266258] 1.0\n",
      "Episode =  488, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.27629452  0.36543534  8.88591025] 1.0\n",
      "positions (x,y,z), reward: [ 1.54452199  0.19984112  7.28374701] 1.0\n",
      "positions (x,y,z), reward: [ 1.85917084  0.14439017  6.77330003] 1.0\n",
      "positions (x,y,z), reward: [ 1.93160799  0.13602509  6.63656905] 1.0\n",
      "positions (x,y,z), reward: [ 2.7916837   0.07196475  4.99100321] 1.0\n",
      "positions (x,y,z), reward: [ 2.961286    0.06427099  4.60908965] 1.0\n",
      "positions (x,y,z), reward: [ 4.17166132  0.01542119  1.80479099] 1.0\n",
      "positions (x,y,z), reward: [ 4.27279752  0.01450024  1.56458563] 1.0\n",
      "Episode =  490, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.34479233e-03   2.53880351e-03   1.00088958e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.67162477 -0.47312263  8.59070659] 1.0\n",
      "positions (x,y,z), reward: [-1.86773885 -1.93784735  3.8229751 ] 1.0\n",
      "positions (x,y,z), reward: [-1.94531931 -1.95802705  3.64281515] 1.0\n",
      "positions (x,y,z), reward: [-2.64654152 -2.13931767  1.85325691] 1.0\n",
      "positions (x,y,z), reward: [-3.028137   -2.27711981  0.72202213] 1.0\n",
      "Episode =  491, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05357459 -0.0638958   9.07942275] 1.0\n",
      "positions (x,y,z), reward: [ 0.42784204  0.15585028  8.27586265] 1.0\n",
      "positions (x,y,z), reward: [ 0.46054616  0.19481972  8.14637702] 1.0\n",
      "positions (x,y,z), reward: [ 1.76701594  1.22678438  4.61798266] 1.0\n",
      "positions (x,y,z), reward: [ 1.96124829  1.33696134  3.7734711 ] 1.0\n",
      "Episode =  492, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.58293668 -1.31487914  7.99873024] 1.0\n",
      "Episode =  493, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.48023486 -0.20690475  9.62485455] 1.0\n",
      "positions (x,y,z), reward: [ 2.71570983 -0.95618197  7.20838203] 1.0\n",
      "positions (x,y,z), reward: [ 3.39899853 -1.20552233  5.962751  ] 1.0\n",
      "positions (x,y,z), reward: [ 5.45958157 -1.91002314  0.43387282] 1.0\n",
      "Episode =  494, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.00038545 -0.27022955  8.98203866] 1.0\n",
      "positions (x,y,z), reward: [ 2.21993738 -0.29637952  8.84804912] 1.0\n",
      "Episode =  495, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.74098417 -0.0477964   9.97989927] 1.0\n",
      "positions (x,y,z), reward: [ 5.17086166 -0.93989146  5.98803541] 1.0\n",
      "positions (x,y,z), reward: [ 6.34877104 -2.31233201  0.08154758] 1.0\n",
      "Episode =  496, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.97386177  0.16355812  4.94729556] 1.0\n",
      "Episode =  497, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.00327102e-03   6.62945074e-04   1.00157646e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.15437601 -0.0723562   9.93689958] 1.0\n",
      "positions (x,y,z), reward: [ 0.38638362 -0.18704169  9.76283867] 1.0\n",
      "positions (x,y,z), reward: [ 2.48565369 -1.92636679  7.23703629] 1.0\n",
      "positions (x,y,z), reward: [ 2.56819611 -2.10645461  6.89488306] 1.0\n",
      "positions (x,y,z), reward: [ 3.00858842 -3.03600831  4.64759815] 1.0\n",
      "Episode =  498, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08020836  0.02009674  9.94927154] 1.0\n",
      "positions (x,y,z), reward: [ -3.47346745e-02  -7.85684903e-03   9.87794643e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.50714813 -0.58024124  9.53962831] 1.0\n",
      "positions (x,y,z), reward: [ 1.01066825 -2.30516307  7.4716924 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.92665239 -3.17102842  5.43661185] 1.0\n",
      "Episode =  499, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.21767079 -0.01129992  9.62512743] 1.0\n",
      "positions (x,y,z), reward: [-0.57952641  0.11123912  9.27273651] 1.0\n",
      "positions (x,y,z), reward: [-2.03131876  0.15444533  8.99766275] 1.0\n",
      "positions (x,y,z), reward: [-4.37847186  0.42746565  7.73168383] 1.0\n",
      "positions (x,y,z), reward: [-5.36337874  0.64964549  7.01911725] 1.0\n",
      "positions (x,y,z), reward: [-7.66313053  1.11411904  5.25549006] 1.0\n",
      "Episode =  500, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.49983893  0.07222907  9.90458211] 1.0\n",
      "positions (x,y,z), reward: [-0.58443693 -0.26626529  9.56987491] 1.0\n",
      "positions (x,y,z), reward: [-4.90530135 -2.86130584  3.44071272] 1.0\n",
      "positions (x,y,z), reward: [-6.31568547 -3.20915953  1.1466654 ] 1.0\n",
      "positions (x,y,z), reward: [-7.1698831  -3.36369027  0.        ] 1.0\n",
      "Episode =  501, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.1037365   0.06282725  9.82484315] 1.0\n",
      "positions (x,y,z), reward: [-0.232599    0.26987619  9.62479091] 1.0\n",
      "positions (x,y,z), reward: [-0.61239044  0.55332511  9.06799563] 1.0\n",
      "positions (x,y,z), reward: [-2.75490243  2.42878874  5.51313156] 1.0\n",
      "Episode =  502, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04067151   0.01159234  10.02410126] 1.0\n",
      "positions (x,y,z), reward: [-0.08530552  0.02018144  9.97714017] 1.0\n",
      "positions (x,y,z), reward: [-0.12721188  0.03620653  9.95315454] 1.0\n",
      "positions (x,y,z), reward: [-0.1772388   0.05669692  9.95177013] 1.0\n",
      "positions (x,y,z), reward: [-0.82952426  0.23550082  9.86846083] 1.0\n",
      "positions (x,y,z), reward: [-2.77337181  0.46811173  9.09315596] 1.0\n",
      "positions (x,y,z), reward: [-8.7560162   0.54819507  5.07212478] 1.0\n",
      "Episode =  503, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.26645398  0.62642425  9.93325241] 1.0\n",
      "positions (x,y,z), reward: [-10.52009803   6.55995887   5.96162933] 1.0\n",
      "Episode =  504, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05600745   0.02592449  10.04880599] 1.0\n",
      "positions (x,y,z), reward: [-0.83284494  1.95482034  7.99486615] 1.0\n",
      "positions (x,y,z), reward: [-1.40470652  4.34544189  5.41810242] 1.0\n",
      "positions (x,y,z), reward: [-1.42901402  5.6693321   3.30499901] 1.0\n",
      "positions (x,y,z), reward: [-1.0517613   7.36046685  0.        ] 1.0\n",
      "Episode =  505, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.36066832e-02   3.73454995e-03   1.00202218e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.31192052  0.25439194  9.86215211] 1.0\n",
      "positions (x,y,z), reward: [ 3.62938606 -1.19951282  6.84412783] 1.0\n",
      "positions (x,y,z), reward: [ 3.81181058 -1.48007736  6.20528043] 1.0\n",
      "Episode =  506, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.71308558  1.57644024  9.15148885] 1.0\n",
      "positions (x,y,z), reward: [-2.48439423  5.29216392  5.25182623] 1.0\n",
      "positions (x,y,z), reward: [-2.83868046  6.22105946  3.35430162] 1.0\n",
      "positions (x,y,z), reward: [-2.9157333   6.42286031  2.8938646 ] 1.0\n",
      "positions (x,y,z), reward: [-3.16494755  7.10907321  1.13819707] 1.0\n",
      "Episode =  507, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.99131876e-03  -5.66459819e-02   9.96228318e+00] 1.0\n",
      "positions (x,y,z), reward: [ 3.71292195 -5.05690502  0.87710475] 1.0\n",
      "positions (x,y,z), reward: [ 3.7421484  -5.13791311  0.63419289] 1.0\n",
      "Episode =  508, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0348751   0.49206168  9.94327302] 1.0\n",
      "positions (x,y,z), reward: [ -0.95726956   0.78492535  10.043924  ] 1.0\n",
      "positions (x,y,z), reward: [-5.3001566   1.69233824  9.43089761] 1.0\n",
      "positions (x,y,z), reward: [-6.69131202  1.74951174  8.62720149] 1.0\n",
      "positions (x,y,z), reward: [-8.11519413  1.98731043  7.20570173] 1.0\n",
      "positions (x,y,z), reward: [-9.02956457  2.17786984  6.03694567] 1.0\n",
      "positions (x,y,z), reward: [-10.80080764   2.55232928   3.32595024] 1.0\n",
      "positions (x,y,z), reward: [-12.18710058   2.77069561   0.86472682] 1.0\n",
      "Episode =  509, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.5053788  -0.54618937  8.8637693 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.12695121 -0.83552746  8.34418515] 1.0\n",
      "positions (x,y,z), reward: [-1.54482369 -2.20119911  4.96094308] 1.0\n",
      "positions (x,y,z), reward: [-1.94887599 -2.49619445  3.91447353] 1.0\n",
      "positions (x,y,z), reward: [-2.36009967 -2.79041029  2.75132285] 1.0\n",
      "Episode =  510, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00527991] 1.0\n",
      "positions (x,y,z), reward: [ 0.87136373 -0.23955241  8.88456778] 1.0\n",
      "positions (x,y,z), reward: [ 3.9223568  -0.92961027  6.20155655] 1.0\n",
      "Episode =  511, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.89785183 -2.97601016  5.7088504 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.93931811 -3.20864731  5.32039082] 1.0\n",
      "positions (x,y,z), reward: [ 2.0329328  -3.78497715  4.28914415] 1.0\n",
      "Episode =  512, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13890076  0.01426865  9.83136891] 1.0\n",
      "positions (x,y,z), reward: [ 1.86018681 -0.36698973  8.51839509] 1.0\n",
      "Episode =  513, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.46714652  0.08153408  9.52041266] 1.0\n",
      "positions (x,y,z), reward: [ 0.90139587  0.27342668  9.24933726] 1.0\n",
      "positions (x,y,z), reward: [-1.2729783   3.5788706   5.91696103] 1.0\n",
      "positions (x,y,z), reward: [-2.15362546  4.26275551  4.53952821] 1.0\n",
      "positions (x,y,z), reward: [-2.4001875   4.43459646  4.16518197] 1.0\n",
      "positions (x,y,z), reward: [-3.03321849  4.86659235  3.17680071] 1.0\n",
      "Episode =  514, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.17712336 -1.49029306  1.07271606] 1.0\n",
      "Episode =  515, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04364718  0.03301737  9.99500281] 1.0\n",
      "positions (x,y,z), reward: [-0.01021523  0.50078891  7.51277235] 1.0\n",
      "positions (x,y,z), reward: [-1.26114358  1.1344147   1.23518887] 1.0\n",
      "Episode =  516, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.48733082 -0.03649085  9.5243612 ] 1.0\n",
      "Episode =  517, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.08896227 -4.62572602  5.17349362] 1.0\n",
      "Episode =  518, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.3975713  -0.29462663  9.95984304] 1.0\n",
      "positions (x,y,z), reward: [-1.95999252 -1.48450877  9.39138219] 1.0\n",
      "positions (x,y,z), reward: [-2.60254775 -1.69228622  9.15905375] 1.0\n",
      "positions (x,y,z), reward: [-6.24386226 -2.19459888  7.22092436] 1.0\n",
      "positions (x,y,z), reward: [-10.18042373  -2.32188567   4.01962096] 1.0\n",
      "Episode =  519, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.17999746 -0.05417527  9.94863276] 1.0\n",
      "positions (x,y,z), reward: [-0.16013379 -0.19471426  9.68498308] 1.0\n",
      "positions (x,y,z), reward: [  3.08178595e-03  -3.05119232e-01   9.45356054e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.05919447 -0.34114218  9.39798773] 1.0\n",
      "positions (x,y,z), reward: [ 1.87484416 -3.29706977  4.94453508] 1.0\n",
      "positions (x,y,z), reward: [ 2.96923583 -4.53046347  2.20449773] 1.0\n",
      "Episode =  520, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.23576649  0.35189336  9.57061106] 1.0\n",
      "positions (x,y,z), reward: [-0.81971503  0.57677711  9.06632437] 1.0\n",
      "Episode =  521, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11765164 -0.10963989  9.72461016] 1.0\n",
      "positions (x,y,z), reward: [-0.12713557 -0.1550703   9.67091541] 1.0\n",
      "positions (x,y,z), reward: [-0.51539047 -0.88243301  8.65339629] 1.0\n",
      "positions (x,y,z), reward: [-3.09537505 -3.11604689  4.45346226] 1.0\n",
      "Episode =  522, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 5.1938986  -0.24462544  5.56262607] 1.0\n",
      "Episode =  523, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.45996414  0.93099558  1.7037794 ] 1.0\n",
      "positions (x,y,z), reward: [-2.74629668  1.01595774  0.57130424] 1.0\n",
      "Episode =  524, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02105228 -0.09457589  9.88986269] 1.0\n",
      "positions (x,y,z), reward: [ 0.58852997 -0.54160375  9.28877307] 1.0\n",
      "positions (x,y,z), reward: [-11.51219664   1.27048364   0.        ] 1.0\n",
      "Episode =  525, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0575184  -0.03381915  9.97258427] 1.0\n",
      "positions (x,y,z), reward: [ 0.12221949 -0.47078242  9.52932873] 1.0\n",
      "positions (x,y,z), reward: [ 0.31674448 -0.61972051  9.32682834] 1.0\n",
      "positions (x,y,z), reward: [ 3.88895951 -4.65811781  4.02741449] 1.0\n",
      "Episode =  526, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05520388   0.01468067  10.02555269] 1.0\n",
      "positions (x,y,z), reward: [ 0.0614873   0.04375271  9.94806409] 1.0\n",
      "positions (x,y,z), reward: [ 1.86007898 -0.55685906  8.29026837] 1.0\n",
      "positions (x,y,z), reward: [ 3.44007598 -1.34631186  5.93596997] 1.0\n",
      "positions (x,y,z), reward: [ 4.21571116 -1.84600612  4.09494119] 1.0\n",
      "Episode =  527, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06221126   0.05945974  10.0216327 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.13382575   0.09349333  10.02176999] 1.0\n",
      "positions (x,y,z), reward: [ -0.20856129   0.11668524  10.03549354] 1.0\n",
      "positions (x,y,z), reward: [ -0.43022659   0.10221941  10.11795148] 1.0\n",
      "positions (x,y,z), reward: [ -0.81201219  -0.05567843  10.16935734] 1.0\n",
      "positions (x,y,z), reward: [-15.97545296   0.43483861   0.76444133] 1.0\n",
      "Episode =  528, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.44905788e-02  -8.81741958e-03   1.00251497e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.2737147  -0.07133793  9.94317146] 1.0\n",
      "positions (x,y,z), reward: [ 0.54521574 -0.06115586  9.82792155] 1.0\n",
      "positions (x,y,z), reward: [  1.36997562e+00  -6.74996996e-03   9.44856147e+00] 1.0\n",
      "positions (x,y,z), reward: [ 3.59064361  0.16415419  8.37759943] 1.0\n",
      "positions (x,y,z), reward: [ 5.72658251  0.20827666  7.31764865] 1.0\n",
      "positions (x,y,z), reward: [ 7.1523791   0.22678192  6.58066216] 1.0\n",
      "positions (x,y,z), reward: [ 13.63973372   0.6718895    2.33783354] 1.0\n",
      "Episode =  529, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.27698878 -0.11593052  9.54890156] 1.0\n",
      "positions (x,y,z), reward: [-2.34476353  2.51607193  7.12846183] 1.0\n",
      "positions (x,y,z), reward: [-3.24556149  2.97121022  6.48243582] 1.0\n",
      "Episode =  530, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.27704879  0.52304702  8.34551683] 1.0\n",
      "positions (x,y,z), reward: [ 2.93949563  1.059275    6.66992357] 1.0\n",
      "positions (x,y,z), reward: [ 4.19280986  1.46740417  5.0261095 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.96010383  1.86438082  3.42285805] 1.0\n",
      "Episode =  531, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0053272] 1.0\n",
      "positions (x,y,z), reward: [-0.09385851  0.21323139  9.94091566] 1.0\n",
      "positions (x,y,z), reward: [-1.21928812 -1.66634487  8.09322533] 1.0\n",
      "Episode =  532, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00569731] 1.0\n",
      "positions (x,y,z), reward: [ -0.07230715   0.06432722  10.03322517] 1.0\n",
      "positions (x,y,z), reward: [-4.0317403   3.78674128  3.55217984] 1.0\n",
      "Episode =  533, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.66414542  0.99467412  8.40053279] 1.0\n",
      "positions (x,y,z), reward: [-0.86512281  1.24595933  8.09920097] 1.0\n",
      "positions (x,y,z), reward: [-1.04034142  1.60908325  7.49822686] 1.0\n",
      "positions (x,y,z), reward: [-0.79348055  2.21025519  4.33351905] 1.0\n",
      "Episode =  534, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.4760496   0.61289387  9.7792882 ] 1.0\n",
      "positions (x,y,z), reward: [-0.72618734  0.99868857  9.45430535] 1.0\n",
      "positions (x,y,z), reward: [-2.44372444  2.43539974  7.44103945] 1.0\n",
      "positions (x,y,z), reward: [-3.66811928  3.39830969  5.7876733 ] 1.0\n",
      "positions (x,y,z), reward: [-4.44532754  3.97498577  4.82365885] 1.0\n",
      "positions (x,y,z), reward: [-7.42496349  6.06952841  0.48309826] 1.0\n",
      "Episode =  536, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.16591291  0.06072614  9.92565311] 1.0\n",
      "positions (x,y,z), reward: [ 1.79382164 -0.41984577  8.75753924] 1.0\n",
      "positions (x,y,z), reward: [ 2.38190196 -0.86999682  8.04254765] 1.0\n",
      "positions (x,y,z), reward: [ 3.01144431 -1.66349566  6.79899967] 1.0\n",
      "positions (x,y,z), reward: [ 3.56097011 -2.34057083  5.45807519] 1.0\n",
      "positions (x,y,z), reward: [ 3.90571572 -2.88472591  3.93996961] 1.0\n",
      "Episode =  537, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03813526   0.02555609  10.04631672] 1.0\n",
      "positions (x,y,z), reward: [ 0.63947957  0.13607009  9.57717883] 1.0\n",
      "positions (x,y,z), reward: [ 0.98481825  0.16400711  9.40984444] 1.0\n",
      "positions (x,y,z), reward: [ 1.65150152  0.19282954  9.06468546] 1.0\n",
      "positions (x,y,z), reward: [ 2.97359848  0.12546928  8.10631993] 1.0\n",
      "Episode =  538, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.81150877  2.80658032  5.07347343] 1.0\n",
      "positions (x,y,z), reward: [-7.70535835  3.27891215  3.33344033] 1.0\n",
      "positions (x,y,z), reward: [-8.84807856  3.54954784  2.11178419] 1.0\n",
      "positions (x,y,z), reward: [-9.96754304  3.8118154   0.77415312] 1.0\n",
      "positions (x,y,z), reward: [-10.70248231   3.9775649    0.        ] 1.0\n",
      "Episode =  539, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.53600324 -2.91285845  6.82938953] 1.0\n",
      "positions (x,y,z), reward: [ 0.2983453  -3.62418506  5.76481124] 1.0\n",
      "positions (x,y,z), reward: [ 0.16305508 -3.99349617  5.19374512] 1.0\n",
      "positions (x,y,z), reward: [ 0.01811648 -4.36133548  4.5994156 ] 1.0\n",
      "positions (x,y,z), reward: [-0.30719057 -5.09438566  3.32084624] 1.0\n",
      "Episode =  540, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.43875254e-02  -9.56569396e-04   9.97082740e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.05804814  0.27689355  9.92024563] 1.0\n",
      "positions (x,y,z), reward: [ -1.76697263   1.16738251  10.4631879 ] 1.0\n",
      "positions (x,y,z), reward: [ -8.6235842    4.39453376  10.15309418] 1.0\n",
      "positions (x,y,z), reward: [-12.8220483    6.28355474   8.72849228] 1.0\n",
      "positions (x,y,z), reward: [-20.83922653  10.30372434   2.49871889] 1.0\n",
      "Episode =  541, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.05905087e-02   3.54534729e-04   1.00030553e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.40957788 -1.92624085  7.01507817] 1.0\n",
      "positions (x,y,z), reward: [-0.40449457 -2.74388956  5.09527014] 1.0\n",
      "Episode =  542, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.54142616 -0.25714906  5.79959259] 1.0\n",
      "positions (x,y,z), reward: [-6.870325   -0.19027735  4.48978368] 1.0\n",
      "Episode =  543, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00491254] 1.0\n",
      "positions (x,y,z), reward: [ 0.13131565 -0.01041304  9.8054851 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.69630778 -0.96474814  7.77591775] 1.0\n",
      "positions (x,y,z), reward: [ 1.99262943 -1.27515781  7.08900018] 1.0\n",
      "positions (x,y,z), reward: [ 2.4045757  -1.72197919  5.92307102] 1.0\n",
      "positions (x,y,z), reward: [ 3.05849999 -2.63385798  3.13486597] 1.0\n",
      "Episode =  544, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.30894806  0.06980239  9.72319872] 1.0\n",
      "positions (x,y,z), reward: [ 2.59184204  1.01194916  8.031514  ] 1.0\n",
      "positions (x,y,z), reward: [ 4.1708966   1.42572197  6.56796732] 1.0\n",
      "positions (x,y,z), reward: [ 6.33103738  1.79358286  3.7755168 ] 1.0\n",
      "positions (x,y,z), reward: [ 7.92309349  2.05161536  1.16671333] 1.0\n",
      "Episode =  545, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.84993618  0.02355308  7.44039592] 1.0\n",
      "positions (x,y,z), reward: [ 4.53867508  0.86837325  1.47832928] 1.0\n",
      "Episode =  546, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.68427326 -1.23969955  5.79749254] 1.0\n",
      "Episode =  547, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.71303006  0.80748244  9.66651777] 1.0\n",
      "positions (x,y,z), reward: [-1.99107171  0.94134282  9.59177291] 1.0\n",
      "positions (x,y,z), reward: [-7.95195464  4.04309479  7.41762177] 1.0\n",
      "positions (x,y,z), reward: [-8.90134164  4.40437239  6.94440224] 1.0\n",
      "positions (x,y,z), reward: [-17.5990319    7.27826691   0.        ] 1.0\n",
      "Episode =  548, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.52204566e-02  -5.20081548e-03   1.00427062e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.01159621  -0.08202     10.02913627] 1.0\n",
      "positions (x,y,z), reward: [ 1.07844591 -0.57842721  9.4015052 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.31171016 -0.72201952  9.27607904] 1.0\n",
      "positions (x,y,z), reward: [ 1.96089485 -1.28588211  8.64389402] 1.0\n",
      "positions (x,y,z), reward: [ 4.51481519 -3.98003568  4.54475867] 1.0\n",
      "positions (x,y,z), reward: [ 4.69027176 -4.21864383  4.10277844] 1.0\n",
      "positions (x,y,z), reward: [ 4.77721452 -4.33587434  3.87483574] 1.0\n",
      "positions (x,y,z), reward: [ 5.03877905 -4.69218507  3.16229871] 1.0\n",
      "Episode =  549, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.56466674 -0.03008575  9.67971693] 1.0\n",
      "positions (x,y,z), reward: [ 2.54135453 -0.91641646  7.73099699] 1.0\n",
      "positions (x,y,z), reward: [ 4.25155343 -2.05708332  5.50864375] 1.0\n",
      "positions (x,y,z), reward: [ 5.86582715 -3.51405391  1.878847  ] 1.0\n",
      "Episode =  550, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06007861  0.05678401  9.89922295] 1.0\n",
      "positions (x,y,z), reward: [-0.04030371  0.08778633  9.82153211] 1.0\n",
      "positions (x,y,z), reward: [-0.70977695 -1.30913825  4.73993369] 1.0\n",
      "positions (x,y,z), reward: [-1.23970555 -1.75889581  2.88674129] 1.0\n",
      "positions (x,y,z), reward: [-1.65114238 -2.08280576  1.36748251] 1.0\n",
      "positions (x,y,z), reward: [-1.87034697 -2.24349506  0.55776862] 1.0\n",
      "Episode =  551, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.13808654  0.56699517  9.34567692] 1.0\n",
      "positions (x,y,z), reward: [-0.08461756  0.63563001  9.12867901] 1.0\n",
      "positions (x,y,z), reward: [-0.527562    1.63064054  1.42391467] 1.0\n",
      "positions (x,y,z), reward: [-0.62577293  1.73465766  0.33501894] 1.0\n",
      "Episode =  552, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07106139  0.02392427  9.99233389] 1.0\n",
      "positions (x,y,z), reward: [ -1.04578356e-01  -6.02983324e-03   9.91685541e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.47807006 -0.05766283  8.09824393] 1.0\n",
      "Episode =  553, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.42846446 -0.66902848  8.77328758] 1.0\n",
      "positions (x,y,z), reward: [ 1.78940025 -0.91393941  8.36646026] 1.0\n",
      "positions (x,y,z), reward: [ 3.33823223 -2.21616874  5.47122467] 1.0\n",
      "positions (x,y,z), reward: [ 3.43362747 -2.31784     5.21177409] 1.0\n",
      "positions (x,y,z), reward: [ 3.79022778 -2.73045257  4.11771428] 1.0\n",
      "positions (x,y,z), reward: [ 4.83217701 -4.16788321  0.        ] 1.0\n",
      "Episode =  554, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02785814 -0.10497781  9.78714663] 1.0\n",
      "positions (x,y,z), reward: [-0.13103719 -2.67988176  5.84019204] 1.0\n",
      "positions (x,y,z), reward: [-0.16850344 -2.76178983  5.64439483] 1.0\n",
      "positions (x,y,z), reward: [-0.39885013 -3.24177221  4.39917   ] 1.0\n",
      "positions (x,y,z), reward: [-1.08337403 -4.68323356  0.        ] 1.0\n",
      "Episode =  555, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.30013238  0.05448783  9.55816433] 1.0\n",
      "positions (x,y,z), reward: [-0.6760046  -0.35891525  8.09084128] 1.0\n",
      "positions (x,y,z), reward: [-0.73382259 -0.39568892  7.95384691] 1.0\n",
      "Episode =  556, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.05440346  0.09765526  8.26647261] 1.0\n",
      "positions (x,y,z), reward: [ 4.69666293  0.46368729  3.8111962 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.33879914  0.61616176  1.32158928] 1.0\n",
      "Episode =  557, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.24090242 -0.09580541  9.8385183 ] 1.0\n",
      "positions (x,y,z), reward: [-1.04720507 -0.0751092   9.27870045] 1.0\n",
      "positions (x,y,z), reward: [-3.5474424   0.83607247  7.22930376] 1.0\n",
      "positions (x,y,z), reward: [-3.69449618  0.88842667  7.08645326] 1.0\n",
      "positions (x,y,z), reward: [-7.10398145  1.96939747  2.62020722] 1.0\n",
      "Episode =  558, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.55785074  0.20336903  9.66475373] 1.0\n",
      "positions (x,y,z), reward: [ 0.90771003  0.24185422  9.46697049] 1.0\n",
      "positions (x,y,z), reward: [ 5.6897474   0.05552916  4.85698004] 1.0\n",
      "Episode =  559, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.39878982e-02  -8.35436434e-03   1.00358443e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.19789821 -0.16319486  9.84986305] 1.0\n",
      "positions (x,y,z), reward: [ 1.11651201 -0.3688529   9.65230016] 1.0\n",
      "positions (x,y,z), reward: [ 1.88353898 -6.24421395  4.33718425] 1.0\n",
      "positions (x,y,z), reward: [ 1.86272429 -6.39766811  4.12226704] 1.0\n",
      "Episode =  560, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00507475] 1.0\n",
      "positions (x,y,z), reward: [-1.20342936  0.91937172  9.03996553] 1.0\n",
      "positions (x,y,z), reward: [-2.99534227  2.68841967  7.4304863 ] 1.0\n",
      "positions (x,y,z), reward: [-3.81288635  3.50135511  6.51426862] 1.0\n",
      "positions (x,y,z), reward: [-7.63266522  6.66194573  1.31994564] 1.0\n",
      "Episode =  561, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.71879766  1.31921044  9.35629043] 1.0\n",
      "positions (x,y,z), reward: [-2.66645055  3.73483107  7.52681513] 1.0\n",
      "positions (x,y,z), reward: [-3.58110275  4.8788713   6.07795131] 1.0\n",
      "positions (x,y,z), reward: [-5.00401001  6.53316355  3.4260489 ] 1.0\n",
      "positions (x,y,z), reward: [-5.96687326  7.64461112  1.13488202] 1.0\n",
      "positions (x,y,z), reward: [-6.28169071  8.00947597  0.31887598] 1.0\n",
      "Episode =  562, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.8755386  -1.80658027  7.84892602] 1.0\n",
      "positions (x,y,z), reward: [ 3.93430419 -4.2586587   3.59653646] 1.0\n",
      "Episode =  563, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.09969261 -0.82597422  9.16987952] 1.0\n",
      "positions (x,y,z), reward: [-0.4535379  -1.06648823  8.98684381] 1.0\n",
      "positions (x,y,z), reward: [-1.32369137 -1.56347836  8.38552811] 1.0\n",
      "positions (x,y,z), reward: [-4.98228147 -4.20001075  2.26777708] 1.0\n",
      "Episode =  564, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06904108 -0.15782836  9.92822578] 1.0\n",
      "positions (x,y,z), reward: [ 0.16922628 -0.34890913  9.56683986] 1.0\n",
      "positions (x,y,z), reward: [ 0.12873478 -0.43499944  9.48945256] 1.0\n",
      "positions (x,y,z), reward: [-0.1988883  -0.71617816  9.1914738 ] 1.0\n",
      "positions (x,y,z), reward: [-0.43941535 -0.81013797  9.06047952] 1.0\n",
      "positions (x,y,z), reward: [-2.07187279 -1.66829911  7.90697254] 1.0\n",
      "positions (x,y,z), reward: [-5.426691   -3.14028713  4.72377932] 1.0\n",
      "positions (x,y,z), reward: [-7.61897655 -3.92453831  2.08629935] 1.0\n",
      "Episode =  565, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02696809  0.02737481  9.40645406] 1.0\n",
      "positions (x,y,z), reward: [-0.96664026  0.20654099  9.08470549] 1.0\n",
      "positions (x,y,z), reward: [-1.68101854  0.55436961  8.88095366] 1.0\n",
      "positions (x,y,z), reward: [-2.41877067  0.94245941  8.6665689 ] 1.0\n",
      "positions (x,y,z), reward: [-6.27930966  2.13514137  7.57848294] 1.0\n",
      "positions (x,y,z), reward: [-16.87435577   4.4992732    0.91442245] 1.0\n",
      "Episode =  566, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00445421] 1.0\n",
      "positions (x,y,z), reward: [ -6.47806725e-02   8.71430420e-03   1.00240198e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.35942405e-01  -9.53065005e-03   9.89640074e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.56507453  1.55833449  6.08379213] 1.0\n",
      "positions (x,y,z), reward: [ 0.4153674   1.75012926  5.30196784] 1.0\n",
      "positions (x,y,z), reward: [-0.46651411  2.71923265  0.83196574] 1.0\n",
      "Episode =  567, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.41064238  0.45237774  9.32020897] 1.0\n",
      "positions (x,y,z), reward: [-0.5052526   0.51389241  9.14609993] 1.0\n",
      "positions (x,y,z), reward: [-2.78111177  1.77986346  4.49374402] 1.0\n",
      "positions (x,y,z), reward: [-2.87887696  1.82863198  4.27596896] 1.0\n",
      "Episode =  568, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.10684553  -0.0181484   10.01536297] 1.0\n",
      "positions (x,y,z), reward: [-3.5056665  -7.35715385  3.83943148] 1.0\n",
      "positions (x,y,z), reward: [-4.77148153 -8.80164034  1.52002272] 1.0\n",
      "Episode =  569, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08874183 -0.37788854  9.96486526] 1.0\n",
      "positions (x,y,z), reward: [ 3.68071751 -7.20892874  2.90821758] 1.0\n",
      "positions (x,y,z), reward: [ 3.87601032 -7.49079708  2.43308853] 1.0\n",
      "positions (x,y,z), reward: [ 4.62998955 -9.17454042  0.        ] 1.0\n",
      "Episode =  570, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.24466625e-02   3.74620313e-03   1.00086046e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.79162856 -2.58028941  5.99853247] 1.0\n",
      "positions (x,y,z), reward: [ 0.74862304 -2.63905232  5.80836066] 1.0\n",
      "positions (x,y,z), reward: [ 0.33894451 -3.09048813  3.9272867 ] 1.0\n",
      "Episode =  571, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05370825  0.03738596  9.47270331] 1.0\n",
      "positions (x,y,z), reward: [-0.02807872 -0.74325955  4.19105134] 1.0\n",
      "positions (x,y,z), reward: [-0.17634601 -0.80925158  3.57195159] 1.0\n",
      "positions (x,y,z), reward: [-0.58412675 -0.97266457  1.77621023] 1.0\n",
      "Episode =  572, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.19969644  0.30998876  9.55026567] 1.0\n",
      "positions (x,y,z), reward: [ 0.12594588  0.71560583  8.38378655] 1.0\n",
      "positions (x,y,z), reward: [-1.09387452  1.12587928  5.06220001] 1.0\n",
      "positions (x,y,z), reward: [-3.05935726  1.67034129  0.51834912] 1.0\n",
      "Episode =  573, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 6.00024817 -0.87710174  3.99250275] 1.0\n",
      "positions (x,y,z), reward: [ 6.42291056 -1.05486742  3.26647979] 1.0\n",
      "Episode =  574, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.98758871e-03  -1.80998500e-03   1.00196320e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.04035672 -0.15971216  9.88097771] 1.0\n",
      "positions (x,y,z), reward: [ 1.0551614  -0.27361909  8.91851825] 1.0\n",
      "positions (x,y,z), reward: [ 3.8741967  0.0087045  5.9910773] 1.0\n",
      "positions (x,y,z), reward: [ 4.390783    0.1179812   5.12340678] 1.0\n",
      "positions (x,y,z), reward: [ 4.83740166  0.23267594  4.07767183] 1.0\n",
      "positions (x,y,z), reward: [ 5.05846146  0.29453814  3.50041167] 1.0\n",
      "positions (x,y,z), reward: [ 6.40435899  0.72999006  0.        ] 1.0\n",
      "Episode =  575, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.80206717e-03  -2.15208290e-01   1.06642651e+01] 1.0\n",
      "positions (x,y,z), reward: [-10.6960757   -4.93247072  11.35546523] 1.0\n",
      "positions (x,y,z), reward: [-21.18127353  -9.30911511   7.84897323] 1.0\n",
      "positions (x,y,z), reward: [-23.07462923 -10.44110436   6.76580026] 1.0\n",
      "Episode =  576, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.65968121 -0.63341836  5.17126712] 1.0\n",
      "Episode =  577, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05228664  -0.35777346  10.51599208] 1.0\n",
      "positions (x,y,z), reward: [ -0.66911898  -1.04380023  10.38138543] 1.0\n",
      "positions (x,y,z), reward: [ -0.95351405  -1.36169786  10.20417796] 1.0\n",
      "positions (x,y,z), reward: [-3.38901511 -2.58169201  8.61777706] 1.0\n",
      "positions (x,y,z), reward: [-7.53611625 -4.06625126  5.13942376] 1.0\n",
      "positions (x,y,z), reward: [-12.21936586  -5.19016755   0.        ] 1.0\n",
      "Episode =  578, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.22938102e-02   3.64466127e-03   1.00170197e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.21645139 -0.75992829  8.80198577] 1.0\n",
      "positions (x,y,z), reward: [ 1.13483678 -1.53373993  7.55221208] 1.0\n",
      "positions (x,y,z), reward: [ 1.00681959 -1.75575196  7.09553321] 1.0\n",
      "Episode =  579, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.69968975  0.38890563  9.18162427] 1.0\n",
      "positions (x,y,z), reward: [ 7.94039231  0.50457577  0.24349873] 1.0\n",
      "Episode =  580, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.81665831e-02   8.75967098e-03   9.96285414e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.46173558  0.16159823  9.89544143] 1.0\n",
      "positions (x,y,z), reward: [-1.05716207  0.52117953  9.5457429 ] 1.0\n",
      "positions (x,y,z), reward: [-1.42552798  1.010433    9.06492086] 1.0\n",
      "positions (x,y,z), reward: [-2.55080059  2.29776698  6.90599839] 1.0\n",
      "positions (x,y,z), reward: [-5.96495899  4.93165915  0.36725932] 1.0\n",
      "Episode =  581, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.13844273e-03  -5.95247655e-03   1.00112874e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.35774525 -0.18686667  9.17590811] 1.0\n",
      "positions (x,y,z), reward: [ 0.32119025 -0.50658599  8.81847511] 1.0\n",
      "positions (x,y,z), reward: [ 0.12256723 -0.85039851  8.34667597] 1.0\n",
      "positions (x,y,z), reward: [-0.38428525 -1.4058429   7.56585565] 1.0\n",
      "positions (x,y,z), reward: [-0.67299229 -1.64013155  7.17604155] 1.0\n",
      "positions (x,y,z), reward: [-0.98962393 -1.86469677  6.73794009] 1.0\n",
      "positions (x,y,z), reward: [-1.20956896 -2.00320919  6.41672603] 1.0\n",
      "Episode =  582, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.42337965e-02  -5.67408680e-03   1.00623755e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.14437732  0.66197819  9.29468376] 1.0\n",
      "positions (x,y,z), reward: [-0.04450644  0.99711277  8.91493251] 1.0\n",
      "positions (x,y,z), reward: [-0.10777987  1.06357604  8.828988  ] 1.0\n",
      "positions (x,y,z), reward: [-0.50664819  1.37313846  8.31613933] 1.0\n",
      "positions (x,y,z), reward: [-2.81504931  2.46226509  4.01239789] 1.0\n",
      "positions (x,y,z), reward: [-3.16905532  2.61089416  3.0260907 ] 1.0\n",
      "Episode =  583, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.12075874e+00  -9.55287223e-03   9.94039507e+00] 1.0\n",
      "positions (x,y,z), reward: [-7.74849023  0.27907982  8.43355451] 1.0\n",
      "positions (x,y,z), reward: [-8.29605723  0.33511505  8.22921995] 1.0\n",
      "positions (x,y,z), reward: [-8.8446013   0.39160773  8.00902369] 1.0\n",
      "positions (x,y,z), reward: [-13.77058408   0.62071338   5.46656421] 1.0\n",
      "positions (x,y,z), reward: [-14.31601191   0.63093162   5.11901937] 1.0\n",
      "positions (x,y,z), reward: [-17.00463406   0.69761464   3.17151362] 1.0\n",
      "positions (x,y,z), reward: [-17.2730995    0.70694295   2.94927592] 1.0\n",
      "Episode =  584, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.69819456 -0.07578705  9.23123907] 1.0\n",
      "positions (x,y,z), reward: [ 3.27003538 -1.0475116   6.75155269] 1.0\n",
      "positions (x,y,z), reward: [ 3.72086308 -1.29029796  6.16788158] 1.0\n",
      "positions (x,y,z), reward: [ 6.66189013 -3.53649625  0.28273139] 1.0\n",
      "Episode =  585, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0607776   -0.03159477  10.08349016] 1.0\n",
      "positions (x,y,z), reward: [ 3.7084879  -0.27908456  7.83349271] 1.0\n",
      "positions (x,y,z), reward: [  5.46722150e+00  -2.23935675e-03   6.50951767e+00] 1.0\n",
      "positions (x,y,z), reward: [ 10.46532079   0.46079708   1.63747439] 1.0\n",
      "Episode =  586, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.29568192 -1.62123329  7.39889713] 1.0\n",
      "positions (x,y,z), reward: [ 1.89982341 -4.41089269  0.        ] 1.0\n",
      "Episode =  587, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.37614376 -1.39831325  2.70041419] 1.0\n",
      "Episode =  588, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16740444  0.14831169  9.90401525] 1.0\n",
      "positions (x,y,z), reward: [ 0.08369057  0.29453846  9.60686582] 1.0\n",
      "positions (x,y,z), reward: [ 5.7521102   1.98536903  4.45973161] 1.0\n",
      "positions (x,y,z), reward: [ 6.07514037  2.11601003  4.06946437] 1.0\n",
      "Episode =  589, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.27996664e-02  -5.74356677e-03   9.98257872e+00] 1.0\n",
      "positions (x,y,z), reward: [-1.1181786   1.25261744  6.97106721] 1.0\n",
      "positions (x,y,z), reward: [-1.81445109  1.59864558  5.3156241 ] 1.0\n",
      "positions (x,y,z), reward: [-3.53724733  2.30641668  1.14037654] 1.0\n",
      "Episode =  590, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  4.20884988e-03   6.16435201e-02   1.00601738e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.03716629  0.93821206  8.23051354] 1.0\n",
      "positions (x,y,z), reward: [ 5.84780708  1.91509634  1.24352676] 1.0\n",
      "Episode =  591, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04753291   0.02839131  10.02588077] 1.0\n",
      "positions (x,y,z), reward: [ 1.06785163 -0.44774169  9.43548441] 1.0\n",
      "positions (x,y,z), reward: [ 1.07070252 -0.70597504  9.26711363] 1.0\n",
      "positions (x,y,z), reward: [ 0.95786255 -0.96536819  8.89641631] 1.0\n",
      "positions (x,y,z), reward: [-1.16774322 -0.96522255  6.67074449] 1.0\n",
      "positions (x,y,z), reward: [-1.68932353 -0.87068683  6.17031033] 1.0\n",
      "Episode =  592, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15365125  0.27260229  9.56018161] 1.0\n",
      "positions (x,y,z), reward: [ 0.2206836   0.64808154  9.03811286] 1.0\n",
      "Episode =  593, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.13131345  0.06488001  9.91688494] 1.0\n",
      "positions (x,y,z), reward: [-3.05258882 -0.97261093  7.73274773] 1.0\n",
      "positions (x,y,z), reward: [-6.32647482 -1.8666375   4.65854296] 1.0\n",
      "Episode =  594, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.7515191   -0.6493419   10.26818064] 1.0\n",
      "positions (x,y,z), reward: [ -0.9725339   -0.83993013  10.24522336] 1.0\n",
      "positions (x,y,z), reward: [ -2.02922418  -1.50533636  10.06954212] 1.0\n",
      "positions (x,y,z), reward: [-3.21128163 -2.0557626   9.76469575] 1.0\n",
      "positions (x,y,z), reward: [-7.40497644 -3.29186574  7.92136026] 1.0\n",
      "positions (x,y,z), reward: [-13.60971039  -4.70754984   3.57631214] 1.0\n",
      "positions (x,y,z), reward: [-14.38414155  -4.82350256   2.89754205] 1.0\n",
      "Episode =  595, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.27306554  0.02068879  9.93675858] 1.0\n",
      "positions (x,y,z), reward: [-3.27835937 -1.39045455  6.99707919] 1.0\n",
      "positions (x,y,z), reward: [-5.46773788 -2.76111088  2.1207528 ] 1.0\n",
      "positions (x,y,z), reward: [-5.75904957 -2.9536042   1.15014568] 1.0\n",
      "Episode =  596, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.01326617  0.13573622  9.90571608] 1.0\n",
      "positions (x,y,z), reward: [ 0.11864516  0.12614607  9.63975236] 1.0\n",
      "positions (x,y,z), reward: [ 2.34034933 -1.29084659  5.73329549] 1.0\n",
      "Episode =  597, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.02350752 -3.29347813  7.76747836] 1.0\n",
      "positions (x,y,z), reward: [ 2.10990565 -5.29727242  5.31923297] 1.0\n",
      "positions (x,y,z), reward: [ 2.10601487 -5.45565798  5.0919646 ] 1.0\n",
      "Episode =  598, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0054071] 1.0\n",
      "positions (x,y,z), reward: [ -0.04463185   0.01959773  10.01887889] 1.0\n",
      "positions (x,y,z), reward: [ 0.91761288 -0.25516573  9.24058288] 1.0\n",
      "Episode =  599, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00587989] 1.0\n",
      "positions (x,y,z), reward: [-0.1510546  -0.20356262  8.485578  ] 1.0\n",
      "positions (x,y,z), reward: [-0.02311607 -0.39028034  0.72223266] 1.0\n",
      "Episode =  600, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.87035455e-03  -5.16176862e-03   1.00083529e+01] 1.0\n",
      "positions (x,y,z), reward: [-1.33199318 -0.15676522  8.3688854 ] 1.0\n",
      "positions (x,y,z), reward: [-2.53963923 -0.33817039  4.81802469] 1.0\n",
      "Episode =  601, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.62435342  -0.17387458  10.0647933 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.98188963  -0.16862212  10.13651331] 1.0\n",
      "positions (x,y,z), reward: [ -2.7847325    0.01913754  10.17506026] 1.0\n",
      "positions (x,y,z), reward: [ -3.54936611   0.11424354  10.05061276] 1.0\n",
      "positions (x,y,z), reward: [-8.74924016  1.06551414  7.22169726] 1.0\n",
      "positions (x,y,z), reward: [-10.54587152   1.24830189   5.41061746] 1.0\n",
      "positions (x,y,z), reward: [-13.64261047   1.84300939   1.29926049] 1.0\n",
      "Episode =  602, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02422954  0.4564619   9.50857048] 1.0\n",
      "positions (x,y,z), reward: [-3.63709406  4.27703522  5.20959445] 1.0\n",
      "positions (x,y,z), reward: [-3.79737914  4.39234371  5.01909131] 1.0\n",
      "Episode =  603, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  2.17561522e-02   4.47821685e-03   9.75402269e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.03536594 -0.87374954  8.39818593] 1.0\n",
      "positions (x,y,z), reward: [ 0.63072981 -1.74751196  6.70592623] 1.0\n",
      "positions (x,y,z), reward: [-0.36251176 -2.81871787  3.1574235 ] 1.0\n",
      "Episode =  605, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.12920455 -2.35729578  7.58796494] 1.0\n",
      "positions (x,y,z), reward: [-0.61570677 -3.84300947  3.50701659] 1.0\n",
      "Episode =  606, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.37148633   0.41759765  10.09262551] 1.0\n",
      "positions (x,y,z), reward: [ -0.4374067    0.48426559  10.0580032 ] 1.0\n",
      "positions (x,y,z), reward: [-1.32170962  1.3493182   9.41324747] 1.0\n",
      "positions (x,y,z), reward: [-2.45310572  2.0506605   8.67150114] 1.0\n",
      "positions (x,y,z), reward: [-2.61737317  2.15307855  8.55852345] 1.0\n",
      "positions (x,y,z), reward: [-5.33552136  4.44098048  6.25250586] 1.0\n",
      "positions (x,y,z), reward: [-6.02231061  4.97430323  5.65197372] 1.0\n",
      "Episode =  607, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.47886873e-02  -2.18652118e-04   1.00198799e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.07179286 -1.72335232  9.20793914] 1.0\n",
      "positions (x,y,z), reward: [ 0.02511263 -2.46522181  8.31226707] 1.0\n",
      "positions (x,y,z), reward: [-0.91718378 -3.66263466  5.57632311] 1.0\n",
      "positions (x,y,z), reward: [-2.13422558 -4.48505559  1.86433823] 1.0\n",
      "Episode =  609, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02308891  -0.02394239  10.13021624] 1.0\n",
      "Episode =  610, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00512109] 1.0\n",
      "positions (x,y,z), reward: [-0.23218319  0.13694169  9.9676765 ] 1.0\n",
      "positions (x,y,z), reward: [-8.36395807  0.23107376  5.49730411] 1.0\n",
      "positions (x,y,z), reward: [-13.04131381   0.61410218   1.05394099] 1.0\n",
      "Episode =  611, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 4.40002501  3.51976521  3.69581685] 1.0\n",
      "Episode =  612, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.46501652e-02  -5.42445064e-03   9.79309318e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.05798693  0.02766662  9.69006931] 1.0\n",
      "positions (x,y,z), reward: [-0.07199054  0.03193263  9.65565365] 1.0\n",
      "positions (x,y,z), reward: [-1.01737499  0.12468458  9.11994711] 1.0\n",
      "positions (x,y,z), reward: [-2.37940454  0.10743986  8.4217074 ] 1.0\n",
      "positions (x,y,z), reward: [-4.3446229   0.08257201  6.76151268] 1.0\n",
      "positions (x,y,z), reward: [-5.50802402  0.1026052   5.52327917] 1.0\n",
      "Episode =  613, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04824243 -0.19772972  9.83259549] 1.0\n",
      "positions (x,y,z), reward: [ 0.45237752 -0.27633817  8.63293234] 1.0\n",
      "positions (x,y,z), reward: [ 0.49190075 -0.27512565  8.47670909] 1.0\n",
      "Episode =  614, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.396661    1.791933    8.19825459] 1.0\n",
      "positions (x,y,z), reward: [-2.95534236  2.73141277  7.06983957] 1.0\n",
      "Episode =  615, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05286497   0.01688984  10.03272725] 1.0\n",
      "positions (x,y,z), reward: [ 1.35915979  0.13424463  9.25546995] 1.0\n",
      "positions (x,y,z), reward: [ 1.78099634 -0.18733935  8.76361948] 1.0\n",
      "positions (x,y,z), reward: [ 1.83778481 -0.3573694   8.47961231] 1.0\n",
      "positions (x,y,z), reward: [ 2.06675752 -1.4529971   5.18251361] 1.0\n",
      "positions (x,y,z), reward: [ 2.37723189 -2.58114349  1.3140334 ] 1.0\n",
      "Episode =  616, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.09717879e-02   2.88687885e-03   1.00194176e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.20658583 -0.05121359  9.90513552] 1.0\n",
      "positions (x,y,z), reward: [ 1.90158744 -2.45042538  6.86954199] 1.0\n",
      "positions (x,y,z), reward: [ 2.46761642 -4.45675651  2.72933152] 1.0\n",
      "Episode =  617, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.1966561  -0.02299255  9.59471974] 1.0\n",
      "positions (x,y,z), reward: [ 0.37991143 -0.04837543  9.47559874] 1.0\n",
      "positions (x,y,z), reward: [ 0.56942855 -0.13203979  9.36379603] 1.0\n",
      "Episode =  618, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.95131665e-02   2.69587311e-03   1.00197744e+01] 1.0\n",
      "positions (x,y,z), reward: [ -3.60361784e-02  -4.76948342e-03   1.00056581e+01] 1.0\n",
      "positions (x,y,z), reward: [ -8.18656077e-03   2.22725038e-02   9.98450337e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.39853224  0.48228385  9.90213341] 1.0\n",
      "Episode =  619, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.26575852  0.33682157  9.48293231] 1.0\n",
      "positions (x,y,z), reward: [-0.41358516  0.39855802  9.32262303] 1.0\n",
      "positions (x,y,z), reward: [-1.0118687   0.82227935  8.76410093] 1.0\n",
      "positions (x,y,z), reward: [-3.61359806  2.35235688  6.87340123] 1.0\n",
      "positions (x,y,z), reward: [-5.64178609  3.77485288  5.01852342] 1.0\n",
      "Episode =  620, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.22629949 -0.19958512  9.73534152] 1.0\n",
      "positions (x,y,z), reward: [ 0.69605823 -0.19831764  7.56427867] 1.0\n",
      "positions (x,y,z), reward: [ 1.57160613 -0.34379707  4.53050388] 1.0\n",
      "Episode =  621, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.12223604  -0.55096718  10.21353162] 1.0\n",
      "positions (x,y,z), reward: [ 0.94371514 -4.53093113  9.24411323] 1.0\n",
      "positions (x,y,z), reward: [ 1.83828401 -4.80925371  8.34191382] 1.0\n",
      "positions (x,y,z), reward: [ 4.71959229 -6.63823293  2.76951841] 1.0\n",
      "Episode =  622, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.23311275  0.85936066  8.48527175] 1.0\n",
      "positions (x,y,z), reward: [-2.93251202  3.24156617  4.61380974] 1.0\n",
      "positions (x,y,z), reward: [-3.3436014   3.59936807  3.865971  ] 1.0\n",
      "positions (x,y,z), reward: [-4.32250524  4.51368691  1.80360471] 1.0\n",
      "positions (x,y,z), reward: [-4.52350851  4.69998975  1.35874207] 1.0\n",
      "Episode =  623, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.57184858 -0.4823227   9.29054205] 1.0\n",
      "positions (x,y,z), reward: [ 0.38912738 -0.68004249  9.18433263] 1.0\n",
      "positions (x,y,z), reward: [-1.09701838 -1.44811851  8.09684616] 1.0\n",
      "Episode =  624, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15796705 -0.13608486  9.94076317] 1.0\n",
      "positions (x,y,z), reward: [ 0.80762778 -0.25423267  9.33098159] 1.0\n",
      "positions (x,y,z), reward: [ 0.90667983 -0.27707128  9.25561007] 1.0\n",
      "positions (x,y,z), reward: [ 2.19096663 -0.83948876  8.00059855] 1.0\n",
      "positions (x,y,z), reward: [ 5.89923961 -3.51981646  1.36388417] 1.0\n",
      "Episode =  625, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.63592297  -1.07684852  10.22612297] 1.0\n",
      "positions (x,y,z), reward: [-3.12313007 -2.55089779  9.58388221] 1.0\n",
      "positions (x,y,z), reward: [-6.45682095 -3.09078011  8.37624706] 1.0\n",
      "positions (x,y,z), reward: [-10.53935248  -3.07535585   5.89093173] 1.0\n",
      "positions (x,y,z), reward: [-13.8399047   -3.17203451   2.3765505 ] 1.0\n",
      "Episode =  626, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0051868] 1.0\n",
      "positions (x,y,z), reward: [-0.07906673  0.03613341  9.98100802] 1.0\n",
      "positions (x,y,z), reward: [-0.0381338   0.26417854  9.29958846] 1.0\n",
      "positions (x,y,z), reward: [ 1.66699627  1.3239727   3.27232242] 1.0\n",
      "positions (x,y,z), reward: [ 2.59211613  1.73189703  0.09888411] 1.0\n",
      "Episode =  627, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10103262  0.04015222  9.98942843] 1.0\n",
      "positions (x,y,z), reward: [ 0.51542938  1.51465773  8.53145287] 1.0\n",
      "positions (x,y,z), reward: [ 2.03861893  2.56716529  6.22959824] 1.0\n",
      "positions (x,y,z), reward: [ 5.60983741  3.21084612  0.        ] 1.0\n",
      "Episode =  628, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.35942459 -0.05209758  9.54382091] 1.0\n",
      "positions (x,y,z), reward: [ 1.24764958 -1.15925546  8.39024911] 1.0\n",
      "positions (x,y,z), reward: [ 1.18263218 -1.42600129  8.01126524] 1.0\n",
      "positions (x,y,z), reward: [ 0.93454533 -1.80906532  7.29386451] 1.0\n",
      "positions (x,y,z), reward: [-0.23748178 -2.65398032  4.33658139] 1.0\n",
      "Episode =  629, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.6777754   0.25039138  9.9625317 ] 1.0\n",
      "positions (x,y,z), reward: [-4.55781407  0.92884659  9.99526576] 1.0\n",
      "positions (x,y,z), reward: [-6.07547929  1.13494444  9.52104723] 1.0\n",
      "positions (x,y,z), reward: [-8.01901227  1.41705817  8.86644093] 1.0\n",
      "positions (x,y,z), reward: [-12.39353589   1.86665032   6.7652408 ] 1.0\n",
      "positions (x,y,z), reward: [-17.39640201   2.49603385   3.12838242] 1.0\n",
      "Episode =  630, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.10704456  -0.05189493  10.03848261] 1.0\n",
      "positions (x,y,z), reward: [  0.19001958   0.30561285  10.24455875] 1.0\n",
      "positions (x,y,z), reward: [ -4.90445316   2.70646124  10.74667423] 1.0\n",
      "positions (x,y,z), reward: [ -5.14916771   2.82373136  10.72876482] 1.0\n",
      "positions (x,y,z), reward: [-23.26410838   7.53898879   5.91324374] 1.0\n",
      "positions (x,y,z), reward: [-24.371631     7.7871851    5.40482929] 1.0\n",
      "positions (x,y,z), reward: [-26.91558133   8.20291027   3.99538677] 1.0\n",
      "positions (x,y,z), reward: [-29.73300638   8.63034577   2.08480793] 1.0\n",
      "positions (x,y,z), reward: [-30.41144834   8.749229     1.559906  ] 1.0\n",
      "Episode =  631, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00503658] 1.0\n",
      "positions (x,y,z), reward: [ -5.96436979e-03  -1.39994931e-03   1.00097659e+01] 1.0\n",
      "positions (x,y,z), reward: [ -4.78160509e-02  -3.03655706e-03   9.98215404e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.12393044 -1.43084847  8.33417076] 1.0\n",
      "positions (x,y,z), reward: [ 0.43535542 -2.89772666  6.03159699] 1.0\n",
      "Episode =  632, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.61039942 -2.59567152  5.61705181] 1.0\n",
      "positions (x,y,z), reward: [-2.95479943 -2.82481756  4.97758404] 1.0\n",
      "Episode =  633, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.64875684  0.64138417  5.5033173 ] 1.0\n",
      "positions (x,y,z), reward: [-7.24430716  1.05236797  4.13526988] 1.0\n",
      "Episode =  634, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.8916032  -0.80208298  6.80937686] 1.0\n",
      "Episode =  635, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.25543957 -0.21339462  9.44628537] 1.0\n",
      "positions (x,y,z), reward: [-9.72278434 -0.29623289  2.71417702] 1.0\n",
      "positions (x,y,z), reward: [-10.1832164   -0.28010329   2.214157  ] 1.0\n",
      "Episode =  636, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05369863 -0.11072613  9.94654369] 1.0\n",
      "positions (x,y,z), reward: [ 0.01872753 -0.35624515  8.87340676] 1.0\n",
      "positions (x,y,z), reward: [-2.24293721 -1.36003144  4.30615501] 1.0\n",
      "positions (x,y,z), reward: [-4.01875129 -2.03276976  0.14140759] 1.0\n",
      "positions (x,y,z), reward: [-4.26733936 -2.128578    0.        ] 1.0\n",
      "Episode =  637, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0545456   -0.03139623  10.05565656] 1.0\n",
      "positions (x,y,z), reward: [ 0.13249482 -0.14157067  9.99036647] 1.0\n",
      "positions (x,y,z), reward: [ 1.05448128 -0.32254246  9.63248845] 1.0\n",
      "positions (x,y,z), reward: [ 4.96085052 -1.62617524  6.69802548] 1.0\n",
      "positions (x,y,z), reward: [ 10.10259837  -2.82881132   1.68064488] 1.0\n",
      "Episode =  638, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.08700328  0.26275207  9.73836743] 1.0\n",
      "positions (x,y,z), reward: [ 1.90660462  1.03798261  6.03652655] 1.0\n",
      "positions (x,y,z), reward: [ 2.20511374  1.04719641  5.39814461] 1.0\n",
      "Episode =  639, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-21.96252746   0.62074731   6.09410377] 1.0\n",
      "positions (x,y,z), reward: [-25.04847265   0.93246077   3.56422634] 1.0\n",
      "positions (x,y,z), reward: [ -2.81298989e+01   1.22350090e+00   1.63002494e-02] 1.0\n",
      "Episode =  640, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05479554   0.02652383  10.00614007] 1.0\n",
      "positions (x,y,z), reward: [-0.15763197  0.15916735  9.79981508] 1.0\n",
      "positions (x,y,z), reward: [-0.4871915   0.32857496  9.34320973] 1.0\n",
      "positions (x,y,z), reward: [-2.49737578  0.78556963  6.38656621] 1.0\n",
      "Episode =  641, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00529055] 1.0\n",
      "positions (x,y,z), reward: [ 1.30950192 -0.62669463  8.86281794] 1.0\n",
      "positions (x,y,z), reward: [ 6.74784976 -5.18239809  0.        ] 1.0\n",
      "Episode =  642, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06014966 -0.12701245  9.95184604] 1.0\n",
      "positions (x,y,z), reward: [ 0.07334892 -0.40907707  9.64808367] 1.0\n",
      "positions (x,y,z), reward: [ 0.42442005 -0.86261409  9.02448049] 1.0\n",
      "positions (x,y,z), reward: [-0.16653865 -1.6544172   6.30146556] 1.0\n",
      "Episode =  643, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.61603533e-03  -4.76176838e-03   1.00134997e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.16981879 -0.10318391  9.99595247] 1.0\n",
      "positions (x,y,z), reward: [-0.14215316 -0.13911118  9.88755826] 1.0\n",
      "positions (x,y,z), reward: [ 0.06396894 -0.12427894  9.56324287] 1.0\n",
      "positions (x,y,z), reward: [ 0.07068411 -0.12264858  9.3140726 ] 1.0\n",
      "positions (x,y,z), reward: [-0.48713733 -0.22956603  8.18455917] 1.0\n",
      "positions (x,y,z), reward: [-1.04042467 -0.29093342  7.4838145 ] 1.0\n",
      "positions (x,y,z), reward: [-2.09499125 -0.34391106  6.22637484] 1.0\n",
      "positions (x,y,z), reward: [-3.38178038 -0.27885098  4.50209893] 1.0\n",
      "positions (x,y,z), reward: [-3.83112368 -0.2517451   3.86892305] 1.0\n",
      "Episode =  644, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.02601124e-02   5.86668829e-03   1.00256803e+01] 1.0\n",
      "positions (x,y,z), reward: [ 2.98932947  0.48632478  8.12536878] 1.0\n",
      "positions (x,y,z), reward: [ 8.61607454  1.04074883  3.63890352] 1.0\n",
      "positions (x,y,z), reward: [ 9.50791278  1.00176538  2.70208675] 1.0\n",
      "Episode =  645, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.06465253 -0.03826128  9.76436863] 1.0\n",
      "positions (x,y,z), reward: [-0.74661972  1.29592124  8.69203805] 1.0\n",
      "positions (x,y,z), reward: [-2.43205694  2.47864646  7.76075087] 1.0\n",
      "Episode =  646, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.62063365  0.16380731  9.1025415 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.01072608 -0.72060192  6.91319764] 1.0\n",
      "positions (x,y,z), reward: [ 0.96098511 -1.29120271  5.42259727] 1.0\n",
      "positions (x,y,z), reward: [ 0.85920341 -1.73688943  4.23405147] 1.0\n",
      "Episode =  647, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.42063453  0.71672723  8.19330783] 1.0\n",
      "positions (x,y,z), reward: [ 0.37875576  0.77939095  7.88270476] 1.0\n",
      "Episode =  648, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.01388386 -1.86497482  8.00231302] 1.0\n",
      "positions (x,y,z), reward: [-1.96068357 -2.87237076  5.75896655] 1.0\n",
      "Episode =  649, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.01330583   0.02379019  10.00016803] 1.0\n",
      "positions (x,y,z), reward: [ 0.89605283 -0.5360449   8.8816469 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.70856306 -1.93836996  6.45231267] 1.0\n",
      "positions (x,y,z), reward: [ 1.80477236 -2.63609275  4.91436813] 1.0\n",
      "Episode =  650, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.9296536  -0.51292348  9.11387285] 1.0\n",
      "positions (x,y,z), reward: [ 0.945689   -0.59349717  9.02197697] 1.0\n",
      "positions (x,y,z), reward: [-0.0473964  -2.70872032  4.41606369] 1.0\n",
      "positions (x,y,z), reward: [-0.60993269 -3.29972253  2.48440431] 1.0\n",
      "positions (x,y,z), reward: [-1.0048256  -3.71468603  1.01221945] 1.0\n",
      "Episode =  651, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00539105] 1.0\n",
      "positions (x,y,z), reward: [-0.14149644 -0.03256217  9.12461042] 1.0\n",
      "Episode =  652, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.08388135  -0.15672495  10.06087302] 1.0\n",
      "positions (x,y,z), reward: [ 1.39327809 -0.54319393  9.40074712] 1.0\n",
      "Episode =  653, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  4.92425995e-04  -3.01734074e-02   9.80423213e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.92625936 -0.5130158   8.73280792] 1.0\n",
      "positions (x,y,z), reward: [ 1.13081947 -2.07628581  5.28671621] 1.0\n",
      "Episode =  654, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04427567  -0.02831785  10.01509394] 1.0\n",
      "positions (x,y,z), reward: [ 0.08974126 -0.23147379  9.8958431 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.41571841 -0.45755526  9.13187755] 1.0\n",
      "positions (x,y,z), reward: [ 3.66195775 -1.5167501   5.44389026] 1.0\n",
      "positions (x,y,z), reward: [ 3.91112399 -1.67931561  4.24765638] 1.0\n",
      "positions (x,y,z), reward: [ 4.1110588  -1.79562524  3.16390083] 1.0\n",
      "positions (x,y,z), reward: [ 4.31587698 -1.92436091  1.9867953 ] 1.0\n",
      "Episode =  655, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.58933876e-03   5.07045027e-03   1.00115012e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.10506782  0.05071888  9.97933975] 1.0\n",
      "positions (x,y,z), reward: [-1.59300586 -0.31730144  9.3105783 ] 1.0\n",
      "positions (x,y,z), reward: [-6.73607653 -0.75365946  7.1999602 ] 1.0\n",
      "positions (x,y,z), reward: [-10.19309225  -0.73789809   5.38446329] 1.0\n",
      "positions (x,y,z), reward: [-11.02558615  -0.76178512   4.86447887] 1.0\n",
      "positions (x,y,z), reward: [-16.28305098  -0.86843932   0.68449074] 1.0\n",
      "Episode =  656, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.55421621e-03  -4.23493907e-03   1.00132105e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.28997322   0.12534821  10.22971681] 1.0\n",
      "positions (x,y,z), reward: [ -0.26021457   0.26161166  10.44864068] 1.0\n",
      "positions (x,y,z), reward: [-9.10020758  2.1183216   6.77495757] 1.0\n",
      "positions (x,y,z), reward: [-10.79899993   2.45886132   5.45628415] 1.0\n",
      "Episode =  657, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.89891407  1.41226118  6.56124617] 1.0\n",
      "positions (x,y,z), reward: [ 5.13219459  1.84356863  5.11616662] 1.0\n",
      "positions (x,y,z), reward: [ 6.09791011  2.10913304  3.99202826] 1.0\n",
      "positions (x,y,z), reward: [ 7.64055888  2.44735304  1.90905908] 1.0\n",
      "Episode =  658, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04703856 -0.01489418  9.98656972] 1.0\n",
      "positions (x,y,z), reward: [-0.0230935  -0.17226376  9.7559967 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.70367249 -1.47278166  8.13773012] 1.0\n",
      "positions (x,y,z), reward: [ 0.67448607 -1.5389522   8.03024333] 1.0\n",
      "positions (x,y,z), reward: [ 0.6095773  -1.66021279  7.81916264] 1.0\n",
      "positions (x,y,z), reward: [ 0.41486549 -1.99135396  7.12482797] 1.0\n",
      "positions (x,y,z), reward: [ 0.31511025 -2.23299374  6.55528333] 1.0\n",
      "positions (x,y,z), reward: [ 0.19663632 -2.63140149  5.50268049] 1.0\n",
      "positions (x,y,z), reward: [-0.20353957 -3.92997763  1.06673495] 1.0\n",
      "Episode =  659, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.7594489  -1.02439209  7.26997409] 1.0\n",
      "positions (x,y,z), reward: [ 0.24951927 -1.68650009  4.87626124] 1.0\n",
      "positions (x,y,z), reward: [-0.45556691 -2.28043871  2.14015802] 1.0\n",
      "Episode =  661, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07815415  -0.06696939  10.06430565] 1.0\n",
      "positions (x,y,z), reward: [ -0.07907076  -0.09744726  10.06037797] 1.0\n",
      "positions (x,y,z), reward: [ 1.5275986  -3.10386731  8.52120006] 1.0\n",
      "positions (x,y,z), reward: [-0.71379368 -6.19875322  4.59939345] 1.0\n",
      "Episode =  662, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.03456314e-02  -2.36298399e-03   1.00175654e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.46178308 -0.30452497  9.79388955] 1.0\n",
      "positions (x,y,z), reward: [ 0.80962032 -0.53543372  9.65237697] 1.0\n",
      "positions (x,y,z), reward: [ 1.61421772 -1.92518589  8.13567128] 1.0\n",
      "positions (x,y,z), reward: [ 1.63062443 -2.03247003  7.98210656] 1.0\n",
      "positions (x,y,z), reward: [ 0.80831889 -4.79155326  1.36209625] 1.0\n",
      "Episode =  663, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05587536 -0.02636834  9.69024565] 1.0\n",
      "positions (x,y,z), reward: [-0.10396952  0.12259444  9.43955916] 1.0\n",
      "positions (x,y,z), reward: [-1.15034337  1.01136242  8.26028875] 1.0\n",
      "positions (x,y,z), reward: [-7.71540923  4.77316721  2.5196432 ] 1.0\n",
      "Episode =  664, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.61707047 -0.01535153  9.30606022] 1.0\n",
      "positions (x,y,z), reward: [ 0.63667918 -0.0472419   9.20807225] 1.0\n",
      "positions (x,y,z), reward: [ 0.09404807 -1.12016493  5.53909115] 1.0\n",
      "Episode =  665, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.35188895e-02   4.03402991e-03   1.00039609e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.16568176 -0.01260454  9.82648597] 1.0\n",
      "positions (x,y,z), reward: [ 2.2423596  -1.83228388  7.43893724] 1.0\n",
      "positions (x,y,z), reward: [ 2.23866207 -6.05224658  0.45167031] 1.0\n",
      "Episode =  666, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.73508451e-01  -5.58166773e-03   9.36164273e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.07892309 -0.09256344  8.79751972] 1.0\n",
      "positions (x,y,z), reward: [ 5.58755338 -0.52524866  0.06859462] 1.0\n",
      "Episode =  668, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07046665   0.06338993  10.03344743] 1.0\n",
      "positions (x,y,z), reward: [-0.144951    0.20364407  9.90821536] 1.0\n",
      "positions (x,y,z), reward: [ 0.1062749   0.23608878  9.54558284] 1.0\n",
      "positions (x,y,z), reward: [ 0.64812732  0.22166011  9.09769491] 1.0\n",
      "positions (x,y,z), reward: [ 8.44386456 -0.31734622  2.69783378] 1.0\n",
      "positions (x,y,z), reward: [ 10.01670053  -0.33869354   1.13244615] 1.0\n",
      "Episode =  669, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.24792327e-03   3.41216268e-04   1.00139889e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.10011422  0.04457661  9.28675326] 1.0\n",
      "positions (x,y,z), reward: [ 0.01500686 -1.13332397  6.36300973] 1.0\n",
      "positions (x,y,z), reward: [-0.64013036 -1.77640394  4.32968774] 1.0\n",
      "positions (x,y,z), reward: [-1.74920017 -2.80168893  0.        ] 1.0\n",
      "Episode =  670, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04008568  -0.02797289  10.03004599] 1.0\n",
      "positions (x,y,z), reward: [ 0.71447983 -0.4070543   9.50466048] 1.0\n",
      "positions (x,y,z), reward: [ 2.17418246 -1.33135463  8.22297789] 1.0\n",
      "positions (x,y,z), reward: [ 3.36644926 -3.12928752  5.06426256] 1.0\n",
      "Episode =  671, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.13616934 -0.86083135  8.95831453] 1.0\n",
      "positions (x,y,z), reward: [-2.34310469 -4.48903695  3.5234865 ] 1.0\n",
      "positions (x,y,z), reward: [-3.18570866 -5.44974562  1.54998599] 1.0\n",
      "Episode =  672, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06376479  0.08600217  9.89872359] 1.0\n",
      "positions (x,y,z), reward: [ 0.2166547   0.34333293  9.72099981] 1.0\n",
      "positions (x,y,z), reward: [-0.88479737  0.2145528   9.45846864] 1.0\n",
      "positions (x,y,z), reward: [-3.87270432  0.92044618  8.5348747 ] 1.0\n",
      "Episode =  673, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.92072572e-02  -6.34770829e-03   1.00194879e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.70179486  0.29998129  8.96382734] 1.0\n",
      "positions (x,y,z), reward: [-1.06118375  0.50871308  8.3168907 ] 1.0\n",
      "positions (x,y,z), reward: [-2.18083446  0.88410601  5.45722226] 1.0\n",
      "positions (x,y,z), reward: [-2.64812495  0.86803595  4.37556964] 1.0\n",
      "positions (x,y,z), reward: [-3.18383236  0.86113495  3.17480566] 1.0\n",
      "positions (x,y,z), reward: [-3.74094924  0.8546375   1.82289828] 1.0\n",
      "Episode =  674, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.08474859  0.5656372   8.34075287] 1.0\n",
      "positions (x,y,z), reward: [-1.01019586  1.36523     6.93130332] 1.0\n",
      "Episode =  675, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06641036  -0.06539591  10.05781827] 1.0\n",
      "positions (x,y,z), reward: [ 1.77086665 -1.01518454  9.50837316] 1.0\n",
      "positions (x,y,z), reward: [ 2.15276804 -1.16748981  9.34070639] 1.0\n",
      "positions (x,y,z), reward: [ 2.55183756 -1.31707336  9.15972861] 1.0\n",
      "positions (x,y,z), reward: [ 3.383917   -1.57317613  8.75310135] 1.0\n",
      "positions (x,y,z), reward: [ 8.16971611 -2.45045811  4.88979758] 1.0\n",
      "positions (x,y,z), reward: [ 11.721431    -3.22236776   0.93486033] 1.0\n",
      "positions (x,y,z), reward: [ 12.67222603  -3.44766533   0.        ] 1.0\n",
      "Episode =  676, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.26172624 -0.04695472  5.22859302] 1.0\n",
      "positions (x,y,z), reward: [-8.31963484 -0.06536859  2.58546973] 1.0\n",
      "Episode =  677, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.22812160e-01   8.59654460e-03   9.99094051e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.26614593 -1.48451756  7.87802701] 1.0\n",
      "positions (x,y,z), reward: [ 0.73633316 -4.53081493  2.91654046] 1.0\n",
      "positions (x,y,z), reward: [ 1.03242154 -5.76398141  0.31758277] 1.0\n",
      "Episode =  678, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.83864059e-02  -7.56487446e-04   1.00391784e+01] 1.0\n",
      "positions (x,y,z), reward: [-5.84894121 -8.70224357  0.78791398] 1.0\n",
      "Episode =  679, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-8.02551582  0.22909972  4.96963195] 1.0\n",
      "Episode =  680, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.17033237  1.09502979  6.23264854] 1.0\n",
      "positions (x,y,z), reward: [-5.48359944  1.14830259  5.87626632] 1.0\n",
      "positions (x,y,z), reward: [-6.08556499  1.26587535  5.1220454 ] 1.0\n",
      "positions (x,y,z), reward: [-6.52468434  1.36723533  4.53843534] 1.0\n",
      "positions (x,y,z), reward: [-7.27838257  1.56416403  3.52979826] 1.0\n",
      "positions (x,y,z), reward: [-9.33351571  2.1202376   0.48866675] 1.0\n",
      "Episode =  681, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.30683204 -0.23979637  9.3844231 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.50699782 -0.31476327  9.22690374] 1.0\n",
      "positions (x,y,z), reward: [ 0.87707321 -0.67035191  8.83751847] 1.0\n",
      "positions (x,y,z), reward: [ 0.92083045 -0.97192998  8.47785253] 1.0\n",
      "positions (x,y,z), reward: [ 0.90785188 -1.09785856  8.31778352] 1.0\n",
      "positions (x,y,z), reward: [ 0.89469952 -1.16113804  8.23188823] 1.0\n",
      "positions (x,y,z), reward: [ 0.81497394 -1.39144781  7.80756234] 1.0\n",
      "positions (x,y,z), reward: [ 0.53864108 -1.79767422  6.69359336] 1.0\n",
      "positions (x,y,z), reward: [-0.10032371 -2.28169163  4.42149646] 1.0\n",
      "Episode =  682, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 5.50505012  0.04098686  4.9803124 ] 1.0\n",
      "positions (x,y,z), reward: [ 7.74676361  0.22454977  0.        ] 1.0\n",
      "Episode =  683, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.12275035e-02   2.59233103e-03   1.00229760e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.23035979  0.10675808  9.58503412] 1.0\n",
      "Episode =  684, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.10833636   0.05465335  10.02096927] 1.0\n",
      "positions (x,y,z), reward: [ -0.1723444    0.16029134  10.08885545] 1.0\n",
      "Episode =  685, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.81515933 -0.21167801  9.43716534] 1.0\n",
      "positions (x,y,z), reward: [-0.58197983 -0.16569876  8.94646323] 1.0\n",
      "positions (x,y,z), reward: [-4.21720142 -0.09802401  6.09301302] 1.0\n",
      "positions (x,y,z), reward: [-10.02989845   0.2626233    0.23403796] 1.0\n",
      "Episode =  686, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04208376  -0.02163252  10.03556263] 1.0\n",
      "positions (x,y,z), reward: [ 0.64888481 -1.85051344  3.37290284] 1.0\n",
      "Episode =  687, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  9.10317747e-02  -8.84075960e-03   9.85357878e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.18934686 -0.02818943  9.8187236 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.17502199 -1.54442171  7.96536039] 1.0\n",
      "positions (x,y,z), reward: [ 1.30252077 -2.46868723  5.70785143] 1.0\n",
      "Episode =  688, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.63134721e-02   1.23149194e-03   1.00329534e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.09121884  -0.02749649  10.03492305] 1.0\n",
      "positions (x,y,z), reward: [ 0.1533245  -0.21684042  9.82102445] 1.0\n",
      "positions (x,y,z), reward: [ 0.47224147 -0.34844744  9.74839963] 1.0\n",
      "positions (x,y,z), reward: [ 0.53060407 -0.48893902  9.70787318] 1.0\n",
      "positions (x,y,z), reward: [ 0.44574834 -0.53748992  9.6405204 ] 1.0\n",
      "positions (x,y,z), reward: [-0.88771046 -0.07171737  7.55053088] 1.0\n",
      "positions (x,y,z), reward: [-2.73149275  0.06082915  4.8379499 ] 1.0\n",
      "Episode =  689, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.17021246 -0.04925002  9.9400681 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.10322851 -0.20888678  8.74025603] 1.0\n",
      "positions (x,y,z), reward: [ 2.57743144 -0.21912931  6.49276389] 1.0\n",
      "positions (x,y,z), reward: [ 3.86911738  0.33618472  1.8136247 ] 1.0\n",
      "Episode =  690, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.05475953  0.43869146  8.9259936 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.58798445  0.89082773  7.3949944 ] 1.0\n",
      "positions (x,y,z), reward: [ 8.38925082  1.59857012  4.30945034] 1.0\n",
      "positions (x,y,z), reward: [ 11.15084693   2.10320603   0.99573462] 1.0\n",
      "positions (x,y,z), reward: [ 11.49043043   2.16503975   0.42315844] 1.0\n",
      "Episode =  691, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.40390968  0.10433649  9.90825724] 1.0\n",
      "positions (x,y,z), reward: [ 0.91290916  0.09377334  9.95647318] 1.0\n",
      "Episode =  692, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.220888   -0.15491107  7.92670195] 1.0\n",
      "positions (x,y,z), reward: [-4.19768494 -0.12628355  5.57439642] 1.0\n",
      "positions (x,y,z), reward: [-5.38234583 -0.09135279  3.88104918] 1.0\n",
      "Episode =  693, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.99390047 -0.33983176  9.70472246] 1.0\n",
      "positions (x,y,z), reward: [ 12.56672786  -0.4165436    0.        ] 1.0\n",
      "Episode =  694, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.58921617  0.04688936  9.3119756 ] 1.0\n",
      "Episode =  695, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.12677425 -0.0131005   9.94237821] 1.0\n",
      "positions (x,y,z), reward: [ 0.74848141 -0.32986074  9.82148955] 1.0\n",
      "Episode =  696, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03255692  0.01374224  9.99043487] 1.0\n",
      "positions (x,y,z), reward: [-0.06046903  0.03734132  9.96908254] 1.0\n",
      "positions (x,y,z), reward: [ -0.87521711   0.20189211  10.37714651] 1.0\n",
      "positions (x,y,z), reward: [-6.94100513  0.40238557  7.04098697] 1.0\n",
      "positions (x,y,z), reward: [-7.18132436  0.40954458  6.71809529] 1.0\n",
      "positions (x,y,z), reward: [-7.8954328   0.43534133  5.65188362] 1.0\n",
      "Episode =  697, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.29007205e-03   4.99728878e-03   1.00168963e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.19833741 -0.86702968  9.91322494] 1.0\n",
      "positions (x,y,z), reward: [-0.32560105 -1.87456902  9.38659698] 1.0\n",
      "positions (x,y,z), reward: [-2.17178127 -3.28216155  8.39982994] 1.0\n",
      "positions (x,y,z), reward: [-2.56207665 -3.41553638  8.14051625] 1.0\n",
      "positions (x,y,z), reward: [-3.95251794 -3.72340096  7.22465801] 1.0\n",
      "positions (x,y,z), reward: [-5.33945738 -3.94969157  6.23330719] 1.0\n",
      "positions (x,y,z), reward: [-8.48913567 -4.21320416  3.74297544] 1.0\n",
      "Episode =  698, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.7698782  -0.76578335  7.33023773] 1.0\n",
      "positions (x,y,z), reward: [-4.27708626 -1.10765351  5.87566838] 1.0\n",
      "positions (x,y,z), reward: [-6.41290152 -1.52987527  3.34577387] 1.0\n",
      "Episode =  699, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.21865977 -0.99482113  6.4965558 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.26052775 -1.14887067  5.97146611] 1.0\n",
      "positions (x,y,z), reward: [ 1.27557059 -1.25210591  5.59898624] 1.0\n",
      "positions (x,y,z), reward: [ 1.31100749 -1.68317763  3.94223169] 1.0\n",
      "positions (x,y,z), reward: [ 1.32510249 -1.94325903  2.80980606] 1.0\n",
      "positions (x,y,z), reward: [ 1.318264   -2.14875344  1.86039439] 1.0\n",
      "positions (x,y,z), reward: [ 1.26931572 -2.50319577  0.04704949] 1.0\n",
      "Episode =  700, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.16857481  -0.07002956  10.07604463] 1.0\n",
      "positions (x,y,z), reward: [ -1.63730203  -0.52857897  10.4352302 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.93097331  -0.58359212  10.47433474] 1.0\n",
      "positions (x,y,z), reward: [-6.69411501 -0.91020754  8.648353  ] 1.0\n",
      "Episode =  701, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.45426276 -2.60213492  7.03371074] 1.0\n",
      "positions (x,y,z), reward: [ 2.30453512 -4.09681115  3.44902006] 1.0\n",
      "positions (x,y,z), reward: [ 2.24963049 -4.27989064  2.94999263] 1.0\n",
      "positions (x,y,z), reward: [ 2.10515797 -4.74470555  1.62570561] 1.0\n",
      "Episode =  702, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.44511638  0.44735837  9.11577405] 1.0\n",
      "positions (x,y,z), reward: [ 0.47239675  0.47961254  9.07015391] 1.0\n",
      "positions (x,y,z), reward: [ 0.46261988  0.77546871  8.636751  ] 1.0\n",
      "positions (x,y,z), reward: [ 0.69484578  1.73548861  7.10135741] 1.0\n",
      "positions (x,y,z), reward: [ 2.15164169  2.64478951  4.12328856] 1.0\n",
      "Episode =  703, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.48403362 -0.23527046  9.73813161] 1.0\n",
      "positions (x,y,z), reward: [-0.56020535 -0.27098297  9.58023309] 1.0\n",
      "positions (x,y,z), reward: [-0.7522776  -0.31435742  9.05221944] 1.0\n",
      "positions (x,y,z), reward: [-2.0812563   0.19795839  6.99243878] 1.0\n",
      "positions (x,y,z), reward: [-2.85768787  0.65995564  5.6626247 ] 1.0\n",
      "Episode =  704, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.52494934 -0.24413879  9.18496452] 1.0\n",
      "positions (x,y,z), reward: [ 1.33453829 -3.09518625  1.85783581] 1.0\n",
      "Episode =  705, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.31799573 -1.23378904  8.21298047] 1.0\n",
      "positions (x,y,z), reward: [ 1.47667762 -2.3758932   5.06938741] 1.0\n",
      "Episode =  706, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01374922  -0.0103797   10.03014101] 1.0\n",
      "positions (x,y,z), reward: [ 11.47207008  -1.20748541   0.        ] 1.0\n",
      "Episode =  707, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.23008653 -1.02143053  9.77456346] 1.0\n",
      "positions (x,y,z), reward: [-0.53040323 -4.53649169  5.09213797] 1.0\n",
      "Episode =  708, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.06988542 -2.16959419  7.35388739] 1.0\n",
      "positions (x,y,z), reward: [ 1.80649753 -3.27122571  5.6700453 ] 1.0\n",
      "Episode =  709, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.15240981   0.06955221  10.04775967] 1.0\n",
      "positions (x,y,z), reward: [ -0.27426982   0.06955251  10.28518963] 1.0\n",
      "positions (x,y,z), reward: [ -1.00729701  -0.60186009  10.41822783] 1.0\n",
      "positions (x,y,z), reward: [ -1.8836564   -0.98668058  10.36691729] 1.0\n",
      "positions (x,y,z), reward: [ -3.33464511  -1.19449081  10.19352256] 1.0\n",
      "positions (x,y,z), reward: [-4.31469549 -1.28887558  9.98839148] 1.0\n",
      "positions (x,y,z), reward: [-5.33381323 -1.67911432  9.69795946] 1.0\n",
      "positions (x,y,z), reward: [-5.46031597 -1.76203217  9.62814864] 1.0\n",
      "positions (x,y,z), reward: [-6.5082009  -2.54689265  8.90787515] 1.0\n",
      "Episode =  710, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.99534226e-02   7.60831576e-03   1.00297370e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.11840317  0.32985229  9.80846636] 1.0\n",
      "positions (x,y,z), reward: [-0.70961645  1.3567331   9.15216475] 1.0\n",
      "positions (x,y,z), reward: [-1.06032774  1.58402778  8.91360306] 1.0\n",
      "positions (x,y,z), reward: [-1.19071239  1.66990527  8.82790605] 1.0\n",
      "positions (x,y,z), reward: [-2.03674576  2.28156554  8.29811622] 1.0\n",
      "positions (x,y,z), reward: [-6.74681221  5.07297178  5.01208758] 1.0\n",
      "positions (x,y,z), reward: [-9.52423594  6.47907778  2.65099671] 1.0\n",
      "Episode =  711, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.69521296e-02  -3.49040402e-03   1.00041656e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.04086775  0.10261759  9.84740044] 1.0\n",
      "positions (x,y,z), reward: [ 1.00729422  0.05973833  8.74266323] 1.0\n",
      "positions (x,y,z), reward: [ 2.66893676 -0.73453731  5.64273152] 1.0\n",
      "positions (x,y,z), reward: [ 3.1663149  -1.13402562  4.02713013] 1.0\n",
      "Episode =  712, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03426247   0.01165523  10.01961138] 1.0\n",
      "positions (x,y,z), reward: [  9.49119111e-04   3.48413702e-02   9.94752294e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.10540596  0.02970316  9.84498207] 1.0\n",
      "positions (x,y,z), reward: [ 0.15543665  0.02777416  9.80324962] 1.0\n",
      "positions (x,y,z), reward: [ 1.36792223 -0.73150018  8.80516054] 1.0\n",
      "positions (x,y,z), reward: [ 0.25956559 -1.52901166  5.23169563] 1.0\n",
      "positions (x,y,z), reward: [-0.54754307 -1.64490064  3.27240597] 1.0\n",
      "positions (x,y,z), reward: [-0.63698149 -1.65748176  3.05808738] 1.0\n",
      "positions (x,y,z), reward: [-0.72878311 -1.67023764  2.83913707] 1.0\n",
      "Episode =  713, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.87401689  0.57183902  7.15592672] 1.0\n",
      "positions (x,y,z), reward: [ 2.99843633  0.63298843  7.0054709 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.24708178  0.76327138  6.6959869 ] 1.0\n",
      "Episode =  715, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0822291  -0.03492318  9.95973638] 1.0\n",
      "positions (x,y,z), reward: [ 0.36380706 -0.30691063  9.14464247] 1.0\n",
      "positions (x,y,z), reward: [ 1.1297978  -0.64254902  8.35335347] 1.0\n",
      "positions (x,y,z), reward: [ 1.30361725 -0.92991212  7.79860246] 1.0\n",
      "positions (x,y,z), reward: [ 1.32222402 -0.97566709  7.69961337] 1.0\n",
      "positions (x,y,z), reward: [ 1.30470212 -2.25515371  2.89187498] 1.0\n",
      "Episode =  716, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.41053823e-03   1.17943500e-03   1.00151851e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.06892206   0.2630615   10.12237474] 1.0\n",
      "positions (x,y,z), reward: [-0.3500294  -0.83778394  8.83111499] 1.0\n",
      "positions (x,y,z), reward: [-0.37479948 -1.05985542  8.48407347] 1.0\n",
      "positions (x,y,z), reward: [-0.62312341 -1.6410701   7.54243279] 1.0\n",
      "positions (x,y,z), reward: [-2.72602064 -3.57488034  0.47142544] 1.0\n",
      "Episode =  717, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.3018483   0.02987158  9.03914429] 1.0\n",
      "positions (x,y,z), reward: [ 4.61279774 -1.10806027  5.21587331] 1.0\n",
      "positions (x,y,z), reward: [ 7.22161622 -2.57400209  0.0492723 ] 1.0\n",
      "positions (x,y,z), reward: [ 7.53090675 -2.73236933  0.        ] 1.0\n",
      "Episode =  718, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  3.72162880e-01  -8.47463929e-04   9.63838450e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.48238652 -0.94372581  7.76572156] 1.0\n",
      "positions (x,y,z), reward: [ 1.5041253  -1.32949475  6.82385121] 1.0\n",
      "Episode =  719, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.31368498e-02   2.96766306e-03   1.00155697e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.23840343 -0.46855983  9.2111572 ] 1.0\n",
      "positions (x,y,z), reward: [-4.46852067 -2.02037677  4.98103596] 1.0\n",
      "positions (x,y,z), reward: [-7.11996183 -2.42702754  1.8046479 ] 1.0\n",
      "Episode =  720, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.32983721 -0.64726149  9.67497352] 1.0\n",
      "positions (x,y,z), reward: [-8.09689728 -0.43274681  5.61785169] 1.0\n",
      "Episode =  721, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.7311509    0.96569736  10.03857943] 1.0\n",
      "positions (x,y,z), reward: [-4.570852    5.46046409  6.68371834] 1.0\n",
      "positions (x,y,z), reward: [-5.69564729  7.2299256   4.24727557] 1.0\n",
      "Episode =  722, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00633814] 1.0\n",
      "positions (x,y,z), reward: [  1.00098871e-01  -8.17993724e-03   9.98460060e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.74325175 -0.04817485  9.39592767] 1.0\n",
      "positions (x,y,z), reward: [ 2.18872358 -0.27961903  8.21683499] 1.0\n",
      "Episode =  723, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.2665386  -1.96547334  3.88939664] 1.0\n",
      "Episode =  724, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04060838  -0.01595688  10.00753269] 1.0\n",
      "positions (x,y,z), reward: [ 0.08093366 -0.13426189  9.64200708] 1.0\n",
      "positions (x,y,z), reward: [ 0.26063946  0.02816924  9.16021858] 1.0\n",
      "positions (x,y,z), reward: [ 0.2367508   0.07794381  9.09960759] 1.0\n",
      "positions (x,y,z), reward: [ 0.19742793  0.19863095  8.97891861] 1.0\n",
      "positions (x,y,z), reward: [-0.01194391  0.95237747  8.01588483] 1.0\n",
      "positions (x,y,z), reward: [-1.74458589  2.45305269  3.14971885] 1.0\n",
      "positions (x,y,z), reward: [-2.46612713  2.8900086   0.49264804] 1.0\n",
      "Episode =  725, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0048923] 1.0\n",
      "positions (x,y,z), reward: [-0.5063671  -0.06066164  8.59484528] 1.0\n",
      "positions (x,y,z), reward: [-0.58679766 -0.05181831  8.46898835] 1.0\n",
      "positions (x,y,z), reward: [-3.24735205  0.26538856  4.78450303] 1.0\n",
      "positions (x,y,z), reward: [-6.23115919  0.84025177  0.        ] 1.0\n",
      "Episode =  726, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01798235  -0.01291831  10.00928974] 1.0\n",
      "positions (x,y,z), reward: [ -4.7580122    0.34861783  10.29042579] 1.0\n",
      "positions (x,y,z), reward: [-10.60052222   0.55399019   7.98658248] 1.0\n",
      "positions (x,y,z), reward: [-18.28369651   0.04585754   2.4978217 ] 1.0\n",
      "positions (x,y,z), reward: [-18.56364778   0.02935259   2.23012681] 1.0\n",
      "Episode =  727, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00575733] 1.0\n",
      "positions (x,y,z), reward: [ 0.14955824 -0.45051239  9.62113144] 1.0\n",
      "positions (x,y,z), reward: [ 2.10923749 -1.33867981  7.22467223] 1.0\n",
      "positions (x,y,z), reward: [ 4.43432506 -1.33309745  1.96852892] 1.0\n",
      "Episode =  729, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.23953061 -0.06383094  9.49643453] 1.0\n",
      "positions (x,y,z), reward: [-3.88419806 -3.86207162  1.90558557] 1.0\n",
      "Episode =  730, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.97839774  0.01257428  9.7715142 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.04563263  0.63303749  9.42932352] 1.0\n",
      "positions (x,y,z), reward: [-0.85368401  1.03924381  8.83894454] 1.0\n",
      "positions (x,y,z), reward: [-1.07643217  1.10232318  8.64220906] 1.0\n",
      "positions (x,y,z), reward: [-4.18141338  2.04124637  4.84588238] 1.0\n",
      "positions (x,y,z), reward: [-4.80233447  2.26714949  3.78279007] 1.0\n",
      "Episode =  731, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 4.1567729   2.16547504  4.09251723] 1.0\n",
      "Episode =  732, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.12457905e-02  -3.57178665e-03   1.00708989e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.11742218   0.11143223  10.01842524] 1.0\n",
      "positions (x,y,z), reward: [ 1.10490086  0.42534732  9.26662634] 1.0\n",
      "positions (x,y,z), reward: [ 1.26346539  0.44550367  9.17144217] 1.0\n",
      "positions (x,y,z), reward: [ 1.42631532  0.4656569   9.07214244] 1.0\n",
      "positions (x,y,z), reward: [ 2.90003169  0.63002165  8.06781811] 1.0\n",
      "positions (x,y,z), reward: [ 4.16774763  0.71509982  7.11785278] 1.0\n",
      "Episode =  733, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.27872671 -0.21738975  9.66951313] 1.0\n",
      "positions (x,y,z), reward: [-0.81160252 -1.16322437  8.66032828] 1.0\n",
      "Episode =  734, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -8.97647367e-03  -1.12809077e-02   1.00718369e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.04539107  -0.49868399  10.18192884] 1.0\n",
      "positions (x,y,z), reward: [-9.01338547  0.8420346   4.7867899 ] 1.0\n",
      "positions (x,y,z), reward: [-10.7873089    1.27056447   3.13352979] 1.0\n",
      "positions (x,y,z), reward: [-12.30162369   1.61475048   1.56620212] 1.0\n",
      "Episode =  735, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02538773  -0.01615726  10.03719668] 1.0\n",
      "positions (x,y,z), reward: [ 1.31126264 -1.40945197  7.65423104] 1.0\n",
      "positions (x,y,z), reward: [ 1.72772384 -2.11595975  6.36250289] 1.0\n",
      "positions (x,y,z), reward: [ 2.67931741 -3.34933953  3.54081148] 1.0\n",
      "positions (x,y,z), reward: [ 3.11803817 -4.00622426  1.81018266] 1.0\n",
      "Episode =  736, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05179415 -0.07627788  9.83707808] 1.0\n",
      "positions (x,y,z), reward: [ 1.28532381 -0.29891628  9.09620968] 1.0\n",
      "positions (x,y,z), reward: [ 1.06566662 -1.07461407  7.95552412] 1.0\n",
      "positions (x,y,z), reward: [-3.52202165 -2.11274048  0.        ] 1.0\n",
      "Episode =  737, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.78778312 -0.27435951  7.4373977 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.38052911 -0.17417254  6.86021194] 1.0\n",
      "positions (x,y,z), reward: [ 3.69293978 -0.11830193  6.54143445] 1.0\n",
      "positions (x,y,z), reward: [ 4.3475614   0.01305972  5.85530815] 1.0\n",
      "positions (x,y,z), reward: [ 5.21737013  0.22346823  4.97270158] 1.0\n",
      "positions (x,y,z), reward: [ 6.22162855  0.50099426  3.86855774] 1.0\n",
      "Episode =  738, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.37451964 -0.31504459  8.95066324] 1.0\n",
      "positions (x,y,z), reward: [ 0.09840976 -0.57323478  8.60110885] 1.0\n",
      "positions (x,y,z), reward: [-1.42043653 -1.15073065  6.52792433] 1.0\n",
      "positions (x,y,z), reward: [-2.26295237 -1.4246389   4.8392113 ] 1.0\n",
      "Episode =  739, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0351818    0.0226299   10.03602948] 1.0\n",
      "positions (x,y,z), reward: [ 0.68466865 -0.03738718  9.68575909] 1.0\n",
      "positions (x,y,z), reward: [ 6.6166215  -1.30220728  6.53357604] 1.0\n",
      "positions (x,y,z), reward: [ 12.72336789  -2.68560966   1.6258352 ] 1.0\n",
      "positions (x,y,z), reward: [ 13.22430419  -2.80607167   1.12726927] 1.0\n",
      "Episode =  740, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.29345038 -0.90366293  9.92725513] 1.0\n",
      "positions (x,y,z), reward: [-0.40494338 -0.94911431  9.90296742] 1.0\n",
      "positions (x,y,z), reward: [-0.52340712 -0.99649267  9.88526749] 1.0\n",
      "positions (x,y,z), reward: [-1.83624339 -1.35802499  9.44766433] 1.0\n",
      "positions (x,y,z), reward: [-4.06576827 -2.65641937  8.03996664] 1.0\n",
      "positions (x,y,z), reward: [-9.73914267 -4.37880517  3.40844568] 1.0\n",
      "positions (x,y,z), reward: [-10.38536202  -4.51590945   2.73895422] 1.0\n",
      "Episode =  741, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.38474751  0.02844455  9.87822951] 1.0\n",
      "positions (x,y,z), reward: [ 0.39717195  0.02067817  9.87398759] 1.0\n",
      "positions (x,y,z), reward: [ 0.33729878 -0.05074889  9.83628285] 1.0\n",
      "positions (x,y,z), reward: [ 0.29746405 -0.05684673  9.81781859] 1.0\n",
      "positions (x,y,z), reward: [-0.18001967  0.29024487  9.62746276] 1.0\n",
      "positions (x,y,z), reward: [-0.66199974  0.76172536  9.09018132] 1.0\n",
      "positions (x,y,z), reward: [-1.45995225  0.9523104   8.10664853] 1.0\n",
      "positions (x,y,z), reward: [-3.71094722  0.39607632  2.26605734] 1.0\n",
      "Episode =  742, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -9.01587070e-03  -1.65989718e-02   1.00202805e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.043038    -0.03864208  10.01929969] 1.0\n",
      "positions (x,y,z), reward: [-0.07001853 -0.09305558  9.99675371] 1.0\n",
      "positions (x,y,z), reward: [ 0.06471706 -0.21496892  9.58369627] 1.0\n",
      "positions (x,y,z), reward: [ 4.46979097 -3.57454335  2.87627136] 1.0\n",
      "positions (x,y,z), reward: [ 5.14790465 -4.06669148  1.62989333] 1.0\n",
      "positions (x,y,z), reward: [ 5.70629641 -4.44111037  0.55958358] 1.0\n",
      "positions (x,y,z), reward: [  5.98709255e+00  -4.62373704e+00   5.77439830e-03] 1.0\n",
      "Episode =  743, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.44909458  0.16572797  9.67433749] 1.0\n",
      "positions (x,y,z), reward: [-2.04185056  0.65273257  9.2109512 ] 1.0\n",
      "positions (x,y,z), reward: [-3.84336439  1.34806785  8.52605331] 1.0\n",
      "positions (x,y,z), reward: [-5.44620981  2.09665009  7.80786859] 1.0\n",
      "positions (x,y,z), reward: [-8.08784065  3.30536279  6.53616518] 1.0\n",
      "positions (x,y,z), reward: [-15.60888025   6.55120954   0.9349557 ] 1.0\n",
      "Episode =  744, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.25139123  0.23637999  9.48442757] 1.0\n",
      "positions (x,y,z), reward: [ 1.27422771  0.3441359   9.10023442] 1.0\n",
      "positions (x,y,z), reward: [ 1.26170528  0.36227244  9.04816938] 1.0\n",
      "Episode =  745, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0049951] 1.0\n",
      "positions (x,y,z), reward: [-0.16939692  0.04056718  9.96678089] 1.0\n",
      "positions (x,y,z), reward: [-0.54759859  0.03250076  9.8404761 ] 1.0\n",
      "positions (x,y,z), reward: [-2.0837504   0.0943346   9.10207066] 1.0\n",
      "positions (x,y,z), reward: [-9.89861195  1.80825914  3.89340198] 1.0\n",
      "positions (x,y,z), reward: [-11.12942944   2.10787473   2.79705418] 1.0\n",
      "positions (x,y,z), reward: [-11.37907528   2.17962611   2.57088059] 1.0\n",
      "Episode =  746, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.20921911 -0.04694591  9.97113453] 1.0\n",
      "positions (x,y,z), reward: [ 0.56496018 -0.1615138   9.82763881] 1.0\n",
      "positions (x,y,z), reward: [ 0.65935572 -0.18563765  9.7882477 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.98538113 -0.74113356  9.41568087] 1.0\n",
      "positions (x,y,z), reward: [ 2.19453789 -1.89916054  8.85855511] 1.0\n",
      "positions (x,y,z), reward: [ 2.04725265 -2.14360673  8.61425956] 1.0\n",
      "positions (x,y,z), reward: [-0.31432553 -3.71966551  6.61084   ] 1.0\n",
      "positions (x,y,z), reward: [-0.72327482 -3.88997485  6.24215144] 1.0\n",
      "positions (x,y,z), reward: [-2.03295243 -4.40228677  4.89902669] 1.0\n",
      "positions (x,y,z), reward: [-3.39405813 -4.89586142  3.21884964] 1.0\n",
      "Episode =  747, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.70118516e-02  -6.10328209e-03   1.00350927e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.27568641  1.49003072  8.60308995] 1.0\n",
      "positions (x,y,z), reward: [-1.04670184  2.71374057  7.17446859] 1.0\n",
      "positions (x,y,z), reward: [-1.6973802   3.45135362  5.94310292] 1.0\n",
      "positions (x,y,z), reward: [-3.87866181  5.25927609  1.93057564] 1.0\n",
      "Episode =  748, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.71177027 -0.5807877   8.69217712] 1.0\n",
      "positions (x,y,z), reward: [ 2.73913507 -4.36817306  3.81435969] 1.0\n",
      "Episode =  749, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.33825252 -5.52997248  1.0346293 ] 1.0\n",
      "Episode =  750, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.98867986 -0.16136391  9.40280925] 1.0\n",
      "positions (x,y,z), reward: [ 1.75659201 -3.43702797  3.31408274] 1.0\n",
      "Episode =  751, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.14851124 -0.22922291  9.62757236] 1.0\n",
      "positions (x,y,z), reward: [-0.04227547 -0.32065571  8.76468561] 1.0\n",
      "Episode =  752, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.31704064 -0.26731746  9.48058446] 1.0\n",
      "positions (x,y,z), reward: [-1.36412607 -0.5975995   8.7724782 ] 1.0\n",
      "positions (x,y,z), reward: [-9.16505374 -1.81002098  2.68497595] 1.0\n",
      "Episode =  753, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.05930952   0.11689226  10.02774149] 1.0\n",
      "positions (x,y,z), reward: [ 0.24528786 -1.61906348  6.48773451] 1.0\n",
      "positions (x,y,z), reward: [ 0.08748667 -1.80416352  5.74514259] 1.0\n",
      "Episode =  754, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.31966175  0.4910659   8.92034205] 1.0\n",
      "positions (x,y,z), reward: [ 4.37952419  1.34925647  7.79096009] 1.0\n",
      "positions (x,y,z), reward: [ 4.46526494  1.42396005  7.70107157] 1.0\n",
      "positions (x,y,z), reward: [ 5.68178653  2.61909992  5.07850152] 1.0\n",
      "positions (x,y,z), reward: [ 5.78048694  2.79932101  4.51293971] 1.0\n",
      "positions (x,y,z), reward: [ 6.17264644  3.34208332  1.98203073] 1.0\n",
      "Episode =  755, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  5.41294551e-02  -2.35173378e-03   9.79947234e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.72200399 -0.34878083  8.61436128] 1.0\n",
      "positions (x,y,z), reward: [ 2.88340443 -1.79388949  4.38572833] 1.0\n",
      "Episode =  756, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.45070569 -0.09639751  9.55189198] 1.0\n",
      "positions (x,y,z), reward: [ 0.81218615 -0.2725998   9.38486167] 1.0\n",
      "positions (x,y,z), reward: [ 0.89701416 -0.34297633  9.3314492 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.27587242 -1.27033287  8.41029246] 1.0\n",
      "positions (x,y,z), reward: [ 1.37161385 -2.48020372  7.19669565] 1.0\n",
      "positions (x,y,z), reward: [ 1.18714281 -3.49417289  6.00333746] 1.0\n",
      "positions (x,y,z), reward: [-0.00838385 -6.52985577  1.53902271] 1.0\n",
      "Episode =  757, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.41304039  0.21296203  9.74885235] 1.0\n",
      "positions (x,y,z), reward: [-2.41328657 -0.16918319  7.33497675] 1.0\n",
      "Episode =  758, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.55503202  0.02363837  9.88630645] 1.0\n",
      "positions (x,y,z), reward: [ 0.45649099  0.06357745  9.87689332] 1.0\n",
      "positions (x,y,z), reward: [-1.3708894   0.56747812  8.42145212] 1.0\n",
      "positions (x,y,z), reward: [-2.67576803  0.79048746  6.73425861] 1.0\n",
      "positions (x,y,z), reward: [-2.82696922  0.84479389  6.416933  ] 1.0\n",
      "Episode =  759, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07333132   0.02576848  10.04664465] 1.0\n",
      "positions (x,y,z), reward: [ 0.3738334   0.21166586  9.77273153] 1.0\n",
      "positions (x,y,z), reward: [ 0.83779265  0.85976047  9.51814054] 1.0\n",
      "positions (x,y,z), reward: [-2.02341897  6.9255328   3.7582891 ] 1.0\n",
      "positions (x,y,z), reward: [-3.57091776  9.20173929  0.44130768] 1.0\n",
      "Episode =  760, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04433772  -0.02024722  10.05604392] 1.0\n",
      "positions (x,y,z), reward: [ -0.03487193  -0.02625417  10.05985376] 1.0\n",
      "positions (x,y,z), reward: [ 0.504871   -0.07683554  9.91801425] 1.0\n",
      "positions (x,y,z), reward: [ 2.48038683 -0.33910489  9.31253898] 1.0\n",
      "positions (x,y,z), reward: [ 2.37128969 -0.98282434  8.15205854] 1.0\n",
      "positions (x,y,z), reward: [ 0.1822434  -2.72218114  2.71766964] 1.0\n",
      "positions (x,y,z), reward: [-0.61746381 -3.34339986  0.37562452] 1.0\n",
      "Episode =  761, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  2.27232245e-03   2.52637851e-01   9.90497264e+00] 1.0\n",
      "positions (x,y,z), reward: [-11.71139765   0.34917221   4.22700449] 1.0\n",
      "positions (x,y,z), reward: [-14.44456071   0.37816893   1.66917048] 1.0\n",
      "Episode =  762, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-7.32254692 -0.9799123   5.26506644] 1.0\n",
      "Episode =  763, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.6949923   0.98234382  8.01891201] 1.0\n",
      "positions (x,y,z), reward: [ 1.0064479   1.12298128  7.6730098 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.93123713  1.70084664  5.53807465] 1.0\n",
      "positions (x,y,z), reward: [ 3.81904512  1.85275893  3.34319199] 1.0\n",
      "Episode =  764, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.11211273  0.04005247  9.71696086] 1.0\n",
      "positions (x,y,z), reward: [ 0.67594146 -0.40868374  9.09951585] 1.0\n",
      "positions (x,y,z), reward: [ 0.03989418 -0.97760162  8.25196242] 1.0\n",
      "positions (x,y,z), reward: [-0.48449601 -1.2025025   7.6704569 ] 1.0\n",
      "positions (x,y,z), reward: [-2.03966046 -1.39051863  5.96489019] 1.0\n",
      "positions (x,y,z), reward: [-2.16067804 -1.39919189  5.82488597] 1.0\n",
      "positions (x,y,z), reward: [-3.99602442 -1.54068111  3.24768687] 1.0\n",
      "positions (x,y,z), reward: [-4.98422081 -1.64386205  1.44778629] 1.0\n",
      "Episode =  765, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00524482] 1.0\n",
      "positions (x,y,z), reward: [ -3.05338993e-02   5.36006564e-03   9.95518779e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.48058556 -0.86607698  8.47810362] 1.0\n",
      "positions (x,y,z), reward: [-2.26336176 -0.62802003  3.77428905] 1.0\n",
      "Episode =  766, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.72196783 -0.09409672  9.16793032] 1.0\n",
      "positions (x,y,z), reward: [-2.52588933 -0.26016346  8.09717295] 1.0\n",
      "positions (x,y,z), reward: [-2.81896199 -0.28403246  7.9050124 ] 1.0\n",
      "positions (x,y,z), reward: [-5.21444458 -0.35040221  6.12587136] 1.0\n",
      "positions (x,y,z), reward: [-8.46809449 -0.60028067  2.38271761] 1.0\n",
      "positions (x,y,z), reward: [-9.53860274 -0.70205022  0.83441437] 1.0\n",
      "Episode =  767, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.01811994e-01  -5.53858305e-03   9.73374109e+00] 1.0\n",
      "positions (x,y,z), reward: [-7.51328497  2.09622739  6.01621517] 1.0\n",
      "positions (x,y,z), reward: [-8.22370222  2.35556651  5.58732931] 1.0\n",
      "Episode =  768, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.32187354  0.12653584  9.79781235] 1.0\n",
      "positions (x,y,z), reward: [ 3.8365993  -0.47339566  7.55524031] 1.0\n",
      "positions (x,y,z), reward: [ 5.63679591 -0.76077229  6.24130683] 1.0\n",
      "positions (x,y,z), reward: [ 6.10961736 -0.83716985  5.86850127] 1.0\n",
      "positions (x,y,z), reward: [ 10.78339218  -1.59943035   1.15738984] 1.0\n",
      "Episode =  769, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.5254918  -0.22987157  8.66362219] 1.0\n",
      "positions (x,y,z), reward: [ 4.96744918 -0.49184251  6.86488545] 1.0\n",
      "positions (x,y,z), reward: [ 5.60202627 -0.50591534  6.2963482 ] 1.0\n",
      "Episode =  770, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11599092  0.03487788  9.90574984] 1.0\n",
      "positions (x,y,z), reward: [-0.63126753  0.48284555  7.71774505] 1.0\n",
      "positions (x,y,z), reward: [-0.82082909  0.52488652  7.38960152] 1.0\n",
      "Episode =  771, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.26328758  0.3689624   9.69594087] 1.0\n",
      "positions (x,y,z), reward: [ 0.30152773  0.40902316  9.63478034] 1.0\n",
      "positions (x,y,z), reward: [ 0.2175772   1.25907695  8.07694336] 1.0\n",
      "positions (x,y,z), reward: [-3.5994278  2.4786708  1.6405406] 1.0\n",
      "Episode =  772, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.16568501  0.02731849  9.84623842] 1.0\n",
      "positions (x,y,z), reward: [ 0.4509573   0.10998866  9.10040858] 1.0\n",
      "positions (x,y,z), reward: [ 0.73114707 -0.58734034  5.76633203] 1.0\n",
      "positions (x,y,z), reward: [ 1.0809391  -0.99908077  3.70945677] 1.0\n",
      "Episode =  773, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.38817601  0.48343945  9.77328639] 1.0\n",
      "positions (x,y,z), reward: [ 9.61294326  1.22435491  2.44468464] 1.0\n",
      "positions (x,y,z), reward: [ 10.35074928   1.30162843   1.69561562] 1.0\n",
      "positions (x,y,z), reward: [ 11.35093064   1.37924751   0.6561813 ] 1.0\n",
      "positions (x,y,z), reward: [ 11.60280526   1.3918925    0.39015698] 1.0\n",
      "Episode =  774, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-5.2017325  -2.45155803  7.7896779 ] 1.0\n",
      "positions (x,y,z), reward: [-6.50179054 -2.89790755  7.00300992] 1.0\n",
      "positions (x,y,z), reward: [-8.06863418 -3.42372621  5.89155546] 1.0\n",
      "Episode =  775, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.0522338   0.27788348  9.80983623] 1.0\n",
      "positions (x,y,z), reward: [-0.51646328  0.62854769  9.87388228] 1.0\n",
      "positions (x,y,z), reward: [-1.75516756  0.81577812  9.74774511] 1.0\n",
      "positions (x,y,z), reward: [-2.59895659  0.69430782  9.33743833] 1.0\n",
      "positions (x,y,z), reward: [-6.76985019  1.14634508  6.41050546] 1.0\n",
      "positions (x,y,z), reward: [-10.93257517   1.3997255    0.7964945 ] 1.0\n",
      "Episode =  776, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.66301360e-03  -1.91969116e-03   1.00098129e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.79560063e-02  -7.15360864e-03   1.00038226e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.5990997  -0.54125853  9.0260925 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.30142116 -0.80423454  8.61249406] 1.0\n",
      "positions (x,y,z), reward: [ 0.06409465 -0.89652536  8.31408159] 1.0\n",
      "positions (x,y,z), reward: [-0.01107813 -0.92036924  8.22984763] 1.0\n",
      "Episode =  777, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.20389739 -0.10551965  9.93843961] 1.0\n",
      "positions (x,y,z), reward: [-2.84379411 -2.7277043   9.08062185] 1.0\n",
      "positions (x,y,z), reward: [-5.18463265 -3.80752479  8.22157508] 1.0\n",
      "positions (x,y,z), reward: [-6.6118904  -4.35216721  7.6145144 ] 1.0\n",
      "positions (x,y,z), reward: [-15.46392614  -6.99771209   1.21124054] 1.0\n",
      "Episode =  778, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02033627  0.02060405  9.97906791] 1.0\n",
      "positions (x,y,z), reward: [ 2.71745449 -1.50674927  2.49283916] 1.0\n",
      "Episode =  779, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.65202042  0.05179426  9.55384981] 1.0\n",
      "positions (x,y,z), reward: [-0.83049807  0.06889037  9.42755816] 1.0\n",
      "positions (x,y,z), reward: [-3.33369288  0.80997678  6.70221621] 1.0\n",
      "positions (x,y,z), reward: [-5.51873111  1.37832527  3.17424064] 1.0\n",
      "positions (x,y,z), reward: [-6.65316244  1.71248759  1.05280222] 1.0\n",
      "Episode =  780, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00586794] 1.0\n",
      "positions (x,y,z), reward: [-0.68553816  0.28564086  9.01458627] 1.0\n",
      "positions (x,y,z), reward: [-0.19122703 -0.09073365  7.02729655] 1.0\n",
      "positions (x,y,z), reward: [ 0.77770582 -0.61880698  4.57483706] 1.0\n",
      "Episode =  781, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.72632469 -0.1278844   8.47787588] 1.0\n",
      "positions (x,y,z), reward: [-1.74500332  0.26691818  7.26170463] 1.0\n",
      "positions (x,y,z), reward: [-4.53618638  1.21086102  3.8102601 ] 1.0\n",
      "positions (x,y,z), reward: [-4.66128306  1.24581176  3.62078529] 1.0\n",
      "positions (x,y,z), reward: [-5.15746395  1.38258823  2.83328134] 1.0\n",
      "Episode =  782, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07293304  0.0884035   9.96522478] 1.0\n",
      "positions (x,y,z), reward: [ 0.65958392  0.1925016   8.65775882] 1.0\n",
      "positions (x,y,z), reward: [ 1.10709023 -0.3277382   6.94321897] 1.0\n",
      "positions (x,y,z), reward: [ 1.26617376 -0.59968488  5.94730208] 1.0\n",
      "Episode =  783, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-2.58430005  0.68235497  9.51242808] 1.0\n",
      "Episode =  784, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.37580509  -0.1132358   10.04194904] 1.0\n",
      "positions (x,y,z), reward: [ 1.64169033  0.29584762  9.20046683] 1.0\n",
      "positions (x,y,z), reward: [ 2.8304594   0.65869105  8.39699086] 1.0\n",
      "positions (x,y,z), reward: [ 4.14714869  1.0333619   7.55396465] 1.0\n",
      "positions (x,y,z), reward: [ 10.75836572   2.355753     1.23374182] 1.0\n",
      "positions (x,y,z), reward: [ 11.62692954   2.56774949   0.06832982] 1.0\n",
      "Episode =  786, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.45419019e-02  -5.23756698e-03   1.00007219e+01] 1.0\n",
      "positions (x,y,z), reward: [  7.76298945e-02   4.25031393e-03   9.70665912e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.31396241  0.09517436  9.4771571 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.47053485  0.18303351  9.36057689] 1.0\n",
      "positions (x,y,z), reward: [ 0.69060309  0.36473259  9.13190447] 1.0\n",
      "positions (x,y,z), reward: [-4.65210183  3.42420489  3.65290616] 1.0\n",
      "Episode =  787, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05248497  0.07922364  9.91997654] 1.0\n",
      "positions (x,y,z), reward: [-0.0379827   0.10108047  9.89867942] 1.0\n",
      "positions (x,y,z), reward: [ 0.13528386  0.2764872   9.79644376] 1.0\n",
      "positions (x,y,z), reward: [-0.18161004  0.42669456  9.74243014] 1.0\n",
      "positions (x,y,z), reward: [-0.69528514  0.40177406  9.57742041] 1.0\n",
      "positions (x,y,z), reward: [-0.69116749  0.38229841  9.53186767] 1.0\n",
      "positions (x,y,z), reward: [-0.16957253  0.2539644   8.79741863] 1.0\n",
      "positions (x,y,z), reward: [ 1.77923815 -0.30921774  4.60825579] 1.0\n",
      "Episode =  788, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0335982   0.05502166  9.99741179] 1.0\n",
      "positions (x,y,z), reward: [ 5.11549455  0.99681842  6.22500867] 1.0\n",
      "positions (x,y,z), reward: [ 6.79464812  0.92744677  4.53997202] 1.0\n",
      "Episode =  789, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.79074295 -0.35073392  9.64455813] 1.0\n",
      "positions (x,y,z), reward: [ 0.79633098 -0.42815046  9.57808805] 1.0\n",
      "positions (x,y,z), reward: [ 1.04142743 -1.62969063  8.58419194] 1.0\n",
      "positions (x,y,z), reward: [ 1.35757749 -2.26216897  7.93316019] 1.0\n",
      "positions (x,y,z), reward: [ 2.66916811 -6.17417626  3.08518086] 1.0\n",
      "Episode =  790, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.22056979  0.01056245  9.97254895] 1.0\n",
      "positions (x,y,z), reward: [-0.19257148 -0.04849769  9.97226071] 1.0\n",
      "positions (x,y,z), reward: [-0.1530228  -0.22685246  9.9399363 ] 1.0\n",
      "positions (x,y,z), reward: [-0.29723529 -0.88710551  9.5035957 ] 1.0\n",
      "positions (x,y,z), reward: [-0.45564725 -1.36392374  9.11397165] 1.0\n",
      "positions (x,y,z), reward: [-5.00137026 -4.79724769  5.31920714] 1.0\n",
      "positions (x,y,z), reward: [-7.37607048 -5.79077933  2.78004502] 1.0\n",
      "Episode =  791, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  8.37925861e-03   6.66141929e-01   9.37342226e+00] 1.0\n",
      "positions (x,y,z), reward: [-6.17442977  5.53813048  1.45855569] 1.0\n",
      "Episode =  792, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00542805] 1.0\n",
      "positions (x,y,z), reward: [ -0.0484036   -0.02291222  10.03635699] 1.0\n",
      "positions (x,y,z), reward: [ -6.94680966e-03  -2.49262505e-01   9.07395118e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.97263652 -0.64499091  7.5084796 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.17127969 -0.75468972  7.14165637] 1.0\n",
      "positions (x,y,z), reward: [ 1.82386238 -1.09452377  5.92784871] 1.0\n",
      "positions (x,y,z), reward: [ 2.31310074 -1.32708327  5.03792359] 1.0\n",
      "Episode =  793, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.0520444    0.01948155  10.02253594] 1.0\n",
      "positions (x,y,z), reward: [-0.01585106  0.03723014  9.99264741] 1.0\n",
      "positions (x,y,z), reward: [ 0.22224697  0.046717    9.80196258] 1.0\n",
      "positions (x,y,z), reward: [ 0.43555681  0.04234843  9.61938388] 1.0\n",
      "positions (x,y,z), reward: [ 1.11407938 -0.0678158   9.065399  ] 1.0\n",
      "positions (x,y,z), reward: [ 1.23634446 -0.08343404  8.97556999] 1.0\n",
      "positions (x,y,z), reward: [ 4.50376702 -2.16121709  3.36995779] 1.0\n",
      "Episode =  794, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.09311961  0.13398662  9.71911918] 1.0\n",
      "positions (x,y,z), reward: [-0.07002519  0.20926221  9.61336247] 1.0\n",
      "positions (x,y,z), reward: [ 0.08292737  0.52334732  9.26615755] 1.0\n",
      "positions (x,y,z), reward: [ 0.03380538  1.20224619  8.62934533] 1.0\n",
      "positions (x,y,z), reward: [-0.23807407  3.27964803  6.21565893] 1.0\n",
      "positions (x,y,z), reward: [-0.25828886  3.48442187  5.88653552] 1.0\n",
      "Episode =  795, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.59315785  0.25172065  9.79801465] 1.0\n",
      "positions (x,y,z), reward: [ 0.25941718  0.28471665  9.64146557] 1.0\n",
      "positions (x,y,z), reward: [-0.00982203  0.30876289  9.61589447] 1.0\n",
      "positions (x,y,z), reward: [-5.44152965  0.62487259  6.56920515] 1.0\n",
      "positions (x,y,z), reward: [-8.18153021  0.71389282  3.50041805] 1.0\n",
      "positions (x,y,z), reward: [-8.5138039   0.72557827  3.07488477] 1.0\n",
      "positions (x,y,z), reward: [-8.68330169  0.73155872  2.85555668] 1.0\n",
      "positions (x,y,z), reward: [-10.72893158   0.76707225   0.        ] 1.0\n",
      "Episode =  796, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.07330608 -0.7917045   9.03226029] 1.0\n",
      "positions (x,y,z), reward: [ 0.23861572 -0.96598946  8.71090995] 1.0\n",
      "positions (x,y,z), reward: [ 0.79958787 -1.65610521  7.71394822] 1.0\n",
      "positions (x,y,z), reward: [ 3.76004367 -4.77248655  1.47584743] 1.0\n",
      "Episode =  797, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.10062992  -0.0129316   10.06121569] 1.0\n",
      "positions (x,y,z), reward: [ -3.50472844   0.91448443  10.36415147] 1.0\n",
      "positions (x,y,z), reward: [-11.82824259   3.16685095   8.15513668] 1.0\n",
      "Episode =  798, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.03150638  0.12893196  9.85152327] 1.0\n",
      "positions (x,y,z), reward: [ 0.76461939  0.44940612  9.5195425 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.78353445  0.49353191  9.42058676] 1.0\n",
      "positions (x,y,z), reward: [ 0.12508565  0.91270073  9.2436568 ] 1.0\n",
      "positions (x,y,z), reward: [-0.71072426  1.1434767   8.98879488] 1.0\n",
      "positions (x,y,z), reward: [-9.88197531  2.76730914  2.2178237 ] 1.0\n",
      "positions (x,y,z), reward: [-12.26365119   3.20179673   0.        ] 1.0\n",
      "positions (x,y,z), reward: [-12.481777     3.23919886   0.        ] 1.0\n",
      "Episode =  799, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.3315598   -0.09673478  10.0538105 ] 1.0\n",
      "positions (x,y,z), reward: [-2.52822074 -1.97065854  8.9391059 ] 1.0\n",
      "positions (x,y,z), reward: [-3.05645704 -2.26517799  8.60215967] 1.0\n",
      "Episode =  800, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.05393025   0.08366629  10.06473186] 1.0\n",
      "positions (x,y,z), reward: [-0.04034417 -0.47396696  9.74880053] 1.0\n",
      "Episode =  801, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.34903007 -0.489069    9.2817767 ] 1.0\n",
      "positions (x,y,z), reward: [-0.60958775 -0.83797053  8.33151067] 1.0\n",
      "positions (x,y,z), reward: [-3.42412257 -4.1412396   0.        ] 1.0\n",
      "Episode =  802, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.20139880e-03   5.36589573e-03   1.00117669e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.78058312 -0.15643023  8.30991554] 1.0\n",
      "positions (x,y,z), reward: [-3.1421989  -0.68609904  1.6688132 ] 1.0\n",
      "Episode =  803, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.34297827   0.5225631   10.60003215] 1.0\n",
      "positions (x,y,z), reward: [ -3.80075737   0.53787867  10.62931341] 1.0\n",
      "positions (x,y,z), reward: [-10.02760223   0.97535241  10.00208966] 1.0\n",
      "positions (x,y,z), reward: [-21.43924672   1.89596393   5.78277868] 1.0\n",
      "positions (x,y,z), reward: [-22.1340791    1.97392997   5.43385486] 1.0\n",
      "positions (x,y,z), reward: [-24.20956813   2.24604058   4.29765221] 1.0\n",
      "positions (x,y,z), reward: [-24.90115174   2.33772261   3.87890897] 1.0\n",
      "positions (x,y,z), reward: [-27.62909015   2.72715354   1.97007156] 1.0\n",
      "positions (x,y,z), reward: [-29.56914977   3.21886008   0.41502259] 1.0\n",
      "Episode =  804, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05242257  -0.09370865  10.02817361] 1.0\n",
      "positions (x,y,z), reward: [ 0.35213505 -0.25902009  9.74921862] 1.0\n",
      "positions (x,y,z), reward: [ 0.73035901 -0.22942108  9.10283244] 1.0\n",
      "positions (x,y,z), reward: [ 0.94640805 -0.04686181  8.24119101] 1.0\n",
      "positions (x,y,z), reward: [ 0.97602554  0.26097096  7.35230094] 1.0\n",
      "positions (x,y,z), reward: [ 0.98759297  0.33476125  6.89389486] 1.0\n",
      "Episode =  805, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.85458345 -0.25009305  9.72327926] 1.0\n",
      "positions (x,y,z), reward: [ 0.96335273 -0.2814795   9.66547364] 1.0\n",
      "positions (x,y,z), reward: [ 1.61836338 -0.46700037  9.36150459] 1.0\n",
      "positions (x,y,z), reward: [ 3.91303084 -2.37065296  6.79971437] 1.0\n",
      "positions (x,y,z), reward: [ 4.77377309 -3.87094314  4.04546187] 1.0\n",
      "positions (x,y,z), reward: [ 5.13412721 -4.53586771  2.57971775] 1.0\n",
      "positions (x,y,z), reward: [ 5.19241274 -4.6429196   2.32842895] 1.0\n",
      "Episode =  806, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.08290751 -0.13488505  9.99308588] 1.0\n",
      "positions (x,y,z), reward: [ 0.12352818 -0.24753435  9.94769348] 1.0\n",
      "positions (x,y,z), reward: [ 0.08046293 -0.39879952  9.95175263] 1.0\n",
      "positions (x,y,z), reward: [-0.8933087  -0.42883477  9.42298139] 1.0\n",
      "Episode =  807, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.09305381 -1.0098854   9.38124978] 1.0\n",
      "positions (x,y,z), reward: [ 0.07429748 -1.12062163  9.27120368] 1.0\n",
      "positions (x,y,z), reward: [ 0.11156426 -2.08546803  8.13834737] 1.0\n",
      "positions (x,y,z), reward: [ 0.0407102  -4.419126    4.38251883] 1.0\n",
      "positions (x,y,z), reward: [-0.19945093 -5.90295473  1.22267498] 1.0\n",
      "Episode =  808, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.09650396  -0.49273841  10.32242305] 1.0\n",
      "positions (x,y,z), reward: [ -0.13387086  -0.77813992  10.43485523] 1.0\n",
      "positions (x,y,z), reward: [ -3.23218326 -12.92600564   6.82224389] 1.0\n",
      "positions (x,y,z), reward: [ -4.58935296 -18.43928898   1.53913552] 1.0\n",
      "Episode =  809, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.89448653  0.10672232  9.74355314] 1.0\n",
      "positions (x,y,z), reward: [-11.94220782   0.07863054   4.08155629] 1.0\n",
      "positions (x,y,z), reward: [ -1.35291404e+01  -7.73989051e-03   2.18775971e+00] 1.0\n",
      "Episode =  810, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.98735016   0.47229444  10.32344138] 1.0\n",
      "positions (x,y,z), reward: [ -3.17160604   1.41259636  11.36141458] 1.0\n",
      "positions (x,y,z), reward: [ -5.07596178   0.1530309   12.2463646 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.98909745  -2.46786356  12.1575299 ] 1.0\n",
      "positions (x,y,z), reward: [ -8.81277486  -5.12510091  10.52420095] 1.0\n",
      "positions (x,y,z), reward: [-10.03321879  -6.61082455   8.79448476] 1.0\n",
      "positions (x,y,z), reward: [-10.27888524  -6.95834339   8.34582048] 1.0\n",
      "positions (x,y,z), reward: [-11.82959557  -9.32081161   5.13305326] 1.0\n",
      "Episode =  811, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.16806867e-03  -2.55982181e-01   9.83225678e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.02628866 -0.29383658  9.79893746] 1.0\n",
      "positions (x,y,z), reward: [ 0.70744737 -0.61525708  9.38009238] 1.0\n",
      "positions (x,y,z), reward: [ 0.85571837 -1.33187044  8.80817889] 1.0\n",
      "positions (x,y,z), reward: [ 0.76395152 -1.35194655  8.69807764] 1.0\n",
      "positions (x,y,z), reward: [-2.54557946 -1.09320512  6.03762281] 1.0\n",
      "positions (x,y,z), reward: [-5.22696808 -1.08379486  2.71955956] 1.0\n",
      "positions (x,y,z), reward: [-5.69503464 -1.07777795  2.04014364] 1.0\n",
      "Episode =  812, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.33444597 -0.3236583   9.70224946] 1.0\n",
      "positions (x,y,z), reward: [ 2.10336325 -3.28829574  6.00240281] 1.0\n",
      "Episode =  813, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.01148300e-02   8.95944079e-03   1.00189044e+01] 1.0\n",
      "positions (x,y,z), reward: [ 2.10296147 -1.63735799  6.22244862] 1.0\n",
      "positions (x,y,z), reward: [ 2.36276519 -2.07758279  3.52749985] 1.0\n",
      "Episode =  814, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.44095388 -0.09366498  9.57139352] 1.0\n",
      "positions (x,y,z), reward: [ 1.91598561  0.20744416  8.26044422] 1.0\n",
      "positions (x,y,z), reward: [ 2.29147801  0.38628037  7.87930052] 1.0\n",
      "positions (x,y,z), reward: [ 2.5505241   0.52045308  7.59476379] 1.0\n",
      "Episode =  815, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.17261628   0.11344463  10.02326948] 1.0\n",
      "positions (x,y,z), reward: [-4.36532707 -0.48720223  9.84721324] 1.0\n",
      "positions (x,y,z), reward: [-6.07209796 -1.07109645  9.6806912 ] 1.0\n",
      "positions (x,y,z), reward: [-12.19965061  -2.88351746   5.77671657] 1.0\n",
      "positions (x,y,z), reward: [-14.44241776  -3.53400719   3.08817224] 1.0\n",
      "Episode =  816, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-8.91676649  5.0576541   2.7384408 ] 1.0\n",
      "positions (x,y,z), reward: [-9.35410556  5.26394862  2.25259406] 1.0\n",
      "positions (x,y,z), reward: [-9.79470372  5.47013752  1.74450684] 1.0\n",
      "Episode =  817, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.17415335  0.08968696  9.78485998] 1.0\n",
      "Episode =  818, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.06750723 -0.31357179  9.51595614] 1.0\n",
      "positions (x,y,z), reward: [ 4.13815798 -0.12674641  7.7613298 ] 1.0\n",
      "positions (x,y,z), reward: [ 7.45941039  0.60056529  1.74417275] 1.0\n",
      "Episode =  819, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.64956712 -0.04987661  9.7218299 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.87416786 -0.12106454  9.52671893] 1.0\n",
      "positions (x,y,z), reward: [ 0.82131191 -0.13491367  9.23083913] 1.0\n",
      "positions (x,y,z), reward: [-1.85258652  0.39516431  4.12382968] 1.0\n",
      "Episode =  820, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.15939725 -0.12007976  9.82177409] 1.0\n",
      "positions (x,y,z), reward: [ 0.16845244 -0.20921776  9.72364663] 1.0\n",
      "positions (x,y,z), reward: [-1.92351194  0.16168485  7.46037296] 1.0\n",
      "positions (x,y,z), reward: [-4.89691191  0.83912707  4.34422067] 1.0\n",
      "Episode =  821, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  2.77520707e-01   6.63502798e-03   9.66397335e+00] 1.0\n",
      "positions (x,y,z), reward: [ 6.34471406 -2.05459736  2.40177036] 1.0\n",
      "Episode =  822, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02502812  0.04432005  9.9774339 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.2327495  -5.84196226  1.73237273] 1.0\n",
      "positions (x,y,z), reward: [ 0.18410781 -5.91730496  1.48981589] 1.0\n",
      "Episode =  823, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.01660771  0.09845038  9.66581284] 1.0\n",
      "positions (x,y,z), reward: [-0.0818743   0.03369123  9.59547525] 1.0\n",
      "positions (x,y,z), reward: [-1.02994685 -0.31557254  9.36814191] 1.0\n",
      "positions (x,y,z), reward: [-1.7522512  -0.74046254  8.9591026 ] 1.0\n",
      "positions (x,y,z), reward: [-4.58313127 -1.11007633  7.45168717] 1.0\n",
      "Episode =  824, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.21865922e-03   5.00463599e-03   1.00095447e+01] 1.0\n",
      "positions (x,y,z), reward: [-4.40802463 -0.85874293  7.07900688] 1.0\n",
      "positions (x,y,z), reward: [-6.53397731 -1.225745    5.47478938] 1.0\n",
      "positions (x,y,z), reward: [-6.97396464 -1.29170267  5.11221174] 1.0\n",
      "positions (x,y,z), reward: [-10.29269205  -1.69619303   2.23815952] 1.0\n",
      "Episode =  825, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.37419977  0.0142562   9.59162339] 1.0\n",
      "positions (x,y,z), reward: [ 0.49485033 -0.23588125  9.31108146] 1.0\n",
      "positions (x,y,z), reward: [ 0.50006071 -0.30226114  9.22276831] 1.0\n",
      "positions (x,y,z), reward: [ 0.15218674 -0.98985821  7.92433141] 1.0\n",
      "positions (x,y,z), reward: [-0.16096222 -1.20322679  7.4088181 ] 1.0\n",
      "positions (x,y,z), reward: [-1.92469069 -2.48650911  3.87005336] 1.0\n",
      "Episode =  826, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00558681] 1.0\n",
      "positions (x,y,z), reward: [ 0.53386043  0.47594282  8.67578335] 1.0\n",
      "positions (x,y,z), reward: [ 1.52916029  0.42191997  7.22291334] 1.0\n",
      "positions (x,y,z), reward: [ 5.14786371 -0.34852619  0.50359051] 1.0\n",
      "Episode =  827, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.63751128 -1.09206024  7.55371665] 1.0\n",
      "positions (x,y,z), reward: [ 5.06730059 -2.95257249  1.07418049] 1.0\n",
      "positions (x,y,z), reward: [ 5.22204287 -3.08825863  0.47983493] 1.0\n",
      "Episode =  828, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  6.32345196e-03   1.90091822e-02   9.80423360e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.5930953  -1.3439137   6.12417394] 1.0\n",
      "positions (x,y,z), reward: [-0.67673365 -1.38293296  5.95890848] 1.0\n",
      "Episode =  830, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.16525273 -0.13879417  9.84917286] 1.0\n",
      "positions (x,y,z), reward: [-4.88042058 -2.60561771  6.79281881] 1.0\n",
      "positions (x,y,z), reward: [-5.63150348 -2.90378088  6.14502344] 1.0\n",
      "Episode =  831, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.41429217 -3.32257752  4.1917878 ] 1.0\n",
      "Episode =  832, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.24936197 -0.61257806  9.02236575] 1.0\n",
      "positions (x,y,z), reward: [-0.57088798 -3.70465528  0.        ] 1.0\n",
      "Episode =  833, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.49162473e-02  -7.21174416e-03   1.00419789e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.10002022 -1.37174864  9.67525932] 1.0\n",
      "positions (x,y,z), reward: [ 0.03681352 -1.96481935  9.08534387] 1.0\n",
      "positions (x,y,z), reward: [  4.74919526e-03  -2.21548568e+00   8.82446896e+00] 1.0\n",
      "positions (x,y,z), reward: [-2.14492273 -6.75097845  3.18899535] 1.0\n",
      "positions (x,y,z), reward: [-3.08583631 -8.26752409  0.32535553] 1.0\n",
      "Episode =  834, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.07751105  0.49646318  8.45156547] 1.0\n",
      "positions (x,y,z), reward: [ 5.82842035  0.14801283  5.2716125 ] 1.0\n",
      "Episode =  835, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.53765225 -1.99309491  6.06399321] 1.0\n",
      "Episode =  836, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10677013  0.02541254  9.98425781] 1.0\n",
      "Episode =  837, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.66271672e-02  -2.37300655e-03   1.00160998e+01] 1.0\n",
      "Episode =  838, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05397878  -0.15230718  10.01279005] 1.0\n",
      "positions (x,y,z), reward: [  7.58744333e-03  -2.38162722e-01   1.00069615e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.20769404 -0.50195423  9.99205395] 1.0\n",
      "positions (x,y,z), reward: [ 0.5874318  -3.17151716  7.54972536] 1.0\n",
      "positions (x,y,z), reward: [ 0.2347156  -4.96823004  4.81901015] 1.0\n",
      "positions (x,y,z), reward: [-0.14845628 -6.30070425  1.93617614] 1.0\n",
      "positions (x,y,z), reward: [-0.33331476 -6.91435768  0.34720082] 1.0\n",
      "Episode =  839, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.28049289  2.02072438  8.72391982] 1.0\n",
      "positions (x,y,z), reward: [ 5.47603511  3.90072307  6.87976565] 1.0\n",
      "Episode =  840, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.04942961   0.41047851  10.05605433] 1.0\n",
      "positions (x,y,z), reward: [-2.29047307  1.02529081  9.69868408] 1.0\n",
      "positions (x,y,z), reward: [-10.49088633   5.11877296   5.42788321] 1.0\n",
      "positions (x,y,z), reward: [-13.94397822   6.90207558   2.55418931] 1.0\n",
      "Episode =  841, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.79539286e-03   1.13378372e-03   1.00184203e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.15596564 -0.03537106  9.82310472] 1.0\n",
      "positions (x,y,z), reward: [ 1.84779514 -0.13060382  8.76448686] 1.0\n",
      "positions (x,y,z), reward: [ 4.21732466 -0.47263102  7.13633611] 1.0\n",
      "positions (x,y,z), reward: [ 5.78396758 -0.77083862  5.76500693] 1.0\n",
      "positions (x,y,z), reward: [ 7.17203206 -1.06396687  4.46221037] 1.0\n",
      "positions (x,y,z), reward: [ 7.40780152 -1.12193333  4.23544396] 1.0\n",
      "positions (x,y,z), reward: [ 7.64380834 -1.18287426  4.00569866] 1.0\n",
      "Episode =  842, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.96040321 -1.97928645  8.74210159] 1.0\n",
      "positions (x,y,z), reward: [-5.30135371 -3.46001886  6.01266425] 1.0\n",
      "positions (x,y,z), reward: [-6.08301493 -3.78359338  5.22093323] 1.0\n",
      "positions (x,y,z), reward: [-9.35752258 -4.9198331   1.41286287] 1.0\n",
      "Episode =  843, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0420187  -0.02469262  9.98330881] 1.0\n",
      "positions (x,y,z), reward: [ 0.13888262  0.11392487  9.68653078] 1.0\n",
      "positions (x,y,z), reward: [ 0.28445165  0.2731113   9.59460418] 1.0\n",
      "positions (x,y,z), reward: [-0.17928198  0.81639121  9.36903798] 1.0\n",
      "positions (x,y,z), reward: [-1.32280531  1.38979018  9.28249463] 1.0\n",
      "positions (x,y,z), reward: [-1.54222488  1.37494261  9.24347283] 1.0\n",
      "positions (x,y,z), reward: [-2.36595514  1.21829467  8.88348344] 1.0\n",
      "positions (x,y,z), reward: [-4.31312923  0.71258874  7.37874296] 1.0\n",
      "Episode =  844, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.15200802 -5.95387325  1.35178   ] 1.0\n",
      "Episode =  845, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11933393 -0.29699945  9.90023921] 1.0\n",
      "positions (x,y,z), reward: [-0.51827481 -2.02010252  8.52726217] 1.0\n",
      "positions (x,y,z), reward: [-1.40656215 -3.01206806  7.01436718] 1.0\n",
      "positions (x,y,z), reward: [-2.08684467 -3.52158326  5.84377188] 1.0\n",
      "positions (x,y,z), reward: [-2.28672017 -3.66180838  5.48018782] 1.0\n",
      "positions (x,y,z), reward: [-2.78849478 -3.98533185  4.51016457] 1.0\n",
      "Episode =  847, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.28550367 -2.60550352  5.48402304] 1.0\n",
      "positions (x,y,z), reward: [ 4.01455199 -3.98298145  1.06008963] 1.0\n",
      "positions (x,y,z), reward: [ 4.14122248 -4.23749437  0.03286172] 1.0\n",
      "Episode =  848, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.86506845e-02   2.71867205e-03   1.00193068e+01] 1.0\n",
      "positions (x,y,z), reward: [  2.43689324e-01   6.88738082e-03   9.89810318e+00] 1.0\n",
      "positions (x,y,z), reward: [ 7.45846148 -1.87088242  0.52493556] 1.0\n",
      "Episode =  849, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.0749868  -0.05430495  9.95043726] 1.0\n",
      "positions (x,y,z), reward: [ 0.20984384 -0.12246973  9.74492157] 1.0\n",
      "positions (x,y,z), reward: [ 2.65315776 -0.86991956  6.21338582] 1.0\n",
      "positions (x,y,z), reward: [ 3.07154873 -1.00646468  5.5482185 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.32526432 -1.51443002  3.30207045] 1.0\n",
      "positions (x,y,z), reward: [ 4.86481808 -1.75244833  2.16234084] 1.0\n",
      "Episode =  850, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.09175189 -0.22857004  9.5573469 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.27142979 -0.32566528  9.34994069] 1.0\n",
      "positions (x,y,z), reward: [ 0.34568285 -0.35958604  9.2799861 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.99358172 -0.74754024  8.78012876] 1.0\n",
      "positions (x,y,z), reward: [ 1.37000449 -1.12939643  8.35783321] 1.0\n",
      "positions (x,y,z), reward: [ 3.7249374  -4.25294502  3.0346349 ] 1.0\n",
      "Episode =  851, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.4304515  -1.95500751  9.35465185] 1.0\n",
      "positions (x,y,z), reward: [ 1.77344635 -2.70891183  8.9638086 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.82950045 -2.98780115  8.81027628] 1.0\n",
      "positions (x,y,z), reward: [ 0.44345106 -7.63218964  2.80350935] 1.0\n",
      "Episode =  852, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.41498561e-01  -2.92215665e-03   9.98295181e+00] 1.0\n",
      "positions (x,y,z), reward: [ -1.42372670e-01  -3.76130280e-03   9.94930983e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.11037305 -0.01901679  9.86923107] 1.0\n",
      "positions (x,y,z), reward: [ 0.3663184   0.19533893  9.18651969] 1.0\n",
      "Episode =  853, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.46898546 -0.0154631   9.85578735] 1.0\n",
      "positions (x,y,z), reward: [ 0.92817799 -0.08288831  9.69530463] 1.0\n",
      "Episode =  854, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00552594] 1.0\n",
      "positions (x,y,z), reward: [ 0.80748332 -0.44197169  9.53858071] 1.0\n",
      "positions (x,y,z), reward: [ 0.94619343 -0.68386625  9.36527583] 1.0\n",
      "positions (x,y,z), reward: [ 0.68752679 -2.95116081  7.32459519] 1.0\n",
      "positions (x,y,z), reward: [-0.50790883 -4.40849936  4.84542397] 1.0\n",
      "positions (x,y,z), reward: [-0.64598242 -4.58301722  4.49076446] 1.0\n",
      "positions (x,y,z), reward: [-0.78334044 -4.75810863  4.12210834] 1.0\n",
      "positions (x,y,z), reward: [-2.16571209 -6.58987893  0.        ] 1.0\n",
      "Episode =  855, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.54805751  -0.38117436  10.14052951] 1.0\n",
      "positions (x,y,z), reward: [-2.49564596 -1.72885262  9.41759564] 1.0\n",
      "positions (x,y,z), reward: [-4.1741159  -2.4405656   8.29124892] 1.0\n",
      "positions (x,y,z), reward: [-6.70704937 -3.39663565  5.76479865] 1.0\n",
      "positions (x,y,z), reward: [-8.2098325  -3.87008904  3.96757976] 1.0\n",
      "positions (x,y,z), reward: [-10.90138974  -4.69446312   0.24024592] 1.0\n",
      "Episode =  856, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04181373   0.01027815  10.02790791] 1.0\n",
      "positions (x,y,z), reward: [ 0.13395661  0.02802606  9.79754002] 1.0\n",
      "positions (x,y,z), reward: [ 0.33346749  0.05513402  9.62263163] 1.0\n",
      "positions (x,y,z), reward: [ 1.27979894  0.09533065  8.91254084] 1.0\n",
      "positions (x,y,z), reward: [ 6.50342393 -0.90572459  2.39027456] 1.0\n",
      "Episode =  857, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.4954809  -0.01428088  9.6324912 ] 1.0\n",
      "positions (x,y,z), reward: [ 6.84704377 -1.22524144  4.23994302] 1.0\n",
      "Episode =  858, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06265537 -0.01068446  9.82879829] 1.0\n",
      "positions (x,y,z), reward: [ 0.03312634 -0.18252812  9.55176495] 1.0\n",
      "positions (x,y,z), reward: [ 0.85724641 -1.49625374  8.100986  ] 1.0\n",
      "positions (x,y,z), reward: [ 0.81235179 -1.66475348  7.926838  ] 1.0\n",
      "positions (x,y,z), reward: [ 0.78591123 -1.73882457  7.83548771] 1.0\n",
      "positions (x,y,z), reward: [ 0.73573111 -1.86803053  7.63372089] 1.0\n",
      "Episode =  859, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00542873] 1.0\n",
      "positions (x,y,z), reward: [-0.10816947  0.11477118  9.87895651] 1.0\n",
      "positions (x,y,z), reward: [ 0.74219056  0.48634547  8.65366013] 1.0\n",
      "positions (x,y,z), reward: [ 1.31044208  0.62280696  8.13850294] 1.0\n",
      "positions (x,y,z), reward: [ 2.74606787  0.83029348  6.60368486] 1.0\n",
      "positions (x,y,z), reward: [ 3.46820727  0.9430671   5.46211324] 1.0\n",
      "positions (x,y,z), reward: [ 3.98908773  1.09152748  4.49608275] 1.0\n",
      "positions (x,y,z), reward: [ 4.39308068  1.23085516  3.42874343] 1.0\n",
      "Episode =  860, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.17727776 -0.05057086  9.95978777] 1.0\n",
      "positions (x,y,z), reward: [-3.26129311 -0.01214351  9.83866157] 1.0\n",
      "positions (x,y,z), reward: [-4.80796104  0.25914471  9.61279807] 1.0\n",
      "positions (x,y,z), reward: [-6.10572045  0.50080848  9.28497154] 1.0\n",
      "positions (x,y,z), reward: [-8.14893527  1.00573214  8.40006965] 1.0\n",
      "positions (x,y,z), reward: [-11.13421805   1.90190117   6.4101487 ] 1.0\n",
      "positions (x,y,z), reward: [-11.75821157   2.10372902   5.88747263] 1.0\n",
      "positions (x,y,z), reward: [-15.29272413   3.00223408   2.28081923] 1.0\n",
      "Episode =  861, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07428291 -0.16514742  9.56331245] 1.0\n",
      "positions (x,y,z), reward: [-0.35018896 -0.60201368  8.87471527] 1.0\n",
      "positions (x,y,z), reward: [-0.38078099 -0.82979271  8.36722733] 1.0\n",
      "Episode =  862, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.00824191 -0.95149529  9.46979005] 1.0\n",
      "positions (x,y,z), reward: [ 0.70057436 -1.06736781  9.16193968] 1.0\n",
      "positions (x,y,z), reward: [-1.35052003 -1.56153441  7.53633326] 1.0\n",
      "positions (x,y,z), reward: [-1.93764474 -1.71209979  7.03820679] 1.0\n",
      "positions (x,y,z), reward: [-2.08572274 -1.7496089   6.90799997] 1.0\n",
      "positions (x,y,z), reward: [-7.17311328 -2.11698539  1.70882367] 1.0\n",
      "positions (x,y,z), reward: [-7.36165029 -2.12390647  1.47513951] 1.0\n",
      "positions (x,y,z), reward: [-8.54801884 -2.17866365  0.        ] 1.0\n",
      "Episode =  863, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.39674994  0.01187617  9.42084263] 1.0\n",
      "positions (x,y,z), reward: [ 3.38433442  0.43526609  6.11318053] 1.0\n",
      "positions (x,y,z), reward: [ 3.77933461  0.57075026  4.73834347] 1.0\n",
      "positions (x,y,z), reward: [ 4.60088152  0.91994407  1.02206866] 1.0\n",
      "Episode =  864, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -9.71108385e-02   1.12453306e-03   9.95713365e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.27770743  0.27069503  9.35127219] 1.0\n",
      "positions (x,y,z), reward: [ 0.21618154  0.35937369  9.23159496] 1.0\n",
      "positions (x,y,z), reward: [-0.16812505  0.7691548   8.64422149] 1.0\n",
      "positions (x,y,z), reward: [-1.09078259  1.66351945  7.68647173] 1.0\n",
      "positions (x,y,z), reward: [-1.72803576  2.18596465  6.98863272] 1.0\n",
      "positions (x,y,z), reward: [-2.36492398  2.63317992  6.29558157] 1.0\n",
      "positions (x,y,z), reward: [-3.74932045  3.78062727  4.45611041] 1.0\n",
      "positions (x,y,z), reward: [-6.22022714  5.89803336  0.22986457] 1.0\n",
      "Episode =  865, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.10009743  1.7569337   5.00453327] 1.0\n",
      "positions (x,y,z), reward: [-8.08930817  2.34516956  2.99834545] 1.0\n",
      "positions (x,y,z), reward: [-9.64646493  2.7757353   1.25495518] 1.0\n",
      "Episode =  866, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.09846932 -0.16908323  9.64700582] 1.0\n",
      "positions (x,y,z), reward: [ 0.43349836 -0.2479476   9.14171903] 1.0\n",
      "positions (x,y,z), reward: [ 1.98283589 -0.37899141  7.4306254 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.1446003  -0.39592732  5.86005495] 1.0\n",
      "positions (x,y,z), reward: [ 4.40255336 -0.25197297  2.92151273] 1.0\n",
      "Episode =  867, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.44021250e-02   4.51061774e-04   1.00162784e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.52803828 -0.63363909  8.23264938] 1.0\n",
      "positions (x,y,z), reward: [ 2.35367469 -1.4021291   6.73151056] 1.0\n",
      "positions (x,y,z), reward: [ 3.16595132 -2.9688034   0.78620658] 1.0\n",
      "Episode =  868, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.04184892  0.17965813  8.7515294 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.69290571  0.6668536   3.8909401 ] 1.0\n",
      "Episode =  869, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.55125868 -0.57353178  8.36427864] 1.0\n",
      "positions (x,y,z), reward: [-7.05677345  0.84159616  4.37729482] 1.0\n",
      "positions (x,y,z), reward: [-8.69353529  1.23248811  2.98215   ] 1.0\n",
      "positions (x,y,z), reward: [-9.77994908  1.47127642  2.01139164] 1.0\n",
      "positions (x,y,z), reward: [-11.38617459   1.78843887   0.51389073] 1.0\n",
      "Episode =  870, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.31164223 -0.21378795  9.35973677] 1.0\n",
      "positions (x,y,z), reward: [ 0.32322603 -0.21240668  8.83154308] 1.0\n",
      "positions (x,y,z), reward: [-3.12578151  1.57475816  5.62044636] 1.0\n",
      "positions (x,y,z), reward: [-3.87933844  2.04311242  4.73197249] 1.0\n",
      "positions (x,y,z), reward: [-5.28647015  2.93931827  2.78570729] 1.0\n",
      "positions (x,y,z), reward: [-7.04068661  3.9961303   0.02415847] 1.0\n",
      "Episode =  871, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16309209  0.2009337   9.74011589] 1.0\n",
      "positions (x,y,z), reward: [ 0.0404471   0.31634434  9.58356898] 1.0\n",
      "positions (x,y,z), reward: [-3.30190777 -0.46796781  5.40822051] 1.0\n",
      "positions (x,y,z), reward: [-5.95411419 -0.52983105  0.04713387] 1.0\n",
      "Episode =  872, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -1.34314739e-02   8.67167029e-03   1.00002440e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.03830734  0.28980978  9.83418974] 1.0\n",
      "positions (x,y,z), reward: [-0.62619758  0.27727741  9.82680112] 1.0\n",
      "positions (x,y,z), reward: [-4.12724754  0.67857005  8.4310088 ] 1.0\n",
      "Episode =  873, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.54601282 -2.83622874  7.12010639] 1.0\n",
      "positions (x,y,z), reward: [ 0.04257688 -3.35383212  6.17257588] 1.0\n",
      "positions (x,y,z), reward: [-1.41146129 -5.13849798  2.21650655] 1.0\n",
      "Episode =  874, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02773435  -0.0206102   10.0305147 ] 1.0\n",
      "positions (x,y,z), reward: [-2.06825955  1.74891453  3.77069967] 1.0\n",
      "positions (x,y,z), reward: [-2.39722524  2.01484361  2.8419256 ] 1.0\n",
      "positions (x,y,z), reward: [-2.73263707  2.28703226  1.83493346] 1.0\n",
      "Episode =  875, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.84876915 -3.18919178  7.37597209] 1.0\n",
      "positions (x,y,z), reward: [-2.05293593 -3.95005314  6.48474371] 1.0\n",
      "positions (x,y,z), reward: [-2.54671337 -4.22652777  6.09954588] 1.0\n",
      "positions (x,y,z), reward: [-3.21445467 -4.60536102  5.53494635] 1.0\n",
      "positions (x,y,z), reward: [-8.08617225 -7.26024638  0.02559769] 1.0\n",
      "Episode =  876, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.03292011 -0.27403937  8.07242901] 1.0\n",
      "positions (x,y,z), reward: [-0.55062695 -0.71039626  6.9259134 ] 1.0\n",
      "positions (x,y,z), reward: [-1.82684578 -1.80802153  3.04004685] 1.0\n",
      "positions (x,y,z), reward: [-2.61945359 -2.32243613  0.        ] 1.0\n",
      "Episode =  877, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.42159318e-02  -5.62228558e-03   1.00243283e+01] 1.0\n",
      "positions (x,y,z), reward: [-5.95131122 -3.53833393  6.66138685] 1.0\n",
      "positions (x,y,z), reward: [-8.01065369 -5.49867381  3.41278   ] 1.0\n",
      "Episode =  878, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.20697659  0.75335194  9.09750368] 1.0\n",
      "positions (x,y,z), reward: [ 0.16445978  1.4801576   8.51217273] 1.0\n",
      "positions (x,y,z), reward: [-2.69595498  6.53575645  3.21689365] 1.0\n",
      "Episode =  879, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.26203517 -0.28580806  9.07824979] 1.0\n",
      "positions (x,y,z), reward: [ 0.22891588 -0.22095558  8.88056839] 1.0\n",
      "positions (x,y,z), reward: [ 0.53755324  0.2739502   7.05113537] 1.0\n",
      "Episode =  880, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05412515 -0.46091994  9.42758635] 1.0\n",
      "positions (x,y,z), reward: [ 0.15422889 -0.55996932  9.27227441] 1.0\n",
      "positions (x,y,z), reward: [ 0.59543893 -0.93067885  8.77560313] 1.0\n",
      "positions (x,y,z), reward: [ 1.43014774 -2.10408764  7.08351304] 1.0\n",
      "positions (x,y,z), reward: [ 2.30791661 -3.96226966  2.87838005] 1.0\n",
      "Episode =  881, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05007946  -0.02615515  10.06280308] 1.0\n",
      "positions (x,y,z), reward: [ -0.06337589  -0.04316345  10.06185804] 1.0\n",
      "positions (x,y,z), reward: [ 0.29099712 -0.28841092  9.38828336] 1.0\n",
      "positions (x,y,z), reward: [ 3.3538931  -0.82655043  6.45559998] 1.0\n",
      "positions (x,y,z), reward: [ 6.07412563 -1.19970311  3.04641255] 1.0\n",
      "Episode =  882, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05371572  0.01829306  9.7812099 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.07989453 -0.81827212  8.80904172] 1.0\n",
      "positions (x,y,z), reward: [-0.39995633 -2.36350904  5.33900895] 1.0\n",
      "Episode =  883, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.60845987  1.43481822  7.3380193 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.92408987  1.82173207  6.30152725] 1.0\n",
      "positions (x,y,z), reward: [ 1.46825866  2.38789122  4.12834498] 1.0\n",
      "Episode =  884, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.69733029  0.04341117  9.69984256] 1.0\n",
      "positions (x,y,z), reward: [-0.42890341 -2.55327911  5.99829378] 1.0\n",
      "positions (x,y,z), reward: [-0.51229222 -2.63675326  5.81387284] 1.0\n",
      "positions (x,y,z), reward: [-1.69943193 -3.82185816  2.87714843] 1.0\n",
      "Episode =  885, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.84903198 -1.35865728  8.07079313] 1.0\n",
      "positions (x,y,z), reward: [ 0.62688544 -3.28335418  4.74385082] 1.0\n",
      "positions (x,y,z), reward: [ 0.36033452 -4.47978077  1.22056749] 1.0\n",
      "Episode =  886, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.0118601   0.02707744  9.83828609] 1.0\n",
      "positions (x,y,z), reward: [ 4.65256842  0.61710126  6.69120885] 1.0\n",
      "positions (x,y,z), reward: [ 6.56723889  0.39368693  4.79309993] 1.0\n",
      "positions (x,y,z), reward: [ 9.41962271  0.03689509  0.57716975] 1.0\n",
      "Episode =  887, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.50055613  0.90090502  9.53649998] 1.0\n",
      "Episode =  888, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.37297222e-02  -7.55857775e-03   1.00187365e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.08701668 -0.0310013   9.89635452] 1.0\n",
      "positions (x,y,z), reward: [ 0.08909189 -0.0786224   9.63665796] 1.0\n",
      "positions (x,y,z), reward: [ 0.28203906 -0.7675111   6.06419288] 1.0\n",
      "Episode =  889, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.31144559 -1.85771096  7.6917707 ] 1.0\n",
      "positions (x,y,z), reward: [ 1.21000108 -3.1119054   5.73741776] 1.0\n",
      "Episode =  890, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.09825037e-03   5.51878558e-03   1.00102201e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.23141051 -0.14886573  9.66234459] 1.0\n",
      "positions (x,y,z), reward: [-0.56728117 -0.74375146  8.86061881] 1.0\n",
      "positions (x,y,z), reward: [-0.90324468 -1.79847293  6.85128807] 1.0\n",
      "Episode =  891, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04238226  0.02275576  9.99756907] 1.0\n",
      "positions (x,y,z), reward: [-0.14091538 -1.12553308  8.61396602] 1.0\n",
      "positions (x,y,z), reward: [-0.11457947 -1.52178869  8.02284551] 1.0\n",
      "Episode =  892, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.0286896  -0.70355094  8.57900159] 1.0\n",
      "positions (x,y,z), reward: [ 0.99012084 -0.8034181   8.06097408] 1.0\n",
      "positions (x,y,z), reward: [-0.21331464 -0.84079394  5.29755286] 1.0\n",
      "Episode =  893, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04713906   0.03052778  10.02500792] 1.0\n",
      "positions (x,y,z), reward: [-0.04833931  0.07307639  9.96073815] 1.0\n",
      "Episode =  894, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.11020625  0.12598452  9.99141187] 1.0\n",
      "positions (x,y,z), reward: [ -0.12458952   0.16661227  10.0260453 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.60996576   0.16537292  10.35131157] 1.0\n",
      "positions (x,y,z), reward: [ -2.9331595    0.57474169  11.01454343] 1.0\n",
      "positions (x,y,z), reward: [ -4.25035654   0.56977756  11.09044239] 1.0\n",
      "positions (x,y,z), reward: [ -5.33025288   0.36719195  10.85536536] 1.0\n",
      "positions (x,y,z), reward: [-9.1115414  -0.48459357  8.02879188] 1.0\n",
      "positions (x,y,z), reward: [-13.24880756  -2.1860368    1.97844267] 1.0\n",
      "positions (x,y,z), reward: [-14.49445442  -2.7953558    0.        ] 1.0\n",
      "Episode =  895, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.84457346 -0.93638451  9.03320977] 1.0\n",
      "positions (x,y,z), reward: [ 1.09813129 -1.20692358  8.73727903] 1.0\n",
      "positions (x,y,z), reward: [ 1.25620501 -1.39414738  8.49143722] 1.0\n",
      "positions (x,y,z), reward: [ 2.14225394 -3.11869758  5.81446893] 1.0\n",
      "positions (x,y,z), reward: [ 2.25399194 -3.76230122  4.68103331] 1.0\n",
      "positions (x,y,z), reward: [ 2.31007688 -4.28142255  3.70686877] 1.0\n",
      "Episode =  896, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16176077 -0.31351355  9.89530628] 1.0\n",
      "positions (x,y,z), reward: [ 0.35243724 -0.70708208  9.33649644] 1.0\n",
      "positions (x,y,z), reward: [ 0.8025889  -0.88728969  8.99074953] 1.0\n",
      "positions (x,y,z), reward: [ 1.06656448 -0.96856356  8.78353508] 1.0\n",
      "Episode =  897, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.82264007e-03   2.17421774e-03   1.00128430e+01] 1.0\n",
      "positions (x,y,z), reward: [ -4.45485017e-02  -1.91799546e-03   1.00165566e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.53100026 -0.14519359  9.34217769] 1.0\n",
      "positions (x,y,z), reward: [-1.24130931 -3.50833154  2.71548184] 1.0\n",
      "Episode =  898, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.10408902  0.01318324  9.93573698] 1.0\n",
      "positions (x,y,z), reward: [-1.07077689 -2.07200667  7.51895744] 1.0\n",
      "positions (x,y,z), reward: [-1.58464791 -2.16439788  7.02322992] 1.0\n",
      "positions (x,y,z), reward: [-4.06108728 -2.33599638  4.54422414] 1.0\n",
      "positions (x,y,z), reward: [-4.37785144 -2.3512488   4.18771834] 1.0\n",
      "Episode =  899, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.40032406 -0.56778372  8.30153773] 1.0\n",
      "positions (x,y,z), reward: [ 1.85524202 -0.83349514  7.58802121] 1.0\n",
      "positions (x,y,z), reward: [ 3.47063236 -2.40865842  2.92843817] 1.0\n",
      "Episode =  900, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.839805   -3.19922099  5.34753926] 1.0\n",
      "positions (x,y,z), reward: [ 0.59932354 -3.79638931  3.51370682] 1.0\n",
      "positions (x,y,z), reward: [ 0.53419259 -3.93433079  3.02375695] 1.0\n",
      "Episode =  901, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.91206091 -0.66581978  8.01428221] 1.0\n",
      "positions (x,y,z), reward: [ 0.97906361 -0.70143906  5.58139876] 1.0\n",
      "positions (x,y,z), reward: [ 1.04097619 -0.68601324  5.09678824] 1.0\n",
      "positions (x,y,z), reward: [ 1.10107188 -0.66219114  4.00090054] 1.0\n",
      "positions (x,y,z), reward: [ 1.06390457 -0.61972744  1.87524166] 1.0\n",
      "Episode =  902, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.14533516 -0.08616601  9.78083606] 1.0\n",
      "positions (x,y,z), reward: [-0.22398042 -0.3492971   8.92185665] 1.0\n",
      "positions (x,y,z), reward: [-1.19803581 -0.80775543  5.55835534] 1.0\n",
      "positions (x,y,z), reward: [-3.1827791  -1.27110903  0.58083357] 1.0\n",
      "Episode =  903, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.14860535  0.18332194  9.92073691] 1.0\n",
      "positions (x,y,z), reward: [-1.25600088 -1.80326494  6.95481759] 1.0\n",
      "positions (x,y,z), reward: [-1.08696232 -2.00135279  5.97222824] 1.0\n",
      "positions (x,y,z), reward: [-1.02942554 -2.040187    5.63143472] 1.0\n",
      "positions (x,y,z), reward: [-0.7025582  -2.20636258  3.29807178] 1.0\n",
      "positions (x,y,z), reward: [-0.55525234 -2.25059684  1.91893692] 1.0\n",
      "Episode =  904, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.78615241 -0.07997479  9.33793256] 1.0\n",
      "positions (x,y,z), reward: [ 0.33274145 -0.95171804  8.16915419] 1.0\n",
      "positions (x,y,z), reward: [-1.40836113 -1.6317369   3.33486589] 1.0\n",
      "Episode =  905, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01571768   0.01183721  10.02937392] 1.0\n",
      "positions (x,y,z), reward: [ -0.03711464   0.02689377  10.03734544] 1.0\n",
      "positions (x,y,z), reward: [ -0.03328247   0.03723755  10.03299247] 1.0\n",
      "positions (x,y,z), reward: [ 0.01153159  0.06799659  9.97270526] 1.0\n",
      "positions (x,y,z), reward: [-8.66325976 -0.11396981  2.4962685 ] 1.0\n",
      "Episode =  906, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.13190047 -0.06748372  8.8079611 ] 1.0\n",
      "positions (x,y,z), reward: [-4.08217772  1.56989873  3.77320076] 1.0\n",
      "Episode =  907, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04798922  0.03003759  9.99774272] 1.0\n",
      "positions (x,y,z), reward: [ 0.30180319 -1.23722996  8.46294501] 1.0\n",
      "positions (x,y,z), reward: [-0.8371672  -2.29524608  6.92786173] 1.0\n",
      "Episode =  908, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02300279  0.08270512  9.84079848] 1.0\n",
      "positions (x,y,z), reward: [ 0.34170064  0.44143253  9.22446873] 1.0\n",
      "positions (x,y,z), reward: [ 2.64622572  1.66825251  7.00659603] 1.0\n",
      "positions (x,y,z), reward: [ 5.56217564  2.72432017  3.85689258] 1.0\n",
      "Episode =  909, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00530156] 1.0\n",
      "positions (x,y,z), reward: [-0.04596132  0.02191621  9.92923823] 1.0\n",
      "positions (x,y,z), reward: [ -0.29729507   0.1892446   10.01230872] 1.0\n",
      "positions (x,y,z), reward: [-4.70874176 -1.21173867  9.25825407] 1.0\n",
      "positions (x,y,z), reward: [-5.78688738 -2.1056232   8.1110029 ] 1.0\n",
      "positions (x,y,z), reward: [-6.95206407 -3.08025744  6.43624062] 1.0\n",
      "positions (x,y,z), reward: [-8.53155985 -4.54195377  3.37430953] 1.0\n",
      "positions (x,y,z), reward: [-9.25829858 -5.23090316  1.65117516] 1.0\n",
      "Episode =  910, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05268773  -0.04390369  10.04959362] 1.0\n",
      "positions (x,y,z), reward: [ 0.10705776 -0.06504645  9.91984725] 1.0\n",
      "positions (x,y,z), reward: [ 0.47034478 -0.12611142  9.3203176 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.51817382 -0.18649551  9.13112106] 1.0\n",
      "positions (x,y,z), reward: [ 0.46080892 -0.53373171  8.22952098] 1.0\n",
      "Episode =  911, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-3.82981111  1.87851366  9.27960205] 1.0\n",
      "Episode =  912, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.05360635 -0.14717392  9.89044048] 1.0\n",
      "positions (x,y,z), reward: [-0.38114083 -1.59186744  7.57763856] 1.0\n",
      "positions (x,y,z), reward: [-2.771024   -2.49667575  3.1928468 ] 1.0\n",
      "positions (x,y,z), reward: [-4.20479762 -2.7889719   0.        ] 1.0\n",
      "Episode =  913, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.13964763e-02  -3.03203448e-03   9.99103346e+00] 1.0\n",
      "Episode =  914, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00485191] 1.0\n",
      "positions (x,y,z), reward: [ 1.60868564  0.46310903  6.14988141] 1.0\n",
      "Episode =  915, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04280061   0.01021669  10.00587587] 1.0\n",
      "positions (x,y,z), reward: [ 0.63118396 -2.2697247   7.30124578] 1.0\n",
      "positions (x,y,z), reward: [-0.17724481 -3.71869989  4.38242348] 1.0\n",
      "positions (x,y,z), reward: [-1.30117258 -5.01435612  0.69833671] 1.0\n",
      "Episode =  916, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.10318445  0.05613847  9.98548209] 1.0\n",
      "positions (x,y,z), reward: [ 0.03994014  0.18201675  9.65306675] 1.0\n",
      "positions (x,y,z), reward: [ 0.97058173 -1.37479387  6.49308011] 1.0\n",
      "positions (x,y,z), reward: [ 0.42649581 -2.47487706  3.73565328] 1.0\n",
      "positions (x,y,z), reward: [-0.45009638 -3.60388648  0.26329949] 1.0\n",
      "Episode =  917, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00571248] 1.0\n",
      "positions (x,y,z), reward: [ 0.06409053 -0.15146061  9.79789006] 1.0\n",
      "positions (x,y,z), reward: [ 1.07372365 -0.88636212  8.95271461] 1.0\n",
      "positions (x,y,z), reward: [ 0.69074654 -3.57471953  4.97137413] 1.0\n",
      "positions (x,y,z), reward: [ 0.31988885 -4.14481755  3.54614129] 1.0\n",
      "Episode =  918, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.79659645 -0.27892626  9.43121886] 1.0\n",
      "positions (x,y,z), reward: [ 0.92514006 -0.50138986  9.25566749] 1.0\n",
      "positions (x,y,z), reward: [-0.34105902 -2.31837338  5.74994109] 1.0\n",
      "Episode =  919, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  7.58096441e-03   6.80185305e-02   9.89680894e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.43148003  0.14118636  9.49566159] 1.0\n",
      "positions (x,y,z), reward: [ 0.24735199  0.1325407   9.472333  ] 1.0\n",
      "positions (x,y,z), reward: [-0.10189244  0.14835912  9.43960115] 1.0\n",
      "positions (x,y,z), reward: [-4.22648926  0.13340133  8.83368563] 1.0\n",
      "positions (x,y,z), reward: [-9.1733786  -0.20069319  6.36217549] 1.0\n",
      "positions (x,y,z), reward: [-10.85066548  -0.17270372   5.42514857] 1.0\n",
      "positions (x,y,z), reward: [-12.89189556  -0.12457708   4.09932214] 1.0\n",
      "positions (x,y,z), reward: [-17.1371273    0.18333218   0.59676111] 1.0\n",
      "Episode =  920, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06910279   0.05533353  10.04236274] 1.0\n",
      "positions (x,y,z), reward: [-0.80017778  0.98387769  6.92266731] 1.0\n",
      "positions (x,y,z), reward: [-1.57432191  1.6883743   2.11990662] 1.0\n",
      "Episode =  921, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.33597064  0.11277068  9.94189047] 1.0\n",
      "positions (x,y,z), reward: [-0.38811413  0.15900691  9.85904317] 1.0\n",
      "positions (x,y,z), reward: [-0.30928314 -0.94252164  5.79457877] 1.0\n",
      "positions (x,y,z), reward: [-0.28052522 -1.94598789  0.41093405] 1.0\n",
      "Episode =  922, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02527112  -0.01401345  10.0220715 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.16597706 -1.65565955  7.3904738 ] 1.0\n",
      "positions (x,y,z), reward: [ 4.77056359 -3.53212241  3.2932232 ] 1.0\n",
      "Episode =  923, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.7743045  -0.0193877   9.62716643] 1.0\n",
      "positions (x,y,z), reward: [ 7.78809125 -2.91066617  4.39498955] 1.0\n",
      "positions (x,y,z), reward: [ 7.89930426 -3.01145076  4.17991601] 1.0\n",
      "positions (x,y,z), reward: [ 9.26723026 -4.52381206  0.58860207] 1.0\n",
      "Episode =  924, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.07372151 -0.74497844  7.86129191] 1.0\n",
      "positions (x,y,z), reward: [ 0.33207752 -0.87581974  6.89541173] 1.0\n",
      "positions (x,y,z), reward: [ 0.97036041 -1.05414095  0.5122519 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.96605272 -1.0546285   0.20548941] 1.0\n",
      "Episode =  925, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00510314] 1.0\n",
      "positions (x,y,z), reward: [ -2.61172912e-03   3.70952681e-03   1.00079334e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.13527403  0.14696979  9.88942426] 1.0\n",
      "positions (x,y,z), reward: [-3.66227636  3.42325166  8.9100229 ] 1.0\n",
      "positions (x,y,z), reward: [-9.37173171  8.66287678  0.3251207 ] 1.0\n",
      "Episode =  926, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.01294142  -0.01515918  10.01791175] 1.0\n",
      "positions (x,y,z), reward: [ -0.65679568  -1.07553815  10.06308448] 1.0\n",
      "positions (x,y,z), reward: [-10.33296152  -4.70618634   3.60351817] 1.0\n",
      "positions (x,y,z), reward: [-12.41453944  -5.28973781   1.01489475] 1.0\n",
      "Episode =  927, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07785179  0.09900825  9.87067465] 1.0\n",
      "positions (x,y,z), reward: [-0.0675623   0.1110618   9.83656841] 1.0\n",
      "positions (x,y,z), reward: [-0.06484313  1.27385746  8.37224796] 1.0\n",
      "positions (x,y,z), reward: [-0.77788011  1.80488832  7.86236525] 1.0\n",
      "positions (x,y,z), reward: [-1.92854609  2.54112038  6.70988596] 1.0\n",
      "positions (x,y,z), reward: [-2.22004549  2.6404726   6.15436977] 1.0\n",
      "positions (x,y,z), reward: [-3.05246853  2.99043118  3.53371102] 1.0\n",
      "Episode =  928, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.17324865 -0.05644313  9.94851642] 1.0\n",
      "positions (x,y,z), reward: [-0.21042462 -0.09643382  9.94914363] 1.0\n",
      "positions (x,y,z), reward: [-1.63404851 -1.90922416  9.22827723] 1.0\n",
      "positions (x,y,z), reward: [-3.97094514 -3.23388754  7.28701375] 1.0\n",
      "Episode =  929, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02102443   0.01561918  10.02531695] 1.0\n",
      "positions (x,y,z), reward: [-0.75376199  0.09052236  9.63968944] 1.0\n",
      "Episode =  930, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06920822  0.04913302  9.98758599] 1.0\n",
      "positions (x,y,z), reward: [ 0.03465449  0.1643387   9.75895444] 1.0\n",
      "positions (x,y,z), reward: [ 0.52581537  1.51200395  8.28918134] 1.0\n",
      "positions (x,y,z), reward: [ 0.62573323  1.52683293  8.0497241 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.50490902  1.47142503  7.37106767] 1.0\n",
      "positions (x,y,z), reward: [-0.064023    1.49280563  5.95778847] 1.0\n",
      "positions (x,y,z), reward: [-0.23412705  1.55489195  5.49196154] 1.0\n",
      "positions (x,y,z), reward: [-0.29452786  1.57720149  5.33107925] 1.0\n",
      "positions (x,y,z), reward: [-0.41944589  1.61797887  4.99224105] 1.0\n",
      "Episode =  931, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.60205421 -0.08904265  9.55409541] 1.0\n",
      "positions (x,y,z), reward: [ 3.04656373  0.46314892  6.51092443] 1.0\n",
      "Episode =  932, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-1.66055951  0.81629536  9.79839584] 1.0\n",
      "positions (x,y,z), reward: [-2.80958642  1.5651442   9.31114035] 1.0\n",
      "positions (x,y,z), reward: [-3.48823384  1.72458403  8.52137912] 1.0\n",
      "positions (x,y,z), reward: [-4.19762213  0.59391821  3.80919257] 1.0\n",
      "Episode =  933, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.06920278  -0.20085847  10.7729771 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.49095883  -0.03191176  10.64626056] 1.0\n",
      "Episode =  934, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.13228451e-03  -3.16941899e-03   1.00149421e+01] 1.0\n",
      "positions (x,y,z), reward: [ 1.15935486 -0.4925889   9.1783321 ] 1.0\n",
      "positions (x,y,z), reward: [ 3.49738273 -1.53617097  7.11791835] 1.0\n",
      "positions (x,y,z), reward: [ 7.85167801 -3.67799675  1.89005052] 1.0\n",
      "Episode =  935, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.02633671  -0.07299487  10.02491735] 1.0\n",
      "positions (x,y,z), reward: [-12.52740405  -1.29621385   0.40386261] 1.0\n",
      "Episode =  936, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-9.41010043 -0.44288361  8.7975471 ] 1.0\n",
      "positions (x,y,z), reward: [-16.42446617  -0.11130955   5.89670478] 1.0\n",
      "positions (x,y,z), reward: [-18.40607149  -0.02416159   4.77669787] 1.0\n",
      "Episode =  937, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.03896195  -0.01437075  10.04132591] 1.0\n",
      "positions (x,y,z), reward: [ -0.05364789  -0.01453064  10.05070654] 1.0\n",
      "positions (x,y,z), reward: [ 1.21920173 -0.60966557  9.93782642] 1.0\n",
      "positions (x,y,z), reward: [-6.46049932  4.43158493  8.1836199 ] 1.0\n",
      "positions (x,y,z), reward: [-6.69470771  4.62095817  8.07124865] 1.0\n",
      "positions (x,y,z), reward: [-6.93129494  4.8126638   7.95651956] 1.0\n",
      "Episode =  938, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.76706659  0.8341308   9.67972433] 1.0\n",
      "positions (x,y,z), reward: [-2.39776978  2.17972703  8.22541402] 1.0\n",
      "positions (x,y,z), reward: [-2.81204257  2.33362244  7.7923576 ] 1.0\n",
      "positions (x,y,z), reward: [-5.2323717   2.92551977  4.93736338] 1.0\n",
      "Episode =  939, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.30939342 -0.28591683  7.32609336] 1.0\n",
      "positions (x,y,z), reward: [-0.21864307 -0.38686332  4.54848653] 1.0\n",
      "Episode =  940, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05555433 -2.98455259  8.31016962] 1.0\n",
      "positions (x,y,z), reward: [-1.19164407 -6.49403982  3.12977794] 1.0\n",
      "positions (x,y,z), reward: [-1.62155254 -7.45015481  1.0947118 ] 1.0\n",
      "Episode =  941, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02666224  0.20075564  9.90555467] 1.0\n",
      "positions (x,y,z), reward: [ -0.07725165   0.14650894  10.04193379] 1.0\n",
      "positions (x,y,z), reward: [ -2.29627926   0.09559963  10.06057554] 1.0\n",
      "positions (x,y,z), reward: [ -2.88735771   0.17347523  10.04975499] 1.0\n",
      "positions (x,y,z), reward: [-19.14241611   3.02116979   0.68810187] 1.0\n",
      "Episode =  942, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.57567073 -1.52320229  9.03764199] 1.0\n",
      "positions (x,y,z), reward: [ 0.31420307 -2.11839788  8.46029044] 1.0\n",
      "positions (x,y,z), reward: [ 0.24499985 -2.23720955  8.33295496] 1.0\n",
      "positions (x,y,z), reward: [-0.81750614 -3.47349615  6.40338977] 1.0\n",
      "positions (x,y,z), reward: [-2.20236209 -4.70744168  3.4958367 ] 1.0\n",
      "Episode =  943, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.10566895   0.01275492  10.07021524] 1.0\n",
      "positions (x,y,z), reward: [ -0.23935266   0.0496803   10.04066724] 1.0\n",
      "positions (x,y,z), reward: [ -0.37185712   0.07607509  10.00457948] 1.0\n",
      "positions (x,y,z), reward: [-0.7433314   0.14011154  9.89104557] 1.0\n",
      "positions (x,y,z), reward: [-5.11907684  2.1423664   7.05565001] 1.0\n",
      "positions (x,y,z), reward: [-6.0739178   2.69111631  5.92186221] 1.0\n",
      "positions (x,y,z), reward: [-7.91303133  3.67534686  3.630356  ] 1.0\n",
      "positions (x,y,z), reward: [-8.86393614  4.17195141  2.25070471] 1.0\n",
      "positions (x,y,z), reward: [-9.85786433  4.66545675  0.67993762] 1.0\n",
      "Episode =  944, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.01141661   0.10895743  10.02626347] 1.0\n",
      "positions (x,y,z), reward: [  0.05270966   0.09610842  10.06144163] 1.0\n",
      "positions (x,y,z), reward: [-1.38238152 -1.26722778  4.24433496] 1.0\n",
      "Episode =  945, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.19710221  0.12481553  9.89265735] 1.0\n",
      "positions (x,y,z), reward: [ 0.26640859  0.2255175   9.80633712] 1.0\n",
      "positions (x,y,z), reward: [ 0.34046495  0.29970749  9.72074712] 1.0\n",
      "positions (x,y,z), reward: [ 0.99529196  0.53191732  8.90549418] 1.0\n",
      "positions (x,y,z), reward: [ 1.05293347  0.52264853  5.35092598] 1.0\n",
      "positions (x,y,z), reward: [ 1.0192119   0.51820326  5.16212622] 1.0\n",
      "positions (x,y,z), reward: [ 0.73433132  0.49703174  3.32078309] 1.0\n",
      "Episode =  946, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.32296451  -0.08681226  10.0302839 ] 1.0\n",
      "positions (x,y,z), reward: [-5.34508798 -1.301546    9.02442699] 1.0\n",
      "positions (x,y,z), reward: [-10.26157122  -1.52346839   7.2367906 ] 1.0\n",
      "Episode =  947, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 6.16789828 -3.66862421  0.70530402] 1.0\n",
      "Episode =  948, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-4.42554565 -2.14661248  5.81360065] 1.0\n",
      "positions (x,y,z), reward: [-7.96410722 -3.53771836  0.29735837] 1.0\n",
      "Episode =  949, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.4777536  -2.11413499  3.05796351] 1.0\n",
      "Episode =  950, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.12543592  0.1093992   9.77201011] 1.0\n",
      "positions (x,y,z), reward: [-0.7218625  -1.01378461  8.08896813] 1.0\n",
      "Episode =  951, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.13890773 -1.24740707  7.54634127] 1.0\n",
      "positions (x,y,z), reward: [ 3.59144686 -2.02268087  5.46254696] 1.0\n",
      "Episode =  952, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-6.65216986  2.59522884  2.4050025 ] 1.0\n",
      "positions (x,y,z), reward: [-7.71045878  2.94107265  0.95498308] 1.0\n",
      "positions (x,y,z), reward: [-8.0909735   3.05636448  0.43901651] 1.0\n",
      "Episode =  953, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.90496156  0.10535451  9.68703992] 1.0\n",
      "positions (x,y,z), reward: [ 6.99715945 -0.54451611  5.29691654] 1.0\n",
      "positions (x,y,z), reward: [ 9.89467568 -0.97768749  2.44124593] 1.0\n",
      "positions (x,y,z), reward: [ 10.58137993  -1.09014432   1.6360681 ] 1.0\n",
      "Episode =  954, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -4.61770164e-03  -1.37572023e-03   1.00082794e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.28345761e-01   6.56111142e-03   9.67289104e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.71757969 -0.20212574  9.01744934] 1.0\n",
      "positions (x,y,z), reward: [-1.44255281 -0.67660197  6.69352949] 1.0\n",
      "positions (x,y,z), reward: [-2.59469117 -0.84631935  4.93589358] 1.0\n",
      "positions (x,y,z), reward: [-2.79998254 -0.89613359  4.56148335] 1.0\n",
      "Episode =  955, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.58399265 -0.35953927  7.08010807] 1.0\n",
      "positions (x,y,z), reward: [ 4.03647703 -0.29080514  6.36154708] 1.0\n",
      "positions (x,y,z), reward: [ 4.80502046 -0.2148665   4.87784351] 1.0\n",
      "positions (x,y,z), reward: [ 5.62952314 -0.23331321  2.64138715] 1.0\n",
      "Episode =  956, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.37213249  0.32098563  8.94488141] 1.0\n",
      "positions (x,y,z), reward: [ 3.97823303  1.67320067  5.27563817] 1.0\n",
      "Episode =  957, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.44709847 -0.85251529  8.33660291] 1.0\n",
      "positions (x,y,z), reward: [ 0.44895113 -1.24394837  7.5388826 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.3933785  -1.50678944  6.96363552] 1.0\n",
      "positions (x,y,z), reward: [ 0.1118207  -2.48875793  4.47861717] 1.0\n",
      "Episode =  958, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0524124  -0.02420777  9.91579539] 1.0\n",
      "positions (x,y,z), reward: [ 0.61995492 -0.06728899  9.37440896] 1.0\n",
      "positions (x,y,z), reward: [ 0.87157434 -0.24995392  9.17278597] 1.0\n",
      "positions (x,y,z), reward: [-1.69942256 -2.76056818  3.31088366] 1.0\n",
      "positions (x,y,z), reward: [-1.7552495  -2.81905864  3.10254843] 1.0\n",
      "positions (x,y,z), reward: [-2.53496689 -3.60980772  0.        ] 1.0\n",
      "Episode =  959, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.20279316 -0.28028546  9.40340992] 1.0\n",
      "positions (x,y,z), reward: [ 4.14260448 -0.68053697  6.28912011] 1.0\n",
      "positions (x,y,z), reward: [ 5.19967709 -0.75064404  5.39447056] 1.0\n",
      "positions (x,y,z), reward: [ 6.27109916 -0.82068521  4.40465367] 1.0\n",
      "Episode =  960, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.16896399  0.22723167  9.5239864 ] 1.0\n",
      "positions (x,y,z), reward: [-1.13735605  1.19997747  8.28806356] 1.0\n",
      "Episode =  961, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -3.26158989e-03  -1.02149311e-02   9.99934195e+00] 1.0\n",
      "positions (x,y,z), reward: [ 1.09168     1.29620192  8.15411799] 1.0\n",
      "positions (x,y,z), reward: [ 1.56912684  2.0409678   6.00020747] 1.0\n",
      "positions (x,y,z), reward: [ 2.91629089  3.17281142  0.51810159] 1.0\n",
      "Episode =  962, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0058383] 1.0\n",
      "positions (x,y,z), reward: [ 1.06624676 -0.26637689  9.58302839] 1.0\n",
      "positions (x,y,z), reward: [ 2.45208964 -1.27343208  8.35517244] 1.0\n",
      "positions (x,y,z), reward: [ 2.92338855 -1.3071681   7.69848604] 1.0\n",
      "Episode =  963, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.88376838 -0.37098964  9.03621447] 1.0\n",
      "positions (x,y,z), reward: [ 0.76958238 -0.96000053  8.41807808] 1.0\n",
      "Episode =  964, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0058091] 1.0\n",
      "positions (x,y,z), reward: [ 0.25914095 -0.13339935  9.593841  ] 1.0\n",
      "Episode =  965, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.06511611  -0.01293314  10.01022439] 1.0\n",
      "positions (x,y,z), reward: [ -5.57022079e-04  -2.83807876e-02   9.98983024e+00] 1.0\n",
      "positions (x,y,z), reward: [-2.90180017 -2.53861175  7.84406729] 1.0\n",
      "positions (x,y,z), reward: [-3.62650855 -2.71146998  7.11448698] 1.0\n",
      "positions (x,y,z), reward: [-4.24173675 -2.85610923  6.44651482] 1.0\n",
      "positions (x,y,z), reward: [-6.70601547 -3.40332066  3.22245764] 1.0\n",
      "Episode =  966, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.06611835 -0.0112028   9.97536398] 1.0\n",
      "positions (x,y,z), reward: [-0.07731095 -0.02487829  9.95255203] 1.0\n",
      "positions (x,y,z), reward: [ 1.13794647 -1.41493759  8.17106253] 1.0\n",
      "positions (x,y,z), reward: [ 2.96957924 -3.42475832  4.54833727] 1.0\n",
      "positions (x,y,z), reward: [ 3.21866196 -3.71648381  3.90829935] 1.0\n",
      "positions (x,y,z), reward: [ 3.62085733 -4.16957134  2.77574591] 1.0\n",
      "Episode =  967, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.05606701  -0.03148643  10.06199956] 1.0\n",
      "positions (x,y,z), reward: [ 0.46773288 -0.05397174  9.92935947] 1.0\n",
      "positions (x,y,z), reward: [-4.38141939 -0.2875623   6.72161062] 1.0\n",
      "positions (x,y,z), reward: [-5.10798258 -0.24344827  6.10061998] 1.0\n",
      "positions (x,y,z), reward: [-6.39962674 -0.19147647  4.87061639] 1.0\n",
      "Episode =  968, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0134448  -0.13169063  9.97305286] 1.0\n",
      "positions (x,y,z), reward: [ 1.00528139 -0.88562373  9.11876358] 1.0\n",
      "positions (x,y,z), reward: [ 1.54415135 -1.22418479  8.61772689] 1.0\n",
      "positions (x,y,z), reward: [ 6.72906404 -2.95206022  2.62317557] 1.0\n",
      "positions (x,y,z), reward: [ 7.3864742  -3.13739961  1.6729865 ] 1.0\n",
      "Episode =  969, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.18645821  -0.11096297  10.00313963] 1.0\n",
      "positions (x,y,z), reward: [  0.85446253  -0.62425346  10.05514963] 1.0\n",
      "positions (x,y,z), reward: [ 1.63642991 -1.18183118  9.8905329 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.45374733 -1.6627629   9.61966562] 1.0\n",
      "positions (x,y,z), reward: [ 8.40539699 -4.90736195  5.62267022] 1.0\n",
      "positions (x,y,z), reward: [ 9.22817828 -5.32716383  4.88771762] 1.0\n",
      "positions (x,y,z), reward: [ 11.52628448  -6.54469944   2.3867352 ] 1.0\n",
      "positions (x,y,z), reward: [ 13.66854166  -7.75800435   0.        ] 1.0\n",
      "Episode =  970, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.05445534 -0.01729832  9.81762229] 1.0\n",
      "positions (x,y,z), reward: [ 0.00918372 -1.19706681  8.3090903 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.28381618 -2.27052308  6.29508004] 1.0\n",
      "positions (x,y,z), reward: [ 1.09408196 -4.49755658  1.25206693] 1.0\n",
      "positions (x,y,z), reward: [ 1.19826056 -4.79187092  0.44735266] 1.0\n",
      "Episode =  971, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.08736894 -0.13956002  9.94011523] 1.0\n",
      "positions (x,y,z), reward: [ 0.29918858 -0.34092392  8.23786092] 1.0\n",
      "positions (x,y,z), reward: [ 1.41428492 -0.76341075  4.24257479] 1.0\n",
      "positions (x,y,z), reward: [ 1.51378623 -0.83465197  3.78486452] 1.0\n",
      "positions (x,y,z), reward: [ 1.96509076 -1.16660409  1.55957609] 1.0\n",
      "Episode =  972, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.61480923e-03   2.60416944e-04   1.00109855e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.05425859  0.1325845   9.55128354] 1.0\n",
      "positions (x,y,z), reward: [-0.29590652  0.65058979  8.73566367] 1.0\n",
      "positions (x,y,z), reward: [-2.07774658  2.91950543  5.63398143] 1.0\n",
      "positions (x,y,z), reward: [-3.3679163   4.38214086  3.06972949] 1.0\n",
      "positions (x,y,z), reward: [-4.41552475  5.52846632  0.65214195] 1.0\n",
      "Episode =  973, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.23890541e-02   6.73232235e-03   9.99429312e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.05662575 -0.15618893  9.68346131] 1.0\n",
      "positions (x,y,z), reward: [ 0.20998249 -0.24444497  9.46934564] 1.0\n",
      "positions (x,y,z), reward: [ 1.03544355 -0.85804342  8.56486996] 1.0\n",
      "positions (x,y,z), reward: [ 3.83673353 -3.66862977  2.11068251] 1.0\n",
      "positions (x,y,z), reward: [ 4.01212166 -3.87427549  1.54541997] 1.0\n",
      "positions (x,y,z), reward: [ 4.09918141 -3.97668727  1.25911468] 1.0\n",
      "positions (x,y,z), reward: [ 4.61987421 -4.59028318  0.        ] 1.0\n",
      "Episode =  974, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -2.77101610e-02  -5.33147963e-05   1.00539266e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.09342452 -0.58801702  9.43596296] 1.0\n",
      "Episode =  975, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.11352608   0.03420016  10.0089963 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.26376674  0.41449597  9.60545086] 1.0\n",
      "positions (x,y,z), reward: [ 0.83983394 -0.38519288  7.52587829] 1.0\n",
      "Episode =  976, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.02711789 -0.01183396  9.98667529] 1.0\n",
      "positions (x,y,z), reward: [ 0.34930093 -0.14048     9.51786271] 1.0\n",
      "positions (x,y,z), reward: [ 1.05196804 -0.53751901  9.09929028] 1.0\n",
      "positions (x,y,z), reward: [ 2.58646688 -3.16348723  5.50508992] 1.0\n",
      "positions (x,y,z), reward: [ 2.83769665 -4.67523647  2.76894372] 1.0\n",
      "Episode =  977, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04326358   0.0176633   10.03323203] 1.0\n",
      "positions (x,y,z), reward: [ -0.02787526   0.02031038  10.0144735 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.56250649 -0.03479145  9.62242827] 1.0\n",
      "positions (x,y,z), reward: [ 0.68089784 -0.04673999  9.48462535] 1.0\n",
      "Episode =  978, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  1.86879532e-01   7.50274453e-04   9.43076837e+00] 1.0\n",
      "positions (x,y,z), reward: [ 2.25040021 -1.17002334  4.96063266] 1.0\n",
      "Episode =  979, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.15529729e-03   3.31140600e-03   1.00204335e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.16725687 -2.59078205  8.19644423] 1.0\n",
      "Episode =  980, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -6.24982710e-03  -3.23017984e-03   1.00126480e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.06841824  -0.04181374  10.02051565] 1.0\n",
      "positions (x,y,z), reward: [  0.13566555  -0.01257344  10.03885292] 1.0\n",
      "positions (x,y,z), reward: [-3.09530162 -0.36889062  9.8884424 ] 1.0\n",
      "positions (x,y,z), reward: [-7.05235884 -0.52183621  8.52306204] 1.0\n",
      "positions (x,y,z), reward: [-8.87331708 -0.45084522  7.72284704] 1.0\n",
      "positions (x,y,z), reward: [-11.867176    -0.20998476   6.09536752] 1.0\n",
      "positions (x,y,z), reward: [-16.09038508   0.09237833   3.04425928] 1.0\n",
      "positions (x,y,z), reward: [-16.34703313   0.10758946   2.8294694 ] 1.0\n",
      "positions (x,y,z), reward: [-17.11089905   0.15088618   2.16131563] 1.0\n",
      "positions (x,y,z), reward: [-18.09201622   0.20390371   1.20727393] 1.0\n",
      "Episode =  981, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.07882404   0.0144304   10.03036965] 1.0\n",
      "positions (x,y,z), reward: [-5.27099102 -2.5198741   9.27812243] 1.0\n",
      "positions (x,y,z), reward: [-5.49024448 -2.54246489  9.22515897] 1.0\n",
      "positions (x,y,z), reward: [-9.47955187 -2.90366057  7.82972644] 1.0\n",
      "positions (x,y,z), reward: [-9.72183918 -2.92101119  7.71556094] 1.0\n",
      "positions (x,y,z), reward: [-9.96540122 -2.93782425  7.5966651 ] 1.0\n",
      "positions (x,y,z), reward: [-10.21032164  -2.95341355   7.47273401] 1.0\n",
      "positions (x,y,z), reward: [-15.23662915  -2.97655777   4.42907891] 1.0\n",
      "Episode =  982, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.52072829 -0.16201575  9.81261875] 1.0\n",
      "positions (x,y,z), reward: [-1.86246364 -1.76304655  6.53021358] 1.0\n",
      "positions (x,y,z), reward: [-3.14341208 -2.81476862  3.89448222] 1.0\n",
      "Episode =  983, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00577121] 1.0\n",
      "positions (x,y,z), reward: [ 2.77265657  1.38365526  6.93589424] 1.0\n",
      "positions (x,y,z), reward: [ 4.28201559  1.93455028  4.57658971] 1.0\n",
      "positions (x,y,z), reward: [ 6.19465456  2.71293006  0.3454857 ] 1.0\n",
      "Episode =  984, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00573523] 1.0\n",
      "positions (x,y,z), reward: [  2.15000955e-01  -1.64291399e-03   9.66304667e+00] 1.0\n",
      "positions (x,y,z), reward: [ 3.04715211 -1.60624313  3.18252843] 1.0\n",
      "Episode =  985, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.04962488  0.01572603  9.98899172] 1.0\n",
      "positions (x,y,z), reward: [  8.58514877e-03  -4.56658117e-02   9.79110097e+00] 1.0\n",
      "positions (x,y,z), reward: [ 0.08257418 -0.08033901  9.69565303] 1.0\n",
      "positions (x,y,z), reward: [ 0.61478256 -0.25202876  9.30071287] 1.0\n",
      "positions (x,y,z), reward: [ 0.76199943 -0.3516496   9.20476781] 1.0\n",
      "positions (x,y,z), reward: [ 1.16026306 -2.20338855  6.20052627] 1.0\n",
      "positions (x,y,z), reward: [ 0.96842785 -2.70981951  4.31789848] 1.0\n",
      "Episode =  986, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.07560469  0.05774135  9.97752633] 1.0\n",
      "positions (x,y,z), reward: [-3.76471372  1.74289908  3.42001005] 1.0\n",
      "positions (x,y,z), reward: [-4.27329498  1.89901856  1.99115391] 1.0\n",
      "Episode =  987, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.0606267   0.23839374  9.22199861] 1.0\n",
      "positions (x,y,z), reward: [ 0.52561765  0.37796733  8.3054227 ] 1.0\n",
      "Episode =  988, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 2.15552017  0.68677341  8.33392939] 1.0\n",
      "positions (x,y,z), reward: [ 3.90677297  1.20685472  7.22225858] 1.0\n",
      "positions (x,y,z), reward: [ 4.80595337  1.49901573  6.51946517] 1.0\n",
      "positions (x,y,z), reward: [ 8.33741537  2.3600316   3.34122775] 1.0\n",
      "Episode =  989, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.04189964   0.02397968  10.01150216] 1.0\n",
      "positions (x,y,z), reward: [ 1.39076307 -0.36084153  9.22556191] 1.0\n",
      "Episode =  991, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [-0.1474046  -1.49412939  7.8185744 ] 1.0\n",
      "positions (x,y,z), reward: [-1.76258493 -2.66920297  5.78966505] 1.0\n",
      "positions (x,y,z), reward: [-4.10545774 -3.73545582  2.25578457] 1.0\n",
      "Episode =  992, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.21991881  -0.0991043   10.0068347 ] 1.0\n",
      "positions (x,y,z), reward: [-0.29401031 -0.10284532  9.9297581 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.06144693 -0.04435435  9.57679352] 1.0\n",
      "positions (x,y,z), reward: [ 0.43744215  0.06574449  9.35062633] 1.0\n",
      "positions (x,y,z), reward: [ 0.73967128  0.10890891  8.78175584] 1.0\n",
      "positions (x,y,z), reward: [-0.52228172  1.50286834  7.61047733] 1.0\n",
      "positions (x,y,z), reward: [-1.07793609  1.88848814  7.19603938] 1.0\n",
      "positions (x,y,z), reward: [-2.81578956  2.82730936  5.60365167] 1.0\n",
      "Episode =  993, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -7.58777057e-03  -1.39311745e-03   1.00168298e+01] 1.0\n",
      "positions (x,y,z), reward: [ 0.94742371 -0.05383     9.74148271] 1.0\n",
      "positions (x,y,z), reward: [ 3.89068739 -0.43741693  7.83397539] 1.0\n",
      "Episode =  994, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 3.13157331  0.2715729   7.85173026] 1.0\n",
      "positions (x,y,z), reward: [ 7.93029172  1.20715788  3.70246677] 1.0\n",
      "Episode =  995, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.25650946  1.28789148  8.58291339] 1.0\n",
      "positions (x,y,z), reward: [-0.76764901  3.08712059  6.13918142] 1.0\n",
      "positions (x,y,z), reward: [-2.237477    4.24582313  3.86241579] 1.0\n",
      "positions (x,y,z), reward: [-3.0509674   4.85449158  2.57999978] 1.0\n",
      "positions (x,y,z), reward: [-3.18950203  4.9550642   2.35582311] 1.0\n",
      "Episode =  996, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 1.31240658 -0.48306391  9.58041833] 1.0\n",
      "positions (x,y,z), reward: [ 2.07389367 -0.88355358  8.9480687 ] 1.0\n",
      "positions (x,y,z), reward: [ 2.21671723 -0.94510308  8.831684  ] 1.0\n",
      "positions (x,y,z), reward: [ 4.01628394 -1.54622028  7.26483988] 1.0\n",
      "positions (x,y,z), reward: [ 4.44090017 -1.6488545   6.66134159] 1.0\n",
      "positions (x,y,z), reward: [ 5.8578264  -1.59796666  3.76730448] 1.0\n",
      "positions (x,y,z), reward: [ 7.21138272 -1.27726668  0.        ] 1.0\n",
      "Episode =  997, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -0.09978024  -0.07889921  10.07508107] 1.0\n",
      "positions (x,y,z), reward: [ -0.15159994  -0.09399375  10.07867847] 1.0\n",
      "positions (x,y,z), reward: [ -0.8859771   -0.32747527  10.31828791] 1.0\n",
      "positions (x,y,z), reward: [ -3.44561058  -0.37994782  10.43189721] 1.0\n",
      "positions (x,y,z), reward: [-14.46186059  -1.09894171   0.15257536] 1.0\n",
      "Episode =  998, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ 0.02155084  0.02252355  9.9646767 ] 1.0\n",
      "positions (x,y,z), reward: [ 0.0298595   0.02547163  9.93468844] 1.0\n",
      "positions (x,y,z), reward: [  2.71274044e-01   3.93102206e-03   8.01325089e+00] 1.0\n",
      "positions (x,y,z), reward: [-0.05065508  0.24598426  7.15273619] 1.0\n",
      "positions (x,y,z), reward: [-0.24302894  0.46683193  6.66612158] 1.0\n",
      "positions (x,y,z), reward: [-0.39096325  0.6459904   6.28606484] 1.0\n",
      "positions (x,y,z), reward: [-1.20758792  1.7980613   3.18037035] 1.0\n",
      "Episode =  999, score =   2.000 (best =   2.000), noise_scale = 3.2positions (x,y,z), reward: [ -5.37970892e-03   2.76085518e-03   1.00100840e+01] 1.0\n",
      "positions (x,y,z), reward: [-0.06234326  0.12181874  9.83888202] 1.0\n",
      "positions (x,y,z), reward: [ 0.16015811  0.22054801  9.57916932] 1.0\n",
      "positions (x,y,z), reward: [ 0.62194719  0.50382919  9.17424471] 1.0\n",
      "positions (x,y,z), reward: [ 0.15791677  1.50294549  8.49430604] 1.0\n",
      "positions (x,y,z), reward: [-0.09572262  1.84035978  8.15842313] 1.0\n",
      "positions (x,y,z), reward: [-1.66902431  2.87960861  6.15992574] 1.0\n",
      "positions (x,y,z), reward: [-2.18394309  3.08739116  5.24562977] 1.0\n",
      "positions (x,y,z), reward: [-4.64185455  3.86389493  0.        ] 1.0\n",
      "Episode = 1000, score =   2.000 (best =   2.000), noise_scale = 3.2"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from agents.policy_search import PolicySearch_Agent\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 1000\n",
    "target_pos = np.array([0., 0., 20.])\n",
    "task = Task(target_pos=target_pos)\n",
    "agent = PolicySearch_Agent(task) \n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state) \n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent should perform very poorly on this task.  And that's where you come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the Task, Design the Agent, and Train Your Agent!\n",
    "\n",
    "Amend `task.py` to specify a task of your choosing.  If you're unsure what kind of task to specify, you may like to teach your quadcopter to takeoff, hover in place, land softly, or reach a target pose.  \n",
    "\n",
    "After specifying your task, use the sample agent in `agents/policy_search.py` as a template to define your own agent in `agents/agent.py`.  You can borrow whatever you need from the sample agent, including ideas on how you might modularize your code (using helper methods like `act()`, `learn()`, `reset_episode()`, etc.).\n",
    "\n",
    "Note that it is **highly unlikely** that the first agent and task that you specify will learn well.  You will likely have to tweak various hyperparameters and the reward function for your task until you arrive at reasonably good behavior.\n",
    "\n",
    "As you develop your agent, it's important to keep an eye on how it's performing. Use the code above as inspiration to build in a mechanism to log/save the total rewards obtained in each episode to file.  If the episode rewards are gradually increasing, this is an indication that your agent is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [  3.13660840e-01   3.23532006e-03   1.93891320e+01] 4.70708171343e-30\n",
      "positions (x,y,z), reward: [ 2.57934497  2.39106774  5.53918322] 6.09865330771e-36\n",
      "positions (x,y,z), reward: [ 2.92155209  2.90565208  3.89253486] 3.90507652522e-37\n",
      "Episode =    1, score =   0.000 (best =    -inf), noise_scale = 0.1positions (x,y,z), reward: [ 3.55598567  4.19631852  0.37945004] 7.67240987309e-36\n",
      "Episode =    2, score =   0.002 (best =   0.002), noise_scale = 0.1positions (x,y,z), reward: [  0.16230442   1.87594614  19.85740475] 1.7474178354e-31\n",
      "positions (x,y,z), reward: [  0.33485969   2.41182443  19.29728186] 1.59967504287e-32\n",
      "positions (x,y,z), reward: [  0.74089095   3.20465085  18.26949639] 1.31341893838e-33\n",
      "positions (x,y,z), reward: [  3.08235847   5.53286242  13.18437931] 5.75104959425e-36\n",
      "positions (x,y,z), reward: [  4.28405909   6.33816468  10.69225314] 1.53789359511e-36\n",
      "positions (x,y,z), reward: [ 6.61622418  7.56494576  5.90548853] 1.19319127552e-37\n",
      "positions (x,y,z), reward: [ 9.04802611  8.66449383  1.12908047] 3.28353207217e-38\n",
      "positions (x,y,z), reward: [ 9.42380266  8.78932259  0.41244361] 1.00011308559e-38\n",
      "Episode =    3, score =   0.037 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [  2.41858040e-05   7.20512690e-02   2.01375562e+01] 0.000303652366136\n",
      "positions (x,y,z), reward: [  0.09062881   2.07459775  19.55388231] 2.57436619859e-32\n",
      "positions (x,y,z), reward: [  0.2628858    2.94083909  18.62346673] 6.55074616435e-33\n",
      "positions (x,y,z), reward: [  0.50441112   3.63368353  17.54511763] 2.57859483631e-33\n",
      "positions (x,y,z), reward: [  1.50839366   5.06833429  14.35057206] 1.07230224663e-35\n",
      "positions (x,y,z), reward: [ 6.60960583  8.33061284  3.16371646] 1.01092474813e-35\n",
      "positions (x,y,z), reward: [ 7.53587119  8.40330595  1.28035862] 1.24934699468e-33\n",
      "Episode =    4, score =   0.038 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -4.79166136e-03   1.68300091e+00   1.97872623e+01] 1.41757786754e-31\n",
      "positions (x,y,z), reward: [ -5.51955551e-03   2.40653187e+00   1.91507192e+01] 5.65850246224e-33\n",
      "positions (x,y,z), reward: [ -6.76624714e-03   2.72531096e+00   1.88711636e+01] 2.05534490391e-32\n",
      "positions (x,y,z), reward: [ -8.48366204e-03   2.89828011e+00   1.87068459e+01] 1.47817207821e-32\n",
      "positions (x,y,z), reward: [ -0.02867171   3.55784215  17.65204598] 1.82285624537e-33\n",
      "positions (x,y,z), reward: [ -0.30197558   5.21183195  14.07814106] 1.21156781255e-35\n",
      "positions (x,y,z), reward: [-1.99747164  7.21947078  6.77797991] 4.61258537387e-44\n",
      "positions (x,y,z), reward: [-3.79402635  7.32161573  1.89204146] 2.50144939221e-49\n",
      "Episode =    5, score =   0.038 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -0.18205723   0.03399301  20.1462815 ] 2.11083207512e-18\n",
      "positions (x,y,z), reward: [ -2.73784415  -0.3368249   21.39136793] 2.21824010666e-20\n",
      "positions (x,y,z), reward: [ -3.29033023  -0.40554264  21.85991036] 2.26999362208e-20\n",
      "positions (x,y,z), reward: [ -4.70357645  -0.56026134  23.54980108] 7.8387762658e-20\n",
      "positions (x,y,z), reward: [ -6.17486302  -0.69573028  25.75664428] 2.44020854676e-19\n",
      "positions (x,y,z), reward: [ -6.98680355  -0.7799736   27.22052207] 3.01711728533e-19\n",
      "positions (x,y,z), reward: [ -8.29633249  -0.91353574  30.06141182] 1.00327722122e-18\n",
      "positions (x,y,z), reward: [-10.16872284  -1.03977891  34.93188062] 2.9698985285e-18\n",
      "positions (x,y,z), reward: [-11.67866161  -1.00268277  39.36662068] 0.999964872816\n",
      "positions (x,y,z), reward: [-11.71922719  -0.99942193  39.52932952] 0.999964076773\n",
      "Episode =    6, score =   0.452 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -7.80381967e-01  -1.49017033e-02   2.02528378e+01] 5.59826613114e-21\n",
      "positions (x,y,z), reward: [ -1.37247915  -0.05284278  20.46134232] 4.98829328929e-21\n",
      "positions (x,y,z), reward: [ -5.38127256   0.29921985  24.42848151] 1.04569775029e-19\n",
      "positions (x,y,z), reward: [ -9.39776049   1.85444672  32.63283868] 1.58890449483e-18\n",
      "positions (x,y,z), reward: [ -9.93977299   2.16543507  34.05730353] 1.84156691661e-18\n",
      "positions (x,y,z), reward: [-10.10245177   2.29919288  34.64495176] 2.5871032697e-18\n",
      "positions (x,y,z), reward: [-10.22422687   2.36376428  34.93703594] 2.37242989763e-18\n",
      "positions (x,y,z), reward: [-10.29198718   2.40075872  35.08554617] 2.95549321248e-18\n",
      "positions (x,y,z), reward: [-10.98370767   2.85198397  37.08328879] 0.999952193863\n",
      "positions (x,y,z), reward: [-11.07311539   2.9194419   37.39373356] 0.999938244199\n",
      "positions (x,y,z), reward: [-11.14372275   2.99863839  37.70917841] 0.999958944216\n",
      "positions (x,y,z), reward: [-12.85172229   4.46919478  43.58935789] 0.99998069943\n",
      "Episode =    7, score =   0.437 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -0.14705519   0.05881792  20.13433625] 1.80437017355e-17\n",
      "positions (x,y,z), reward: [ -6.28399684   0.55820312  26.06802033] 2.95307224599e-19\n",
      "positions (x,y,z), reward: [ -6.53247476   0.65007947  26.57929735] 3.49217031788e-19\n",
      "positions (x,y,z), reward: [ -7.02536102   0.80756046  27.44409719] 3.47613395335e-19\n",
      "positions (x,y,z), reward: [ -8.80083416   1.60687681  31.34633115] 1.22768133435e-18\n",
      "positions (x,y,z), reward: [ -8.84978552   1.63172931  31.47723644] 1.04816720218e-18\n",
      "positions (x,y,z), reward: [ -9.0159317    1.75027588  32.01699997] 1.56906632507e-18\n",
      "positions (x,y,z), reward: [-11.00988255   2.95341457  37.4693291 ] 0.99996372385\n",
      "positions (x,y,z), reward: [-12.17404933   3.81464172  41.24865587] 0.999977196547\n",
      "positions (x,y,z), reward: [-12.59410493   4.16939615  42.79178088] 0.999981856492\n",
      "Episode =    8, score =   0.468 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -0.1089139    0.04788621  20.11756198] 2.13388778328e-16\n",
      "positions (x,y,z), reward: [ -1.20782017  -0.05605019  20.40036325] 6.56946776729e-21\n",
      "positions (x,y,z), reward: [ -2.4114852   -0.0883652   21.07872616] 1.59544747943e-20\n",
      "positions (x,y,z), reward: [ -3.98944442   0.03867561  22.6046008 ] 5.4668797112e-20\n",
      "positions (x,y,z), reward: [ -4.31933247   0.08550206  22.94679354] 6.83106563882e-20\n",
      "positions (x,y,z), reward: [ -5.36540901   0.31731815  24.44590493] 9.99331374678e-20\n",
      "positions (x,y,z), reward: [ -5.6428098    0.38464831  24.80159774] 1.51541920989e-19\n",
      "positions (x,y,z), reward: [ -6.44474068   0.65940994  26.23450777] 3.16998559062e-19\n",
      "positions (x,y,z), reward: [ -6.93375776   0.8227136   27.07576219] 3.01889951561e-19\n",
      "positions (x,y,z), reward: [ -7.36600396   1.0135443   27.95726685] 5.72077729974e-19\n",
      "positions (x,y,z), reward: [-10.25444801   2.62096281  35.08650932] 3.01444336837e-18\n",
      "positions (x,y,z), reward: [-11.98421948   3.9198362   40.48487614] 0.999978732277\n",
      "positions (x,y,z), reward: [-12.08416323   3.99531837  40.82231064] 0.999969331665\n",
      "Episode =    9, score =   0.437 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -0.05830571   0.0391252   20.07351476] 2.37547859113e-11\n",
      "positions (x,y,z), reward: [ -0.73627981  -0.06709871  20.24806458] 4.73873705277e-21\n",
      "positions (x,y,z), reward: [ -0.92479039  -0.10583272  20.32381214] 4.33457897195e-21\n",
      "positions (x,y,z), reward: [ -2.00500943  -0.30484429  20.81921946] 8.44117834345e-21\n",
      "positions (x,y,z), reward: [ -2.90547512  -0.50951433  21.51325305] 1.59345840769e-20\n",
      "positions (x,y,z), reward: [ -4.25551162  -0.85677108  22.90774915] 5.51587713951e-20\n",
      "positions (x,y,z), reward: [ -6.63771438  -1.8213121   26.61767176] 2.3700258661e-19\n",
      "positions (x,y,z), reward: [ -7.62727086  -2.36060425  28.51276371] 4.98868520661e-19\n",
      "positions (x,y,z), reward: [-11.23109169  -5.53009384  37.87960603] 0.999964472848\n",
      "positions (x,y,z), reward: [-12.14258771  -6.60716615  40.67810659] 0.999978559325\n",
      "positions (x,y,z), reward: [-12.63858002  -7.29014362  42.38859835] 0.999982711009\n",
      "positions (x,y,z), reward: [-13.19091448  -8.08235304  44.32907142] 1.0\n",
      "positions (x,y,z), reward: [-13.25303025  -8.15659948  44.51210063] 1.0\n",
      "Episode =   10, score =   0.452 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00290762] 0.000196733121956\n",
      "positions (x,y,z), reward: [ -0.0265576    0.02048598  20.02962324] 0.00010922597585\n",
      "positions (x,y,z), reward: [ -0.06710389   0.04542124  20.08831226] 2.74278546403e-13\n",
      "positions (x,y,z), reward: [ -0.10905225   0.05176281  20.11644865] 2.11367085262e-16\n",
      "positions (x,y,z), reward: [ -3.55698806e-01   9.25584266e-03   2.01684856e+01] 1.63969745758e-24\n",
      "positions (x,y,z), reward: [ -3.688801    -0.29958431  22.2406463 ] 4.42918554216e-20\n",
      "positions (x,y,z), reward: [ -5.02305007  -0.38927183  23.90037932] 1.10083770472e-19\n",
      "positions (x,y,z), reward: [ -5.7073479   -0.43633409  24.94026653] 1.3847887716e-19\n",
      "positions (x,y,z), reward: [ -6.50454517  -0.48008225  26.40370006] 3.29926580099e-19\n",
      "positions (x,y,z), reward: [ -7.99361152  -0.52910415  29.35032148] 8.58276531112e-19\n",
      "positions (x,y,z), reward: [ -9.84790791  -0.4533871   33.93875003] 2.65153609839e-18\n",
      "positions (x,y,z), reward: [ -1.19054803e+01  -1.23213385e-02   3.78536454e+01] 0.999999999999\n",
      "positions (x,y,z), reward: [-12.26815677   0.10750321  38.0595033 ] 0.999999999998\n",
      "positions (x,y,z), reward: [-13.3289368    0.39390461  37.75702614] 0.1549728168\n",
      "Episode =   11, score =   0.311 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -5.35736175e-02  -9.27852813e-10   1.99477553e+01] 9.54473120082e-29\n",
      "positions (x,y,z), reward: [ -6.96546558e-02   5.99345263e-10   1.99216357e+01] 1.83138810515e-29\n",
      "positions (x,y,z), reward: [ -5.28554931e-01  -5.42075899e-08   1.89914505e+01] 1.41725074513e-32\n",
      "positions (x,y,z), reward: [ -1.36357925e+00  -2.32073659e-07   1.48112821e+01] 3.75007308243e-35\n",
      "positions (x,y,z), reward: [ -1.38845813e+00  -4.65870624e-08   1.46024910e+01] 2.70297077504e-35\n",
      "positions (x,y,z), reward: [ -1.96304381e+00   4.99933836e-07   9.96266512e+00] 9.60072233165e-37\n",
      "positions (x,y,z), reward: [ -1.98620749e+00   4.56969882e-07   9.68039121e+00] 7.50286466459e-37\n",
      "Episode =   12, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -5.86948459e-03  -6.13991211e-11   2.00021882e+01] 3.76016924596e-06\n",
      "positions (x,y,z), reward: [ -3.67790621e-01  -7.41228767e-08   1.94861078e+01] 8.10339189723e-32\n",
      "positions (x,y,z), reward: [ -9.77886678e-01  -2.16551091e-07   1.72992975e+01] 1.14121576324e-33\n",
      "positions (x,y,z), reward: [ -1.36328133e+00  -2.16656399e-07   1.48770635e+01] 4.21626774773e-35\n",
      "positions (x,y,z), reward: [ -2.26177035e+00   1.98725219e-07   7.04697813e+00] 1.48202679355e-37\n",
      "Episode =   13, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -1.33298134e-02  -3.78384512e-11   2.00027059e+01] 3.60041063786e-07\n",
      "positions (x,y,z), reward: [ -2.94793090e-02  -1.77289421e-10   1.99887345e+01] 5.67479457634e-26\n",
      "positions (x,y,z), reward: [ -1.49522409e+00  -5.86380238e-07   1.39672657e+01] 2.09966863317e-35\n",
      "positions (x,y,z), reward: [ -1.62494613e+00  -2.97185084e-07   1.30761652e+01] 1.27720380513e-35\n",
      "positions (x,y,z), reward: [ -1.74921030e+00  -6.86581515e-07   1.18524409e+01] 2.90548817066e-36\n",
      "positions (x,y,z), reward: [ -2.37454641e+00  -1.79129079e-06   5.64864896e+00] 4.97262108265e-38\n",
      "positions (x,y,z), reward: [ -2.70790345e+00  -2.95323444e-06   1.69549675e+00] 5.8643953653e-39\n",
      "Episode =   14, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -4.99377980e-01   4.68334102e-08   1.90715313e+01] 1.33321455668e-32\n",
      "positions (x,y,z), reward: [ -5.35455440e-01   6.96868031e-08   1.89814825e+01] 1.32548405066e-32\n",
      "positions (x,y,z), reward: [ -1.05673020e+00  -1.19218027e-07   1.67784845e+01] 3.34074580213e-34\n",
      "positions (x,y,z), reward: [ -1.60781786e+00   2.47558659e-07   1.32549325e+01] 1.53886351206e-35\n",
      "positions (x,y,z), reward: [ -2.08816112e+00   1.10724675e-06   8.75774894e+00] 3.10483325424e-37\n",
      "positions (x,y,z), reward: [ -2.28946894e+00   1.92117547e-06   6.89140081e+00] 1.35295005811e-37\n",
      "Episode =   15, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -2.01459888e+00  -1.60965344e-07   9.64977722e+00] 7.16084601914e-37\n",
      "Episode =   16, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -1.21526417e+00   6.85888109e-08   1.59144337e+01] 1.6401917751e-34\n",
      "positions (x,y,z), reward: [ -1.25055348e+00  -1.80974292e-08   1.57367591e+01] 1.56130183276e-34\n",
      "positions (x,y,z), reward: [ -1.57400227e+00   1.40905303e-07   1.34827331e+01] 1.6225780695e-35\n",
      "positions (x,y,z), reward: [ -1.63328736e+00  -7.37108090e-08   1.30311903e+01] 1.1406949545e-35\n",
      "positions (x,y,z), reward: [ -1.65712906e+00  -1.43651827e-07   1.27981169e+01] 8.2738861609e-36\n",
      "positions (x,y,z), reward: [ -2.45150766e+00   1.38649369e-06   4.89209058e+00] 2.9837057096e-38\n",
      "positions (x,y,z), reward: [ -2.52286788e+00   1.64275037e-06   4.18522682e+00] 1.9039654829e-38\n",
      "positions (x,y,z), reward: [ -2.67030891e+00   1.94722529e-06   2.37095044e+00] 1.04499815826e-38\n",
      "Episode =   17, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -3.05963388e-02  -2.18049329e-09   1.99885469e+01] 5.55136900206e-26\n",
      "positions (x,y,z), reward: [ -4.70510195e-01  -5.99765630e-09   1.91494401e+01] 1.41747676359e-32\n",
      "positions (x,y,z), reward: [ -9.36223661e-01   1.15261832e-08   1.74857051e+01] 1.36033188058e-33\n",
      "positions (x,y,z), reward: [ -1.44451858e+00   1.99180938e-08   1.43260243e+01] 2.086267384e-35\n",
      "positions (x,y,z), reward: [ -2.10360702e+00  -3.42912077e-08   8.70780854e+00] 2.96895678249e-37\n",
      "positions (x,y,z), reward: [ -2.24569240e+00  -2.89917426e-08   7.47030497e+00] 1.69599486843e-37\n",
      "Episode =   18, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00046964] 8.57423362436e-05\n",
      "positions (x,y,z), reward: [ -2.47960053e-01  -1.01316112e-08   1.96738333e+01] 2.68995760744e-31\n",
      "positions (x,y,z), reward: [ -3.41748481e-01  -1.33393153e-07   1.95348385e+01] 1.14332029118e-31\n",
      "positions (x,y,z), reward: [ -1.23056940e+00  -1.47347777e-07   1.57910442e+01] 1.64208191772e-34\n",
      "positions (x,y,z), reward: [ -1.60640120e+00  -2.78559069e-07   1.31029149e+01] 1.20987895642e-35\n",
      "positions (x,y,z), reward: [ -2.24940607e+00   7.67059759e-07   6.99808252e+00] 1.38671754556e-37\n",
      "positions (x,y,z), reward: [ -2.77722021e+00   2.53528048e-06   5.72682771e-01] 2.63745089946e-39\n",
      "positions (x,y,z), reward: [ -2.81267432e+00   2.99699912e-06   1.72621073e-01] 2.08906175319e-39\n",
      "Episode =   19, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -2.59549479e+00   1.26115981e-06   3.78689710e+00] 1.79037260291e-38\n",
      "positions (x,y,z), reward: [ -2.65742864e+00   1.25479044e-06   3.06423287e+00] 1.39826643881e-38\n",
      "Episode =   20, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -5.81829135e-03  -5.13713068e-12   2.00022233e+01] 3.77228738535e-06\n",
      "positions (x,y,z), reward: [ -3.17519335e-01   2.75838738e-08   1.95867142e+01] 1.75556827234e-31\n",
      "positions (x,y,z), reward: [ -2.19495203e+00   1.17492594e-07   1.52298629e+01] 1.47838820622e-24\n",
      "positions (x,y,z), reward: [ -5.31747165e+00  -2.84666902e-03   1.25648685e+01] 4.97927240074e-23\n",
      "positions (x,y,z), reward: [ -6.04479343e+00  -5.77460812e-03   1.18867507e+01] 4.45233795584e-23\n",
      "positions (x,y,z), reward: [-6.67989138  0.09129786  0.        ] 5.57969334505e-41\n",
      "Episode =   21, score =   0.000 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [  6.56836030e-03   1.09944405e+00   2.01930636e+01] 4.30081339891e-22\n",
      "positions (x,y,z), reward: [  0.05465054   2.09586801  19.65348556] 2.91863161894e-32\n",
      "positions (x,y,z), reward: [  0.39605174   3.89665956  17.34955513] 8.17170656862e-34\n",
      "positions (x,y,z), reward: [  0.47724577   4.09751218  16.84453712] 1.01037074072e-34\n",
      "positions (x,y,z), reward: [  0.95914758   5.32292429  14.15685902] 2.93742399381e-35\n",
      "positions (x,y,z), reward: [  1.52475076   6.44691763  10.97311837] 4.68194563328e-31\n",
      "positions (x,y,z), reward: [ 2.50237668  7.45955296  3.10968159] 2.51208411235e-30\n",
      "Episode =   22, score =   0.040 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -6.09660059e-06   5.97447379e-02   2.01064656e+01] 0.00986070358895\n",
      "positions (x,y,z), reward: [ -5.18437300e-03   1.00264919e+00   2.01192764e+01] 5.65251889768e-17\n",
      "positions (x,y,z), reward: [ -1.90180986e-02   1.88648608e+00   1.99630599e+01] 3.29427434267e-22\n",
      "positions (x,y,z), reward: [ -0.77078698   8.70890451  19.61928977] 1.36197783403e-22\n",
      "positions (x,y,z), reward: [ -1.92614333   9.18153856  14.62734825] 3.47910536415e-27\n",
      "positions (x,y,z), reward: [ -4.72195749  12.98404682   4.90205529] 7.96691811349e-28\n",
      "positions (x,y,z), reward: [ -7.19787431  16.299872     0.50240789] 1.32213189783e-26\n",
      "Episode =   23, score =   0.146 (best =   1.686), noise_scale = 0.1positions (x,y,z), reward: [ -1.73715762e-05   7.91097993e-02   2.01623491e+01] 3.20525504042e-05\n",
      "positions (x,y,z), reward: [ -2.08933462e-04   1.94665700e-01   2.02449923e+01] 9.21241475844e-16\n",
      "positions (x,y,z), reward: [ -2.15974149e-03   8.17676392e-01   2.01935468e+01] 4.39985476048e-09\n",
      "positions (x,y,z), reward: [ -1.01543570e-02   1.31321973e+00   2.02852377e+01] 1.36423674851e-07\n",
      "positions (x,y,z), reward: [ -0.74466217   1.14850773  16.05478548] 2.36220403768e-34\n",
      "positions (x,y,z), reward: [-2.53633996  0.99471597  8.55355318] 2.54912023854e-37\n",
      "positions (x,y,z), reward: [-2.6165798   1.01315357  8.25085474] 3.52446953735e-37\n",
      "Episode =   24, score =   0.036 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [  2.47213249e-04   1.64700200e-01   2.02319726e+01] 4.69598986604e-08\n",
      "positions (x,y,z), reward: [  1.70959524e-03   7.50990823e-01   2.01308683e+01] 2.56265225447e-17\n",
      "positions (x,y,z), reward: [  0.10130923   1.81024568  18.2599071 ] 1.64242136517e-22\n",
      "positions (x,y,z), reward: [  0.2031752   0.7871821  16.9798343] 1.41124467347e-24\n",
      "positions (x,y,z), reward: [  0.23727896   0.55010194  16.53874263] 4.6197023834e-25\n",
      "positions (x,y,z), reward: [  0.29613134   0.2317956   15.79468195] 9.9503445936e-26\n",
      "positions (x,y,z), reward: [  0.47504458  -0.25735218  13.7417225 ] 6.49463391589e-27\n",
      "positions (x,y,z), reward: [ 1.19711835  0.397122    8.1000155 ] 7.18442351604e-27\n",
      "Episode =   25, score =   0.032 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [  9.61133097e-07   2.00634631e-03   1.99391391e+01] 4.89440577095e-24\n",
      "positions (x,y,z), reward: [  1.55938932e-04  -1.21629575e-02   1.98186866e+01] 1.4077048341e-28\n",
      "positions (x,y,z), reward: [  1.36233948e-03  -3.88278714e-01   1.90963450e+01] 5.06197275446e-32\n",
      "positions (x,y,z), reward: [  2.04475537e-03  -4.12048984e-01   1.88516474e+01] 5.26981359331e-32\n",
      "positions (x,y,z), reward: [  0.15543268  -1.61932375  12.34692604] 1.1643045931e-35\n",
      "Episode =   26, score =   0.001 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [ -1.32906858e-04   1.01538629e-01   2.01884156e+01] 4.52342464496e-06\n",
      "positions (x,y,z), reward: [ -2.24709077e-04   1.27148858e-01   2.02162726e+01] 4.54961096382e-07\n",
      "positions (x,y,z), reward: [ -1.07883891e-02   1.21475731e+00   2.01259016e+01] 6.2436810955e-11\n",
      "positions (x,y,z), reward: [ -0.09174905   2.83225508  18.44323393] 5.85894957509e-25\n",
      "positions (x,y,z), reward: [ -0.71261346   7.8357325   12.46981591] 3.52121112543e-24\n",
      "positions (x,y,z), reward: [ -1.85662633  11.43366894   9.29070147] 7.61446179636e-24\n",
      "Episode =   27, score =   0.038 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [ -1.16715076e-03   1.11993287e-01   1.95323294e+01] 4.69347219793e-26\n",
      "positions (x,y,z), reward: [ -1.51106018e-03   1.78020464e-01   1.94515422e+01] 9.54026583311e-26\n",
      "positions (x,y,z), reward: [ -0.02002259   1.86239584  16.99191646] 1.10963902142e-25\n",
      "positions (x,y,z), reward: [ -0.02260191   2.02424165  16.76284415] 1.03880065639e-25\n",
      "positions (x,y,z), reward: [ -0.02856618   2.37237565  16.29434994] 1.03719584462e-25\n",
      "positions (x,y,z), reward: [ -0.11902095   5.48892445  13.26451557] 3.45978905533e-24\n",
      "positions (x,y,z), reward: [ -1.20050239  10.52087778   4.68438372] 6.81578578319e-28\n",
      "Episode =   28, score =   0.001 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [ -8.97409444e-04   3.29109218e-01   1.96611593e+01] 1.50922619475e-29\n",
      "positions (x,y,z), reward: [ -1.80412011e-03   6.16887579e-01   1.95905875e+01] 2.20382548234e-29\n",
      "positions (x,y,z), reward: [ -1.57226589e-02   3.07695273e+00   1.98209503e+01] 4.07414339465e-08\n",
      "positions (x,y,z), reward: [ -1.62317577e-02   3.21782947e+00   1.98771451e+01] 5.97895262089e-08\n",
      "positions (x,y,z), reward: [ -1.67764776e-02   4.06153020e+00   2.03862150e+01] 0.993311261409\n",
      "positions (x,y,z), reward: [ -0.02919556   3.55126285  18.62957151] 2.94005059384e-25\n",
      "positions (x,y,z), reward: [ -0.06393714   3.51038772  17.29556823] 3.43624047328e-26\n",
      "positions (x,y,z), reward: [ -0.34958185   4.93822554  11.78731569] 3.79990408747e-27\n",
      "positions (x,y,z), reward: [-1.13415017  9.05714017  6.1477691 ] 2.62426147894e-25\n",
      "positions (x,y,z), reward: [-1.24988716  9.56521898  5.65894583] 4.45593565093e-25\n",
      "positions (x,y,z), reward: [ -2.06942411  12.61641482   3.13168143] 6.83313443776e-24\n",
      "positions (x,y,z), reward: [ -2.14676084  12.86333176   2.94855585] 8.2244722852e-24\n",
      "positions (x,y,z), reward: [ -4.03680021  17.34488222   0.        ] 1.07343081292e-22\n",
      "Episode =   29, score =   0.222 (best =   1.687), noise_scale = 0.1positions (x,y,z), reward: [  1.64875754e-07   3.39908317e-02   2.00751519e+01] 0.117640846333\n",
      "positions (x,y,z), reward: [  0.02464174  -2.74845523  19.4092493 ] 3.12094694494e-32\n",
      "positions (x,y,z), reward: [  0.07243685  -3.72098422  18.61992983] 4.39510210769e-33\n",
      "positions (x,y,z), reward: [  0.18605739  -4.86649172  17.60167918] 2.27998381367e-34\n",
      "positions (x,y,z), reward: [  4.05575395 -11.18932034   6.2550253 ] 3.41846407493e-37\n",
      "Episode =   30, score =   0.044 (best =   1.691), noise_scale = 0.1positions (x,y,z), reward: [  1.13187139e-03   8.56819193e-01   2.02766622e+01] 9.20338848964e-14\n",
      "positions (x,y,z), reward: [  0.02145241   0.67386066  19.59314438] 8.07051997949e-23\n",
      "positions (x,y,z), reward: [  6.57703592e-02  -1.19234222e-02   1.81488334e+01] 3.3632240934e-27\n",
      "positions (x,y,z), reward: [  0.12908742  -0.5077061   16.57428326] 1.94734160185e-34\n",
      "positions (x,y,z), reward: [  0.16588616  -0.60392177  15.74855016] 4.30688228842e-36\n",
      "positions (x,y,z), reward: [ 0.66562884 -0.89160232  8.30568083] 1.92434338032e-38\n",
      "Episode =   31, score =   0.046 (best =   1.691), noise_scale = 0.1positions (x,y,z), reward: [ -3.50297925e-04   3.60047033e-01   2.01978291e+01] 1.6666288594e-21\n",
      "positions (x,y,z), reward: [  0.02288471   1.91448842  18.40997096] 3.10553562378e-23\n",
      "positions (x,y,z), reward: [ 0.85533006 -1.43154741  9.325545  ] 1.85834027461e-39\n",
      "positions (x,y,z), reward: [ 1.407101   -2.14491176  6.00008952] 4.3062544155e-40\n",
      "Episode =   32, score =   0.045 (best =   1.691), noise_scale = 0.1positions (x,y,z), reward: [ -0.12825164  -3.26890336  18.36761094] 2.24017075294e-32\n",
      "positions (x,y,z), reward: [ -0.21247457  -3.95975575  17.67164009] 6.37077356855e-34\n",
      "positions (x,y,z), reward: [ -0.32303716  -4.49128032  16.86616105] 1.70225638945e-33\n",
      "positions (x,y,z), reward: [ -0.70385594  -5.96820971  14.38766344] 2.01134213074e-35\n",
      "positions (x,y,z), reward: [ -1.25960552  -7.27760579  11.36157343] 1.35665177336e-36\n",
      "positions (x,y,z), reward: [-1.77461072 -8.16975815  8.95277802] 2.83995781597e-37\n",
      "Episode =   33, score =   0.029 (best =   1.710), noise_scale = 0.1positions (x,y,z), reward: [ -1.50808212e-02   1.97179326e+00   2.01781139e+01] 1.04692266881e-08\n",
      "positions (x,y,z), reward: [ -1.66187187e-02   2.12760213e+00   2.01719856e+01] 5.99679504433e-13\n",
      "positions (x,y,z), reward: [ -4.83914557e-03   8.42929498e+00   2.08036273e+01] 0.95927665661\n",
      "positions (x,y,z), reward: [  0.02150738   8.90727382  20.89304594] 5.04958395244e-07\n",
      "positions (x,y,z), reward: [  0.06719519   9.22005625  20.70617829] 1.04884286143e-12\n",
      "positions (x,y,z), reward: [  0.24498982   9.42025226  18.59077717] 4.87680226623e-25\n",
      "positions (x,y,z), reward: [  0.55259213  10.04623002  14.02490901] 9.29956108176e-28\n",
      "positions (x,y,z), reward: [  0.66138797  10.42939551  12.53858046] 3.58925299992e-28\n",
      "positions (x,y,z), reward: [  1.55393252  14.21932906   4.78472951] 7.96096685228e-28\n",
      "positions (x,y,z), reward: [  1.76499788  15.02789968   3.70939279] 1.66455515602e-27\n",
      "positions (x,y,z), reward: [  2.67743306  17.98029665   0.47554579] 2.80642790818e-26\n",
      "Episode =   34, score =   0.331 (best =   1.710), noise_scale = 0.1positions (x,y,z), reward: [  4.72365934e-03  -1.05955598e+00   1.93753425e+01] 1.98600599016e-31\n",
      "positions (x,y,z), reward: [  6.78003872e-03  -1.30283867e+00   1.92239303e+01] 3.03680925448e-32\n",
      "positions (x,y,z), reward: [  0.40262779  -4.05741265  12.71031853] 1.89911993943e-35\n",
      "positions (x,y,z), reward: [  0.58695603  -4.50294436  11.17278733] 1.61646665882e-36\n",
      "positions (x,y,z), reward: [ 2.79927764 -6.70796851  0.        ] 9.16174234971e-39\n",
      "Episode =   35, score =   0.015 (best =   1.710), noise_scale = 0.1positions (x,y,z), reward: [  1.03436546e-04   1.17680144e-01   2.02187508e+01] 5.1663460049e-07\n",
      "positions (x,y,z), reward: [ -7.24024245e-03   1.49111969e+00   2.01717411e+01] 5.34852285125e-14\n",
      "positions (x,y,z), reward: [ -0.29949121   6.40872486  18.50336025] 8.94498585567e-21\n",
      "positions (x,y,z), reward: [ -0.56294687   8.00586128  18.37246062] 2.59903855334e-20\n",
      "positions (x,y,z), reward: [ -0.64682163   8.33686146  18.34962906] 2.51846641906e-20\n",
      "positions (x,y,z), reward: [ -1.63446519   9.76373403  17.53429752] 1.72482852657e-22\n",
      "positions (x,y,z), reward: [ -2.16463507   9.83436025  16.63738212] 6.32353713935e-24\n",
      "positions (x,y,z), reward: [ -3.10244885   9.78051245  14.55629505] 6.32207203486e-26\n",
      "Episode =   36, score =   0.033 (best =   1.710), noise_scale = 0.1positions (x,y,z), reward: [ -4.15923469e-09   1.25352358e-03   2.00209594e+01] 0.820137509848\n",
      "positions (x,y,z), reward: [ -1.02181353e-06   2.72634546e-03   2.00814511e+01] 0.16449279283\n",
      "positions (x,y,z), reward: [ -5.94621177e-05  -4.52775880e-01   1.92354072e+01] 2.55486251205e-32\n",
      "positions (x,y,z), reward: [  3.39661620e-04  -9.58258381e-01   1.75358455e+01] 1.41210223835e-34\n",
      "positions (x,y,z), reward: [ -0.0491709   -2.06533274  12.73743322] 8.33353309395e-37\n",
      "positions (x,y,z), reward: [-0.67109228 -3.46247635  3.89563959] 7.14192322879e-39\n",
      "positions (x,y,z), reward: [-1.22356079 -3.96075492  0.        ] 1.51717596079e-39\n",
      "Episode =   37, score =   0.063 (best =   1.715), noise_scale = 0.1positions (x,y,z), reward: [  3.82138091e-06  -5.00395621e-02   1.99619121e+01] 5.06761894269e-24\n",
      "positions (x,y,z), reward: [  5.81842871e-03  -4.12368708e-01   1.94982153e+01] 2.03755179841e-31\n",
      "positions (x,y,z), reward: [  3.02512619e-03  -6.81242600e-01   1.90656967e+01] 8.1796316448e-33\n",
      "positions (x,y,z), reward: [ -0.06324398  -0.99874842  17.61299825] 2.7782793191e-33\n",
      "positions (x,y,z), reward: [-3.65215109 -2.60087938  3.10040318] 1.82763799891e-38\n",
      "Episode =   38, score =   0.001 (best =   1.715), noise_scale = 0.1positions (x,y,z), reward: [  2.43291924e-07  -1.09642125e-03   2.00027131e+01] 4.17059666088e-05\n",
      "positions (x,y,z), reward: [  4.92726950e-03  -5.87564601e-01   2.00204035e+01] 3.59742435853e-22\n",
      "positions (x,y,z), reward: [  1.33827990e-02  -9.58599094e-01   1.97957545e+01] 5.27281270531e-32\n",
      "positions (x,y,z), reward: [ 3.26862326 -6.54906372  7.07679584] 4.67134932075e-37\n",
      "positions (x,y,z), reward: [ 3.48999674 -6.73467157  6.46887907] 1.59449059739e-37\n",
      "Episode =   39, score =   0.004 (best =   1.715), noise_scale = 0.1positions (x,y,z), reward: [  2.29196440e-03  -7.17310906e-02   2.03206882e+01] 2.90456102266e-09\n",
      "positions (x,y,z), reward: [  1.07186829   0.44890255  15.27405011] 9.09928980936e-35\n",
      "positions (x,y,z), reward: [ 5.38813342 -0.9793735   6.99447072] 2.02434889386e-26\n",
      "positions (x,y,z), reward: [ 8.09181412 -2.82120461  3.12833713] 3.06793663645e-35\n",
      "Episode =   40, score =   0.035 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.1040456   -0.93003448  18.85427496] 2.69905725512e-32\n",
      "positions (x,y,z), reward: [ 3.39800981 -2.95587264  0.77968475] 8.77979283004e-39\n",
      "Episode =   41, score =   0.028 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.02253288  -1.39687816  15.75576387] 4.07537112082e-34\n",
      "positions (x,y,z), reward: [  0.04787857  -1.73660831  13.81410287] 7.99185949313e-35\n",
      "positions (x,y,z), reward: [-0.27477204 -3.09660522  3.32732536] 9.27092564352e-39\n",
      "Episode =   42, score =   0.033 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  8.85635206e-03  -3.60497539e-01   1.95106920e+01] 1.22621514532e-31\n",
      "positions (x,y,z), reward: [  1.45653083e-02  -3.94231691e-01   1.94092052e+01] 2.89663854347e-31\n",
      "positions (x,y,z), reward: [  1.82332942  -1.77036498  12.66864733] 7.56687783772e-36\n",
      "positions (x,y,z), reward: [  2.04626772  -1.84962422  12.16570218] 2.77226387858e-36\n",
      "positions (x,y,z), reward: [ 4.92018097 -2.26383328  7.3928003 ] 8.71858377477e-37\n",
      "positions (x,y,z), reward: [ 10.90506814  -3.06767444   0.40319227] 3.40257370344e-27\n",
      "Episode =   43, score =   0.001 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.01334899e-04   4.74234922e-01   1.94457441e+01] 3.43244789205e-23\n",
      "positions (x,y,z), reward: [  0.03948371   1.8507436   10.68108282] 9.30018172393e-29\n",
      "positions (x,y,z), reward: [ 0.05621382  2.26979651  9.18502727] 1.40954475996e-28\n",
      "Episode =   44, score =   0.003 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.06595418e-03   1.29801932e+00   2.06174441e+01] 0.509149329866\n",
      "positions (x,y,z), reward: [ -1.09904035e-02   1.55969694e+00   2.07723108e+01] 0.863652978867\n",
      "positions (x,y,z), reward: [ -1.85420600e-02   1.94523284e+00   2.10493820e+01] 0.978653785018\n",
      "positions (x,y,z), reward: [ -0.04518249   2.59968068  21.83870394] 0.998128272382\n",
      "positions (x,y,z), reward: [ -0.06014812   2.72766709  22.17060248] 0.998322905299\n",
      "positions (x,y,z), reward: [ -0.20268922   1.99474828  22.98725671] 2.33057716839e-12\n",
      "positions (x,y,z), reward: [ -0.42308052   0.79615329  20.63365143] 2.19108425892e-16\n",
      "positions (x,y,z), reward: [ -3.58441631  11.92671042   5.63687775] 5.72646834931e-22\n",
      "Episode =   45, score =   0.339 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.56218386e-05   8.65111787e-02   2.01591003e+01] 3.16460901733e-05\n",
      "positions (x,y,z), reward: [ -1.54892118e-03   5.30537544e-01   2.01765504e+01] 1.0196167142e-21\n",
      "positions (x,y,z), reward: [ -2.07365718e-03   6.39059397e-01   2.01648199e+01] 1.17514765397e-21\n",
      "positions (x,y,z), reward: [ -1.67934820e-02   1.54239501e+00   2.02238830e+01] 7.72796249895e-14\n",
      "positions (x,y,z), reward: [ -0.07362387   8.12808875  17.63484502] 6.97767300031e-21\n",
      "positions (x,y,z), reward: [  0.48049693  11.06216513  14.89992494] 1.00188266536e-24\n",
      "Episode =   46, score =   0.034 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.43998912e-02   1.29330338e+00   2.00427917e+01] 2.82136259065e-23\n",
      "positions (x,y,z), reward: [  1.74442220e-02   1.37738898e+00   1.99797173e+01] 4.41942271118e-32\n",
      "positions (x,y,z), reward: [  0.11606732   2.52372045  19.09024416] 1.03307200479e-32\n",
      "positions (x,y,z), reward: [  0.33180844   3.28330727  18.016215  ] 4.8562716307e-26\n",
      "positions (x,y,z), reward: [  0.77167173   3.60125986  16.76456232] 3.51269730971e-22\n",
      "positions (x,y,z), reward: [  0.86116434   3.58810599  16.63309992] 5.52505946363e-22\n",
      "positions (x,y,z), reward: [  0.90846919   3.56943782  16.56911749] 6.31460215322e-22\n",
      "positions (x,y,z), reward: [  1.48387626   2.89018388  15.74574747] 9.37836821128e-23\n",
      "positions (x,y,z), reward: [  2.64857547   0.9366806   13.19805648] 1.58665029858e-32\n",
      "positions (x,y,z), reward: [ 7.84385684 -5.89048057  4.48205385] 7.36516950461e-38\n",
      "Episode =   47, score =   0.033 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  4.08388080e-05   9.60826187e-02   2.01878550e+01] 4.68764663398e-06\n",
      "positions (x,y,z), reward: [ -0.19408727   4.61657887  14.70811004] 2.0780506201e-26\n",
      "positions (x,y,z), reward: [ -0.30274392   5.74396957  13.06055916] 6.78148280737e-26\n",
      "positions (x,y,z), reward: [ -0.54383602   7.68132927  10.87995373] 6.06418455101e-25\n",
      "positions (x,y,z), reward: [ -0.57638789   7.89603192  10.65679369] 7.07396428689e-25\n",
      "positions (x,y,z), reward: [ -1.73768115  11.74739515   5.33836048] 1.38604563193e-25\n",
      "positions (x,y,z), reward: [ -2.18408753  12.03410216   3.623773  ] 9.63936756486e-27\n",
      "Episode =   48, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  5.00112107e-06   5.85696670e-02   2.01070122e+01] 0.00991310853442\n",
      "positions (x,y,z), reward: [  1.41756027e-03   4.32873178e-01   2.01971685e+01] 1.26184911722e-21\n",
      "positions (x,y,z), reward: [  1.13616500e-02   1.22124096e+00   2.01304366e+01] 6.43270726923e-23\n",
      "positions (x,y,z), reward: [  0.03062385   1.887268    19.79063034] 2.39499946466e-31\n",
      "positions (x,y,z), reward: [  0.0692812    2.52116077  19.16305514] 1.28684349665e-32\n",
      "positions (x,y,z), reward: [  0.28964679   4.39179536  16.26959122] 2.58779925046e-34\n",
      "positions (x,y,z), reward: [  0.6901414    5.41523567  11.95660278] 3.09809727138e-26\n",
      "Episode =   49, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.14237848   3.17676134  18.18408292] 6.17947199884e-34\n",
      "positions (x,y,z), reward: [  0.35977117   4.51532516  15.34191806] 8.24462371169e-28\n",
      "positions (x,y,z), reward: [  0.66590161   4.72603703  11.4958145 ] 5.40690031407e-25\n",
      "positions (x,y,z), reward: [  0.75545682   4.33203022  10.33780472] 9.41366742311e-26\n",
      "positions (x,y,z), reward: [ 0.91898364  3.37537412  7.70169061] 2.52902843053e-27\n",
      "positions (x,y,z), reward: [ 1.13816766  2.26512122  2.69215515] 2.45836349554e-29\n",
      "Episode =   50, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.75896455e-06   4.01769111e-02   2.00707800e+01] 0.0996121834292\n",
      "positions (x,y,z), reward: [ -0.0327417    1.48426791  19.90223675] 5.42139307113e-32\n",
      "positions (x,y,z), reward: [ -0.2090128    2.74856926  18.89587674] 2.38594959889e-32\n",
      "positions (x,y,z), reward: [ -0.23188139   2.84173003  18.8167254 ] 4.27890178509e-31\n",
      "positions (x,y,z), reward: [ -0.30924463   3.0922261   18.59751272] 3.87976459094e-27\n",
      "positions (x,y,z), reward: [ -0.61818227   3.97144801  17.73459776] 2.16917272893e-24\n",
      "positions (x,y,z), reward: [ -0.70297767   4.22322362  17.43814514] 1.49207091314e-24\n",
      "positions (x,y,z), reward: [ -0.99257305   5.11410925  16.34390199] 5.28506076415e-25\n",
      "positions (x,y,z), reward: [ -1.04624216   5.28672105  16.1401664 ] 4.89690629223e-25\n",
      "positions (x,y,z), reward: [ -4.70778589  12.8594677   10.04316763] 1.4706546083e-23\n",
      "positions (x,y,z), reward: [ -5.17500509  13.16360074   9.51761403] 5.17979461106e-24\n",
      "positions (x,y,z), reward: [ -6.55914971  13.64744599   7.73519306] 1.26845672985e-25\n",
      "positions (x,y,z), reward: [ -9.11355854  13.96350035   3.60434085] 8.19365855871e-28\n",
      "positions (x,y,z), reward: [ -9.52377794  14.00200478   2.86593502] 4.84584174693e-28\n",
      "positions (x,y,z), reward: [ -9.72974068  14.02132771   2.48895732] 3.78567060496e-28\n",
      "Episode =   51, score =   0.033 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.66139352   7.31194638  15.0639008 ] 3.73193038607e-22\n",
      "positions (x,y,z), reward: [ -5.68918048  10.09798799  10.09953541] 3.9028152978e-26\n",
      "Episode =   52, score =   0.032 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.02285695   2.04456638  19.632356  ] 6.18760001125e-32\n",
      "positions (x,y,z), reward: [ -0.0305409    2.17007018  19.48076342] 1.06464129005e-32\n",
      "positions (x,y,z), reward: [ -0.03507183   2.24241445  19.38192717] 5.98760024046e-33\n",
      "positions (x,y,z), reward: [-3.43893429  1.05968884  5.57192971] 2.33294998929e-38\n",
      "positions (x,y,z), reward: [-3.7777408   0.96895795  4.79596271] 1.48451642259e-38\n",
      "positions (x,y,z), reward: [-5.43897143  0.50055272  1.68734989] 1.23798975373e-39\n",
      "Episode =   53, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.14237588   4.77046484  15.14381502] 8.75120436447e-23\n",
      "positions (x,y,z), reward: [ -1.60450339   4.66934803  14.52779423] 1.71462137648e-22\n",
      "positions (x,y,z), reward: [ -2.50989041   3.83610654  13.24054769] 6.34058273192e-28\n",
      "positions (x,y,z), reward: [-4.94373224  2.23303315  9.6022344 ] 5.10794162414e-36\n",
      "Episode =   54, score =   0.033 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.02068580e-04   1.02133853e-01   2.01872242e+01] 4.4928124956e-06\n",
      "positions (x,y,z), reward: [ -7.04734404e-04   2.75222159e-01   2.02260759e+01] 6.66334894789e-21\n",
      "positions (x,y,z), reward: [ -0.07678411   2.74723221  18.87687381] 2.1596119335e-32\n",
      "positions (x,y,z), reward: [ -0.13200339   3.1843456   18.23388304] 6.92884262548e-34\n",
      "positions (x,y,z), reward: [ -0.14360095   3.27069553  18.08428205] 5.99615155946e-34\n",
      "positions (x,y,z), reward: [ -0.35604249   4.31038038  16.25171758] 1.00285889373e-34\n",
      "positions (x,y,z), reward: [ -0.9834357    5.78538692  12.80376372] 7.73805842235e-36\n",
      "positions (x,y,z), reward: [ -1.25796572   6.1819564   11.48840335] 2.01693180144e-36\n",
      "Episode =   55, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  3.14274008e-05   1.07635359e-01   2.01861774e+01] 4.41915331638e-06\n",
      "positions (x,y,z), reward: [  0.0275349    1.61683869  19.77945485] 6.0051362553e-32\n",
      "positions (x,y,z), reward: [  0.05979095   2.08275154  19.54494167] 5.36547787391e-32\n",
      "positions (x,y,z), reward: [  0.97095658   5.33057301  13.9122596 ] 1.15346413984e-35\n",
      "positions (x,y,z), reward: [  1.3271729    6.00877363  12.0852503 ] 1.67855540375e-36\n",
      "positions (x,y,z), reward: [ 2.74799756  7.96754811  5.30631655] 2.15019887023e-38\n",
      "positions (x,y,z), reward: [ 3.23610259  8.54937743  3.25075587] 4.41006117549e-38\n",
      "Episode =   56, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.20082309e-05   5.66374773e-02   2.01080897e+01] 0.0100545677471\n",
      "positions (x,y,z), reward: [  6.45497335e-03   1.20091983e+00   2.01472112e+01] 6.38337330948e-23\n",
      "positions (x,y,z), reward: [  0.03651016   2.48531282  19.19798594] 1.31971264716e-32\n",
      "positions (x,y,z), reward: [  0.04384024   2.69327129  19.03764126] 2.88538738502e-32\n",
      "positions (x,y,z), reward: [  0.16922462   4.1267371   16.68889326] 1.0372418249e-34\n",
      "positions (x,y,z), reward: [  0.32096974   5.04706411  14.63210265] 1.32132970076e-35\n",
      "positions (x,y,z), reward: [ 0.88739977  6.98345786  8.81802419] 3.66083676024e-37\n",
      "positions (x,y,z), reward: [ 1.58855851  8.40695173  3.30043352] 1.32591939607e-38\n",
      "positions (x,y,z), reward: [ 1.97016278  9.015698    0.65118294] 1.03435557459e-38\n",
      "Episode =   57, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.97905898e-08   3.99327317e-03   2.00201961e+01] 0.790945930328\n",
      "positions (x,y,z), reward: [  2.68270004e-05   7.40592057e-02   2.01364499e+01] 0.000299592540976\n",
      "positions (x,y,z), reward: [  2.03406294e-03   6.38619756e-01   2.01533092e+01] 9.62237602524e-22\n",
      "positions (x,y,z), reward: [  1.61628192e-02   2.62904027e+00   1.90117202e+01] 1.76488371112e-32\n",
      "positions (x,y,z), reward: [  9.49876925e-04   3.56624706e+00   1.77344726e+01] 2.22518452113e-33\n",
      "positions (x,y,z), reward: [ -0.17242985   5.88798304  12.41092509] 2.00793967274e-36\n",
      "positions (x,y,z), reward: [-0.54353897  7.74579553  6.0593266 ] 3.01197386842e-38\n",
      "Episode =   58, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  3.10193823e-05   2.15284047e-01   2.02375645e+01] 8.61942436676e-16\n",
      "positions (x,y,z), reward: [  1.83310210e-04   6.50140407e-01   2.01646389e+01] 1.19091776918e-21\n",
      "positions (x,y,z), reward: [  4.93616176e-04   1.03885623e+00   2.01906383e+01] 8.5382614144e-15\n",
      "positions (x,y,z), reward: [  2.23464465e-03   1.80989615e+00   1.98243682e+01] 2.37679373505e-31\n",
      "positions (x,y,z), reward: [  0.10762498   4.21713909  16.64121008] 9.59990343198e-35\n",
      "positions (x,y,z), reward: [ 1.38020559  8.16760456  4.91598907] 6.49225407501e-38\n",
      "Episode =   59, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  5.21605258e-04   7.51940433e-01   2.01500232e+01] 4.28435207861e-15\n",
      "positions (x,y,z), reward: [  0.52092318   4.60226833  15.84147801] 3.61184368486e-34\n",
      "positions (x,y,z), reward: [ 4.52662039  8.4742052   3.1647075 ] 1.99498909235e-38\n",
      "positions (x,y,z), reward: [ 4.92242629  8.67906832  2.04681982] 5.91062281805e-39\n",
      "Episode =   60, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.46108800e-08   4.02974717e-03   2.00201543e+01] 0.790148888543\n",
      "positions (x,y,z), reward: [ -8.12159256e-03   3.12014060e+00   1.84222737e+01] 1.28642527294e-33\n",
      "positions (x,y,z), reward: [  4.89250239e-03   3.48770280e+00   1.78453921e+01] 1.36844042579e-33\n",
      "positions (x,y,z), reward: [ 3.34304749  9.19080814  0.3380826 ] 1.07235661059e-38\n",
      "Episode =   61, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.39097014e-05   8.73629691e-02   2.01596172e+01] 3.20801035505e-05\n",
      "positions (x,y,z), reward: [  0.40915331   4.11348075  16.76521929] 9.4841289044e-35\n",
      "positions (x,y,z), reward: [  0.76005092   5.04737508  14.72635265] 1.20657252898e-35\n",
      "positions (x,y,z), reward: [  1.15468873   5.83450047  12.74817957] 4.01147270175e-36\n",
      "positions (x,y,z), reward: [ 2.55890848  7.68032844  6.5398631 ] 5.96113123285e-38\n",
      "positions (x,y,z), reward: [ 3.30852246  8.4690834   3.49191852] 2.63259645768e-38\n",
      "Episode =   62, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.24344811e-09   4.10678674e-03   2.00201209e+01] 0.78897115601\n",
      "positions (x,y,z), reward: [ -1.64562385e-05   2.21319028e-01   2.02322123e+01] 6.80706662939e-16\n",
      "positions (x,y,z), reward: [  3.11803108e-03   1.49999001e+00   1.98538979e+01] 4.28951879971e-32\n",
      "positions (x,y,z), reward: [  8.52667626e-03   2.19772670e+00   1.94056500e+01] 9.24725248646e-33\n",
      "positions (x,y,z), reward: [  1.56021747e-02   3.81940830e+00   1.73130734e+01] 2.10599649076e-33\n",
      "positions (x,y,z), reward: [ -1.42076329e-02   4.84254547e+00   1.52605262e+01] 1.42143826987e-34\n",
      "positions (x,y,z), reward: [ -0.08355086   5.62130695  13.2987869 ] 3.20981369457e-35\n",
      "positions (x,y,z), reward: [ -0.2598022    6.56482494  10.52861936] 3.79717527687e-36\n",
      "Episode =   63, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.13098986e-05   7.48151143e-02   2.01358787e+01] 0.000303550262512\n",
      "positions (x,y,z), reward: [  2.59099428e-05   1.00230520e-01   2.01872083e+01] 4.70389223441e-06\n",
      "positions (x,y,z), reward: [ -8.06714346e-04   7.54219016e-01   2.01675770e+01] 1.34806548675e-14\n",
      "positions (x,y,z), reward: [ -2.55209282e-03   1.03082128e+00   2.01951856e+01] 8.21346711565e-15\n",
      "positions (x,y,z), reward: [ -9.93038382e-03   1.37921450e+00   2.00233970e+01] 2.57729156359e-23\n",
      "positions (x,y,z), reward: [ -0.2133105    3.16571827  18.39400423] 8.54956874342e-34\n",
      "positions (x,y,z), reward: [ -0.84598919   4.75879224  15.64197666] 1.99396127124e-34\n",
      "positions (x,y,z), reward: [-4.32137172  7.5525103   7.10262551] 1.77399785602e-37\n",
      "Episode =   64, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.09306352e-06   3.92570300e-02   2.00714133e+01] 0.102576953665\n",
      "positions (x,y,z), reward: [ -2.58449805e-05   7.33086868e-02   2.01365777e+01] 0.000305794240561\n",
      "positions (x,y,z), reward: [ -2.88509348e-03   8.51570887e-01   2.01800259e+01] 3.52483197927e-10\n",
      "positions (x,y,z), reward: [ -0.10445618   3.878138    17.36405395] 8.03338369363e-34\n",
      "positions (x,y,z), reward: [-1.06314478  7.97468557  5.30131661] 5.1673542572e-38\n",
      "positions (x,y,z), reward: [-1.37136908  8.89974053  1.34972792] 7.34666809714e-39\n",
      "Episode =   65, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.07696301e-02   2.06791911e+00   1.95517840e+01] 5.79656399025e-32\n",
      "positions (x,y,z), reward: [ -1.15671916e-02   2.13088348e+00   1.94823368e+01] 2.35158938068e-32\n",
      "positions (x,y,z), reward: [ -1.34394669e-02   2.26724269e+00   1.92935696e+01] 5.44989852724e-33\n",
      "positions (x,y,z), reward: [ -1.58158008e-02   2.45076082e+00   1.90733148e+01] 5.2742233946e-33\n",
      "positions (x,y,z), reward: [ -1.72523310e-02   2.55844733e+00   1.89695146e+01] 8.36137763212e-33\n",
      "positions (x,y,z), reward: [ -0.02282135   2.86689204  18.70701101] 1.96384609479e-32\n",
      "positions (x,y,z), reward: [ -0.2640073    4.40912056  15.22031808] 9.4034424088e-43\n",
      "positions (x,y,z), reward: [ -0.33784318   4.62111143  14.18153107] 2.03292564711e-45\n",
      "Episode =   66, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.04986826   0.02551531  20.03799358] 5.46096456796e-07\n",
      "positions (x,y,z), reward: [ -1.11896305e-01   1.69053306e-02   2.00651787e+01] 2.46600123714e-22\n",
      "positions (x,y,z), reward: [ -2.42642375e-01  -1.62660968e-02   1.99584144e+01] 6.90767219359e-41\n",
      "positions (x,y,z), reward: [ -0.49144922  -0.94338859  19.40671546] 4.00088722539e-42\n",
      "positions (x,y,z), reward: [ -0.57064939  -1.57695112  19.18623596] 3.58128137841e-42\n",
      "positions (x,y,z), reward: [ -0.65219215  -2.00746783  19.0457788 ] 3.51042117578e-42\n",
      "positions (x,y,z), reward: [ -0.83998762  -3.59493278  18.61885885] 3.0099967116e-42\n",
      "positions (x,y,z), reward: [ -1.17991812  -8.48735299  17.54690667] 2.17223978007e-42\n",
      "positions (x,y,z), reward: [ -1.3806658  -12.41420477  16.79445528] 1.5512096139e-42\n",
      "positions (x,y,z), reward: [ -1.40936708 -12.67718402  16.74802573] 1.79444755573e-42\n",
      "positions (x,y,z), reward: [ -1.60555282 -18.18139665  15.76709564] 8.96257831551e-43\n",
      "positions (x,y,z), reward: [ -1.82917544 -23.05011456  14.92673301] 9.77068496434e-43\n",
      "positions (x,y,z), reward: [ -1.87627914 -25.83189612  14.44950586] 7.39229547506e-43\n",
      "positions (x,y,z), reward: [ -1.96112572 -27.25223037  14.2117981 ] 6.94972786784e-43\n",
      "positions (x,y,z), reward: [ -2.17875419 -35.56680241  12.80677801] 5.2236896462e-43\n",
      "positions (x,y,z), reward: [ -2.20603727 -38.37130616  12.3283537 ] 4.87171598792e-43\n",
      "positions (x,y,z), reward: [ -2.27814796 -39.98516181  12.05520731] 4.31639631627e-43\n",
      "positions (x,y,z), reward: [ -2.35387646 -46.26024732  10.98509199] 3.63499086832e-43\n",
      "positions (x,y,z), reward: [ -2.65708093 -65.93138311   7.46732317] 1.95316669571e-43\n",
      "Episode =   67, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.44179714  -9.9653789   18.47885615] 7.65408100366e-42\n",
      "positions (x,y,z), reward: [ -1.49483944 -10.39949633  18.45217741] 1.04931634365e-41\n",
      "positions (x,y,z), reward: [ -1.7678716  -15.50164572  18.2432334 ] 9.88429969802e-42\n",
      "positions (x,y,z), reward: [ -1.96726715 -19.07089237  18.13282257] 2.97131455088e-37\n",
      "positions (x,y,z), reward: [ -1.9889181  -19.35903591  18.12598113] 1.10398743469e-41\n",
      "positions (x,y,z), reward: [ -2.02506891 -21.42499209  18.06603722] 8.80306702389e-42\n",
      "positions (x,y,z), reward: [ -2.15796524 -24.81970686  17.97785688] 8.71265194009e-42\n",
      "positions (x,y,z), reward: [ -2.25889747 -27.72725624  17.91222973] 1.12770540534e-41\n",
      "positions (x,y,z), reward: [ -2.33652312 -29.05941864  17.87349884] 2.94494799103e-37\n",
      "positions (x,y,z), reward: [ -2.4984437  -34.59729012  17.74278041] 2.88295009192e-37\n",
      "positions (x,y,z), reward: [ -2.78555637 -45.03715191  17.47437753] 1.07632912605e-41\n",
      "positions (x,y,z), reward: [ -2.98837214 -55.81714362  17.15510441] 1.02710345159e-41\n",
      "Episode =   68, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.05105593   0.02551376  20.0369379 ] 5.17432723991e-07\n",
      "positions (x,y,z), reward: [ -0.42178006  -0.39528372  19.6896769 ] 5.61263511223e-42\n",
      "positions (x,y,z), reward: [ -1.06680089  -5.06963779  18.95647844] 1.05878282548e-41\n",
      "positions (x,y,z), reward: [ -1.08150993  -5.56388682  18.92485725] 7.81422325272e-42\n",
      "positions (x,y,z), reward: [ -1.20930069  -6.42035649  18.86792944] 8.93246370663e-42\n",
      "positions (x,y,z), reward: [ -1.372492    -8.71471494  18.74106818] 9.1839966334e-42\n",
      "positions (x,y,z), reward: [ -1.93360508 -20.21499085  18.41812187] 3.29935247931e-37\n",
      "positions (x,y,z), reward: [ -2.06153297 -23.52909674  18.36190753] 3.28850221206e-37\n",
      "positions (x,y,z), reward: [ -2.06073185 -23.84433317  18.35947089] 2.86563971536e-37\n",
      "positions (x,y,z), reward: [ -2.48455086 -36.36751086  18.13136453] 3.16698632432e-37\n",
      "positions (x,y,z), reward: [ -2.50733918 -36.72941057  18.12641525] 2.87420244711e-37\n",
      "positions (x,y,z), reward: [ -2.61640357 -42.70477406  17.99091814] 1.13517909694e-41\n",
      "positions (x,y,z), reward: [ -2.80872839 -52.17802418  17.7169065 ] 6.90377085288e-42\n",
      "Episode =   69, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.08094315   0.02762902  20.061607  ] 1.75830024928e-11\n",
      "positions (x,y,z), reward: [ -0.24845278  -0.10075898  19.86142813] 1.40409844351e-41\n",
      "positions (x,y,z), reward: [ -0.32730393  -0.24392751  19.7550824 ] 7.23342037349e-42\n",
      "positions (x,y,z), reward: [ -0.8336344   -3.33813654  18.86192388] 5.16873006714e-42\n",
      "positions (x,y,z), reward: [ -0.86985326  -3.62775181  18.80614897] 3.49888339853e-42\n",
      "positions (x,y,z), reward: [ -1.02155003  -5.38893093  18.49631106] 3.22664337933e-42\n",
      "positions (x,y,z), reward: [ -1.172371    -7.67708041  18.1417377 ] 3.57200879496e-42\n",
      "positions (x,y,z), reward: [ -1.61890562 -17.25987246  16.89455745] 2.36385920809e-42\n",
      "positions (x,y,z), reward: [ -1.71654684 -19.05295998  16.67616417] 2.74929404704e-42\n",
      "positions (x,y,z), reward: [ -1.94338619 -25.22846532  15.93486978] 2.14917745236e-42\n",
      "positions (x,y,z), reward: [ -2.01352002 -28.378794    15.5489485 ] 2.36809918283e-42\n",
      "positions (x,y,z), reward: [ -2.07788259 -31.66237272  15.15156397] 1.36665555952e-42\n",
      "positions (x,y,z), reward: [ -2.22974603 -36.59769884  14.53941646] 1.82629870108e-42\n",
      "positions (x,y,z), reward: [ -2.44517091 -47.95893933  13.09910588] 1.17004037523e-42\n",
      "positions (x,y,z), reward: [ -2.53320618 -52.21811742  12.5328889 ] 1.19313166707e-42\n",
      "Episode =   70, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.25244245  -0.16031888  19.82738336] 8.03979447524e-42\n",
      "positions (x,y,z), reward: [ -0.42489893  -0.82228538  19.4716201 ] 3.11476495218e-42\n",
      "positions (x,y,z), reward: [ -0.86031713  -4.12050253  18.48701417] 2.37539107307e-42\n",
      "positions (x,y,z), reward: [ -0.8593113   -4.27868002  18.44804398] 2.92493997593e-42\n",
      "positions (x,y,z), reward: [ -1.13707986  -7.88549428  17.67594782] 1.75224107321e-42\n",
      "positions (x,y,z), reward: [ -1.34496816 -12.44662224  16.81592134] 1.61954572444e-42\n",
      "positions (x,y,z), reward: [ -2.21595988 -39.48921528  12.33187538] 5.47559794342e-43\n",
      "Episode =   71, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.25307528  -0.06108834  19.88157917] 2.02446475135e-41\n",
      "positions (x,y,z), reward: [ -0.68062775  -1.49162255  18.07465264] 1.57531551003e-34\n",
      "positions (x,y,z), reward: [ -0.7647365   -2.05549721  16.68138787] 1.0726117172e-34\n",
      "positions (x,y,z), reward: [ -0.85977839  -2.46089181  15.20208746] 9.07085932184e-36\n",
      "positions (x,y,z), reward: [-1.1724505  -3.71808816  9.80533551] 3.06237638961e-37\n",
      "Episode =   72, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534442] 0.893045726109\n",
      "positions (x,y,z), reward: [ -4.59105125e-01  -1.21963259e-03   2.00894490e+01] 2.14551259611e-22\n",
      "positions (x,y,z), reward: [ -1.11172020e+00   6.43582702e-03   1.74747295e+01] 6.66287055211e-34\n",
      "positions (x,y,z), reward: [ -1.35776030e+00  -2.33977019e-03   1.52797506e+01] 1.7450271648e-34\n",
      "positions (x,y,z), reward: [ -1.59331739e+00  -3.30442460e-03   1.33393503e+01] 1.15211416579e-35\n",
      "positions (x,y,z), reward: [-2.02364249 -0.10421259  8.58316937] 1.33589272933e-37\n",
      "positions (x,y,z), reward: [-2.22460047 -0.22478668  5.34168837] 2.24120679995e-38\n",
      "positions (x,y,z), reward: [-2.37597923 -0.40446262  2.02796089] 5.72575506023e-39\n",
      "Episode =   73, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.82840484e-01  -3.61494702e-06   2.01161592e+01] 1.44518526387e-17\n",
      "positions (x,y,z), reward: [ -7.33239586e-01   4.89641154e-04   1.93935344e+01] 1.71045755259e-32\n",
      "positions (x,y,z), reward: [ -1.08270456e+00  -1.78864736e-03   1.74911543e+01] 6.94168856461e-34\n",
      "positions (x,y,z), reward: [ -1.08421120e+00  -5.15021514e-04   1.72127223e+01] 1.53004495572e-33\n",
      "positions (x,y,z), reward: [-2.46152098 -0.09135998  0.        ] 3.09297940614e-39\n",
      "Episode =   74, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.74405238e-01   9.20323200e-05   2.01932361e+01] 3.55414856724e-07\n",
      "positions (x,y,z), reward: [ -4.72398775e-01   1.89516110e-03   2.00809603e+01] 2.14660670385e-22\n",
      "positions (x,y,z), reward: [ -1.89006656  -0.0378884   10.5489497 ] 1.57266733574e-36\n",
      "positions (x,y,z), reward: [-1.95591224 -0.02748198  9.48583376] 1.20753973739e-36\n",
      "positions (x,y,z), reward: [-2.20449449 -0.07089592  6.09001298] 1.28644879143e-37\n",
      "Episode =   75, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.22544302e-01  -2.57469147e-05   2.01616495e+01] 3.73861606263e-05\n",
      "positions (x,y,z), reward: [ -2.99389062e-01  -7.50683459e-05   2.02568576e+01] 3.6956526867e-21\n",
      "positions (x,y,z), reward: [ -1.27104510e+00  -7.23673542e-03   1.64413538e+01] 9.2732910857e-35\n",
      "positions (x,y,z), reward: [ -1.57396131e+00  -1.05787645e-02   1.29047295e+01] 2.05177706369e-35\n",
      "positions (x,y,z), reward: [-1.82987909 -0.04639056  9.78367686] 1.84553967564e-36\n",
      "positions (x,y,z), reward: [-2.09925982 -0.12132165  6.08680451] 1.10677655925e-37\n",
      "positions (x,y,z), reward: [-2.29783276 -0.2251528   2.53390623] 1.81617663105e-38\n",
      "positions (x,y,z), reward: [-2.33249858 -0.24622207  2.16867063] 1.02230298346e-38\n",
      "Episode =   76, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.03929221e-03   1.23435513e-09   2.00201546e+01] 0.790050703092\n",
      "positions (x,y,z), reward: [ -1.25523913e+00  -3.19170422e-03   1.66074940e+01] 2.07302326729e-34\n",
      "positions (x,y,z), reward: [ -1.33391936e+00   2.32290225e-04   1.62324355e+01] 5.36877416352e-35\n",
      "positions (x,y,z), reward: [-2.11502327 -0.09031312  6.37801982] 1.66967480519e-37\n",
      "positions (x,y,z), reward: [-2.31923546 -0.15404482  3.55221007] 1.38190193966e-38\n",
      "positions (x,y,z), reward: [-2.55205071 -0.34892516  0.05575263] 6.82751203357e-40\n",
      "positions (x,y,z), reward: [-2.55429289 -0.37022783  0.        ] 7.29914310189e-40\n",
      "Episode =   77, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.58171245e-01   1.13132559e-04   2.02571061e+01] 1.73044830254e-13\n",
      "positions (x,y,z), reward: [ -6.22379492e-01  -1.15143728e-03   1.96644153e+01] 7.41813039154e-32\n",
      "positions (x,y,z), reward: [ -6.64598208e-01   1.90691251e-03   1.95167432e+01] 8.45789792448e-32\n",
      "positions (x,y,z), reward: [ -8.32152123e-01   7.85159069e-04   1.91802850e+01] 3.82493211377e-33\n",
      "positions (x,y,z), reward: [ -1.07680189e+00   1.03196514e-03   1.79428616e+01] 4.4128413801e-34\n",
      "positions (x,y,z), reward: [ -1.36896388e+00   2.40209552e-04   1.51009239e+01] 1.58337061336e-34\n",
      "positions (x,y,z), reward: [ -1.58609546  -0.02064631  13.34149974] 1.12115962059e-35\n",
      "positions (x,y,z), reward: [ -1.80240696  -0.0211413   11.41417824] 9.1621934519e-37\n",
      "positions (x,y,z), reward: [-1.8845417  -0.02842646  9.5182258 ] 1.25128851022e-36\n",
      "positions (x,y,z), reward: [-2.12335081 -0.09765397  6.14859714] 1.58940224841e-37\n",
      "positions (x,y,z), reward: [-2.2761718  -0.1650774   4.79994395] 2.2858275734e-38\n",
      "positions (x,y,z), reward: [-2.52123734 -0.45213485  0.        ] 9.14403947442e-39\n",
      "Episode =   78, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.36083334e-02  -7.34577888e-07   2.00671178e+01] 0.0809400663809\n",
      "positions (x,y,z), reward: [ -2.07681419e-01  -1.01314725e-04   2.02465031e+01] 2.444515308e-08\n",
      "positions (x,y,z), reward: [ -2.47072643e-01  -1.17919746e-04   2.02611335e+01] 2.76028158629e-11\n",
      "positions (x,y,z), reward: [ -8.30252604e-01   1.81551548e-03   1.88452112e+01] 5.09948038321e-33\n",
      "positions (x,y,z), reward: [ -1.53594433e+00  -7.20541190e-03   1.26892355e+01] 1.90596420363e-35\n",
      "positions (x,y,z), reward: [ -1.56654363e+00  -1.02648955e-02   1.24639343e+01] 1.15985449994e-35\n",
      "positions (x,y,z), reward: [ -1.69172142e+00  -1.12656651e-02   1.17070987e+01] 1.26296603977e-36\n",
      "Episode =   79, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.90067484e-01   8.74247651e-05   2.01099733e+01] 1.50907335398e-17\n",
      "positions (x,y,z), reward: [ -9.08405231e-01   9.31256840e-04   1.85399784e+01] 1.30053781089e-32\n",
      "positions (x,y,z), reward: [ -1.14182016e+00  -4.05932682e-04   1.71810177e+01] 1.56193266565e-33\n",
      "positions (x,y,z), reward: [ -1.38423137e+00  -2.27326846e-03   1.54393530e+01] 1.48145640211e-34\n",
      "positions (x,y,z), reward: [ -1.85467728e+00  -5.62405701e-04   1.13848799e+01] 8.15518106757e-37\n",
      "positions (x,y,z), reward: [ -1.94390305e+00   1.99787600e-03   9.48439268e+00] 1.11377312226e-36\n",
      "positions (x,y,z), reward: [-2.5872536  -0.0398078   0.24892355] 2.31103568925e-39\n",
      "Episode =   80, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.48263197e-01   1.20467167e-03   1.97776420e+01] 2.81290828177e-32\n",
      "positions (x,y,z), reward: [ -8.69043927e-01  -6.01847908e-04   1.91570662e+01] 3.60213923345e-33\n",
      "positions (x,y,z), reward: [ -1.40943126e+00   2.30818466e-03   1.56051776e+01] 8.80000426995e-35\n",
      "positions (x,y,z), reward: [ -1.90327094e+00  -8.18615969e-03   1.10766650e+01] 8.19871604214e-37\n",
      "positions (x,y,z), reward: [-2.06822673 -0.02220531  8.87357871] 2.55240570055e-37\n",
      "positions (x,y,z), reward: [-2.13612506 -0.01978622  8.23941724] 1.00266435911e-37\n",
      "positions (x,y,z), reward: [-2.23043665 -0.03406957  6.04306909] 1.12118378928e-37\n",
      "Episode =   81, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.11150890e-03   3.40094788e-08   2.00201004e+01] 0.788725137736\n",
      "positions (x,y,z), reward: [ -3.53062773e-01   5.42714970e-05   2.02229742e+01] 8.50047037525e-22\n",
      "positions (x,y,z), reward: [ -4.07811383e-01  -1.26337856e-04   2.01039026e+01] 1.48157732353e-17\n",
      "positions (x,y,z), reward: [ -1.03743953e+00   7.41489614e-04   1.82135777e+01] 1.66959371746e-33\n",
      "positions (x,y,z), reward: [ -1.84021537e+00   2.43006317e-03   1.16572793e+01] 1.09504397002e-36\n",
      "positions (x,y,z), reward: [ -2.13713306e+00  -4.49456218e-04   6.99626887e+00] 2.61163116374e-37\n",
      "positions (x,y,z), reward: [ -2.49682122e+00   9.61645826e-04   1.82254283e+00] 6.6018528846e-39\n",
      "Episode =   82, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.90958456e-01   2.15897490e-05   2.01153386e+01] 5.47575060959e-22\n",
      "positions (x,y,z), reward: [ -6.07362934e-01   2.51244290e-04   1.99323096e+01] 3.49646215621e-32\n",
      "positions (x,y,z), reward: [ -1.39863320e+00  -1.05993559e-03   1.54324457e+01] 1.39085241071e-34\n",
      "positions (x,y,z), reward: [ -1.89555268e+00  -4.20004923e-04   1.05385280e+01] 1.55871043375e-36\n",
      "positions (x,y,z), reward: [ -2.14035343e+00   2.57929612e-05   7.61455828e+00] 1.50679012407e-37\n",
      "positions (x,y,z), reward: [ -2.58138283e+00   2.10939450e-03   1.03475658e+00] 2.30014575318e-39\n",
      "Episode =   83, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.82510856e-01   4.31104736e-05   2.02245209e+01] 1.10042497598e-07\n",
      "positions (x,y,z), reward: [ -8.75478525e-01   4.66710234e-03   1.84813974e+01] 8.67526854236e-33\n",
      "positions (x,y,z), reward: [-1.98430801 -0.03131866  6.78663334] 3.08387540684e-37\n",
      "positions (x,y,z), reward: [-2.41542238 -0.11594277  0.        ] 2.95296334227e-39\n",
      "Episode =   84, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.79037387e-01  -6.83767886e-05   2.01209456e+01] 1.51981288355e-17\n",
      "positions (x,y,z), reward: [ -4.04503512e-01   1.81836168e-04   2.01158664e+01] 4.65177942611e-22\n",
      "positions (x,y,z), reward: [ -9.65996402e-01   9.68181459e-04   1.82571168e+01] 1.78377866586e-33\n",
      "positions (x,y,z), reward: [ -1.11821194e+00   1.64176761e-03   1.69548947e+01] 9.67812560629e-34\n",
      "positions (x,y,z), reward: [ -1.24670081e+00   1.50219360e-03   1.64605249e+01] 8.86477976601e-35\n",
      "positions (x,y,z), reward: [ -1.30671172e+00  -2.37141849e-04   1.53141629e+01] 1.94499283908e-34\n",
      "positions (x,y,z), reward: [ -1.35513481e+00   2.48988398e-03   1.49579502e+01] 1.08306321251e-34\n",
      "positions (x,y,z), reward: [ -1.53982794e+00  -3.03388851e-04   1.29354618e+01] 2.27413782144e-35\n",
      "positions (x,y,z), reward: [ -1.97611305e+00  -3.82859512e-03   8.34722614e+00] 1.08761900964e-37\n",
      "positions (x,y,z), reward: [-2.28465988 -0.02216963  2.30190351] 1.39930157119e-38\n",
      "positions (x,y,z), reward: [-2.40265534 -0.0404703   1.15662373] 2.51662226809e-39\n",
      "Episode =   85, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.87504146e-01   2.04855323e-05   2.01641929e+01] 3.22816643691e-22\n",
      "positions (x,y,z), reward: [ -4.03186053e-01   2.46212988e-04   2.01058552e+01] 1.4864147114e-17\n",
      "positions (x,y,z), reward: [ -8.87846089e-01  -1.40460920e-03   1.89366025e+01] 3.52708138879e-33\n",
      "positions (x,y,z), reward: [ -1.19029613e+00   3.42798698e-03   1.69129441e+01] 9.57817682115e-34\n",
      "positions (x,y,z), reward: [ -1.63067433e+00  -6.12144839e-03   1.33245663e+01] 1.16141200443e-35\n",
      "positions (x,y,z), reward: [-2.11662522 -0.02195107  7.32021901] 1.99895566542e-37\n",
      "positions (x,y,z), reward: [-2.11828213 -0.02107457  7.0116351 ] 2.63139042922e-37\n",
      "positions (x,y,z), reward: [-2.57466556 -0.06949762  0.66961818] 2.0861032892e-39\n",
      "Episode =   86, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.03022079e+00   1.45260968e-03   1.72266045e+01] 1.53099094657e-33\n",
      "positions (x,y,z), reward: [ -1.04440117e+00   1.58776501e-04   1.70945551e+01] 1.50793599203e-33\n",
      "positions (x,y,z), reward: [-1.86975452 -0.01350727  8.67048387] 1.46529084342e-37\n",
      "positions (x,y,z), reward: [-2.01068537 -0.02632509  5.83141539] 6.27771161857e-38\n",
      "Episode =   87, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534358] 0.893046424157\n",
      "positions (x,y,z), reward: [ -1.32632817e+00  -7.48908874e-05   1.62362465e+01] 5.63855474268e-35\n",
      "positions (x,y,z), reward: [ -1.49508222e+00  -9.32304477e-03   1.45198106e+01] 2.31947370045e-35\n",
      "positions (x,y,z), reward: [ -1.59387445e+00   2.23333568e-03   1.31155282e+01] 1.74811826199e-35\n",
      "positions (x,y,z), reward: [ -1.65211477  -0.01596727  12.44868941] 1.14492500589e-35\n",
      "Episode =   88, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.67014680e-01   7.93352773e-06   2.01973368e+01] 3.61080060198e-07\n",
      "positions (x,y,z), reward: [ -4.46469930e-01  -6.82718036e-04   2.00911734e+01] 2.30704534193e-22\n",
      "positions (x,y,z), reward: [ -4.91724580e-01  -8.00160243e-04   2.00611138e+01] 8.98357190339e-23\n",
      "positions (x,y,z), reward: [ -8.48588885e-01  -2.89103944e-04   1.87360011e+01] 8.58475389423e-33\n",
      "positions (x,y,z), reward: [ -1.08659548e+00  -1.26214904e-03   1.76309759e+01] 4.14957164165e-34\n",
      "positions (x,y,z), reward: [ -1.78487386e+00  -7.83350609e-03   1.05790029e+01] 1.5041863869e-36\n",
      "positions (x,y,z), reward: [-2.0136944  -0.01544137  7.34729882] 1.94041924364e-37\n",
      "Episode =   89, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.85392245e-01   6.36070828e-04   1.97488319e+01] 4.45040631505e-32\n",
      "positions (x,y,z), reward: [ -8.10177898e-01   2.21090672e-04   1.88693948e+01] 5.84223468695e-33\n",
      "positions (x,y,z), reward: [ -1.46040223e+00  -5.77176824e-04   1.41204964e+01] 6.68879349171e-36\n",
      "Episode =   90, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.39898846e-02   1.88982840e-06   2.01007064e+01] 0.0106076239387\n",
      "positions (x,y,z), reward: [ -1.65657904e-01   1.60201176e-06   2.01983413e+01] 3.62590191535e-07\n",
      "positions (x,y,z), reward: [ -5.33606733e-01  -4.77656426e-04   2.00173393e+01] 3.48610517611e-23\n",
      "positions (x,y,z), reward: [ -8.42467217e-01   7.38847779e-06   1.87442659e+01] 8.63923060517e-33\n",
      "positions (x,y,z), reward: [ -1.04884548e+00  -7.68938861e-04   1.79587076e+01] 4.37535976728e-34\n",
      "positions (x,y,z), reward: [ -1.91776545e+00  -4.98834737e-05   8.95507614e+00] 2.81760312364e-37\n",
      "positions (x,y,z), reward: [ -2.26000830e+00   1.30713135e-04   2.62517301e+00] 2.44902351082e-38\n",
      "positions (x,y,z), reward: [ -2.41192727e+00  -2.14018224e-03   1.11631831e+00] 2.33066755584e-39\n",
      "Episode =   91, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.58237755e-01  -7.12541619e-04   1.95470826e+01] 1.12319567494e-31\n",
      "positions (x,y,z), reward: [ -7.26782232e-01  -3.21726427e-03   1.94363826e+01] 3.93214149032e-32\n",
      "positions (x,y,z), reward: [ -8.92299312e-01   3.80636941e-03   1.88098844e+01] 5.42759034772e-33\n",
      "positions (x,y,z), reward: [ -1.07365357e+00  -4.27322332e-03   1.80648408e+01] 7.43717402452e-34\n",
      "positions (x,y,z), reward: [ -1.28301243e+00  -7.90418572e-03   1.65738473e+01] 1.86521287667e-34\n",
      "Episode =   92, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.48887284e-01  -3.14968633e-05   2.02190833e+01] 4.43949710708e-22\n",
      "positions (x,y,z), reward: [ -7.41641939e-01  -5.17793999e-04   1.93175257e+01] 8.04035774091e-33\n",
      "positions (x,y,z), reward: [ -8.21408823e-01  -2.93478173e-04   1.85768665e+01] 1.31621160796e-32\n",
      "positions (x,y,z), reward: [ -1.19912009e+00   3.01438356e-04   1.64735226e+01] 9.33085882532e-35\n",
      "positions (x,y,z), reward: [ -1.48009572e+00  -4.48282469e-03   1.31647370e+01] 1.55681225857e-35\n",
      "positions (x,y,z), reward: [ -1.56805199e+00   2.48054744e-03   1.22648374e+01] 5.79126233521e-36\n",
      "positions (x,y,z), reward: [-1.92594191 -0.00872855  6.79148953] 2.75853188146e-37\n",
      "positions (x,y,z), reward: [-2.33569505 -0.04039655  0.77032239] 1.97452721979e-39\n",
      "positions (x,y,z), reward: [-2.34623556 -0.04838757  0.36847071] 2.26995413292e-39\n",
      "Episode =   93, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.63875984e-01  -4.57575414e-04   1.88435110e+01] 5.24745113364e-33\n",
      "positions (x,y,z), reward: [ -1.79514983e+00  -2.38328830e-03   1.14265388e+01] 7.73100698552e-37\n",
      "Episode =   94, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.80816010e-02  -1.16946703e-07   2.00411708e+01] 0.411095243326\n",
      "positions (x,y,z), reward: [ -8.48092978e-01   1.55338662e-03   1.86516598e+01] 1.2438739828e-32\n",
      "positions (x,y,z), reward: [ -1.25894230e+00  -9.04203717e-03   1.64465557e+01] 9.10298833591e-35\n",
      "positions (x,y,z), reward: [ -1.55663867  -0.01907187  12.91055507] 1.79871181902e-35\n",
      "positions (x,y,z), reward: [ -1.78085624  -0.04057937  11.13636271] 7.47015703853e-37\n",
      "positions (x,y,z), reward: [ -1.78542052  -0.03872702  10.85451623] 9.14498647208e-37\n",
      "Episode =   95, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.34810342e+00  -2.28855869e-03   1.63845646e+01] 7.48982678302e-35\n",
      "positions (x,y,z), reward: [ -1.60391895e+00  -3.34619415e-03   1.42403290e+01] 8.70557560205e-36\n",
      "positions (x,y,z), reward: [ -1.90728985e+00  -3.21448013e-03   1.05105235e+01] 1.54938427427e-36\n",
      "positions (x,y,z), reward: [ -1.94448347e+00  -5.79344448e-03   9.71826257e+00] 1.81855190942e-36\n",
      "positions (x,y,z), reward: [-2.63522078 -0.01423453  0.        ] 3.34047325161e-39\n",
      "Episode =   96, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.89346509e-01   1.06838078e-04   2.01349973e+01] 3.79900663906e-22\n",
      "positions (x,y,z), reward: [-2.24353448 -0.01372304  5.75482407] 5.59679809318e-38\n",
      "positions (x,y,z), reward: [-2.48673219 -0.02139123  1.83833519] 6.44138449755e-39\n",
      "Episode =   97, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.60680625e-01  -2.93552124e-03   1.88411701e+01] 5.29048997095e-33\n",
      "positions (x,y,z), reward: [ -1.09273490e+00  -1.92330861e-03   1.77909038e+01] 3.50888411055e-34\n",
      "positions (x,y,z), reward: [ -1.15114047e+00   3.11089967e-03   1.69340562e+01] 8.7997565055e-34\n",
      "positions (x,y,z), reward: [ -1.28148708e+00   2.76728935e-03   1.64373205e+01] 8.23226768116e-35\n",
      "positions (x,y,z), reward: [ -1.33811505e+00  -5.44552278e-03   1.54675215e+01] 1.41934132218e-34\n",
      "positions (x,y,z), reward: [-2.04649578 -0.03743757  7.36084879] 2.0089921447e-37\n",
      "Episode =   98, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.60646882e-02   4.08628834e-06   2.00989065e+01] 0.0100255639405\n",
      "positions (x,y,z), reward: [ -1.71555746e-01   1.05638287e-05   2.01947840e+01] 3.53950575598e-07\n",
      "positions (x,y,z), reward: [ -4.21492310e-01   2.86093306e-04   2.01041603e+01] 4.20669058633e-22\n",
      "positions (x,y,z), reward: [ -1.34661874e+00  -1.86190206e-03   1.60288958e+01] 4.9098490216e-35\n",
      "Episode =   99, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.11351884e-03   1.40887625e-08   2.00201167e+01] 0.788859671424\n",
      "positions (x,y,z), reward: [ -1.94051480e-01  -1.23864414e-05   2.02149585e+01] 1.06804625952e-07\n",
      "positions (x,y,z), reward: [ -3.90625077e-01  -1.11381750e-04   2.01145192e+01] 5.24267292534e-22\n",
      "positions (x,y,z), reward: [ -6.46182309e-01  -4.07513104e-04   1.95989857e+01] 1.08119084367e-31\n",
      "positions (x,y,z), reward: [ -1.39328093e+00  -4.26570425e-03   1.58046271e+01] 5.61464500737e-35\n",
      "positions (x,y,z), reward: [ -1.64132495e+00  -5.35584985e-03   1.30783182e+01] 1.66518370321e-35\n",
      "Episode =  100, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.09248367e+00   7.69068494e-04   1.70686346e+01] 1.51555257587e-33\n",
      "positions (x,y,z), reward: [ -1.63520752e+00   4.22719305e-03   1.22225900e+01] 5.73638314834e-36\n",
      "Episode =  101, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.43013381e-01   7.01191920e-04   2.00144699e+01] 3.64362972282e-23\n",
      "positions (x,y,z), reward: [ -6.19865043e-01  -8.99803746e-04   1.97310211e+01] 4.43437720253e-32\n",
      "positions (x,y,z), reward: [ -1.33716291e+00  -3.61988829e-03   1.58478252e+01] 5.85725107073e-35\n",
      "positions (x,y,z), reward: [ -1.51721060e+00   5.35497016e-03   1.43085789e+01] 1.0307096137e-35\n",
      "positions (x,y,z), reward: [ -1.57388333e+00  -7.66337826e-03   1.33564001e+01] 1.12002717228e-35\n",
      "positions (x,y,z), reward: [-2.27244705 -0.08121261  3.68588365] 2.73960043753e-38\n",
      "Episode =  102, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.46044556e-01  -1.00569364e-03   2.00940307e+01] 4.42270244755e-22\n",
      "positions (x,y,z), reward: [ -5.35570115e-01  -1.26603453e-03   2.00428042e+01] 7.80270850409e-23\n",
      "positions (x,y,z), reward: [ -1.43553313e+00  -2.07760969e-03   1.52450924e+01] 1.74575201802e-34\n",
      "positions (x,y,z), reward: [ -1.93532438  -0.01751455  10.25447047] 1.97641008799e-36\n",
      "Episode =  103, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.01280067e-01  -1.60518831e-05   2.02539840e+01] 3.45361276633e-21\n",
      "positions (x,y,z), reward: [ -6.18411095e-01   3.92844203e-05   1.97983296e+01] 2.99320466181e-32\n",
      "positions (x,y,z), reward: [ -1.80994663  -0.02822697  10.86331665] 1.11121237686e-36\n",
      "positions (x,y,z), reward: [-2.23207276 -0.09128743  5.13235667] 2.2942893162e-38\n",
      "positions (x,y,z), reward: [-2.49919959 -0.2470022   0.39603539] 2.97185136454e-39\n",
      "Episode =  104, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.70215593e-01   2.76740412e-04   1.93717935e+01] 1.55944106816e-32\n",
      "positions (x,y,z), reward: [ -1.13741896e+00   1.53721950e-03   1.74573314e+01] 6.50702248149e-34\n",
      "positions (x,y,z), reward: [ -1.63085754e+00   3.63980426e-03   1.33161731e+01] 1.13231485896e-35\n",
      "positions (x,y,z), reward: [ -1.87522548e+00   1.75637807e-03   1.08176985e+01] 1.03497832052e-36\n",
      "positions (x,y,z), reward: [-2.27523506 -0.01571344  5.39701497] 3.07773415809e-38\n",
      "positions (x,y,z), reward: [-2.31329096 -0.01539132  5.0426741 ] 1.71383324874e-38\n",
      "positions (x,y,z), reward: [-2.3949924  -0.02264243  2.55324398] 2.23507423235e-38\n",
      "Episode =  105, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.85783316e-01   5.79616493e-04   2.01400340e+01] 3.62975458704e-22\n",
      "positions (x,y,z), reward: [ -1.33107795e+00  -1.32138234e-03   1.62216183e+01] 5.33502719445e-35\n",
      "positions (x,y,z), reward: [ -1.36033234e+00   3.18607450e-03   1.56258846e+01] 8.70629460657e-35\n",
      "positions (x,y,z), reward: [ -1.41245889e+00  -6.53912922e-03   1.49033874e+01] 1.06566882807e-34\n",
      "positions (x,y,z), reward: [-1.86902512 -0.0233518   9.7510789 ] 1.99641083186e-36\n",
      "positions (x,y,z), reward: [-2.08806728 -0.04745712  6.68636099] 2.71405959329e-37\n",
      "positions (x,y,z), reward: [-2.14360419 -0.06845931  6.06170132] 1.20701968525e-37\n",
      "Episode =  106, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.54270708e-01   7.77549459e-06   2.01787285e+01] 1.69904197192e-06\n",
      "positions (x,y,z), reward: [ -3.88662535e-01  -2.38940178e-04   2.01371935e+01] 3.70796918727e-22\n",
      "positions (x,y,z), reward: [ -6.39387789e-01  -4.31377349e-04   1.96062309e+01] 1.07802354111e-31\n",
      "positions (x,y,z), reward: [ -1.38658424e+00  -1.22815614e-03   1.52645638e+01] 1.85321103223e-34\n",
      "positions (x,y,z), reward: [ -1.90237044e+00  -9.41653497e-04   9.75970138e+00] 2.01242498889e-36\n",
      "positions (x,y,z), reward: [ -2.14729351e+00  -2.40742901e-03   6.39598470e+00] 2.13567919656e-37\n",
      "Episode =  107, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.31431741e-01  -2.36197325e-04   2.01008045e+01] 4.81000109273e-22\n",
      "positions (x,y,z), reward: [ -1.39180830e+00  -1.24673095e-03   1.54442527e+01] 1.34782901121e-34\n",
      "positions (x,y,z), reward: [ -1.86192241e+00   3.09655321e-04   1.13937993e+01] 7.89179152787e-37\n",
      "Episode =  108, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.83749815e-01   5.06477972e-04   2.01919264e+01] 4.11809722474e-22\n",
      "positions (x,y,z), reward: [ -1.31882781e+00  -8.55041304e-03   1.65776331e+01] 1.77757938141e-34\n",
      "positions (x,y,z), reward: [ -1.68193159e+00  -4.07887187e-03   1.30702565e+01] 1.63097664713e-35\n",
      "positions (x,y,z), reward: [-1.96725528 -0.05254904  9.71504589] 1.7284451715e-36\n",
      "positions (x,y,z), reward: [-2.25695258 -0.14394268  5.99596444] 9.40643199144e-38\n",
      "positions (x,y,z), reward: [-2.43301692 -0.22164141  3.1300899 ] 1.91426683186e-38\n",
      "Episode =  109, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.58213165e-02   4.39215320e-06   2.00647875e+01] 0.0717156846862\n",
      "positions (x,y,z), reward: [ -3.97907586e-01  -5.74843292e-04   2.01100878e+01] 5.37848069822e-22\n",
      "positions (x,y,z), reward: [ -1.17297576e+00  -1.98571775e-03   1.74363350e+01] 7.10745412826e-34\n",
      "positions (x,y,z), reward: [ -1.23209634e+00   3.61520257e-03   1.68867887e+01] 8.64588947488e-34\n",
      "positions (x,y,z), reward: [ -1.93659962e+00  -1.92691124e-03   1.07853662e+01] 1.10926276267e-36\n",
      "Episode =  110, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.69201369e-01   1.20771749e-05   2.01956378e+01] 3.55606995649e-07\n",
      "positions (x,y,z), reward: [ -1.47768667e+00   1.36590491e-03   1.45130114e+01] 2.12768403792e-35\n",
      "positions (x,y,z), reward: [ -2.46218157e+00   8.61589897e-04   1.07177882e+00] 2.3902891828e-39\n",
      "positions (x,y,z), reward: [ -2.49623013e+00   2.27673151e-03   2.66700858e-01] 2.41708922965e-39\n",
      "Episode =  111, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.91693889e-01  -1.78560466e-03   1.88181955e+01] 5.48034636313e-33\n",
      "positions (x,y,z), reward: [ -9.41180066e-01   8.59386709e-04   1.84399053e+01] 8.16154039447e-33\n",
      "positions (x,y,z), reward: [ -9.82810214e-01   1.47040537e-03   1.83346577e+01] 3.89023361867e-33\n",
      "positions (x,y,z), reward: [ -1.14036046e+00  -1.96421813e-03   1.74520165e+01] 6.74740858849e-34\n",
      "positions (x,y,z), reward: [ -1.16312151e+00   4.01851821e-05   1.70410260e+01] 1.40824814201e-33\n",
      "positions (x,y,z), reward: [ -1.38816776e+00  -2.06721436e-03   1.58080119e+01] 5.92039351559e-35\n",
      "positions (x,y,z), reward: [ -1.39514517e+00  -9.96879798e-04   1.52534498e+01] 1.8010097339e-34\n",
      "positions (x,y,z), reward: [ -1.78806921e+00   2.08768958e-03   1.19227752e+01] 2.2659856192e-36\n",
      "positions (x,y,z), reward: [ -1.88011669e+00  -4.06838702e-03   1.05361866e+01] 1.5245590788e-36\n",
      "positions (x,y,z), reward: [ -1.94888763e+00   1.16148297e-03   9.47190257e+00] 1.04511786647e-36\n",
      "positions (x,y,z), reward: [ -2.12268069e+00  -4.86569276e-03   7.29776824e+00] 1.93881414557e-37\n",
      "positions (x,y,z), reward: [-2.36130599 -0.0061501   3.9504911 ] 1.97488222866e-38\n",
      "Episode =  112, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.28467323e-01  -2.67851753e-05   2.01578304e+01] 3.36283739763e-05\n",
      "positions (x,y,z), reward: [ -2.70392874e-01  -1.35778399e-04   2.02512908e+01] 1.52082823067e-13\n",
      "positions (x,y,z), reward: [ -4.09462683e-01  -3.92421595e-04   2.01063082e+01] 1.48383879484e-17\n",
      "positions (x,y,z), reward: [ -7.85414323e-01  -3.50475790e-03   1.93719144e+01] 1.54457530919e-32\n",
      "positions (x,y,z), reward: [ -1.40607509e+00   1.85375767e-03   1.56263670e+01] 9.09140847828e-35\n",
      "positions (x,y,z), reward: [ -1.41424999e+00  -3.51780396e-03   1.52655513e+01] 1.75671044135e-34\n",
      "positions (x,y,z), reward: [ -1.60167730e+00  -1.27240033e-02   1.42738690e+01] 9.51708079943e-36\n",
      "positions (x,y,z), reward: [-2.10722991 -0.04732114  8.58576236] 1.37975559425e-37\n",
      "positions (x,y,z), reward: [-2.14868521 -0.04380773  7.94041529] 1.14758808269e-37\n",
      "positions (x,y,z), reward: [-2.41368484 -0.12261382  2.89321775] 2.92594923077e-38\n",
      "Episode =  113, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.78320337e-01  -2.41799344e-04   1.91513169e+01] 3.53889214023e-33\n",
      "positions (x,y,z), reward: [ -1.27168317e+00  -5.72867592e-04   1.67355268e+01] 4.33830980242e-34\n",
      "positions (x,y,z), reward: [ -1.42665218e+00  -9.56486190e-04   1.54112173e+01] 1.3966126362e-34\n",
      "positions (x,y,z), reward: [ -2.18064917e+00  -7.32339695e-04   7.26794253e+00] 2.01209406087e-37\n",
      "positions (x,y,z), reward: [ -2.25662843e+00  -2.25225264e-03   6.02976584e+00] 1.13653303482e-37\n",
      "positions (x,y,z), reward: [ -2.42609592e+00  -3.15533951e-04   3.56246728e+00] 2.54658526568e-38\n",
      "Episode =  114, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.62304545e-01   2.09632940e-04   2.02546556e+01] 1.64384302267e-13\n",
      "positions (x,y,z), reward: [ -9.65376604e-01   4.40468854e-03   1.83413207e+01] 4.09171805848e-33\n",
      "positions (x,y,z), reward: [ -1.30517569e+00   5.15601377e-03   1.64134655e+01] 8.66181415564e-35\n",
      "Episode =  115, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.79481647e-02  -7.07513910e-08   2.00412807e+01] 0.414322693054\n",
      "positions (x,y,z), reward: [ -5.96948301e-01   4.34763993e-04   1.96730217e+01] 6.67953929685e-32\n",
      "positions (x,y,z), reward: [ -1.02473347e+00   9.48626456e-05   1.79604576e+01] 4.5607907543e-34\n",
      "positions (x,y,z), reward: [ -1.29804466e+00   7.50252145e-04   1.51167994e+01] 1.66214170934e-34\n",
      "positions (x,y,z), reward: [ -1.78432701e+00   3.33335930e-03   9.52960722e+00] 1.19761648145e-36\n",
      "positions (x,y,z), reward: [ -1.95040135e+00  -4.05258611e-03   7.99908025e+00] 1.04862096454e-37\n",
      "Episode =  116, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.00205863e-01   1.83038508e-05   2.02544813e+01] 3.48806637186e-21\n",
      "positions (x,y,z), reward: [ -3.88567817e-01   2.11686200e-05   2.01119478e+01] 1.48708950232e-17\n",
      "positions (x,y,z), reward: [ -4.97872361e-01  -8.19063451e-05   2.00605877e+01] 8.60518101241e-23\n",
      "positions (x,y,z), reward: [ -6.18764382e-01   1.65533510e-04   1.96162153e+01] 1.0857839315e-31\n",
      "positions (x,y,z), reward: [ -9.87941940e-01  -2.14901366e-03   1.82380151e+01] 1.84352658473e-33\n",
      "Episode =  117, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.73425148e-01  -2.45376605e-03   2.00807452e+01] 2.03675454157e-22\n",
      "positions (x,y,z), reward: [ -1.16793315e+00  -4.34027475e-03   1.70414534e+01] 1.38539315704e-33\n",
      "positions (x,y,z), reward: [-2.24887154 -0.14944599  5.68936643] 5.12931955243e-38\n",
      "positions (x,y,z), reward: [-2.37147158 -0.16495509  4.25110376] 1.15966483787e-38\n",
      "Episode =  118, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.22669224e-01   4.54584121e-06   2.01608654e+01] 3.7241949102e-05\n",
      "positions (x,y,z), reward: [ -1.10243372e+00   5.44924101e-06   1.71905668e+01] 1.39604858707e-33\n",
      "positions (x,y,z), reward: [ -1.23120203e+00   8.92988786e-04   1.66091583e+01] 2.03261529357e-34\n",
      "positions (x,y,z), reward: [ -1.33920198e+00  -3.20444332e-04   1.56387769e+01] 8.19075001641e-35\n",
      "positions (x,y,z), reward: [ -1.58030396e+00  -1.02835389e-05   1.28888344e+01] 2.13840592472e-35\n",
      "positions (x,y,z), reward: [ -1.62922500e+00   4.10306993e-04   1.24440960e+01] 1.18546490215e-35\n",
      "positions (x,y,z), reward: [ -1.95340583e+00  -2.36890495e-04   8.92423794e+00] 2.91025986541e-37\n",
      "positions (x,y,z), reward: [ -1.99345834e+00   2.66245909e-04   8.61390136e+00] 1.48268944106e-37\n",
      "positions (x,y,z), reward: [ -2.28007913e+00  -8.90111318e-04   2.93545947e+00] 3.447084331e-38\n",
      "Episode =  119, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.69860633e-01  -9.35950844e-07   2.01960998e+01] 3.58397913227e-07\n",
      "positions (x,y,z), reward: [ -3.01781358e-01  -1.87082248e-05   2.02538588e+01] 3.61696022251e-21\n",
      "positions (x,y,z), reward: [ -8.55569645e-01   6.76971709e-04   1.90624845e+01] 2.92608445237e-33\n",
      "positions (x,y,z), reward: [ -8.67768865e-01   5.96704964e-04   1.86362399e+01] 1.25315410356e-32\n",
      "Episode =  120, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.74185260e-01  -1.69995125e-03   1.94716576e+01] 4.56607001653e-32\n",
      "positions (x,y,z), reward: [ -1.57408245  -0.01809282  12.48058494] 1.17338297238e-35\n",
      "positions (x,y,z), reward: [ -1.73047491  -0.01766323  11.44686572] 8.2072964674e-37\n",
      "positions (x,y,z), reward: [-1.84593338 -0.04665861  9.2578855 ] 6.03052656933e-37\n",
      "positions (x,y,z), reward: [-2.19915697 -0.11134163  4.00982796] 1.66316178353e-38\n",
      "Episode =  121, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534402] 0.893060451718\n",
      "positions (x,y,z), reward: [ -3.02954297e-01   2.52518498e-06   2.02530210e+01] 3.36083991573e-21\n",
      "positions (x,y,z), reward: [ -3.78486845e-01   2.13696179e-05   2.01696634e+01] 3.20853594427e-22\n",
      "positions (x,y,z), reward: [ -4.17576680e-01   2.89179094e-04   2.01070959e+01] 4.44766219548e-22\n",
      "positions (x,y,z), reward: [ -1.34382277e+00  -1.60692801e-04   1.58432303e+01] 6.16926970752e-35\n",
      "positions (x,y,z), reward: [ -2.05154784e+00   2.63312766e-03   7.35517624e+00] 1.99394725164e-37\n",
      "positions (x,y,z), reward: [ -2.11974649e+00   1.45790111e-03   6.12105837e+00] 1.1702381619e-37\n",
      "positions (x,y,z), reward: [ -2.50726164e+00   1.97396507e-03   0.00000000e+00] 2.87185463923e-39\n",
      "Episode =  122, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.00849473e-01  -3.52812024e-05   2.01249382e+01] 3.90040646029e-22\n",
      "positions (x,y,z), reward: [ -6.61193014e-01  -3.28379066e-04   1.97684922e+01] 3.12629714519e-32\n",
      "positions (x,y,z), reward: [ -1.18536973e+00  -1.43300098e-03   1.72890245e+01] 1.17825987484e-33\n",
      "positions (x,y,z), reward: [ -1.67751441e+00   1.52935997e-04   1.39962262e+01] 6.37305152669e-36\n",
      "Episode =  123, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.78858878e-02  -7.11008467e-06   2.00972809e+01] 0.00950490853957\n",
      "positions (x,y,z), reward: [-2.14265926 -0.0155325   8.25254572] 1.0665066936e-37\n",
      "Episode =  124, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.00241863e-01   2.34732383e-06   2.01312802e+01] 0.000409726676481\n",
      "positions (x,y,z), reward: [ -1.25008217e-01   3.53431934e-06   2.01587577e+01] 3.58427434931e-05\n",
      "positions (x,y,z), reward: [ -4.22958239e-01   5.67168914e-05   2.00980849e+01] 4.64760541022e-22\n",
      "positions (x,y,z), reward: [ -7.11632455e-01   3.87532248e-04   1.94468140e+01] 4.19967805781e-32\n",
      "positions (x,y,z), reward: [ -8.40838803e-01   3.31242615e-05   1.91695832e+01] 3.82567412577e-33\n",
      "positions (x,y,z), reward: [ -1.21056017e+00   1.15109650e-03   1.67577883e+01] 4.67456706741e-34\n",
      "positions (x,y,z), reward: [ -1.41763944e+00   1.06964412e-03   1.48999264e+01] 1.0184895988e-34\n",
      "positions (x,y,z), reward: [ -1.59962537e+00  -3.16841873e-04   1.37922507e+01] 6.00588985007e-36\n",
      "positions (x,y,z), reward: [ -1.75147612e+00   1.86822277e-03   1.19325239e+01] 2.41650162854e-36\n",
      "positions (x,y,z), reward: [ -2.15113577e+00   1.74072083e-03   6.07197831e+00] 1.21312267323e-37\n",
      "positions (x,y,z), reward: [ -2.19303528e+00   1.90719859e-03   5.74427442e+00] 6.28325277262e-38\n",
      "positions (x,y,z), reward: [ -2.35423780e+00   1.68201281e-03   2.55999640e+00] 2.31057879547e-38\n",
      "Episode =  125, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.57537310e-01  -6.69689209e-04   1.99602354e+01] 3.85256573138e-32\n",
      "positions (x,y,z), reward: [ -1.71039629  -0.02174361  11.43772109] 7.98343390643e-37\n",
      "Episode =  126, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -9.98113108e-01  -5.52992470e-03   1.82455406e+01] 1.63572809918e-33\n",
      "positions (x,y,z), reward: [-1.97013558 -0.05385739  8.94625946] 2.54088779574e-37\n",
      "positions (x,y,z), reward: [-2.03483975 -0.04867892  8.31254504] 1.04490737028e-37\n",
      "positions (x,y,z), reward: [-2.06146285 -0.0758393   6.73791539] 2.62312640282e-37\n",
      "positions (x,y,z), reward: [-2.16438037 -0.11155931  5.77956925] 5.38440990268e-38\n",
      "Episode =  127, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.52398989e-01  -1.52310754e-03   1.91698850e+01] 3.83585915829e-33\n",
      "positions (x,y,z), reward: [ -1.84823289  -0.02629459  11.3841292 ] 7.99249172223e-37\n",
      "positions (x,y,z), reward: [ -1.86530153  -0.02372244  11.10055417] 8.01951565149e-37\n",
      "positions (x,y,z), reward: [-1.97774894 -0.05019023  9.19368265] 5.84157272369e-37\n",
      "positions (x,y,z), reward: [-2.35092601 -0.105822    3.24002787] 2.95717197487e-38\n",
      "Episode =  128, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.62015015e-01  -8.94125984e-04   1.95645324e+01] 1.13197608413e-31\n",
      "positions (x,y,z), reward: [ -8.84945376e-01   5.25701461e-04   1.90562326e+01] 2.91796435387e-33\n",
      "positions (x,y,z), reward: [ -1.03773504e+00  -4.78145274e-03   1.82265381e+01] 1.57380725675e-33\n",
      "positions (x,y,z), reward: [ -1.50268236e+00  -1.41687207e-02   1.47219913e+01] 4.25897889739e-35\n",
      "positions (x,y,z), reward: [ -1.90535316  -0.03313971  10.03140715] 2.34931900897e-36\n",
      "positions (x,y,z), reward: [-2.36719292 -0.1309625   4.66928899] 1.21003238894e-38\n",
      "Episode =  129, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.67861142e-01   2.11368559e-04   1.86381047e+01] 1.25583529361e-32\n",
      "positions (x,y,z), reward: [ -1.59471098e+00  -1.21799296e-04   1.28908260e+01] 2.16896249923e-35\n",
      "positions (x,y,z), reward: [ -1.61277720e+00  -1.92748856e-03   1.26714750e+01] 1.95096817991e-35\n",
      "positions (x,y,z), reward: [ -1.68594259e+00  -4.52282060e-03   1.22085048e+01] 5.8034067624e-36\n",
      "positions (x,y,z), reward: [ -1.77284894e+00  -3.61698193e-03   1.16886801e+01] 1.29708556217e-36\n",
      "positions (x,y,z), reward: [ -1.88683537e+00  -6.55023110e-03   9.50516879e+00] 1.24338945988e-36\n",
      "positions (x,y,z), reward: [-2.16783245 -0.0133489   5.77172168] 6.88108279447e-38\n",
      "positions (x,y,z), reward: [-2.29538042 -0.01257765  3.99280825] 1.97982774575e-38\n",
      "Episode =  130, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.01473171e-01   4.34196860e-06   2.01310249e+01] 0.000409145289125\n",
      "positions (x,y,z), reward: [ -1.54768694e-01   6.24066777e-06   2.01783409e+01] 1.6513711827e-06\n",
      "positions (x,y,z), reward: [ -6.38012916e-01  -2.45374299e-04   1.96105220e+01] 1.12007982208e-31\n",
      "positions (x,y,z), reward: [ -1.84641484e+00  -5.38143264e-03   1.13956870e+01] 7.88596256045e-37\n",
      "positions (x,y,z), reward: [-2.34692189 -0.06825452  3.29302706] 3.6095795036e-38\n",
      "positions (x,y,z), reward: [-2.56600756 -0.10698767  0.68953404] 2.31639611654e-39\n",
      "Episode =  131, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.40546218e-01   6.79856427e-05   2.02311647e+01] 8.90737127267e-22\n",
      "positions (x,y,z), reward: [ -8.58973013e-01  -5.40930443e-04   1.89450038e+01] 3.60056770203e-33\n",
      "positions (x,y,z), reward: [ -9.04955492e-01   3.55371975e-04   1.84577019e+01] 8.73817806638e-33\n",
      "positions (x,y,z), reward: [ -1.33088567e+00  -1.10046013e-03   1.60322287e+01] 4.58212041338e-35\n",
      "positions (x,y,z), reward: [ -1.56979436e+00  -2.34610852e-03   1.38117719e+01] 6.13329406004e-36\n",
      "positions (x,y,z), reward: [ -1.81110709e+00  -6.00350588e-03   1.03039070e+01] 2.11314086254e-36\n",
      "positions (x,y,z), reward: [-2.48928249 -0.05130446  0.6865703 ] 2.01887951861e-39\n",
      "positions (x,y,z), reward: [-2.50072407 -0.0634951   0.        ] 2.96797462483e-39\n",
      "Episode =  132, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.47606233e-02  -3.27751425e-07   2.00658663e+01] 0.0760243679944\n",
      "positions (x,y,z), reward: [ -3.72688946e-01  -7.71627256e-05   2.02006413e+01] 4.25411154509e-22\n",
      "positions (x,y,z), reward: [ -1.21674303e+00   4.54738665e-03   1.67553736e+01] 4.82760966984e-34\n",
      "positions (x,y,z), reward: [ -1.58950466e+00   1.25120665e-03   1.40342826e+01] 6.48432659239e-36\n",
      "positions (x,y,z), reward: [ -1.61683183e+00  -3.41816975e-03   1.35502985e+01] 7.53257785023e-36\n",
      "positions (x,y,z), reward: [-2.48670946 -0.01001709  1.44013005] 4.04914136372e-39\n",
      "Episode =  133, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.73820535e-02   1.17736238e-05   2.00976745e+01] 0.00967508254238\n",
      "positions (x,y,z), reward: [ -4.07719836e-01   3.31247724e-04   2.01026545e+01] 1.39937136496e-17\n",
      "positions (x,y,z), reward: [ -1.89150048  -0.01391731  10.26733459] 2.15095358385e-36\n",
      "Episode =  134, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.05046996e+00  -1.66407043e-03   1.79594360e+01] 4.38420981698e-34\n",
      "positions (x,y,z), reward: [ -1.60100916  -0.02009597  12.46976776] 1.10866627154e-35\n",
      "positions (x,y,z), reward: [-2.45524651 -0.25677071  0.21499616] 1.37685615084e-39\n",
      "Episode =  135, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.78914171e-02   6.43384397e-06   2.00971682e+01] 0.00951454781244\n",
      "positions (x,y,z), reward: [ -8.96805099e-01  -1.57658231e-04   1.90372471e+01] 2.80197052849e-33\n",
      "positions (x,y,z), reward: [ -1.89924963e+00   3.33950944e-04   1.13528216e+01] 7.75076537887e-37\n",
      "positions (x,y,z), reward: [ -1.99390118e+00   3.25628735e-03   9.45117080e+00] 1.01813543526e-36\n",
      "positions (x,y,z), reward: [ -2.16424491e+00  -2.31569567e-03   7.90845541e+00] 1.133348076e-37\n",
      "positions (x,y,z), reward: [ -2.20962388e+00   1.85141656e-03   6.35438795e+00] 2.05315445164e-37\n",
      "Episode =  136, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.94667527e-01   5.66585808e-04   1.85399903e+01] 1.29378987142e-32\n",
      "positions (x,y,z), reward: [ -9.62840505e-01   1.97986144e-03   1.83429684e+01] 4.50439981673e-33\n",
      "positions (x,y,z), reward: [ -1.61145112e+00  -6.61227829e-03   1.35597292e+01] 7.48017064793e-36\n",
      "Episode =  137, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.92240637e-01   4.51882658e-04   1.92936213e+01] 6.69522371448e-33\n",
      "positions (x,y,z), reward: [ -8.28745179e-01   8.50952201e-05   1.91855154e+01] 3.61176843395e-33\n",
      "positions (x,y,z), reward: [ -8.78242328e-01   1.96426217e-04   1.85567624e+01] 1.30315733848e-32\n",
      "positions (x,y,z), reward: [ -1.03762011e+00   9.02653456e-04   1.81016554e+01] 7.72559088174e-34\n",
      "positions (x,y,z), reward: [ -1.55700169e+00   6.65429006e-04   1.40662351e+01] 6.55886318179e-36\n",
      "positions (x,y,z), reward: [ -1.68106958e+00   2.51752402e-03   1.22220145e+01] 5.26688418965e-36\n",
      "positions (x,y,z), reward: [ -2.47265583e+00   9.49484942e-04   1.09777667e+00] 2.19183867537e-39\n",
      "positions (x,y,z), reward: [ -2.49587983e+00  -6.89997911e-04   6.95453304e-01] 1.85847617357e-39\n",
      "Episode =  138, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.51309827e-01  -1.88583242e-05   2.01815711e+01] 1.71876331149e-06\n",
      "positions (x,y,z), reward: [ -1.24403956e+00  -3.33183155e-03   1.66299797e+01] 1.87906488895e-34\n",
      "positions (x,y,z), reward: [ -1.34850453e+00   2.59680486e-04   1.53034618e+01] 1.92111017422e-34\n",
      "positions (x,y,z), reward: [ -1.40048701e+00  -4.74208205e-03   1.49464708e+01] 9.98140744655e-35\n",
      "positions (x,y,z), reward: [ -1.44295858e+00  -6.04124139e-03   1.47520590e+01] 4.69032572871e-35\n",
      "positions (x,y,z), reward: [ -1.53014069e+00  -4.14866633e-03   1.43161811e+01] 9.95898347376e-36\n",
      "positions (x,y,z), reward: [ -1.68673519e+00  -1.22050876e-02   1.22383101e+01] 5.10497588797e-36\n",
      "positions (x,y,z), reward: [-2.32502153 -0.1075677   2.60866048] 2.06699838e-38\n",
      "Episode =  139, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.24868949e-01  -9.78939281e-05   2.02421045e+01] 2.1070463669e-08\n",
      "positions (x,y,z), reward: [ -1.39304291e+00  -2.20767708e-03   1.52879609e+01] 1.82126058885e-34\n",
      "positions (x,y,z), reward: [ -1.66469386e+00  -7.18940216e-03   1.26853508e+01] 1.72445327282e-35\n",
      "positions (x,y,z), reward: [ -1.78967565e+00  -9.91676037e-03   1.19625331e+01] 2.13054127227e-36\n",
      "positions (x,y,z), reward: [-2.03881827 -0.01466314  8.93413681] 2.4646801939e-37\n",
      "positions (x,y,z), reward: [-2.59073893 -0.03474263  0.2836569 ] 2.44556052486e-39\n",
      "Episode =  140, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.49932904e-02   2.09057410e-05   2.00998753e+01] 0.0103480408523\n",
      "positions (x,y,z), reward: [ -9.86008576e-02   3.70429604e-05   2.01328159e+01] 0.000417400354866\n",
      "Episode =  141, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.77257580e-01  -7.27628366e-05   2.01952593e+01] 4.0714907422e-22\n",
      "positions (x,y,z), reward: [ -8.61157584e-01  -2.29867445e-04   1.91667280e+01] 3.61665343368e-33\n",
      "positions (x,y,z), reward: [ -1.54561164e+00  -6.52362419e-03   1.44961494e+01] 2.05419474084e-35\n",
      "positions (x,y,z), reward: [-2.36073665 -0.03905646  4.67899411] 1.41538861787e-38\n",
      "Episode =  142, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.41846098e+00   4.92604699e-03   1.47249872e+01] 4.94283281174e-35\n",
      "positions (x,y,z), reward: [ -1.65891660e+00   4.57510830e-03   1.22067481e+01] 5.50091216567e-36\n",
      "positions (x,y,z), reward: [ -2.03595402e+00  -4.10018417e-03   6.71834923e+00] 3.0369893465e-37\n",
      "Episode =  143, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.28553899e-01  -2.02129639e-03   1.96547270e+01] 7.05216291754e-32\n",
      "positions (x,y,z), reward: [ -6.41674520e-01   2.08209422e-04   1.95536343e+01] 1.19268884851e-31\n",
      "positions (x,y,z), reward: [-2.08272512 -0.01324858  6.68326165] 2.70999721387e-37\n",
      "Episode =  144, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.82055683e-01   1.42015817e-04   2.01174807e+01] 1.52307530142e-17\n",
      "positions (x,y,z), reward: [ -6.25128955e-01   9.69982147e-04   1.96686044e+01] 8.02710039091e-32\n",
      "positions (x,y,z), reward: [ -1.17074376e+00  -1.56509201e-03   1.69361651e+01] 8.64772968463e-34\n",
      "positions (x,y,z), reward: [ -1.57860813e+00  -2.65562583e-03   1.40647853e+01] 6.21816222239e-36\n",
      "positions (x,y,z), reward: [ -2.07715738e+00  -4.96551289e-03   7.67005257e+00] 1.57593132953e-37\n",
      "positions (x,y,z), reward: [-2.39037754 -0.00596733  2.25687091] 1.15473833747e-38\n",
      "positions (x,y,z), reward: [-2.5290222  -0.00554927  0.69988004] 1.94175511957e-39\n",
      "positions (x,y,z), reward: [-2.53992025 -0.00583139  0.        ] 3.45053578734e-39\n",
      "Episode =  145, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.47729744e-02  -1.40085226e-06   2.00659136e+01] 0.0755911431753\n",
      "positions (x,y,z), reward: [ -1.55989918e+00  -8.78350572e-04   1.42760464e+01] 9.9761218575e-36\n",
      "Episode =  146, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.44267274e-02  -1.79836650e-06   2.00662231e+01] 0.0767665015704\n",
      "positions (x,y,z), reward: [ -6.19945023e-01   4.76328392e-04   1.97950870e+01] 3.05476272086e-32\n",
      "positions (x,y,z), reward: [ -8.61012754e-01   5.55660763e-04   1.89477335e+01] 3.68970049432e-33\n",
      "positions (x,y,z), reward: [ -2.04818700e+00  -3.01647721e-03   7.03883753e+00] 2.67557840779e-37\n",
      "positions (x,y,z), reward: [ -2.08094718e+00  -5.10592565e-03   6.42799540e+00] 2.13833989763e-37\n",
      "positions (x,y,z), reward: [-2.23802793 -0.0058318   5.08868769] 1.76379557757e-38\n",
      "Episode =  147, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.43773252e-02   2.53287098e-07   2.00663613e+01] 0.0764010839451\n",
      "positions (x,y,z), reward: [ -2.20078505e-01  -1.62491041e-05   2.02443062e+01] 2.22395885105e-08\n",
      "positions (x,y,z), reward: [ -1.08538977e+00   6.72581534e-04   1.79460087e+01] 4.34236085314e-34\n",
      "positions (x,y,z), reward: [ -1.10642401e+00   9.57095533e-04   1.77870899e+01] 3.75191429461e-34\n",
      "positions (x,y,z), reward: [ -1.62546924e+00   3.98497957e-04   1.26820805e+01] 1.83347437614e-35\n",
      "positions (x,y,z), reward: [ -2.30701287e+00  -2.10775141e-03   3.64891954e+00] 2.61466397103e-38\n",
      "positions (x,y,z), reward: [ -2.52318028e+00  -2.51342212e-03   6.86391208e-01] 1.9157491144e-39\n",
      "positions (x,y,z), reward: [-2.53311427 -0.00315637  0.28453787] 2.33206034556e-39\n",
      "Episode =  148, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.55050743e-02   6.38665955e-07   2.00651778e+01] 0.0725322762643\n",
      "positions (x,y,z), reward: [ -6.41974295e-01  -3.90555317e-04   1.98547309e+01] 2.69726093716e-32\n",
      "Episode =  149, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.66260818e-01  -5.83448324e-05   2.01735711e+01] 3.15740505734e-22\n",
      "positions (x,y,z), reward: [ -1.05836939e+00  -3.96187421e-04   1.72134780e+01] 1.57620307506e-33\n",
      "positions (x,y,z), reward: [ -1.10379496e+00   1.85290087e-03   1.69444124e+01] 9.59164709557e-34\n",
      "positions (x,y,z), reward: [ -2.06805426e+00  -9.07965019e-04   5.81065701e+00] 6.39386967697e-38\n",
      "Episode =  150, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.27316445e+00   2.37940293e-04   1.66029960e+01] 1.98934115015e-34\n",
      "positions (x,y,z), reward: [ -1.61675604e+00   2.58788363e-03   1.38041700e+01] 6.12928734021e-36\n",
      "positions (x,y,z), reward: [ -1.63102582e+00   1.02459967e-03   1.28852496e+01] 2.15184878144e-35\n",
      "positions (x,y,z), reward: [ -2.10261165e+00  -2.86478029e-03   7.95953585e+00] 1.14339391866e-37\n",
      "Episode =  151, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.03546485e+00  -1.84103592e-03   1.82201158e+01] 1.67646370986e-33\n",
      "positions (x,y,z), reward: [ -1.36732024e+00  -1.06760784e-03   1.62174367e+01] 5.10075308189e-35\n",
      "positions (x,y,z), reward: [ -1.38667922e+00  -9.55540262e-04   1.60165257e+01] 4.74871833687e-35\n",
      "positions (x,y,z), reward: [ -1.88818866e+00  -2.74530061e-03   1.05516358e+01] 1.55139303015e-36\n",
      "positions (x,y,z), reward: [ -2.53428103e+00  -8.07767908e-04   1.45018997e+00] 3.6646814159e-39\n",
      "Episode =  152, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.50731275e+00  -1.30243463e-03   1.40869869e+01] 6.94798265767e-36\n",
      "positions (x,y,z), reward: [ -1.75373899e+00  -1.84805642e-03   1.11630033e+01] 8.42354150423e-37\n",
      "positions (x,y,z), reward: [ -1.98242346e+00  -3.69163851e-03   7.07268122e+00] 2.63676171494e-37\n",
      "positions (x,y,z), reward: [ -2.04546364e+00  -3.60112267e-03   6.14766426e+00] 1.23312841846e-37\n",
      "positions (x,y,z), reward: [-2.20268339 -0.0052703   4.40286672] 1.59492860128e-38\n",
      "Episode =  153, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.49580442e-01   2.87114812e-05   2.01818289e+01] 1.75812167367e-06\n",
      "positions (x,y,z), reward: [ -2.41232879e+00  -1.97804653e-03   1.49443881e+00] 4.24638998534e-39\n",
      "Episode =  154, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.57266219e-01  -3.28080589e-05   2.02579631e+01] 2.76550930046e-11\n",
      "positions (x,y,z), reward: [ -9.13803509e-01   6.72225548e-05   1.84561107e+01] 8.48211939312e-33\n",
      "positions (x,y,z), reward: [ -1.10340791e+00   1.94550312e-04   1.77862061e+01] 3.44165825323e-34\n",
      "positions (x,y,z), reward: [ -1.29117209e+00   1.35522643e-04   1.64306544e+01] 8.47793479167e-35\n",
      "positions (x,y,z), reward: [ -1.77950926e+00  -1.02930706e-03   1.16892066e+01] 1.25180389662e-36\n",
      "positions (x,y,z), reward: [ -2.06376836e+00  -4.57558027e-04   7.97264959e+00] 1.16333841025e-37\n",
      "positions (x,y,z), reward: [-2.52827312 -0.00712073  0.        ] 3.26523606932e-39\n",
      "Episode =  155, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.84868118e-01  -1.41227427e-04   2.02641936e+01] 4.20547234238e-21\n",
      "positions (x,y,z), reward: [ -1.04293024e+00   6.54923076e-03   1.73582354e+01] 1.00240227319e-33\n",
      "positions (x,y,z), reward: [ -1.20760537e+00  -1.34804442e-02   1.64636826e+01] 1.05696544327e-34\n",
      "positions (x,y,z), reward: [ -1.27187877e+00   2.76720487e-03   1.58716009e+01] 5.73028979319e-35\n",
      "positions (x,y,z), reward: [-1.93994812 -0.18119654  6.68829473] 1.7630452758e-37\n",
      "Episode =  156, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.69129393e-01  -7.33251132e-05   2.01284637e+01] 4.92434262528e-22\n",
      "positions (x,y,z), reward: [-2.357216   -0.28162434  1.39949186] 2.94794699004e-39\n",
      "Episode =  157, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.86915351e-01  -2.06151332e-04   1.99459956e+01] 3.38397796814e-32\n",
      "Episode =  158, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.26656780e-01  -4.64783565e-04   2.00478509e+01] 7.5887309192e-23\n",
      "positions (x,y,z), reward: [ -6.10855028e-01   9.34995510e-05   1.99309437e+01] 3.35564891523e-32\n",
      "positions (x,y,z), reward: [ -7.86109770e-01  -1.91970527e-03   1.93673933e+01] 1.56433100642e-32\n",
      "positions (x,y,z), reward: [ -1.40785858e+00   5.14990020e-03   1.56166483e+01] 9.63704959155e-35\n",
      "positions (x,y,z), reward: [-1.97810336 -0.05244     9.46309975] 9.69159997987e-37\n",
      "Episode =  159, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.01284756e-01  -1.40891546e-05   2.01306356e+01] 0.000408823234702\n",
      "positions (x,y,z), reward: [ -8.96263376e-01   1.07986083e-03   1.88191296e+01] 5.25452959116e-33\n",
      "positions (x,y,z), reward: [ -1.19756174e+00   8.79260885e-04   1.69013021e+01] 9.38717047851e-34\n",
      "positions (x,y,z), reward: [ -1.64381521e+00  -1.94495850e-04   1.33091202e+01] 1.0985792767e-35\n",
      "positions (x,y,z), reward: [ -1.65130807e+00   1.04176774e-03   1.28617007e+01] 2.03517418891e-35\n",
      "positions (x,y,z), reward: [ -1.89089952e+00   1.28775175e-04   1.02679121e+01] 2.07726897482e-36\n",
      "positions (x,y,z), reward: [ -2.11256529e+00   1.20481858e-03   8.25736942e+00] 1.04001951934e-37\n",
      "positions (x,y,z), reward: [ -2.38704997e+00  -1.31823000e-03   2.89776883e+00] 3.33153178107e-38\n",
      "Episode =  160, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.77258165e-01  -1.11295358e-03   1.90545579e+01] 2.90791902832e-33\n",
      "positions (x,y,z), reward: [ -9.36576708e-01   2.75131464e-03   1.84473945e+01] 8.39915793387e-33\n",
      "positions (x,y,z), reward: [ -1.32189667e+00   4.32264551e-03   1.64164399e+01] 9.04099981648e-35\n",
      "positions (x,y,z), reward: [ -1.52994148e+00   7.73476974e-03   1.45037156e+01] 2.26262600624e-35\n",
      "positions (x,y,z), reward: [ -1.73434047e+00   3.76444983e-03   1.21953164e+01] 5.39012502115e-36\n",
      "positions (x,y,z), reward: [-2.06907135 -0.04062513  8.61721871] 1.79432478101e-37\n",
      "positions (x,y,z), reward: [-2.31394088 -0.12686232  5.12817167] 2.85648695096e-38\n",
      "positions (x,y,z), reward: [-2.47351268 -0.24295905  1.99574164] 1.53940005599e-38\n",
      "Episode =  161, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.83111869e-02   6.24844822e-07   2.00409689e+01] 0.407342579343\n",
      "positions (x,y,z), reward: [ -8.73698024e-01   1.47372658e-03   1.85517325e+01] 1.33734898172e-32\n",
      "positions (x,y,z), reward: [ -1.35528738e+00   1.99598449e-03   1.51059829e+01] 1.65318908108e-34\n",
      "positions (x,y,z), reward: [ -1.71316638e+00   3.82932796e-03   1.19628334e+01] 2.42857080989e-36\n",
      "positions (x,y,z), reward: [ -1.80046862  -0.01161005  11.1341359 ] 8.09631274977e-37\n",
      "positions (x,y,z), reward: [ -1.86538617e+00  -6.32398747e-03   9.51720972e+00] 1.18875290429e-36\n",
      "positions (x,y,z), reward: [-2.22359751 -0.04183226  5.10021053] 2.00843640223e-38\n",
      "positions (x,y,z), reward: [-2.47600508 -0.10533894  0.7172753 ] 2.11102651489e-39\n",
      "Episode =  162, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.83916517e-01  -3.28523739e-08   2.01142428e+01] 1.52186652235e-17\n",
      "positions (x,y,z), reward: [ -3.97447047e-01   4.99573742e-04   2.01110918e+01] 1.46770339899e-17\n",
      "positions (x,y,z), reward: [ -4.64797706e-01   1.39402163e-03   2.00890481e+01] 2.05608468796e-22\n",
      "positions (x,y,z), reward: [ -5.94645390e-01   6.11373565e-04   1.99411864e+01] 3.41649755879e-32\n",
      "positions (x,y,z), reward: [ -1.84828052e+00  -2.74369673e-03   1.08481728e+01] 1.09079875351e-36\n",
      "positions (x,y,z), reward: [ -2.08629604e+00  -7.25863375e-03   7.34198084e+00] 1.98279264142e-37\n",
      "positions (x,y,z), reward: [ -2.09804384e+00  -3.16555699e-03   6.72942232e+00] 2.86055183933e-37\n",
      "positions (x,y,z), reward: [-2.5517735  -0.04267846  0.        ] 2.91762408643e-39\n",
      "Episode =  163, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.20265882e-01   2.26220445e-04   2.02423067e+01] 2.21834542362e-08\n",
      "positions (x,y,z), reward: [ -3.83434595e-01  -8.32603127e-04   2.01398080e+01] 3.78933200386e-22\n",
      "positions (x,y,z), reward: [ -6.71134698e-01   2.10938774e-03   1.95166606e+01] 8.23566809294e-32\n",
      "positions (x,y,z), reward: [ -8.02722333e-01   2.55616039e-03   1.92866272e+01] 6.92022085553e-33\n",
      "positions (x,y,z), reward: [ -1.11872880e+00  -1.73748492e-04   1.71937994e+01] 1.62586686832e-33\n",
      "positions (x,y,z), reward: [ -1.35744770e+00  -4.01768536e-03   1.56404606e+01] 9.54555946289e-35\n",
      "positions (x,y,z), reward: [ -1.81574389e+00  -2.18368285e-03   1.14104661e+01] 8.6039534715e-37\n",
      "positions (x,y,z), reward: [ -1.83740986e+00  -9.94974564e-03   1.03060577e+01] 2.1911910818e-36\n",
      "positions (x,y,z), reward: [-2.0737862  -0.02263267  7.34267564] 1.98072633562e-37\n",
      "positions (x,y,z), reward: [-2.07478448 -0.02192238  7.03402931] 2.6051470944e-37\n",
      "positions (x,y,z), reward: [-2.10614164 -0.01621646  6.42311366] 2.20244713972e-37\n",
      "positions (x,y,z), reward: [-2.4619154  -0.05477626  1.49472969] 4.2083317752e-39\n",
      "Episode =  164, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.74737331e-01   3.01340438e-06   2.01939335e+01] 3.55985095865e-07\n",
      "positions (x,y,z), reward: [ -6.28067298e-01   7.73725200e-04   1.98615121e+01] 2.58308446699e-32\n",
      "positions (x,y,z), reward: [ -8.89674306e-01   3.47891136e-03   1.88271495e+01] 5.6080056845e-33\n",
      "positions (x,y,z), reward: [ -9.85292605e-01  -4.79380084e-03   1.83456702e+01] 3.74889448776e-33\n",
      "positions (x,y,z), reward: [ -1.38813714e+00   5.77835823e-03   1.58224864e+01] 6.41287569475e-35\n",
      "positions (x,y,z), reward: [ -1.86228854  -0.03034996  11.38445959] 7.99698201652e-37\n",
      "positions (x,y,z), reward: [ -1.87744894  -0.02556711  11.10150413] 8.25004714543e-37\n",
      "positions (x,y,z), reward: [-2.13900485 -0.13417429  6.65381859] 1.98216215249e-37\n",
      "Episode =  165, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.43250687e+00   6.07913947e-03   1.49186495e+01] 9.46334446124e-35\n",
      "positions (x,y,z), reward: [ -1.47527494e+00   8.25606768e-03   1.47240897e+01] 4.55112254887e-35\n",
      "positions (x,y,z), reward: [ -1.61864249e+00  -1.09005146e-02   1.31126795e+01] 1.76996543765e-35\n",
      "positions (x,y,z), reward: [ -1.86215372  -0.02246896  10.30536166] 2.24631220409e-36\n",
      "positions (x,y,z), reward: [-2.33538452 -0.0775407   4.37047672] 1.68222018767e-38\n",
      "positions (x,y,z), reward: [-2.53475069 -0.11922926  1.11266187] 2.51906872148e-39\n",
      "Episode =  166, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.72420704e-01   3.11864513e-05   2.01955659e+01] 3.58209722073e-07\n",
      "positions (x,y,z), reward: [ -3.79823485e-01  -1.58661450e-04   2.01232358e+01] 5.61735590536e-22\n",
      "positions (x,y,z), reward: [ -6.74437542e-01   7.73182683e-04   1.95218183e+01] 7.93728464139e-32\n",
      "positions (x,y,z), reward: [ -8.71181512e-01  -1.47658321e-03   1.87373856e+01] 9.74675777254e-33\n",
      "positions (x,y,z), reward: [ -1.55035538e+00   2.30722055e-03   1.42985834e+01] 9.42539888765e-36\n",
      "positions (x,y,z), reward: [ -1.60113096e+00  -3.35263573e-03   1.33488338e+01] 1.25209118285e-35\n",
      "positions (x,y,z), reward: [-2.31328986 -0.01690721  4.01129631] 2.17435705293e-38\n",
      "Episode =  167, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.00363105e-01  -4.68348973e-04   1.98766080e+01] 2.68184288075e-32\n",
      "positions (x,y,z), reward: [ -6.50289778e-01   1.18939189e-03   1.95246503e+01] 8.51750681737e-32\n",
      "positions (x,y,z), reward: [ -1.64995079e+00   2.02005598e-03   1.22271292e+01] 5.54936846534e-36\n",
      "positions (x,y,z), reward: [ -1.69447245e+00   1.88485453e-03   1.19740679e+01] 2.5514275078e-36\n",
      "positions (x,y,z), reward: [ -2.19927163e+00  -1.00741579e-03   5.10166259e+00] 1.84337169135e-38\n",
      "positions (x,y,z), reward: [-2.23980363 -0.00814791  3.66228231] 2.57885972192e-38\n",
      "Episode =  168, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534259] 0.893013477665\n",
      "positions (x,y,z), reward: [ -1.84262133e-02  -7.70892285e-08   2.00408422e+01] 0.405083995943\n",
      "positions (x,y,z), reward: [ -3.82312204e-01  -1.16132699e-04   2.01379129e+01] 3.65403976999e-22\n",
      "positions (x,y,z), reward: [ -1.10982810e+00   1.51294766e-03   1.76142860e+01] 4.47490276022e-34\n",
      "positions (x,y,z), reward: [ -2.16794744e+00  -3.58334463e-03   5.75133376e+00] 6.37550689437e-38\n",
      "positions (x,y,z), reward: [-2.32537728 -0.00444864  2.56764708] 2.29052781092e-38\n",
      "Episode =  169, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.88156794e-01  -3.30001029e-05   2.02188145e+01] 1.09877581543e-07\n",
      "positions (x,y,z), reward: [ -5.88401634e-01   6.46114269e-05   1.99437667e+01] 3.61740051068e-32\n",
      "positions (x,y,z), reward: [ -1.13187610e+00  -4.99735637e-05   1.70558886e+01] 1.43100277063e-33\n",
      "positions (x,y,z), reward: [ -1.59569810e+00   1.50589118e-03   1.33331460e+01] 1.11157056933e-35\n",
      "positions (x,y,z), reward: [ -1.86293312e+00  -5.83509035e-03   9.76945073e+00] 1.9979135086e-36\n",
      "positions (x,y,z), reward: [-1.98299513 -0.00926993  8.91874964] 2.74512327517e-37\n",
      "positions (x,y,z), reward: [-2.30024079 -0.01396007  4.34314854] 1.49075609024e-38\n",
      "Episode =  170, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.86013721e-01   7.84042406e-04   2.01630022e+01] 3.14793315177e-22\n",
      "positions (x,y,z), reward: [ -1.15022133e+00  -1.99790050e-03   1.70423076e+01] 1.51103367557e-33\n",
      "positions (x,y,z), reward: [ -1.51819312e+00  -1.11303549e-02   1.44940294e+01] 2.23441073014e-35\n",
      "positions (x,y,z), reward: [ -1.72043527  -0.01959374  12.18139676] 5.55185484209e-36\n",
      "Episode =  171, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.01601968e-01  -2.47373419e-05   2.02536227e+01] 3.30949232367e-21\n",
      "positions (x,y,z), reward: [ -3.64545658e-01   4.25052345e-04   2.02029427e+01] 4.12118026686e-22\n",
      "positions (x,y,z), reward: [ -8.55651801e-01   2.20270532e-03   1.87420107e+01] 9.14733186816e-33\n",
      "positions (x,y,z), reward: [-2.4896285  -0.00704288  0.        ] 2.76440933081e-39\n",
      "Episode =  172, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.77668078  -0.0179809   11.68043968] 1.46002964433e-36\n",
      "positions (x,y,z), reward: [ -1.83141664  -0.0617468   10.84807011] 1.12502072906e-36\n",
      "positions (x,y,z), reward: [ -1.83025431  -0.06930708  10.30793314] 2.04120861713e-36\n",
      "positions (x,y,z), reward: [-2.36963282 -0.35206628  2.48565169] 4.01129056727e-38\n",
      "Episode =  173, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.12188255e-01  -9.61622344e-04   1.97334914e+01] 4.74567081864e-32\n",
      "positions (x,y,z), reward: [-2.26203827 -0.00930523  2.98754033] 3.46438212714e-38\n",
      "positions (x,y,z), reward: [-2.36304892 -0.00743766  1.90578112] 7.1135675441e-39\n",
      "Episode =  174, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.28650675e-01  -3.89365778e-06   2.01570532e+01] 3.41078849585e-05\n",
      "positions (x,y,z), reward: [ -3.96186312e-01  -4.96980066e-04   2.01313672e+01] 3.76115071711e-22\n",
      "positions (x,y,z), reward: [ -3.97865125e-01  -1.63928687e-04   2.01041725e+01] 1.48802463494e-17\n",
      "positions (x,y,z), reward: [ -9.10140835e-01  -1.24304319e-03   1.86176359e+01] 1.3218343312e-32\n",
      "positions (x,y,z), reward: [ -9.99287890e-01   2.04916386e-03   1.83284481e+01] 4.27087691712e-33\n",
      "positions (x,y,z), reward: [ -1.65696415e+00   1.32425639e-03   1.37742710e+01] 6.14933658673e-36\n",
      "positions (x,y,z), reward: [ -1.66452613e+00   1.46273263e-03   1.32998981e+01] 1.17261438533e-35\n",
      "positions (x,y,z), reward: [ -1.69430406e+00   8.84609597e-05   1.26337507e+01] 1.8117037257e-35\n",
      "positions (x,y,z), reward: [ -1.77186264e+00  -6.46301857e-04   1.21677998e+01] 5.10555333473e-36\n",
      "positions (x,y,z), reward: [ -1.98274531e+00  -1.49023561e-03   9.46084145e+00] 1.12737466973e-36\n",
      "positions (x,y,z), reward: [ -2.17433864e+00  -6.77054089e-04   6.67204651e+00] 2.94407151769e-37\n",
      "Episode =  175, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.77906848e-01   1.50646240e-04   1.99502155e+01] 3.67295439181e-32\n",
      "positions (x,y,z), reward: [ -1.13713820e+00  -1.02061178e-03   1.69324511e+01] 1.00983957641e-33\n",
      "positions (x,y,z), reward: [ -1.65870608e+00  -6.00510001e-03   1.22225715e+01] 5.48384424045e-36\n",
      "Episode =  176, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.12543008e-01   7.54166106e-04   1.92803894e+01] 7.03602227455e-33\n",
      "positions (x,y,z), reward: [ -1.15351929e+00   5.72499340e-04   1.70483884e+01] 1.48667519188e-33\n",
      "positions (x,y,z), reward: [-1.89782749 -0.01634424  9.7544481 ] 1.9116924216e-36\n",
      "positions (x,y,z), reward: [-1.93183976 -0.02182836  9.48337865] 1.1033773636e-36\n",
      "positions (x,y,z), reward: [-2.08871921 -0.02229009  8.26993862] 1.00271983634e-37\n",
      "Episode =  177, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.22955042e-01  -7.48422001e-06   2.01607844e+01] 3.70933195339e-05\n",
      "positions (x,y,z), reward: [ -4.13352706e-01   2.93943988e-04   2.01050456e+01] 4.6168456931e-22\n",
      "positions (x,y,z), reward: [ -4.96981672e-01   3.47766194e-04   2.00592975e+01] 8.64441529845e-23\n",
      "positions (x,y,z), reward: [ -6.56753087e-01  -1.36852893e-04   1.95182119e+01] 7.97531755969e-32\n",
      "positions (x,y,z), reward: [ -1.02987413e+00  -8.86902252e-04   1.80977650e+01] 7.68820972217e-34\n",
      "positions (x,y,z), reward: [ -1.56318430e+00   7.28553161e-04   1.38187592e+01] 6.19927156409e-36\n",
      "positions (x,y,z), reward: [-2.2635151  -0.06936172  3.62794951] 2.10344749539e-38\n",
      "Episode =  178, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.82341184e-01  -1.39831654e-04   1.91559058e+01] 3.47905680441e-33\n",
      "positions (x,y,z), reward: [ -1.42261843e+00  -7.37956438e-04   1.60001082e+01] 4.85890513985e-35\n",
      "positions (x,y,z), reward: [ -1.42949168e+00  -1.44670330e-03   1.58017649e+01] 6.45811669705e-35\n",
      "positions (x,y,z), reward: [ -2.19291791e+00   1.35736202e-03   7.29309848e+00] 2.13919058825e-37\n",
      "positions (x,y,z), reward: [-2.48813071 -0.0031341   2.54356296] 2.22097691833e-38\n",
      "Episode =  179, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.84773135e-02   5.45468073e-07   2.00408266e+01] 0.403676730962\n",
      "positions (x,y,z), reward: [ -1.52268371e+00  -5.15593747e-03   1.45146992e+01] 1.97017731362e-35\n",
      "positions (x,y,z), reward: [ -1.72587785e+00  -9.47817444e-03   1.22077387e+01] 4.84814346249e-36\n",
      "positions (x,y,z), reward: [-2.17389162 -0.03527856  6.09715069] 1.09759091612e-37\n",
      "positions (x,y,z), reward: [-2.53349741 -0.08566773  1.0611426 ] 2.13932984214e-39\n",
      "positions (x,y,z), reward: [-2.56738986 -0.09460768  0.        ] 2.65086813069e-39\n",
      "Episode =  180, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.63840403e-01  -1.25964133e-04   2.02539952e+01] 1.55194393389e-13\n",
      "positions (x,y,z), reward: [ -3.71371079e-01   4.62226825e-04   2.01974627e+01] 4.03437515437e-22\n",
      "positions (x,y,z), reward: [-2.32576834 -0.04177708  3.62399813] 2.45187907461e-38\n",
      "Episode =  181, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.14674924e-01   6.17261952e-06   2.02441059e+01] 3.28727184178e-21\n",
      "positions (x,y,z), reward: [ -3.94764267e-01  -7.34341902e-04   2.01112310e+01] 5.11398449384e-22\n",
      "positions (x,y,z), reward: [ -5.72973697e-01   9.76141159e-04   1.99922864e+01] 6.54577700941e-32\n",
      "positions (x,y,z), reward: [ -6.49533529e-01  -2.24398803e-03   1.97760413e+01] 2.85423720957e-32\n",
      "positions (x,y,z), reward: [ -1.40337507e+00  -4.84509300e-03   1.59929829e+01] 4.59286284167e-35\n",
      "Episode =  182, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.10606107e-01   8.88715235e-04   2.00541302e+01] 8.35032326505e-23\n",
      "positions (x,y,z), reward: [ -6.18986213e-01  -9.27866144e-05   1.98651141e+01] 2.65695824834e-32\n",
      "positions (x,y,z), reward: [ -2.15307565e+00   1.59471029e-03   6.09228297e+00] 1.17756115963e-37\n",
      "Episode =  183, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.73904340e-01  -3.19305535e-04   2.01225898e+01] 5.015070757e-22\n",
      "positions (x,y,z), reward: [ -3.86519405e-01  -6.33063279e-05   2.01097164e+01] 1.4300041962e-17\n",
      "positions (x,y,z), reward: [ -8.50644967e-01  -1.60048641e-03   1.87312076e+01] 8.56433577721e-33\n",
      "positions (x,y,z), reward: [ -1.55954499e+00  -7.17576129e-03   1.35717124e+01] 8.15556918069e-36\n",
      "positions (x,y,z), reward: [-2.25942615 -0.04643652  2.95040297] 3.33901008622e-38\n",
      "positions (x,y,z), reward: [-2.28286085 -0.04570321  2.60051612] 2.33090408132e-38\n",
      "Episode =  184, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.43703977e-02   1.81106628e-06   2.01003054e+01] 0.0104388170748\n",
      "positions (x,y,z), reward: [ -1.84255674e-01   2.81717366e-05   2.02205582e+01] 1.10985795771e-07\n",
      "positions (x,y,z), reward: [ -2.12863085e-01   7.55598695e-05   2.02450318e+01] 2.39689886313e-08\n",
      "positions (x,y,z), reward: [ -2.53099399e-01   8.57488731e-05   2.02591571e+01] 2.68822535513e-11\n",
      "positions (x,y,z), reward: [ -6.01275712e-01  -4.87162174e-04   1.98756444e+01] 2.52939012115e-32\n",
      "positions (x,y,z), reward: [ -1.55096860e+00  -6.07789130e-03   1.38228851e+01] 6.34383324644e-36\n",
      "positions (x,y,z), reward: [ -1.55636767e+00  -1.18042934e-02   1.33485437e+01] 1.17013453672e-35\n",
      "Episode =  185, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.21531138e-01  -8.48367783e-07   2.01610534e+01] 3.80456384241e-05\n",
      "positions (x,y,z), reward: [ -5.35943833e-01  -8.77086235e-05   2.00121559e+01] 3.87413182344e-23\n",
      "positions (x,y,z), reward: [ -1.69493499e+00  -6.62389029e-04   1.19554955e+01] 2.55514926755e-36\n",
      "positions (x,y,z), reward: [ -2.24596563e+00   3.02908195e-04   3.63618676e+00] 2.38364440472e-38\n",
      "Episode =  186, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.81349215e-01  -3.81877184e-04   2.00765129e+01] 2.02867237933e-22\n",
      "positions (x,y,z), reward: [ -6.56856740e-01   4.04771459e-04   1.95954710e+01] 1.07204882806e-31\n",
      "positions (x,y,z), reward: [ -1.09510072e+00  -1.54226081e-03   1.80652689e+01] 7.19918125692e-34\n",
      "positions (x,y,z), reward: [ -1.38811862e+00  -1.01578598e-03   1.61973936e+01] 4.92587165816e-35\n",
      "positions (x,y,z), reward: [ -1.61125620e+00  -3.89365269e-03   1.42499212e+01] 9.3294771059e-36\n",
      "positions (x,y,z), reward: [ -1.92046399e+00  -2.88996620e-03   1.05197073e+01] 1.47456262492e-36\n",
      "Episode =  187, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.23279878e-01   3.62039814e-06   2.01053119e+01] 4.4828735118e-22\n",
      "positions (x,y,z), reward: [ -1.05402556e+00  -8.72353074e-05   1.80940852e+01] 7.47200776303e-34\n",
      "positions (x,y,z), reward: [ -1.21209940e+00  -5.98369823e-04   1.67756532e+01] 4.44417509522e-34\n",
      "Episode =  188, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.93672582e-01  -5.16755383e-05   2.02156694e+01] 1.05491488665e-07\n",
      "positions (x,y,z), reward: [ -4.32398688e-01  -3.58590061e-04   2.00982468e+01] 4.41139683001e-22\n",
      "positions (x,y,z), reward: [ -4.72328571e-01  -5.32210508e-04   2.00819560e+01] 2.07915570962e-22\n",
      "positions (x,y,z), reward: [ -5.65658036e-01  -4.63354099e-04   1.99995934e+01] 6.55195366473e-32\n",
      "positions (x,y,z), reward: [ -6.41954625e-01   4.99076498e-04   1.97147475e+01] 4.39928473998e-32\n",
      "positions (x,y,z), reward: [ -1.38996754e+00   2.09196567e-03   1.58137499e+01] 5.93004241922e-35\n",
      "positions (x,y,z), reward: [ -1.70014748  -0.01256147  12.42300324] 1.03216523658e-35\n",
      "positions (x,y,z), reward: [-2.12668312 -0.03315001  6.9899408 ] 2.54557243387e-37\n",
      "positions (x,y,z), reward: [-2.5999146  -0.19332571  0.        ] 2.36744760738e-39\n",
      "Episode =  189, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.67977719e-02  -1.49657887e-06   2.00982799e+01] 0.00980337953235\n",
      "positions (x,y,z), reward: [ -6.37294570e-01   8.61632482e-04   1.96604708e+01] 7.8041383214e-32\n",
      "positions (x,y,z), reward: [ -1.66550409e+00  -8.24127788e-03   1.26695569e+01] 1.87564525432e-35\n",
      "positions (x,y,z), reward: [ -1.83046968e+00  -1.12916645e-02   1.16784922e+01] 1.21004097765e-36\n",
      "positions (x,y,z), reward: [-2.37858558 -0.05485403  2.92892922] 3.28122925448e-38\n",
      "Episode =  190, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.84310494e-01   7.57958689e-04   1.92941474e+01] 6.81219350222e-33\n",
      "positions (x,y,z), reward: [-2.1748578  -0.0072191   5.45953061] 3.27530435469e-38\n",
      "positions (x,y,z), reward: [-2.24843142 -0.01826954  4.38193348] 1.68533239784e-38\n",
      "Episode =  191, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.08255144e-01   6.41183197e-05   2.02490728e+01] 3.4544037927e-21\n",
      "positions (x,y,z), reward: [ -3.74076084e-01  -6.29513034e-05   2.01975701e+01] 4.10942540938e-22\n",
      "positions (x,y,z), reward: [ -4.02021118e-01   7.06229823e-05   2.01029936e+01] 1.46601619421e-17\n",
      "positions (x,y,z), reward: [ -7.21458212e-01   8.58378329e-04   1.94443298e+01] 3.97387884467e-32\n",
      "positions (x,y,z), reward: [ -2.12464601e+00   7.02523541e-05   6.68029623e+00] 2.81659646521e-37\n",
      "Episode =  192, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.42701658e+00  -2.27051697e-03   1.50858000e+01] 1.68406217232e-34\n",
      "positions (x,y,z), reward: [-2.6198725  -0.12596822  0.        ] 2.24569031762e-39\n",
      "Episode =  193, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.23966483e-01   5.49001098e-05   2.01604618e+01] 3.66464497434e-05\n",
      "positions (x,y,z), reward: [ -6.12844354e-01   1.17894768e-04   1.98700809e+01] 2.50582868685e-32\n",
      "positions (x,y,z), reward: [ -2.05989971e+00   5.14345139e-03   7.96387355e+00] 1.07893604681e-37\n",
      "Episode =  194, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.02883685e-01   1.73340217e-06   2.01295844e+01] 0.000402370735808\n",
      "positions (x,y,z), reward: [ -3.14893807e-01   1.31084417e-05   2.02441516e+01] 3.24649109134e-21\n",
      "positions (x,y,z), reward: [ -4.78396806e-01   2.72818587e-04   2.00758137e+01] 2.04837571434e-22\n",
      "positions (x,y,z), reward: [ -6.36365995e-01   2.79507943e-04   1.98531024e+01] 2.5652683001e-32\n",
      "positions (x,y,z), reward: [ -1.15482854e+00   3.45277889e-03   1.75950491e+01] 4.49793061557e-34\n",
      "positions (x,y,z), reward: [ -1.39818060e+00   1.47761826e-03   1.59968973e+01] 4.4330514965e-35\n",
      "positions (x,y,z), reward: [ -1.65574029e+00   1.51894614e-03   1.35294058e+01] 7.8137070276e-36\n",
      "positions (x,y,z), reward: [-2.34844123 -0.07870203  5.00053837] 1.67073301217e-38\n",
      "positions (x,y,z), reward: [-2.43172953 -0.12778642  2.49509568] 2.01089827388e-38\n",
      "positions (x,y,z), reward: [-2.51127033 -0.15003806  1.75665448] 5.96526057099e-39\n",
      "positions (x,y,z), reward: [-2.61561564 -0.16499022  0.56368652] 1.54426007974e-39\n",
      "positions (x,y,z), reward: [-2.62988035 -0.18010857  0.        ] 2.13734728686e-39\n",
      "Episode =  195, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.60427593e-01   4.94087105e-05   2.02060090e+01] 4.24953469102e-22\n",
      "positions (x,y,z), reward: [ -6.08640600e-01  -5.13348966e-05   1.96134670e+01] 1.09886486668e-31\n",
      "positions (x,y,z), reward: [ -1.98202373e+00   3.63902521e-04   8.30116588e+00] 1.03362001947e-37\n",
      "positions (x,y,z), reward: [ -2.22413915e+00  -3.50635125e-04   3.29317706e+00] 3.04122864981e-38\n",
      "Episode =  196, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.96739701e-01  -1.74468546e-05   2.02152671e+01] 1.03861804571e-07\n",
      "positions (x,y,z), reward: [ -9.02730551e-01  -2.24986191e-03   1.89254756e+01] 3.57285353825e-33\n",
      "positions (x,y,z), reward: [ -1.30492271e+00   8.01226740e-03   1.65816302e+01] 1.76151849424e-34\n",
      "positions (x,y,z), reward: [ -1.34873060e+00   5.22317502e-03   1.63987959e+01] 8.18208905815e-35\n",
      "positions (x,y,z), reward: [ -1.40950225e+00  -9.19886095e-03   1.56114210e+01] 9.20891063621e-35\n",
      "positions (x,y,z), reward: [ -1.63639684e+00  -2.72142329e-03   1.40204081e+01] 6.6195467536e-36\n",
      "positions (x,y,z), reward: [ -1.77125097e+00   2.26620863e-03   1.21739471e+01] 4.95357779632e-36\n",
      "Episode =  197, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.67298071e-01   4.25697776e-06   2.02526287e+01] 1.56106461489e-13\n",
      "positions (x,y,z), reward: [ -6.56890023e-01  -1.00196260e-03   1.95590965e+01] 1.18976256031e-31\n",
      "positions (x,y,z), reward: [ -1.63243559e+00   2.90686943e-04   1.33202895e+01] 1.21845581848e-35\n",
      "positions (x,y,z), reward: [ -1.69497146  -0.02000711  12.42644955] 1.07958196915e-35\n",
      "positions (x,y,z), reward: [ -1.87206213  -0.01381425  11.10111345] 8.30635738183e-37\n",
      "positions (x,y,z), reward: [-2.11540332 -0.044396    7.93646663] 1.11426741262e-37\n",
      "positions (x,y,z), reward: [-2.1313977  -0.06996546  6.68069261] 2.67233077126e-37\n",
      "Episode =  198, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.06002611e+00  -3.29859026e-04   1.72205084e+01] 1.51161462678e-33\n",
      "positions (x,y,z), reward: [ -1.18730229e+00  -6.54777493e-04   1.66404323e+01] 1.99151688847e-34\n",
      "positions (x,y,z), reward: [ -1.28283576e+00  -8.01859881e-05   1.60658240e+01] 4.63301936097e-35\n",
      "positions (x,y,z), reward: [-2.17295987 -0.00636179  4.77126255] 1.42931448795e-38\n",
      "Episode =  200, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.13034660e-01   8.94577740e-05   2.02442862e+01] 2.48632951294e-08\n",
      "positions (x,y,z), reward: [ -3.87692321e-01  -2.13016591e-04   2.01101558e+01] 1.47794603017e-17\n",
      "positions (x,y,z), reward: [ -8.22565114e-01   3.52032241e-04   1.91860384e+01] 3.99653688783e-33\n",
      "positions (x,y,z), reward: [ -8.72432066e-01   2.98653241e-04   1.85503938e+01] 1.34343919931e-32\n",
      "positions (x,y,z), reward: [ -1.81690527e+00   1.52193240e-03   1.00446151e+01] 2.33457245539e-36\n",
      "positions (x,y,z), reward: [ -2.05160617e+00   2.16999934e-03   6.72778358e+00] 2.83579805958e-37\n",
      "Episode =  201, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.07295673e+00   3.12624525e-05   1.77992702e+01] 3.77421613147e-34\n",
      "positions (x,y,z), reward: [ -1.08235757e+00   4.57463594e-04   1.72091637e+01] 1.57730519168e-33\n",
      "positions (x,y,z), reward: [ -1.16687066e+00   1.76398842e-04   1.67919579e+01] 4.92507384077e-34\n",
      "positions (x,y,z), reward: [ -1.64473784e+00   1.67259313e-03   1.22338132e+01] 5.34274999016e-36\n",
      "positions (x,y,z), reward: [ -1.77979511e+00  -1.06973215e-03   1.03299685e+01] 2.11664244253e-36\n",
      "positions (x,y,z), reward: [ -1.92470947e+00   2.16592235e-03   8.95634499e+00] 2.92435184769e-37\n",
      "Episode =  202, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.85443619e-02  -3.11531871e-08   2.00407782e+01] 0.401610800182\n",
      "positions (x,y,z), reward: [ -4.51554072e-02  -2.12473017e-07   2.00655406e+01] 0.0728549722964\n",
      "positions (x,y,z), reward: [ -1.02912097e-01  -1.69913517e-06   2.01306133e+01] 0.00041029246911\n",
      "positions (x,y,z), reward: [ -4.41793963e-01   9.90044741e-05   2.01015479e+01] 4.19553896812e-22\n",
      "positions (x,y,z), reward: [ -8.37884579e-01   2.81028173e-04   1.92785559e+01] 6.36596670206e-33\n",
      "positions (x,y,z), reward: [ -1.41686002e+00  -6.34593113e-03   1.56304922e+01] 1.01380885291e-34\n",
      "positions (x,y,z), reward: [-2.17240497 -0.02704254  7.02050969] 2.725882756e-37\n",
      "Episode =  203, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.71073753e-01   6.66063831e-06   2.01954400e+01] 3.57200742803e-07\n",
      "positions (x,y,z), reward: [ -4.61039254e-01   4.06656940e-04   2.00880260e+01] 2.17303247164e-22\n",
      "positions (x,y,z), reward: [ -6.27341471e-01   1.72991575e-04   1.96626484e+01] 7.68441465531e-32\n",
      "positions (x,y,z), reward: [ -8.71944766e-01   5.02429992e-04   1.87302191e+01] 9.18165366266e-33\n",
      "positions (x,y,z), reward: [ -1.16673898e+00  -3.91867356e-04   1.69213697e+01] 9.45372434505e-34\n",
      "positions (x,y,z), reward: [ -1.83902081e+00   2.62835447e-03   1.05675180e+01] 1.45568646313e-36\n",
      "positions (x,y,z), reward: [ -1.90263851e+00  -9.24449966e-03   9.50370389e+00] 1.11539084661e-36\n",
      "positions (x,y,z), reward: [ -2.05704475e+00  -7.28029570e-03   8.29046466e+00] 1.02360423811e-37\n",
      "Episode =  204, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.86205139e-01   6.41120980e-04   1.99438160e+01] 3.58920477493e-32\n",
      "positions (x,y,z), reward: [ -8.69750812e-01   2.16986013e-04   1.86318562e+01] 1.23993156121e-32\n",
      "positions (x,y,z), reward: [ -1.11017270e+00   4.39550530e-04   1.76197020e+01] 4.20743248456e-34\n",
      "positions (x,y,z), reward: [ -1.12738023e+00   1.21798912e-03   1.70514327e+01] 1.4494306116e-33\n",
      "positions (x,y,z), reward: [ -1.35072993e+00   3.13477225e-04   1.58262508e+01] 5.40321995011e-35\n",
      "positions (x,y,z), reward: [ -2.12498910e+00   4.14220475e-03   6.08630347e+00] 1.20862584577e-37\n",
      "positions (x,y,z), reward: [-2.28914795 -0.0073267   4.34072183] 1.43695308778e-38\n",
      "positions (x,y,z), reward: [-2.29273719 -0.01033581  3.62501763] 2.28401926488e-38\n",
      "positions (x,y,z), reward: [-2.51952104 -0.02551399  0.        ] 2.66693921025e-39\n",
      "Episode =  205, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.01951378e-01  -7.20850766e-06   2.01307210e+01] 0.000407852583078\n",
      "positions (x,y,z), reward: [ -3.76391218e-01   3.79894838e-05   2.01947636e+01] 4.07589621446e-22\n",
      "positions (x,y,z), reward: [ -8.58946836e-01  -8.87093473e-05   1.91674607e+01] 3.67206670072e-33\n",
      "positions (x,y,z), reward: [ -1.19794496e+00   6.41306553e-04   1.69101346e+01] 8.84245871277e-34\n",
      "positions (x,y,z), reward: [ -1.58368286e+00   8.05359502e-04   1.42724252e+01] 9.69018538775e-36\n",
      "positions (x,y,z), reward: [ -1.63898585e+00  -1.32320800e-03   1.33196933e+01] 1.23282245805e-35\n",
      "positions (x,y,z), reward: [ -1.70412169e+00   1.19243072e-03   1.24289624e+01] 1.0361060181e-35\n",
      "positions (x,y,z), reward: [ -1.99832442e+00   1.03765322e-03   9.20148869e+00] 5.17821995634e-37\n",
      "positions (x,y,z), reward: [ -2.20326051e+00  -1.16144828e-04   6.07730902e+00] 1.08833616093e-37\n",
      "positions (x,y,z), reward: [ -2.41043001e+00  -6.04962198e-04   2.56695608e+00] 2.1564274704e-38\n",
      "positions (x,y,z), reward: [ -2.56751526e+00  -9.38247130e-05   1.05117055e+00] 2.15196237154e-39\n",
      "Episode =  206, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.64433307e-01   2.84372793e-05   2.02004008e+01] 4.03912287876e-22\n",
      "positions (x,y,z), reward: [ -6.16346110e-01   5.46036699e-04   1.97249065e+01] 4.51900701686e-32\n",
      "positions (x,y,z), reward: [ -8.70977377e-01   1.59327549e-04   1.85524608e+01] 1.31225920134e-32\n",
      "positions (x,y,z), reward: [ -1.33387632e+00   1.20854730e-03   1.52819342e+01] 1.94876534587e-34\n",
      "positions (x,y,z), reward: [-2.0321139  -0.02045915  7.65197277] 1.5060035067e-37\n",
      "positions (x,y,z), reward: [-2.03117548 -0.02319381  7.33668757] 1.99336897925e-37\n",
      "positions (x,y,z), reward: [-2.0968039  -0.05534994  6.09714842] 1.19874238357e-37\n",
      "positions (x,y,z), reward: [-2.24516894 -0.06342294  4.70937402] 1.33442423251e-38\n",
      "Episode =  207, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.02511839e-01  -2.01469346e-05   2.01300527e+01] 0.000405637092269\n",
      "positions (x,y,z), reward: [ -6.95957085e-01  -2.44932425e-03   1.95043616e+01] 8.06147105794e-32\n",
      "positions (x,y,z), reward: [ -9.02483390e-01   2.66697717e-03   1.88176410e+01] 5.74551676746e-33\n",
      "positions (x,y,z), reward: [ -1.14569324e+00   6.23131536e-04   1.77623075e+01] 3.67556538255e-34\n",
      "positions (x,y,z), reward: [ -1.90992075  -0.03271126  10.26127642] 1.93257797516e-36\n",
      "positions (x,y,z), reward: [-2.13622407 -0.07131587  8.2382916 ] 9.83825078766e-38\n",
      "Episode =  208, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.67547346e-01   8.46140674e-04   1.88318097e+01] 5.66260483487e-33\n",
      "positions (x,y,z), reward: [ -1.09955041e+00   1.08436792e-03   1.77812019e+01] 3.59730988703e-34\n",
      "positions (x,y,z), reward: [ -1.58249105e+00   1.23542113e-03   1.38078784e+01] 6.01280336971e-36\n",
      "positions (x,y,z), reward: [ -1.85404188e+00  -6.64211941e-03   9.76805782e+00] 2.01966418506e-36\n",
      "positions (x,y,z), reward: [-2.24992115 -0.02265189  5.0664045 ] 1.76898193183e-38\n",
      "Episode =  209, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.92382971e-01  -3.85983549e-05   2.02187803e+01] 1.07323684791e-07\n",
      "positions (x,y,z), reward: [ -1.37429460e+00   5.68468329e-03   1.56465791e+01] 9.45479138073e-35\n",
      "positions (x,y,z), reward: [ -1.39944104e+00  -7.26550432e-03   1.51086697e+01] 1.66045295645e-34\n",
      "positions (x,y,z), reward: [ -1.47477001  -0.01624175  14.73191628] 4.95764210895e-35\n",
      "Episode =  210, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.58752224e+00   1.80946186e-03   1.31191573e+01] 1.76407979112e-35\n",
      "positions (x,y,z), reward: [ -1.77630946e+00  -5.40436892e-03   1.16925310e+01] 1.20507545601e-36\n",
      "positions (x,y,z), reward: [ -2.06217108e+00  -7.29195472e-03   7.65615593e+00] 1.57509960265e-37\n",
      "positions (x,y,z), reward: [-2.06175375 -0.00843836  7.34179131] 2.11590371717e-37\n",
      "Episode =  211, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.56638377e-02   9.00985105e-07   2.00649773e+01] 0.0719876375454\n",
      "positions (x,y,z), reward: [ -4.17181903e-01   3.52430467e-04   2.01001503e+01] 1.45924831013e-17\n",
      "positions (x,y,z), reward: [ -8.82560146e-01   8.17232269e-04   1.91571835e+01] 3.57554291083e-33\n",
      "positions (x,y,z), reward: [ -1.17541032e+00  -1.77409116e-03   1.75961016e+01] 4.51376860724e-34\n",
      "positions (x,y,z), reward: [ -1.17657988e+00  -2.26035696e-03   1.74441503e+01] 6.94187823088e-34\n",
      "positions (x,y,z), reward: [ -1.49710785e+00   3.32778529e-03   1.48856478e+01] 9.5496411862e-35\n",
      "positions (x,y,z), reward: [ -1.92101698e+00   6.82501821e-04   1.13621548e+01] 7.83079933394e-37\n",
      "Episode =  212, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.91580757e-01  -2.06322227e-05   2.02163486e+01] 1.05710824653e-07\n",
      "positions (x,y,z), reward: [ -8.69841115e-01   5.19077446e-04   1.90522011e+01] 3.0055834588e-33\n",
      "positions (x,y,z), reward: [ -1.01618099e+00  -2.69238926e-03   1.82199190e+01] 1.78685190969e-33\n",
      "positions (x,y,z), reward: [-2.56287607 -0.11521516  0.        ] 3.04281553706e-39\n",
      "Episode =  213, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.87370971e-01   8.94732918e-04   1.94622286e+01] 4.47990941161e-32\n",
      "positions (x,y,z), reward: [ -1.49504258e+00  -1.76238755e-03   1.43055627e+01] 1.10394930536e-35\n",
      "positions (x,y,z), reward: [ -1.76202241e+00  -2.10959958e-03   1.14234295e+01] 7.98639052421e-37\n",
      "positions (x,y,z), reward: [ -1.80853980e+00  -7.15567464e-03   9.79063914e+00] 2.03622314294e-36\n",
      "positions (x,y,z), reward: [-2.11593288 -0.02784489  5.78690071] 6.40144709112e-38\n",
      "positions (x,y,z), reward: [-2.24828447 -0.04155775  2.95148043] 3.20483310592e-38\n",
      "positions (x,y,z), reward: [-2.34556701 -0.06134785  1.8686417 ] 7.01637090439e-39\n",
      "positions (x,y,z), reward: [-2.45875614 -0.06596641  0.28113955] 2.00833672083e-39\n",
      "Episode =  214, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.73970438e-01   3.79346191e-04   2.01488918e+01] 3.7052116255e-22\n",
      "positions (x,y,z), reward: [ -1.77920178e+00  -5.93889449e-03   1.08780237e+01] 1.05446319808e-36\n",
      "positions (x,y,z), reward: [-2.00673365 -0.00912854  7.37271311] 1.98213876154e-37\n",
      "positions (x,y,z), reward: [-2.4519269  -0.01873774  0.        ] 2.79433570618e-39\n",
      "Episode =  215, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00533962] 0.893046337921\n",
      "positions (x,y,z), reward: [ -3.71050711e-01  -9.57824133e-04   2.01242689e+01] 5.00469370688e-22\n",
      "positions (x,y,z), reward: [ -1.07758299e+00  -6.32385576e-03   1.74747563e+01] 6.2399324675e-34\n",
      "positions (x,y,z), reward: [-2.00827053 -0.07069136  6.74314711] 2.98694947606e-37\n",
      "positions (x,y,z), reward: [-2.22765243 -0.1533565   3.69310322] 2.82845010906e-38\n",
      "Episode =  216, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.27422725e-01  -3.94065538e-06   2.01576298e+01] 3.46107000309e-05\n",
      "positions (x,y,z), reward: [ -3.11905626e-01  -2.20311247e-05   2.02467921e+01] 3.36939210305e-21\n",
      "positions (x,y,z), reward: [ -8.97837115e-01   2.32044633e-03   1.88152608e+01] 5.31941596733e-33\n",
      "positions (x,y,z), reward: [ -9.47128141e-01  -5.90620590e-04   1.84356251e+01] 8.43457945075e-33\n",
      "positions (x,y,z), reward: [ -1.64082939e+00   2.02788665e-03   1.37759196e+01] 6.10165519913e-36\n",
      "positions (x,y,z), reward: [ -1.64848837e+00   2.30221808e-03   1.30748572e+01] 1.67423923531e-35\n",
      "positions (x,y,z), reward: [ -1.89529286e+00  -3.77678334e-03   1.05248206e+01] 1.40289769957e-36\n",
      "positions (x,y,z), reward: [-2.61730575 -0.21024566  0.13283527] 1.45992673342e-39\n",
      "Episode =  217, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.88613114e-01   2.81922118e-05   1.92914915e+01] 7.43152473346e-33\n",
      "positions (x,y,z), reward: [ -8.60254516e-01   3.27273995e-04   1.88379397e+01] 5.55011449119e-33\n",
      "positions (x,y,z), reward: [ -1.83796214e+00  -7.68114376e-03   9.78434666e+00] 1.92774903572e-36\n",
      "positions (x,y,z), reward: [-2.30737388 -0.04052339  2.59532188] 2.35626479056e-38\n",
      "Episode =  218, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.08644045e-01   3.89785386e-05   2.02486983e+01] 3.23012650211e-21\n",
      "positions (x,y,z), reward: [ -6.20899796e-01   2.97931571e-04   1.98631979e+01] 2.58893647354e-32\n",
      "positions (x,y,z), reward: [ -1.09525288e+00  -7.34404329e-04   1.79318005e+01] 4.05276517592e-34\n",
      "positions (x,y,z), reward: [ -1.76447174  -0.02195857  11.93768145] 2.37482722779e-36\n",
      "Episode =  219, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.78445472e-01   3.31678546e-05   2.01914780e+01] 3.50473166229e-07\n",
      "positions (x,y,z), reward: [ -6.59368905e-01  -1.52911378e-04   1.95997544e+01] 1.10156054328e-31\n",
      "positions (x,y,z), reward: [ -8.78292287e-01   3.62416335e-04   1.91583646e+01] 3.58413945354e-33\n",
      "positions (x,y,z), reward: [-2.1824459  -0.00985535  7.60356185] 1.50611104164e-37\n",
      "positions (x,y,z), reward: [-2.34876632 -0.03571579  5.37847372] 2.87683205685e-38\n",
      "Episode =  220, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.03178556e-01  -2.11283694e-05   2.01296450e+01] 0.000402868390128\n",
      "positions (x,y,z), reward: [ -1.29074655e-01  -3.11917271e-05   2.01567999e+01] 3.33908812338e-05\n",
      "positions (x,y,z), reward: [ -6.49426940e-01   7.70977788e-04   1.96499454e+01] 7.78752896353e-32\n",
      "positions (x,y,z), reward: [ -1.00087542e+00  -3.60960858e-03   1.83309035e+01] 3.82052223476e-33\n",
      "positions (x,y,z), reward: [ -1.14931825e+00  -1.74321865e-06   1.77569986e+01] 3.67223812171e-34\n",
      "Episode =  221, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.04036786e-01  -7.31848107e-06   2.01295094e+01] 0.000402600544858\n",
      "positions (x,y,z), reward: [ -7.98998190e-01  -1.86191422e-04   1.93697578e+01] 1.28425298715e-32\n",
      "positions (x,y,z), reward: [-2.16878815 -0.01004267  7.94779989] 1.26030513325e-37\n",
      "positions (x,y,z), reward: [ -2.30282917e+00  -3.49540008e-03   5.75338213e+00] 5.20157293109e-38\n",
      "positions (x,y,z), reward: [-2.41840505 -0.02691534  3.62291178] 2.79317431155e-38\n",
      "positions (x,y,z), reward: [-2.59384945 -0.02984963  1.45565303] 3.42094690948e-39\n",
      "positions (x,y,z), reward: [-2.65953532 -0.05915099  0.        ] 3.80769261912e-39\n",
      "Episode =  222, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534233] 0.893112301766\n",
      "positions (x,y,z), reward: [ -2.50394951e-01   1.69383922e-04   2.02620834e+01] 2.7134514272e-11\n",
      "positions (x,y,z), reward: [ -4.86396585e-01  -3.62441800e-05   2.00685851e+01] 8.83293866557e-23\n",
      "positions (x,y,z), reward: [ -6.16372535e-01  -1.39288432e-04   1.95796483e+01] 1.17600105212e-31\n",
      "positions (x,y,z), reward: [ -6.80397997e-01  -3.13243813e-04   1.94720634e+01] 4.26265684221e-32\n",
      "Episode =  223, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.35601162e-01   1.04115613e-04   2.02363331e+01] 9.81957864002e-22\n",
      "positions (x,y,z), reward: [ -1.31917294e+00   6.34230194e-04   1.60306277e+01] 4.86323731747e-35\n",
      "positions (x,y,z), reward: [ -1.56509751e+00  -8.63306333e-03   1.28794819e+01] 2.03449019361e-35\n",
      "positions (x,y,z), reward: [-2.02459348 -0.08255218  6.98502946] 1.91715691984e-37\n",
      "positions (x,y,z), reward: [-2.35396367 -0.31975751  1.71085949] 4.75149437923e-39\n",
      "positions (x,y,z), reward: [-2.47993448 -0.39703324  0.        ] 9.56771773603e-40\n",
      "Episode =  224, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.88919192e-01  -1.13388856e-03   2.01353306e+01] 3.93568228927e-22\n",
      "positions (x,y,z), reward: [ -1.38363091e+00  -6.98121036e-03   1.58193396e+01] 6.20105190727e-35\n",
      "positions (x,y,z), reward: [ -1.38972147e+00  -3.20312757e-03   1.52638554e+01] 1.77709504879e-34\n",
      "positions (x,y,z), reward: [ -1.88325426  -0.02661954  10.02933843] 2.54270305916e-36\n",
      "positions (x,y,z), reward: [-2.22864606 -0.06522934  5.77735623] 6.96712053808e-38\n",
      "positions (x,y,z), reward: [-2.33755467 -0.10099955  4.72920843] 1.6242140916e-38\n",
      "positions (x,y,z), reward: [-2.58778736 -0.23793869  0.        ] 3.45823240624e-39\n",
      "Episode =  225, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.36302091e-01  -2.76060914e-04   2.01009256e+01] 4.01190154539e-22\n",
      "positions (x,y,z), reward: [ -7.34861881e-01  -2.21301669e-04   1.94486638e+01] 3.64154348973e-32\n",
      "positions (x,y,z), reward: [ -1.38791844e+00   5.13267228e-04   1.60124953e+01] 5.07917663593e-35\n",
      "positions (x,y,z), reward: [-2.173286   -0.01327968  6.38738228] 2.14109674861e-37\n",
      "Episode =  226, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.09970151e-01   5.78263442e-04   2.01102502e+01] 4.25171859347e-22\n",
      "positions (x,y,z), reward: [ -6.91024072e-01   1.98211002e-03   1.94648467e+01] 3.73454928352e-32\n",
      "positions (x,y,z), reward: [ -8.45380864e-01  -1.56632378e-03   1.89519581e+01] 3.71998356116e-33\n",
      "positions (x,y,z), reward: [ -1.31565386e+00  -2.11979274e-03   1.58453684e+01] 6.13322044494e-35\n",
      "positions (x,y,z), reward: [-2.309528   -0.03867225  2.2704061 ] 1.27885982709e-38\n",
      "Episode =  227, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.81148363e-01  -3.11317329e-04   1.99954028e+01] 6.39935214583e-32\n",
      "positions (x,y,z), reward: [ -1.42814048e+00  -7.04781121e-04   1.58066556e+01] 6.15135347447e-35\n",
      "positions (x,y,z), reward: [ -1.49194820e+00  -3.52148853e-04   1.48945021e+01] 1.00172452324e-34\n",
      "positions (x,y,z), reward: [ -1.68301851e+00  -4.89012886e-04   1.35416741e+01] 8.29127953194e-36\n",
      "positions (x,y,z), reward: [ -1.68498267e+00  -8.04691127e-04   1.30829575e+01] 1.77829468279e-35\n",
      "positions (x,y,z), reward: [ -2.09814649e+00  -3.73124028e-03   8.88866521e+00] 2.63295824416e-37\n",
      "Episode =  228, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.15643187e-01   3.36834327e-04   2.01027454e+01] 4.82256971768e-22\n",
      "positions (x,y,z), reward: [ -1.12153090e+00   1.86235767e-04   1.70551363e+01] 1.49919632882e-33\n",
      "positions (x,y,z), reward: [ -1.58671353e+00  -1.46350058e-03   1.28851535e+01] 2.07438464945e-35\n",
      "positions (x,y,z), reward: [ -2.05047190e+00  -6.16903655e-03   7.32900091e+00] 1.88953233537e-37\n",
      "Episode =  229, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00533967] 0.893087345705\n",
      "positions (x,y,z), reward: [ -2.06357982e-01  -6.52743498e-05   2.02469662e+01] 2.49719468898e-08\n",
      "positions (x,y,z), reward: [ -3.53861722e-01   6.86873553e-05   2.02112889e+01] 4.19663471173e-22\n",
      "positions (x,y,z), reward: [ -8.64753852e-01  -3.50211894e-03   1.84679158e+01] 9.57455727763e-33\n",
      "positions (x,y,z), reward: [ -1.25908013e+00  -4.02251274e-03   1.62546271e+01] 5.61815424303e-35\n",
      "Episode =  230, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.35105431e-01  -2.40420631e-04   1.92742794e+01] 6.15077011772e-33\n",
      "positions (x,y,z), reward: [ -2.16047803e+00  -1.74096258e-03   7.62257431e+00] 1.47418399704e-37\n",
      "positions (x,y,z), reward: [ -2.16401394e+00  -6.70418227e-04   7.00169095e+00] 2.60629315093e-37\n",
      "Episode =  231, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.01031172e-01   5.11572626e-05   2.02512034e+01] 3.241884608e-21\n",
      "positions (x,y,z), reward: [ -1.08854713e+00   4.36502145e-04   1.73301032e+01] 1.18212172078e-33\n",
      "positions (x,y,z), reward: [ -1.77755145e+00   1.97933624e-03   1.14091056e+01] 7.88062152249e-37\n",
      "positions (x,y,z), reward: [ -1.86023427e+00   1.84179020e-03   9.51109596e+00] 1.05369272148e-36\n",
      "positions (x,y,z), reward: [ -2.32780032e+00  -2.12942434e-04   2.23682767e+00] 1.22265221101e-38\n",
      "positions (x,y,z), reward: [ -2.47713633e+00   2.01776647e-03   0.00000000e+00] 3.35056200531e-39\n",
      "Episode =  232, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.07357103e-01   1.18759521e-04   2.02499777e+01] 3.34905030394e-21\n",
      "positions (x,y,z), reward: [ -6.19649093e-01  -1.94816568e-04   1.98655821e+01] 2.6693310075e-32\n",
      "positions (x,y,z), reward: [ -6.32358699e-01  -6.87288903e-04   1.97203458e+01] 4.54169406252e-32\n",
      "positions (x,y,z), reward: [ -1.71198929e+00   2.75954412e-03   1.22011271e+01] 5.30241544061e-36\n",
      "positions (x,y,z), reward: [ -2.08869179e+00  -2.92369905e-03   7.64227052e+00] 1.52270640673e-37\n",
      "Episode =  233, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -9.93576527e-02  -1.13979718e-05   2.01321955e+01] 0.000415098210022\n",
      "positions (x,y,z), reward: [ -1.10232471e+00  -7.43183394e-04   1.77820426e+01] 3.65168701425e-34\n",
      "positions (x,y,z), reward: [ -1.35731909e+00  -1.81595695e-03   1.52763817e+01] 1.82232412066e-34\n",
      "positions (x,y,z), reward: [ -1.73913072e+00  -8.98787117e-03   1.19542712e+01] 2.42902899188e-36\n",
      "positions (x,y,z), reward: [ -1.83139010e+00  -4.59968129e-03   1.05690515e+01] 1.51175534732e-36\n",
      "Episode =  234, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.26217076e-01   4.52301918e-05   2.02368958e+01] 2.68253709912e-21\n",
      "positions (x,y,z), reward: [ -6.63453440e-01  -1.67385930e-04   1.96438149e+01] 8.30126094407e-32\n",
      "positions (x,y,z), reward: [ -9.53683779e-01  -1.87818611e-04   1.85243402e+01] 1.24347941975e-32\n",
      "positions (x,y,z), reward: [ -1.65270921e+00  -3.23780133e-04   1.42385878e+01] 8.69434612359e-36\n",
      "positions (x,y,z), reward: [ -1.96098268e+00   9.61176020e-04   1.07848464e+01] 1.18054092535e-36\n",
      "positions (x,y,z), reward: [-2.51716308 -0.01296895  2.52008452] 1.98207954714e-38\n",
      "Episode =  235, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.47057475e-02  -6.75022492e-07   2.00660004e+01] 0.0756553003345\n",
      "positions (x,y,z), reward: [ -6.50012997e-01   1.46373596e-05   1.95631659e+01] 1.12292779912e-31\n",
      "positions (x,y,z), reward: [ -8.10688489e-01  -1.94616579e-04   1.92830264e+01] 6.43130841128e-33\n",
      "positions (x,y,z), reward: [ -1.09758343e+00   1.94854872e-04   1.79355966e+01] 4.27443808818e-34\n",
      "positions (x,y,z), reward: [ -1.59358597e+00   1.01251246e-03   1.40450362e+01] 6.28799381077e-36\n",
      "positions (x,y,z), reward: [ -1.96993793e+00   3.85846915e-03   9.21194765e+00] 5.63844759354e-37\n",
      "positions (x,y,z), reward: [ -2.05418588e+00   1.29243110e-03   8.60244708e+00] 1.44710213204e-37\n",
      "positions (x,y,z), reward: [-2.37659553 -0.00654729  2.57878348] 2.23309410856e-38\n",
      "Episode =  236, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.64100324e-01   5.74800596e-05   2.02537520e+01] 1.52167810337e-13\n",
      "positions (x,y,z), reward: [ -3.08379154e-01   1.56151991e-05   2.02486393e+01] 3.10011206342e-21\n",
      "positions (x,y,z), reward: [ -1.14362903e+00   4.08576666e-04   1.70613636e+01] 1.51705659011e-33\n",
      "positions (x,y,z), reward: [ -2.08373516e+00   1.12118816e-04   7.96704368e+00] 1.18096193387e-37\n",
      "Episode =  237, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.09391283e+00  -6.22720299e-04   1.73362947e+01] 1.08005417984e-33\n",
      "positions (x,y,z), reward: [ -1.33315516e+00  -3.23386755e-04   1.56489590e+01] 8.81226339571e-35\n",
      "positions (x,y,z), reward: [ -1.47271804e+00  -1.78330200e-03   1.45273702e+01] 2.13381509528e-35\n",
      "positions (x,y,z), reward: [-2.22401692 -0.0054562   5.09425312] 1.86809399517e-38\n",
      "positions (x,y,z), reward: [-2.26494849 -0.00445856  4.00998233] 2.10662201191e-38\n",
      "Episode =  238, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.52385031e-01   2.44406780e-05   2.01803227e+01] 1.71358852209e-06\n",
      "positions (x,y,z), reward: [ -3.43389374e-01   1.27806772e-05   2.02314739e+01] 9.03308049505e-22\n",
      "positions (x,y,z), reward: [ -1.35443804e+00  -3.65853971e-03   1.56428309e+01] 8.81271186188e-35\n",
      "Episode =  239, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.02793732e+00  -1.55469353e-03   1.72115600e+01] 1.4628577397e-33\n",
      "positions (x,y,z), reward: [ -1.25164578e+00  -2.86675777e-03   1.56644631e+01] 8.17615100458e-35\n",
      "positions (x,y,z), reward: [ -1.63950536e+00   1.76315599e-03   1.17196875e+01] 1.28210783869e-36\n",
      "positions (x,y,z), reward: [ -1.66986640e+00   3.07844165e-04   1.14413591e+01] 8.06241100422e-37\n",
      "positions (x,y,z), reward: [ -1.69205727e+00  -1.37677557e-03   1.00694911e+01] 2.38315925397e-36\n",
      "positions (x,y,z), reward: [-2.32397556 -0.0071403   0.31763438] 2.23369216468e-39\n",
      "Episode =  240, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.57950513e-01  -5.05325547e-05   1.90665720e+01] 2.88254683198e-33\n",
      "positions (x,y,z), reward: [ -9.53739721e-01   1.11402812e-03   1.83555582e+01] 4.11347685126e-33\n",
      "positions (x,y,z), reward: [-2.06860187 -0.01686706  7.03802347] 2.56689867305e-37\n",
      "positions (x,y,z), reward: [-2.31278754 -0.04411287  2.96220601] 3.54337886114e-38\n",
      "positions (x,y,z), reward: [-2.37225098 -0.0420373   2.25530322] 1.47194981832e-38\n",
      "positions (x,y,z), reward: [-2.41416837 -0.04628169  1.88585957] 8.2173892211e-39\n",
      "Episode =  241, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.          0.         20.0053507] 0.893062116892\n",
      "positions (x,y,z), reward: [ -1.74223108e-01  -8.41779025e-07   2.01936075e+01] 3.53899713833e-07\n",
      "positions (x,y,z), reward: [ -3.87463699e-01  -2.61500838e-04   2.01630539e+01] 3.18302386956e-22\n",
      "positions (x,y,z), reward: [ -6.42227041e-01  -5.28913811e-04   1.96046545e+01] 1.09606532677e-31\n",
      "positions (x,y,z), reward: [ -8.55537986e-01   2.37469988e-04   1.91675833e+01] 3.70454799168e-33\n",
      "positions (x,y,z), reward: [ -1.07276848e+00   2.09716962e-03   1.80798257e+01] 7.44622406893e-34\n",
      "positions (x,y,z), reward: [ -1.14381072e+00  -1.74101162e-03   1.71796670e+01] 1.51426418605e-33\n",
      "positions (x,y,z), reward: [ -1.66248855e+00  -2.23822340e-04   1.26541046e+01] 1.77326467706e-35\n",
      "positions (x,y,z), reward: [-2.1156155  -0.02077699  7.9480619 ] 1.15885907664e-37\n",
      "positions (x,y,z), reward: [-2.11986087 -0.02633576  7.31455032] 2.0111819107e-37\n",
      "positions (x,y,z), reward: [-2.36097277 -0.05676539  3.27237945] 3.29465187212e-38\n",
      "Episode =  242, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.15638288e+00  -3.76389176e-03   1.77415286e+01] 3.7018548329e-34\n",
      "positions (x,y,z), reward: [-1.99385309 -0.03585439  9.45484232] 1.12388288081e-36\n",
      "positions (x,y,z), reward: [-2.12382973 -0.05749404  8.5662593 ] 1.61404179807e-37\n",
      "positions (x,y,z), reward: [-2.17029279 -0.10064404  7.61184037] 1.67513067015e-37\n",
      "positions (x,y,z), reward: [-2.58499164 -0.27071161  1.52768501] 5.80731512866e-39\n",
      "Episode =  243, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.89831454e-01   1.88881107e-04   2.01180262e+01] 5.35122376765e-22\n",
      "positions (x,y,z), reward: [ -6.31929459e-01  -4.00944432e-05   1.98606429e+01] 2.58249933091e-32\n",
      "positions (x,y,z), reward: [ -8.26565062e-01   5.43305246e-04   1.92770120e+01] 6.24966894659e-33\n",
      "positions (x,y,z), reward: [-2.31012964 -0.01672707  5.41218291] 3.17894622599e-38\n",
      "positions (x,y,z), reward: [-2.62905881 -0.12080077  0.        ] 3.89851799776e-39\n",
      "Episode =  244, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.53864303e-02   9.94343068e-08   2.00652999e+01] 0.0731807354745\n",
      "positions (x,y,z), reward: [ -3.14793538e-01  -1.96047171e-05   2.02455892e+01] 3.28833485908e-21\n",
      "positions (x,y,z), reward: [ -3.53709357e-01  -9.07387385e-05   2.02244271e+01] 8.85915380932e-22\n",
      "positions (x,y,z), reward: [ -4.38682205e-01   4.67857361e-04   2.00952752e+01] 4.46996305268e-22\n",
      "positions (x,y,z), reward: [ -9.09811480e-01  -3.59994810e-04   1.86193425e+01] 1.29429655693e-32\n",
      "positions (x,y,z), reward: [-2.11109424 -0.01657907  8.5746176 ] 1.4940931962e-37\n",
      "positions (x,y,z), reward: [-2.35975413 -0.05003556  5.04168567] 1.86515727855e-38\n",
      "Episode =  245, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.79424599e-01   4.72790903e-04   2.01441035e+01] 3.64788448696e-22\n",
      "positions (x,y,z), reward: [ -1.09758861e+00   1.28362464e-03   1.73352261e+01] 1.05381915514e-33\n",
      "positions (x,y,z), reward: [ -1.58048404e+00  -5.04683701e-03   1.29004284e+01] 2.05260530306e-35\n",
      "positions (x,y,z), reward: [ -1.81064732e+00  -6.88821759e-03   1.08524354e+01] 1.07975073608e-36\n",
      "Episode =  246, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.67571631e+00   5.93187943e-03   1.22054356e+01] 5.27366318271e-36\n",
      "positions (x,y,z), reward: [ -1.72062861e+00   5.20178864e-03   1.19520385e+01] 2.42179406116e-36\n",
      "positions (x,y,z), reward: [ -1.81259311e+00  -8.88784937e-03   1.08416736e+01] 1.05392772708e-36\n",
      "positions (x,y,z), reward: [ -1.84044114e+00  -1.11631378e-03   9.77436504e+00] 1.94685179183e-36\n",
      "positions (x,y,z), reward: [ -1.99979331e+00  -3.68165217e-03   8.61288499e+00] 1.42744231545e-37\n",
      "Episode =  247, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.45925425e-02   2.73847156e-06   2.00661542e+01] 0.0755646848718\n",
      "positions (x,y,z), reward: [ -1.25723397e-01   2.49096168e-05   2.01600408e+01] 3.49295907115e-05\n",
      "positions (x,y,z), reward: [ -1.91531857e-01   5.68134200e-05   2.02194883e+01] 1.0795464223e-07\n",
      "positions (x,y,z), reward: [ -1.12819164e+00  -1.15164404e-04   1.72055142e+01] 1.57465134286e-33\n",
      "positions (x,y,z), reward: [ -1.26625352e+00   4.67418339e-03   1.66204174e+01] 1.85220462454e-34\n",
      "positions (x,y,z), reward: [ -1.36827790e+00  -2.48940718e-03   1.58444377e+01] 6.40363534803e-35\n",
      "positions (x,y,z), reward: [ -1.61980883e+00  -8.86134528e-04   1.29101131e+01] 2.15054775276e-35\n",
      "positions (x,y,z), reward: [-2.0926966  -0.01459974  7.35873186] 2.19916453145e-37\n",
      "Episode =  248, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.75639422e-01  -5.89238366e-04   2.01159124e+01] 1.47111526874e-17\n",
      "positions (x,y,z), reward: [ -1.10877656e+00   1.42245978e-03   1.70681952e+01] 1.43230539303e-33\n",
      "positions (x,y,z), reward: [ -1.56006223e+00  -1.02599876e-03   1.31229366e+01] 1.66427105625e-35\n",
      "positions (x,y,z), reward: [ -1.78958612e+00  -3.71234989e-04   1.11356901e+01] 8.22728421952e-37\n",
      "Episode =  249, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.97478655e-03   1.02147823e-07   2.00201928e+01] 0.791120596872\n",
      "positions (x,y,z), reward: [ -4.84755601e-01  -4.11646311e-04   2.00622388e+01] 9.76946058344e-23\n",
      "positions (x,y,z), reward: [ -1.04324777e+00  -5.86920837e-04   1.79511271e+01] 4.42026558144e-34\n",
      "positions (x,y,z), reward: [ -1.74651082e+00  -3.48756730e-03   1.14165274e+01] 8.22957287412e-37\n",
      "positions (x,y,z), reward: [ -1.76862086e+00   1.94160013e-03   1.05758106e+01] 1.41531931728e-36\n",
      "positions (x,y,z), reward: [-2.44000788 -0.14578232  0.23146729] 1.57542860496e-39\n",
      "Episode =  250, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.57341361e-01  -4.51391261e-05   2.02577004e+01] 1.71826457359e-13\n",
      "positions (x,y,z), reward: [ -1.03483562e+00  -2.02048713e-03   1.80988117e+01] 8.27461794273e-34\n",
      "positions (x,y,z), reward: [ -1.18859815e+00  -5.35441090e-03   1.67792301e+01] 4.58123709729e-34\n",
      "positions (x,y,z), reward: [ -1.75943384  -0.01608735  11.69278865] 1.23617847654e-36\n",
      "positions (x,y,z), reward: [-2.05227319 -0.04248998  6.72292958] 2.92921464653e-37\n",
      "positions (x,y,z), reward: [-2.42368219 -0.10690322  1.46661653] 3.84418804667e-39\n",
      "Episode =  251, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.01606945e-01  -1.64373760e-05   2.01306972e+01] 0.000407624187439\n",
      "positions (x,y,z), reward: [ -3.49482372e-01  -3.80716984e-05   2.02262351e+01] 8.6695484421e-22\n",
      "positions (x,y,z), reward: [ -8.90196092e-01  -5.13582574e-04   1.87211184e+01] 9.00210836533e-33\n",
      "positions (x,y,z), reward: [ -8.94875488e-01  -1.96392963e-04   1.86282574e+01] 1.27121841425e-32\n",
      "positions (x,y,z), reward: [ -9.83628239e-01   9.66726561e-04   1.83395803e+01] 4.01668510108e-33\n",
      "positions (x,y,z), reward: [ -2.13820121e+00  -4.81081716e-03   6.69552620e+00] 2.83178410616e-37\n",
      "Episode =  252, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.71470079e-01   1.88041272e-05   2.01947668e+01] 3.57107910762e-07\n",
      "positions (x,y,z), reward: [ -3.43752689e-01  -3.02382819e-05   2.02305472e+01] 9.06037168898e-22\n",
      "positions (x,y,z), reward: [ -6.29786448e-01   1.05034966e-04   1.96101028e+01] 1.12293853502e-31\n",
      "positions (x,y,z), reward: [ -1.12023291e+00   2.16993442e-04   1.71895400e+01] 1.58254085536e-33\n",
      "positions (x,y,z), reward: [ -1.35971012e+00   1.06363943e-03   1.58292569e+01] 5.96999564859e-35\n",
      "positions (x,y,z), reward: [-2.38026505 -0.0280337   2.22405443] 1.28182118893e-38\n",
      "positions (x,y,z), reward: [-2.53439049 -0.03155349  0.26735356] 2.25194865739e-39\n",
      "positions (x,y,z), reward: [-2.53716018 -0.03373684  0.        ] 3.28044393314e-39\n",
      "Episode =  253, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.14127695e+00   1.06800904e-03   1.69248933e+01] 9.66987892291e-34\n",
      "positions (x,y,z), reward: [ -1.22748571e+00   2.12813139e-03   1.66120542e+01] 1.9987916884e-34\n",
      "positions (x,y,z), reward: [ -1.33209504e+00  -2.57615346e-03   1.56421268e+01] 8.62242387701e-35\n",
      "positions (x,y,z), reward: [ -1.70946409e+00   1.61705257e-03   1.19575609e+01] 2.49107722527e-36\n",
      "Episode =  254, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.16781562e-01  -8.69291358e-06   2.02423168e+01] 2.32711903006e-08\n",
      "positions (x,y,z), reward: [ -1.09742800e+00   1.20440565e-03   1.77748077e+01] 3.7046048129e-34\n",
      "positions (x,y,z), reward: [ -1.34581171e+00   2.54216503e-03   1.54419600e+01] 1.33368720472e-34\n",
      "positions (x,y,z), reward: [-2.40019844 -0.08295485  1.8196913 ] 6.51513736347e-39\n",
      "Episode =  255, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.65128056e-01   6.08394317e-04   1.95584573e+01] 1.14030088707e-31\n",
      "positions (x,y,z), reward: [ -1.40392781e+00  -3.84469553e-03   1.58131961e+01] 6.47486542153e-35\n",
      "positions (x,y,z), reward: [ -1.76510001e+00   4.17020728e-03   1.21850562e+01] 5.19161656514e-36\n",
      "positions (x,y,z), reward: [ -1.81123315e+00   3.39449520e-03   1.19303875e+01] 2.39156008799e-36\n",
      "positions (x,y,z), reward: [ -1.85264742e+00   8.13905863e-04   1.16611244e+01] 1.20640435501e-36\n",
      "positions (x,y,z), reward: [-2.5591623  -0.03825068  1.44892727] 3.80026400488e-39\n",
      "positions (x,y,z), reward: [-2.5955696  -0.04537971  1.05373008] 2.25806739612e-39\n",
      "Episode =  256, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.94582245e-03   1.05767087e-07   2.00201961e+01] 0.791465738178\n",
      "positions (x,y,z), reward: [ -2.88694639e-01  -1.00128133e-04   2.02604279e+01] 3.84135370935e-21\n",
      "positions (x,y,z), reward: [ -1.55551143e+00  -8.13616677e-03   1.24822486e+01] 1.12402402449e-35\n",
      "positions (x,y,z), reward: [-1.86793424 -0.02222952  8.96808747] 2.96167066376e-37\n",
      "positions (x,y,z), reward: [-2.16999479 -0.04592734  4.39442783] 1.43872207009e-38\n",
      "positions (x,y,z), reward: [-2.17274343 -0.04757009  4.03326469] 1.81724460543e-38\n",
      "positions (x,y,z), reward: [-2.37468037 -0.10545382  0.70851846] 1.68039321922e-39\n",
      "Episode =  257, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.55724327e-01  -2.34074244e-05   2.02576080e+01] 2.82473905603e-11\n",
      "positions (x,y,z), reward: [ -3.81255914e-01   2.88022294e-04   2.01224548e+01] 4.9931413749e-22\n",
      "positions (x,y,z), reward: [ -8.69385131e-01   7.03921969e-04   1.86351943e+01] 1.22007213864e-32\n",
      "positions (x,y,z), reward: [ -1.32028282e+00  -2.89961571e-04   1.62340915e+01] 5.35443396437e-35\n",
      "positions (x,y,z), reward: [-2.44238772 -0.02732238  1.46572748] 4.21277145414e-39\n",
      "Episode =  258, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.57030374e-01  -1.63693954e-04   2.02094893e+01] 4.32491092155e-22\n",
      "positions (x,y,z), reward: [ -6.12471782e-01  -1.71062047e-04   1.95719190e+01] 1.22203842721e-31\n",
      "positions (x,y,z), reward: [ -8.36133560e-01  -1.54486921e-04   1.88447607e+01] 5.22227011677e-33\n",
      "Episode =  259, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -8.54450892e-01   4.41437131e-04   1.89483974e+01] 3.41301328192e-33\n",
      "positions (x,y,z), reward: [-2.32056889 -0.03745382  2.22905125] 1.24691125808e-38\n",
      "Episode =  260, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.58702627e-02   2.42623175e-05   2.00990433e+01] 0.0100784191826\n",
      "positions (x,y,z), reward: [ -4.61830462e-01   1.02724477e-03   2.00853054e+01] 2.25723681448e-22\n",
      "positions (x,y,z), reward: [ -8.65325378e-01  -2.67668262e-04   1.90575712e+01] 2.96127607812e-33\n",
      "positions (x,y,z), reward: [ -1.36869665e+00  -9.06036293e-04   1.52667237e+01] 1.77156008575e-34\n",
      "positions (x,y,z), reward: [-2.42857252 -0.05231569  1.85525599] 7.46877724544e-39\n",
      "Episode =  261, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.89726843e-01  -6.82935315e-04   2.01190134e+01] 5.32895137214e-22\n",
      "positions (x,y,z), reward: [-2.32308206 -0.0587797   5.07564421] 1.93342137258e-38\n",
      "Episode =  262, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.55830824e-01   6.95082581e-04   1.97075453e+01] 3.99286743508e-32\n",
      "positions (x,y,z), reward: [ -6.99569244e-01  -1.10784251e-03   1.94955592e+01] 7.94930339703e-32\n",
      "positions (x,y,z), reward: [-2.11889037 -0.02956826  8.55268188] 1.44740970233e-37\n",
      "positions (x,y,z), reward: [-2.16546047 -0.02352981  7.90632085] 1.0391472313e-37\n",
      "positions (x,y,z), reward: [-2.28445513 -0.06535722  5.69518479] 5.8492499718e-38\n",
      "positions (x,y,z), reward: [-2.65777136 -0.17362494  0.        ] 1.88375513509e-39\n",
      "Episode =  263, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.10283104e-03   6.96926117e-09   2.00201234e+01] 0.789043990964\n",
      "positions (x,y,z), reward: [ -1.28847422e-01  -8.57744994e-06   2.01577473e+01] 3.34247035959e-05\n",
      "positions (x,y,z), reward: [ -2.71770178e-01  -6.88781707e-05   2.02515280e+01] 1.54086307002e-13\n",
      "positions (x,y,z), reward: [ -5.30108609e-01  -1.16481574e-03   2.00498200e+01] 7.6130078226e-23\n",
      "positions (x,y,z), reward: [ -7.91467470e-01  -2.29084335e-03   1.93700326e+01] 1.4644151169e-32\n",
      "positions (x,y,z), reward: [ -1.41784107e+00   1.09387751e-04   1.54375835e+01] 1.42851140828e-34\n",
      "positions (x,y,z), reward: [ -1.92133350e+00  -5.10342111e-03   1.05444375e+01] 1.55292525408e-36\n",
      "positions (x,y,z), reward: [-2.21029277 -0.04383033  6.38182702] 1.96870283445e-37\n",
      "Episode =  264, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.66270181e-01   1.54886467e-04   1.99531891e+01] 3.71708436301e-32\n",
      "positions (x,y,z), reward: [ -5.92498784e-01  -2.93081214e-05   1.98796605e+01] 2.62084151365e-32\n",
      "positions (x,y,z), reward: [ -6.75431967e-01  -1.08472854e-04   1.94620394e+01] 4.62496238855e-32\n",
      "positions (x,y,z), reward: [ -7.65207840e-01   5.32135678e-05   1.92971178e+01] 7.76229596975e-33\n",
      "positions (x,y,z), reward: [ -1.30158091e+00   1.97936504e-03   1.58444131e+01] 5.43983950181e-35\n",
      "positions (x,y,z), reward: [ -1.50480085e+00  -2.17672580e-03   1.40680402e+01] 6.47882074317e-36\n",
      "positions (x,y,z), reward: [-1.81091256 -0.01342838  9.5154776 ] 1.28401898736e-36\n",
      "positions (x,y,z), reward: [-2.1232305  -0.02980389  5.44256897] 3.61790961962e-38\n",
      "positions (x,y,z), reward: [-2.42060943 -0.05514551  0.28150308] 2.11738471268e-39\n",
      "Episode =  265, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.13160145e+00   4.98052817e-04   1.74612822e+01] 6.83857292999e-34\n",
      "positions (x,y,z), reward: [-2.34121614 -0.01528749  3.61122092] 2.43636773745e-38\n",
      "Episode =  266, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.25317836e-01  -2.77360668e-04   1.98652002e+01] 2.67903268187e-32\n",
      "positions (x,y,z), reward: [ -1.02253781e+00   3.16719575e-03   1.82240002e+01] 1.76478589117e-33\n",
      "positions (x,y,z), reward: [ -1.06741686e+00   2.28441563e-03   1.80861876e+01] 7.6498400108e-34\n",
      "positions (x,y,z), reward: [ -1.56928403e+00   4.38856826e-03   1.42803862e+01] 1.03744291902e-35\n",
      "positions (x,y,z), reward: [ -1.77597955e+00   4.33581733e-03   1.19423108e+01] 2.48174977773e-36\n",
      "positions (x,y,z), reward: [ -1.87058043  -0.01661845  10.83235869] 1.08262253006e-36\n",
      "positions (x,y,z), reward: [ -1.87970635  -0.01328739  10.02782753] 2.44950870417e-36\n",
      "Episode =  267, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.51380841e-02  -3.43901539e-06   2.00999910e+01] 0.0102005686277\n",
      "positions (x,y,z), reward: [ -3.73440969e-01   5.13170265e-04   2.01277057e+01] 5.65424299138e-22\n",
      "positions (x,y,z), reward: [ -5.00436463e-01  -2.01164458e-03   2.00642548e+01] 8.71733109271e-23\n",
      "positions (x,y,z), reward: [ -1.35650923e+00  -1.29531834e-02   1.51227423e+01] 1.48364490267e-34\n",
      "positions (x,y,z), reward: [ -1.80550276  -0.04774253  10.57874654] 1.3469486011e-36\n",
      "positions (x,y,z), reward: [-2.28209029 -0.37734116  2.77644145] 1.37951280513e-38\n",
      "positions (x,y,z), reward: [-2.3427625  -0.44915978  2.03212043] 5.43976003265e-39\n",
      "Episode =  268, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.57397692e-01  -6.20187804e-04   1.95571973e+01] 1.13613475946e-31\n",
      "positions (x,y,z), reward: [ -6.86024713e-01  -1.56289306e-03   1.95073823e+01] 7.8719570225e-32\n",
      "positions (x,y,z), reward: [ -1.02797487e+00  -3.00248853e-03   1.82169263e+01] 1.69138987725e-33\n",
      "positions (x,y,z), reward: [ -1.13769015e+00   1.32353885e-03   1.73134991e+01] 1.12048591071e-33\n",
      "positions (x,y,z), reward: [ -1.41215518e+00  -2.15364346e-03   1.50836849e+01] 1.50653612003e-34\n",
      "positions (x,y,z), reward: [ -1.66256694e+00  -3.93037423e-03   1.26524695e+01] 1.75443273293e-35\n",
      "positions (x,y,z), reward: [-2.15724166 -0.00721017  6.38829513] 2.13751794991e-37\n",
      "positions (x,y,z), reward: [-2.35917898 -0.01403289  3.60816333] 2.7041726119e-38\n",
      "positions (x,y,z), reward: [-2.59015408 -0.02112487  0.24094148] 2.35974836317e-39\n",
      "Episode =  269, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.99071749e-03   2.13336574e-09   2.00201744e+01] 0.790772676345\n",
      "positions (x,y,z), reward: [ -6.19771205e-01   1.80517760e-04   1.97317416e+01] 4.28224634678e-32\n",
      "positions (x,y,z), reward: [ -1.63092461e+00  -9.70900217e-03   1.24655402e+01] 1.14911215864e-35\n",
      "positions (x,y,z), reward: [ -1.7175983   -0.01205242  11.97415889] 2.51329637889e-36\n",
      "positions (x,y,z), reward: [-2.04143243 -0.01863674  7.35592104] 1.89135774525e-37\n",
      "positions (x,y,z), reward: [-2.30530641 -0.04958004  2.60981424] 2.34383870907e-38\n",
      "positions (x,y,z), reward: [-2.49483399 -0.06265537  0.        ] 2.81207883255e-39\n",
      "Episode =  270, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [-2.37731681 -0.13885436  4.62167739] 1.16409473826e-38\n",
      "Episode =  271, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.46697299e-02  -2.02393142e-06   2.01001111e+01] 0.010426338121\n",
      "positions (x,y,z), reward: [ -3.36890142e-01   8.08357954e-05   2.02364364e+01] 9.66448888363e-22\n",
      "positions (x,y,z), reward: [ -6.29151746e-01  -2.95357868e-04   1.95671213e+01] 1.19715376844e-31\n",
      "positions (x,y,z), reward: [ -6.54985342e-01  -9.43720879e-04   1.95180011e+01] 8.74190778101e-32\n",
      "Episode =  272, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00533758] 0.893073381945\n",
      "positions (x,y,z), reward: [ -6.71359118e-01  -1.92453518e-03   1.94738066e+01] 4.47016537943e-32\n",
      "positions (x,y,z), reward: [ -1.03054554e+00  -2.27689193e-03   1.79685432e+01] 4.6653544245e-34\n",
      "positions (x,y,z), reward: [ -1.74274707  -0.01594821  10.61356318] 1.5047340511e-36\n",
      "positions (x,y,z), reward: [-1.96449249 -0.02498972  8.02295965] 1.19309053198e-37\n",
      "positions (x,y,z), reward: [-1.968169   -0.03065036  7.70304681] 1.52570523824e-37\n",
      "positions (x,y,z), reward: [-2.18656201 -0.0624602   4.42216808] 1.71548388616e-38\n",
      "Episode =  273, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.10607822e-03   1.06336880e-07   2.00201279e+01] 0.789050467333\n",
      "positions (x,y,z), reward: [ -6.41996322e-01  -7.03122060e-04   1.96525138e+01] 7.0695209689e-32\n",
      "positions (x,y,z), reward: [ -1.24220112e+00   2.84133460e-03   1.67515425e+01] 4.28020806066e-34\n",
      "positions (x,y,z), reward: [ -1.64339087e+00  -8.82043815e-04   1.33074568e+01] 1.2434772096e-35\n",
      "positions (x,y,z), reward: [ -2.17095431e+00   1.41175814e-03   6.37504704e+00] 2.07703285151e-37\n",
      "Episode =  274, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.60002760e-01   9.50097642e-04   2.00051131e+01] 3.15384303077e-23\n",
      "positions (x,y,z), reward: [ -6.33256505e-01  -1.20746176e-03   1.96613630e+01] 7.29867591661e-32\n",
      "positions (x,y,z), reward: [ -1.39846468e+00   2.57051884e-03   1.50975125e+01] 1.62807418494e-34\n",
      "positions (x,y,z), reward: [-2.2148813  -0.04614551  5.78405549] 6.86588388394e-38\n",
      "Episode =  275, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.84921903e-02   9.71208704e-08   2.00408243e+01] 0.4037509794\n",
      "positions (x,y,z), reward: [ -6.35446792e-01  -2.07267887e-03   1.96582387e+01] 7.14232672589e-32\n",
      "positions (x,y,z), reward: [ -8.83288339e-01  -3.53334354e-03   1.87249221e+01] 8.90789533826e-33\n",
      "Episode =  276, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.95559824e-01  -3.62186522e-05   1.98863638e+01] 2.7652167846e-32\n",
      "positions (x,y,z), reward: [ -8.41299462e-01   2.44827059e-04   1.86597660e+01] 1.26382832062e-32\n",
      "positions (x,y,z), reward: [ -1.11809689e+00   4.17281690e-04   1.69519542e+01] 1.03631394229e-33\n",
      "positions (x,y,z), reward: [ -1.63084908e+00   7.56427333e-04   1.22513537e+01] 5.48331433644e-36\n",
      "positions (x,y,z), reward: [ -1.86453104e+00   1.60957425e-03   9.27255914e+00] 5.98265350787e-37\n",
      "Episode =  277, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.14487843e-01   3.80655882e-04   1.99295417e+01] 3.14528551264e-32\n",
      "positions (x,y,z), reward: [ -1.18824923e+00   1.25829074e-03   1.70471081e+01] 1.38514826319e-33\n",
      "positions (x,y,z), reward: [ -1.35665734e+00   2.17809642e-03   1.64052647e+01] 7.72995299375e-35\n",
      "positions (x,y,z), reward: [ -1.66696277e+00   1.25557465e-03   1.33151701e+01] 1.27452544089e-35\n",
      "positions (x,y,z), reward: [ -1.67889394e+00   1.85049182e-03   1.28723500e+01] 2.16915955036e-35\n",
      "positions (x,y,z), reward: [ -1.70235915e+00   2.30446194e-03   1.26528873e+01] 1.71162500964e-35\n",
      "positions (x,y,z), reward: [ -1.99473431e+00   2.67523353e-03   9.48133683e+00] 9.97773008807e-37\n",
      "positions (x,y,z), reward: [ -2.33557330e+00   2.52915759e-03   5.39905145e+00] 2.87852867976e-38\n",
      "positions (x,y,z), reward: [ -2.45856043e+00   1.05618372e-03   2.56195305e+00] 2.01018382692e-38\n",
      "Episode =  278, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.26810050e-01   2.39602325e-05   2.01577660e+01] 3.49288976515e-05\n",
      "positions (x,y,z), reward: [ -9.78481147e-01   2.95841411e-03   1.83322516e+01] 4.26949236689e-33\n",
      "positions (x,y,z), reward: [ -2.11758869e+00   1.61859373e-03   7.60948186e+00] 1.41262895346e-37\n",
      "positions (x,y,z), reward: [ -2.35550078e+00   2.15348327e-03   3.94799061e+00] 1.99297752838e-38\n",
      "positions (x,y,z), reward: [-2.3695827   0.00347981  2.89508838] 3.27525446573e-38\n",
      "positions (x,y,z), reward: [-2.51449368  0.00478711  1.42605876] 3.78173248474e-39\n",
      "Episode =  279, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.68844842e-01  -8.17882078e-05   2.02510916e+01] 1.63618122887e-13\n",
      "positions (x,y,z), reward: [ -5.70572566e-01  -1.99437545e-04   1.99962155e+01] 7.09647773997e-32\n",
      "positions (x,y,z), reward: [ -9.00413243e-01   1.28446506e-05   1.89258903e+01] 3.54043036785e-33\n",
      "positions (x,y,z), reward: [ -1.42853340e+00   6.68544207e-04   1.50694543e+01] 1.65831840588e-34\n",
      "positions (x,y,z), reward: [ -1.62600058e+00   3.09624025e-04   1.40201429e+01] 6.33673459888e-36\n",
      "Episode =  280, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.44760535e-01   1.40179064e-03   2.00110097e+01] 3.58680990994e-23\n",
      "positions (x,y,z), reward: [ -6.18719665e-01  -1.60573101e-03   1.96661616e+01] 7.25610326415e-32\n",
      "positions (x,y,z), reward: [ -8.58695347e-01  -2.53015659e-03   1.87357115e+01] 8.62373493612e-33\n",
      "positions (x,y,z), reward: [ -9.89189964e-01   6.38006187e-03   1.82356669e+01] 1.79792256379e-33\n",
      "positions (x,y,z), reward: [ -1.91287765e+00  -9.15643914e-03   9.23716042e+00] 6.07118896651e-37\n",
      "positions (x,y,z), reward: [-2.10889089 -0.03481639  6.12086577] 1.27155713736e-37\n",
      "Episode =  281, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534206] 0.893029764323\n",
      "positions (x,y,z), reward: [ -1.23546287e-01  -1.02536360e-05   2.01600294e+01] 3.6181217946e-05\n",
      "positions (x,y,z), reward: [ -3.78206265e-01   1.25028425e-04   2.01146128e+01] 1.47396890084e-17\n",
      "positions (x,y,z), reward: [ -1.10370083e+00   5.66228944e-04   1.71989333e+01] 1.52789417203e-33\n",
      "positions (x,y,z), reward: [-1.84030385 -0.04738342  9.77500505] 1.76777251049e-36\n",
      "Episode =  282, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.97067112e-01   4.40415527e-06   2.02567376e+01] 3.6017452763e-21\n",
      "positions (x,y,z), reward: [ -3.84117460e-01   1.45500091e-04   2.01144312e+01] 1.51822694589e-17\n",
      "positions (x,y,z), reward: [ -8.90488568e-01   1.22825877e-04   1.84684873e+01] 9.10131194578e-33\n",
      "positions (x,y,z), reward: [ -1.10198675e+00  -3.08625776e-05   1.70765329e+01] 1.5076390769e-33\n",
      "positions (x,y,z), reward: [ -1.32391908e+00  -1.00377307e-03   1.52969376e+01] 1.84804869992e-34\n",
      "positions (x,y,z), reward: [ -1.65076370e+00   2.43017832e-03   1.22340729e+01] 5.38711450281e-36\n",
      "positions (x,y,z), reward: [ -1.78795297e+00  -3.81973230e-03   1.08718967e+01] 1.04365711088e-36\n",
      "positions (x,y,z), reward: [ -1.78679666e+00  -3.37733209e-03   1.03300258e+01] 2.06570657472e-36\n",
      "positions (x,y,z), reward: [ -2.01726366e+00  -5.19364390e-03   7.05879821e+00] 2.6973691519e-37\n",
      "positions (x,y,z), reward: [ -2.08032773e+00   1.55292337e-04   6.13349278e+00] 1.29543196645e-37\n",
      "Episode =  283, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.63386493e-01   4.49420820e-05   2.02552775e+01] 1.59519253988e-13\n",
      "positions (x,y,z), reward: [ -3.45802398e-01  -1.25819141e-04   2.02300502e+01] 8.68275056963e-22\n",
      "positions (x,y,z), reward: [ -4.26595108e-01   7.03466382e-04   2.01068755e+01] 4.22610828675e-22\n",
      "positions (x,y,z), reward: [ -8.69698279e-01   9.21447724e-04   1.90631322e+01] 3.07163559743e-33\n",
      "positions (x,y,z), reward: [ -8.79343888e-01   4.26819707e-04   1.88368621e+01] 5.89312896133e-33\n",
      "positions (x,y,z), reward: [ -2.08265934e+00   2.49577027e-03   8.30541366e+00] 1.01940457424e-37\n",
      "positions (x,y,z), reward: [ -2.09989900e+00   1.86126773e-03   7.66386070e+00] 1.50562315038e-37\n",
      "positions (x,y,z), reward: [ -2.33983879e+00   2.44435878e-03   3.30736034e+00] 3.38711642324e-38\n",
      "Episode =  284, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.61804973e-01  -1.61597910e-05   2.02565032e+01] 1.64941272264e-13\n",
      "Episode =  285, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.85394726e-02  -1.03508269e-07   2.00408103e+01] 0.403649586488\n",
      "positions (x,y,z), reward: [ -1.73131449e-01  -1.49487238e-05   2.01935209e+01] 3.55304978827e-07\n",
      "positions (x,y,z), reward: [ -6.52778494e-01  -2.58419576e-04   1.95520450e+01] 1.14874782745e-31\n",
      "positions (x,y,z), reward: [ -1.31298100e+00  -6.29905483e-03   1.64052815e+01] 9.18136616152e-35\n",
      "positions (x,y,z), reward: [ -1.80905439  -0.02621179  11.65010902] 1.22115324401e-36\n",
      "positions (x,y,z), reward: [-2.25608098 -0.1202743   5.35694797] 2.82430763592e-38\n",
      "Episode =  286, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.93655355e-01  -3.80410891e-05   2.02172094e+01] 1.04142017128e-07\n",
      "positions (x,y,z), reward: [ -6.26239603e-01  -3.60291284e-04   1.98609574e+01] 2.60938370913e-32\n",
      "positions (x,y,z), reward: [ -6.55894494e-01   3.10790086e-05   1.95625277e+01] 1.12905643744e-31\n",
      "positions (x,y,z), reward: [ -8.77340714e-01  -1.16574580e-03   1.90522544e+01] 3.04615357049e-33\n",
      "positions (x,y,z), reward: [ -1.02875619e+00   1.95320358e-03   1.82222546e+01] 1.60657338467e-33\n",
      "positions (x,y,z), reward: [ -1.14143766e+00  -1.35933645e-03   1.71864183e+01] 1.5226889984e-33\n",
      "positions (x,y,z), reward: [ -1.35804246e+00  -6.99418558e-04   1.62198021e+01] 4.83514489953e-35\n",
      "positions (x,y,z), reward: [ -1.62393529e+00  -6.67312708e-03   1.37972690e+01] 6.18872533242e-36\n",
      "positions (x,y,z), reward: [-2.12790735 -0.03747003  6.7153301 ] 3.00409363992e-37\n",
      "positions (x,y,z), reward: [-2.276866   -0.04195252  5.4242723 ] 3.23648984647e-38\n",
      "positions (x,y,z), reward: [-2.55271129 -0.1181373   1.09272413] 2.56114783845e-39\n",
      "Episode =  287, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.14255587e-01  -1.56205112e-03   1.94476859e+01] 4.10977443746e-32\n",
      "positions (x,y,z), reward: [-2.5549683  -0.10634761  0.        ] 2.82499106958e-39\n",
      "Episode =  288, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.72049678e-01  -1.11411454e-04   2.02494533e+01] 1.5050823518e-13\n",
      "positions (x,y,z), reward: [ -6.72271769e-01  -1.02180253e-03   1.95531644e+01] 1.15650097593e-31\n",
      "positions (x,y,z), reward: [ -1.00482425e+00  -5.75271484e-03   1.83311610e+01] 3.98200594402e-33\n",
      "positions (x,y,z), reward: [ -1.17022895e+00  -1.38762415e-05   1.71702847e+01] 1.47222276e-33\n",
      "positions (x,y,z), reward: [ -1.39009722e+00  -3.87669300e-03   1.62028757e+01] 4.99092476135e-35\n",
      "positions (x,y,z), reward: [-2.08465266 -0.06102428  8.86970697] 2.57052637531e-37\n",
      "positions (x,y,z), reward: [-2.37532838 -0.12930324  4.99032948] 1.56624983863e-38\n",
      "Episode =  289, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.20639274e-03   1.36377733e-10   2.00200655e+01] 0.787308853039\n",
      "positions (x,y,z), reward: [ -3.65091067e-01  -1.00530396e-05   2.02133654e+01] 7.92401026084e-22\n",
      "positions (x,y,z), reward: [ -4.56292900e-01   5.35172841e-04   2.00883538e+01] 4.02546086507e-22\n",
      "positions (x,y,z), reward: [ -6.55856522e-01   1.40530985e-04   1.98400860e+01] 2.55881455148e-32\n",
      "positions (x,y,z), reward: [ -9.20628757e-01  -1.31888344e-04   1.90236120e+01] 2.9858826851e-33\n",
      "positions (x,y,z), reward: [ -9.58356971e-01   2.12980812e-03   1.85153938e+01] 1.23407581436e-32\n",
      "positions (x,y,z), reward: [ -1.18434069e+00  -5.51342214e-04   1.77350555e+01] 3.78038966673e-34\n",
      "positions (x,y,z), reward: [ -1.30294893e+00   7.03942662e-03   1.67262525e+01] 3.92447041222e-34\n",
      "positions (x,y,z), reward: [ -1.46589166e+00   5.19107229e-04   1.52257095e+01] 1.80897603076e-34\n",
      "positions (x,y,z), reward: [ -1.52431399e+00   7.02011427e-03   1.48655097e+01] 8.89387298667e-35\n",
      "positions (x,y,z), reward: [ -1.65947755e+00   5.15963791e-03   1.42284760e+01] 9.13440209962e-36\n",
      "positions (x,y,z), reward: [ -1.71494467e+00  -5.75108733e-03   1.32764669e+01] 1.25237396854e-35\n",
      "positions (x,y,z), reward: [-2.3580982  -0.01820626  5.69547367] 5.38806726516e-38\n",
      "Episode =  290, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.92104006e-01   3.74392991e-04   2.01325316e+01] 3.79749617413e-22\n",
      "positions (x,y,z), reward: [ -6.48426327e-01   4.88329349e-04   1.96015254e+01] 1.08555213692e-31\n",
      "positions (x,y,z), reward: [ -7.34657944e-01  -2.41367941e-03   1.94437285e+01] 3.65395750958e-32\n",
      "positions (x,y,z), reward: [ -9.01787250e-01   8.73854182e-04   1.86236984e+01] 1.27436816599e-32\n",
      "positions (x,y,z), reward: [-2.00900987 -0.03948015  9.18246068] 5.3996700179e-37\n",
      "positions (x,y,z), reward: [-2.38021856 -0.08490197  3.92923192] 1.92059239119e-38\n",
      "positions (x,y,z), reward: [-2.42132254 -0.13206114  2.51635651] 2.05962998194e-38\n",
      "positions (x,y,z), reward: [-2.5014656  -0.15464735  1.77730903] 6.11220148878e-39\n",
      "Episode =  291, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.08565150e-01  -9.13328060e-07   2.02496216e+01] 3.19439071971e-21\n",
      "positions (x,y,z), reward: [ -8.77939840e-01  -2.60504336e-04   1.89416927e+01] 3.58607333108e-33\n",
      "positions (x,y,z), reward: [ -1.26751125e+00  -5.52252238e-04   1.66061764e+01] 1.81487071845e-34\n",
      "positions (x,y,z), reward: [ -1.47098190e+00   1.57702739e-04   1.47235110e+01] 4.58547792142e-35\n",
      "positions (x,y,z), reward: [ -1.58999906e+00  -1.43857844e-03   1.40489996e+01] 6.28264759541e-36\n",
      "positions (x,y,z), reward: [ -1.60715155e+00  -2.31064370e-03   1.38069525e+01] 6.23895393275e-36\n",
      "positions (x,y,z), reward: [ -1.67645834e+00   6.13024553e-04   1.24448205e+01] 1.02870022233e-35\n",
      "Episode =  292, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.47604715e-02   3.45389941e-07   2.00659612e+01] 0.0759524227116\n",
      "positions (x,y,z), reward: [ -1.90259684e-01   2.82012525e-05   2.02182006e+01] 1.03973758406e-07\n",
      "positions (x,y,z), reward: [ -3.06255540e-01   1.11587813e-05   2.02490413e+01] 3.08168172011e-21\n",
      "positions (x,y,z), reward: [ -6.13261784e-01  -4.47314354e-04   1.98651742e+01] 2.46675868293e-32\n",
      "positions (x,y,z), reward: [ -8.01120241e-01   5.87082256e-04   1.92840269e+01] 6.10495113757e-33\n",
      "positions (x,y,z), reward: [ -1.20606364e+00   1.80478007e-03   1.67744540e+01] 4.34810053001e-34\n",
      "positions (x,y,z), reward: [ -2.06341683e+00  -4.25908538e-03   7.96925894e+00] 1.22753539992e-37\n",
      "Episode =  293, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -7.71758691e-02   1.34112181e-06   2.00979363e+01] 0.00978207864315\n",
      "positions (x,y,z), reward: [ -5.67706244e-01   7.35505791e-04   1.99983495e+01] 6.68106845195e-32\n",
      "positions (x,y,z), reward: [ -1.14534074e+00  -4.11806573e-03   1.74541570e+01] 7.3090765347e-34\n",
      "positions (x,y,z), reward: [ -1.28894496e+00   5.37384655e-03   1.65891761e+01] 1.92125911336e-34\n",
      "positions (x,y,z), reward: [ -1.83748874e+00  -1.60928889e-03   1.16589358e+01] 1.16478897603e-36\n",
      "positions (x,y,z), reward: [-2.61132823 -0.19670833  0.        ] 4.05129384616e-39\n",
      "Episode =  294, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.00671512e-03   3.92390342e-09   2.00201624e+01] 0.790484006043\n",
      "positions (x,y,z), reward: [ -1.23415657e-01   1.03358792e-05   2.01609056e+01] 3.62145261082e-05\n",
      "positions (x,y,z), reward: [ -9.92847403e-01   6.70513667e-03   1.82376298e+01] 1.828557984e-33\n",
      "positions (x,y,z), reward: [ -1.33450621e+00  -2.78275769e-03   1.60418321e+01] 4.6873749506e-35\n",
      "positions (x,y,z), reward: [ -1.34170400e+00  -6.25004676e-03   1.58425939e+01] 5.87056014541e-35\n",
      "positions (x,y,z), reward: [ -1.60404411e+00  -2.57375614e-03   1.26860819e+01] 1.76220251076e-35\n",
      "positions (x,y,z), reward: [-2.04541394 -0.04051168  7.99586438] 1.18638650239e-37\n",
      "positions (x,y,z), reward: [-2.04851103 -0.05053609  7.36355248] 2.05491671628e-37\n",
      "positions (x,y,z), reward: [-2.15770575 -0.04700323  5.80608943] 6.8381895117e-38\n",
      "positions (x,y,z), reward: [-2.43412995 -0.1216708   1.53641413] 4.64080687313e-39\n",
      "positions (x,y,z), reward: [-2.50608298 -0.18690388  0.        ] 3.99145575919e-39\n",
      "Episode =  295, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.53590447e-01   3.21942417e-05   2.01789204e+01] 1.70019826575e-06\n",
      "positions (x,y,z), reward: [ -8.44361836e-01   8.07346046e-04   1.91715377e+01] 3.93280243457e-33\n",
      "positions (x,y,z), reward: [ -8.77114524e-01   6.21562060e-04   1.87239855e+01] 9.57192043606e-33\n",
      "positions (x,y,z), reward: [ -9.65974031e-01   1.76521351e-03   1.83429345e+01] 4.52139005871e-33\n",
      "positions (x,y,z), reward: [ -1.58549117e+00   2.82269434e-03   1.40414096e+01] 6.49308944046e-36\n",
      "positions (x,y,z), reward: [ -1.61057849e+00   1.54978179e-03   1.35584556e+01] 7.9272435878e-36\n",
      "positions (x,y,z), reward: [-2.3211468   0.00624112  4.33327317] 1.62446957973e-38\n",
      "Episode =  296, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.36389142e-01  -6.79314022e-05   2.02379783e+01] 9.79923385599e-22\n",
      "positions (x,y,z), reward: [ -6.16743866e-01  -4.95686700e-04   1.97314301e+01] 4.39884361816e-32\n",
      "positions (x,y,z), reward: [ -9.34688473e-01   1.80641779e-03   1.83602699e+01] 4.74576411108e-33\n",
      "positions (x,y,z), reward: [ -1.53935572e+00   2.53902055e-03   1.40707516e+01] 6.73223864599e-36\n",
      "Episode =  297, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.82311152e-01   2.78365746e-04   1.99456657e+01] 3.4239739222e-32\n",
      "positions (x,y,z), reward: [ -1.09471073e+00   6.65569174e-04   1.74787338e+01] 7.04490987597e-34\n",
      "positions (x,y,z), reward: [ -1.35557584e+00   4.80697594e-04   1.51120467e+01] 1.59695512376e-34\n",
      "positions (x,y,z), reward: [ -1.42965063e+00   7.12676526e-04   1.47360785e+01] 4.53127694757e-35\n",
      "positions (x,y,z), reward: [ -1.47510234e+00   6.05727951e-04   1.45260694e+01] 1.96634108051e-35\n",
      "positions (x,y,z), reward: [ -1.67141528e+00   1.48420253e-03   1.22200448e+01] 5.0370778887e-36\n",
      "positions (x,y,z), reward: [ -1.91049915e+00   1.71486366e-03   9.23634980e+00] 5.59322169546e-37\n",
      "positions (x,y,z), reward: [ -2.22573496e+00   3.68451623e-04   5.09142907e+00] 1.77386781638e-38\n",
      "Episode =  298, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.04865796e-03   2.61679538e-08   2.00201396e+01] 0.789803470725\n",
      "positions (x,y,z), reward: [ -3.69821641e-01   2.58099884e-04   2.02001068e+01] 4.1547361033e-22\n",
      "positions (x,y,z), reward: [ -8.01988592e-01  -7.66039336e-04   1.92856812e+01] 6.85426531205e-33\n",
      "positions (x,y,z), reward: [-1.94482738 -0.01920476  9.22064956] 5.57950862075e-37\n",
      "Episode =  299, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.28410019e-01   1.21025761e-04   2.02391241e+01] 2.11201774988e-08\n",
      "positions (x,y,z), reward: [ -3.93129930e-01  -3.10126489e-04   2.01164097e+01] 5.40242897614e-22\n",
      "positions (x,y,z), reward: [ -9.07794308e-01  -6.72663006e-04   1.86267652e+01] 1.33658737199e-32\n",
      "positions (x,y,z), reward: [ -1.40096925e+00  -9.00028807e-04   1.60109944e+01] 4.64842076558e-35\n",
      "positions (x,y,z), reward: [ -1.40871502e+00  -2.22781260e-03   1.56196917e+01] 9.1583088516e-35\n",
      "positions (x,y,z), reward: [ -1.72680614e+00   3.63420156e-03   1.24240151e+01] 1.0027043969e-35\n",
      "Episode =  300, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.91368645e-01   9.35495247e-04   2.00661453e+01] 8.51494040287e-23\n",
      "positions (x,y,z), reward: [ -5.99324260e-01  -3.55283374e-04   1.98800537e+01] 2.55571093568e-32\n",
      "positions (x,y,z), reward: [ -6.48931419e-01   1.87915396e-03   1.95277848e+01] 8.42125922399e-32\n",
      "positions (x,y,z), reward: [ -1.40863620e+00   9.00105440e-03   1.47478323e+01] 4.90397235218e-35\n",
      "positions (x,y,z), reward: [ -1.78728843  -0.03494751  10.07790106] 2.39688587055e-36\n",
      "positions (x,y,z), reward: [-2.00834605 -0.07589696  8.02842357] 1.30776174291e-37\n",
      "Episode =  301, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00535068] 0.892993497771\n",
      "positions (x,y,z), reward: [ -4.00070023e-01  -6.84099029e-04   2.01277192e+01] 3.95910530892e-22\n",
      "positions (x,y,z), reward: [ -1.18396170e+00  -1.46815144e-03   1.72987713e+01] 1.18159227015e-33\n",
      "positions (x,y,z), reward: [ -1.24700738e+00   2.80381924e-03   1.68928246e+01] 8.32118259356e-34\n",
      "positions (x,y,z), reward: [ -1.93594819e+00   1.43836600e-05   1.13534384e+01] 7.9377448809e-37\n",
      "Episode =  302, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.01207884e-01   2.27990795e-04   2.01071203e+01] 1.43296277025e-17\n",
      "positions (x,y,z), reward: [ -8.74139885e-01   1.95679156e-04   1.90538717e+01] 2.92958535293e-33\n",
      "positions (x,y,z), reward: [ -1.13120581e+00  -4.20519830e-04   1.73192040e+01] 1.11135634709e-33\n",
      "positions (x,y,z), reward: [ -1.13676219e+00   3.50883681e-04   1.71841866e+01] 1.50127770099e-33\n",
      "positions (x,y,z), reward: [-2.57547661  0.00487177  0.25379691] 2.31096732224e-39\n",
      "Episode =  303, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.45194511e-01  -7.36719607e-04   1.95158728e+01] 8.15776491212e-32\n",
      "positions (x,y,z), reward: [ -8.44300182e-01   1.11515248e-03   1.89476972e+01] 3.30587060485e-33\n",
      "positions (x,y,z), reward: [ -1.28445786e+00  -1.68009290e-03   1.62349342e+01] 5.394118012e-35\n",
      "positions (x,y,z), reward: [-2.43989288 -0.01493811  0.27144581] 2.11702422396e-39\n",
      "Episode =  304, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.13416850e+00   1.55981417e-03   1.79172922e+01] 4.02890217106e-34\n",
      "positions (x,y,z), reward: [ -1.57470259e+00   7.75953158e-03   1.44852379e+01] 2.00055978281e-35\n",
      "Episode =  305, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.89637249e-01   1.41818683e-04   2.01349304e+01] 3.6956736927e-22\n",
      "positions (x,y,z), reward: [ -8.78560354e-01  -4.36676591e-04   1.90486092e+01] 2.97193341938e-33\n",
      "positions (x,y,z), reward: [ -1.07177525e+00  -2.89707827e-05   1.80767271e+01] 7.31665925285e-34\n",
      "positions (x,y,z), reward: [ -1.32478236e+00  -5.10642478e-05   1.64070398e+01] 8.26389585657e-35\n",
      "positions (x,y,z), reward: [ -1.44484188e+00   3.80984753e-04   1.48978064e+01] 9.74977362086e-35\n",
      "Episode =  306, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.79566035e-01  -9.53869267e-04   2.00828647e+01] 1.84753914554e-22\n",
      "positions (x,y,z), reward: [ -6.43856636e-01   1.65686051e-03   1.97822104e+01] 3.1206508778e-32\n",
      "positions (x,y,z), reward: [ -7.85450978e-01  -1.98454785e-03   1.93698037e+01] 1.49078245483e-32\n",
      "positions (x,y,z), reward: [ -1.46420381e+00  -4.48855670e-03   1.49047771e+01] 9.53668779943e-35\n",
      "positions (x,y,z), reward: [ -1.65002877e+00  -5.65019615e-04   1.35515929e+01] 8.45206496401e-36\n",
      "positions (x,y,z), reward: [ -1.93492809e+00  -9.02618683e-03   9.75730505e+00] 1.84505363154e-36\n",
      "positions (x,y,z), reward: [-2.14327988 -0.01128007  7.31141632] 2.10400118903e-37\n",
      "positions (x,y,z), reward: [-2.36997636 -0.01640073  4.68548131] 1.36766642569e-38\n",
      "Episode =  307, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534276] 0.892996627864\n",
      "positions (x,y,z), reward: [ -4.07961363e-03   2.98092091e-08   2.00201232e+01] 0.789301766993\n",
      "positions (x,y,z), reward: [ -1.50162366e+00   5.72942137e-03   1.45025582e+01] 2.05366299968e-35\n",
      "positions (x,y,z), reward: [ -1.60415047e+00  -2.45806719e-03   1.28789085e+01] 2.11364685622e-35\n",
      "positions (x,y,z), reward: [ -1.74632286e+00   4.45082412e-03   1.19387009e+01] 2.33738219875e-36\n",
      "positions (x,y,z), reward: [ -1.83590242  -0.01119651  10.82781835] 1.13870240608e-36\n",
      "positions (x,y,z), reward: [-2.07204979 -0.02559131  7.32084029] 2.0580051748e-37\n",
      "positions (x,y,z), reward: [-2.07345169 -0.02459979  7.01266789] 2.70940522438e-37\n",
      "positions (x,y,z), reward: [-2.30301438 -0.04624492  4.34099436] 1.69029872733e-38\n",
      "Episode =  308, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.87033228e-01   4.05468302e-04   2.01181414e+01] 5.52721503832e-22\n",
      "positions (x,y,z), reward: [ -6.38075981e-01   6.65151088e-04   1.96570423e+01] 7.80524792799e-32\n",
      "positions (x,y,z), reward: [ -8.56678512e-01  -7.32958359e-04   1.91674448e+01] 3.55862420475e-33\n",
      "positions (x,y,z), reward: [ -9.09994410e-01  -6.44519392e-04   1.85414647e+01] 1.28453897014e-32\n",
      "positions (x,y,z), reward: [ -1.10904728e+00  -7.83726290e-04   1.79279835e+01] 4.2366174095e-34\n",
      "positions (x,y,z), reward: [ -1.23709360e+00  -2.37019449e-03   1.67623403e+01] 4.29125764799e-34\n",
      "positions (x,y,z), reward: [ -1.57821132e+00  -2.71649039e-03   1.42743766e+01] 9.50643726093e-36\n",
      "positions (x,y,z), reward: [ -1.82762167e+00  -4.69477450e-03   1.16672036e+01] 1.09703558822e-36\n",
      "positions (x,y,z), reward: [ -2.10180343e+00  -7.62065668e-03   8.27156302e+00] 1.04266814552e-37\n",
      "positions (x,y,z), reward: [-2.34333687 -0.02155225  4.69003964] 1.36428320394e-38\n",
      "positions (x,y,z), reward: [-2.36140527 -0.02985385  3.26354133] 3.16468065844e-38\n",
      "Episode =  309, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -6.44175338e-01   2.89478478e-04   1.95647970e+01] 1.18523991243e-31\n",
      "positions (x,y,z), reward: [ -9.19991149e-01   1.49927381e-03   1.84541673e+01] 9.15837806795e-33\n",
      "positions (x,y,z), reward: [ -1.13820372e+00   6.93249448e-04   1.70583338e+01] 1.44886010193e-33\n",
      "positions (x,y,z), reward: [ -1.36190023e+00  -2.03854178e-03   1.58315022e+01] 5.76475592798e-35\n",
      "positions (x,y,z), reward: [ -1.38412597e+00   1.04792340e-03   1.50989516e+01] 1.66382718422e-34\n",
      "positions (x,y,z), reward: [ -2.38435045e+00  -1.49548479e-03   2.22751335e+00] 1.37661088575e-38\n",
      "Episode =  310, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.34307874e+00   1.83043968e-03   1.54633886e+01] 1.3945348394e-34\n",
      "positions (x,y,z), reward: [ -1.73155572e+00  -3.02821418e-03   1.19642610e+01] 2.28913091375e-36\n",
      "Episode =  311, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.01619547e-03   6.92156687e-09   2.00201651e+01] 0.790404893414\n",
      "positions (x,y,z), reward: [ -2.99890684e-01   2.10570225e-05   2.02535551e+01] 3.39146030182e-21\n",
      "positions (x,y,z), reward: [ -4.50877416e-01  -3.86973560e-04   2.00909526e+01] 2.19960869828e-22\n",
      "positions (x,y,z), reward: [ -1.14012230e+00  -4.84980226e-03   1.69290589e+01] 9.53421466126e-34\n",
      "positions (x,y,z), reward: [-1.89993453 -0.04988853  9.22269424] 5.72230116364e-37\n",
      "positions (x,y,z), reward: [-2.44604575 -0.23520029  1.01152218] 1.76252466424e-39\n",
      "Episode =  312, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.03675752e-03   1.40093208e-07   2.00201228e+01] 0.789774287452\n",
      "positions (x,y,z), reward: [ -7.12980548e-01  -1.02178847e-03   1.94558333e+01] 3.99381814707e-32\n",
      "positions (x,y,z), reward: [ -9.62608802e-01  -1.31791040e-03   1.83507653e+01] 4.2394523775e-33\n",
      "positions (x,y,z), reward: [ -1.10994005e+00  -7.88716843e-04   1.77808995e+01] 3.78491677482e-34\n",
      "positions (x,y,z), reward: [ -2.23381783e+00  -7.98729841e-04   5.43290455e+00] 3.54656005791e-38\n",
      "Episode =  313, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.00747596e-01  -2.64680057e-04   2.01044115e+01] 1.47346952187e-17\n",
      "positions (x,y,z), reward: [ -5.12268894e-01  -8.67596291e-04   2.00515272e+01] 8.33830909028e-23\n",
      "positions (x,y,z), reward: [ -1.31228477e+00  -2.11367831e-03   1.64115769e+01] 8.78633274302e-35\n",
      "positions (x,y,z), reward: [ -1.36709626e+00   1.05513046e-03   1.60155373e+01] 4.58038647028e-35\n",
      "positions (x,y,z), reward: [-2.09905996 -0.01232631  6.99180891] 2.44103111507e-37\n",
      "positions (x,y,z), reward: [-2.33280404 -0.0259356   3.95174219] 1.94359852195e-38\n",
      "Episode =  314, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.95219756e-03   2.85690768e-08   2.00201977e+01] 0.791412796629\n",
      "positions (x,y,z), reward: [ -3.32045683e-01   6.88054973e-06   2.02391905e+01] 9.40025229752e-22\n",
      "positions (x,y,z), reward: [ -1.32054048e+00   7.27700950e-04   1.51333654e+01] 1.7098152005e-34\n",
      "positions (x,y,z), reward: [ -1.47857393e+00   1.29741871e-03   1.43256293e+01] 1.03478308933e-35\n",
      "positions (x,y,z), reward: [ -1.53071719e+00  -3.24453401e-03   1.33744409e+01] 1.19090918916e-35\n",
      "positions (x,y,z), reward: [ -1.76055891e+00  -5.42830924e-03   1.08858208e+01] 1.12971680103e-36\n",
      "positions (x,y,z), reward: [-2.04610138 -0.08376195  6.04362704] 1.11049400594e-42\n",
      "positions (x,y,z), reward: [-2.2988366  -0.21847306  0.90348777] 9.13214115899e-50\n",
      "Episode =  315, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.31166685  -0.21131071  19.7674467 ] 6.23343274482e-42\n",
      "positions (x,y,z), reward: [ -0.95069573  -4.67649612  18.34356555] 9.50786738119e-33\n",
      "positions (x,y,z), reward: [  2.40212504  -8.19784246  14.28180716] 1.25102236663e-34\n",
      "positions (x,y,z), reward: [ -3.17026536 -12.34475245   4.03223118] 3.94625860916e-37\n",
      "Episode =  316, score =   0.000 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  2.64399986e-07   1.74973066e-02   2.00419735e+01] 0.431568162827\n",
      "positions (x,y,z), reward: [  0.95848377   4.80735262  15.28858921] 8.14412297072e-35\n",
      "positions (x,y,z), reward: [  2.17929373   6.32217452  11.0945589 ] 4.74774697572e-36\n",
      "Episode =  317, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.0351913    2.54488377  19.05789797] 1.01846296125e-32\n",
      "positions (x,y,z), reward: [ -0.0583751    2.92948225  18.72274282] 1.50083292533e-32\n",
      "positions (x,y,z), reward: [ -0.15598275   3.79278469  17.42742673] 2.57581608448e-33\n",
      "positions (x,y,z), reward: [ -0.39273239   4.87489208  15.22308113] 7.60997263664e-35\n",
      "positions (x,y,z), reward: [ -0.58759136   5.48144555  13.68032094] 3.10032277008e-35\n",
      "positions (x,y,z), reward: [ -0.72400544   5.809682    12.81886601] 8.05738953801e-36\n",
      "positions (x,y,z), reward: [ -0.87978312   6.10570362  11.77195506] 1.37045484712e-36\n",
      "positions (x,y,z), reward: [-1.67542747  7.44849649  7.54374866] 5.45718179406e-37\n",
      "positions (x,y,z), reward: [-2.75891481  8.24811337  2.84992443] 7.57693829485e-31\n",
      "positions (x,y,z), reward: [-3.76349818  7.63727585  0.        ] 2.81866777454e-31\n",
      "Episode =  318, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.88042531e-07   1.76979804e-02   2.00418039e+01] 0.42705263389\n",
      "positions (x,y,z), reward: [  7.67210193e-05   1.03345144e-01   2.01879400e+01] 4.50248981504e-06\n",
      "positions (x,y,z), reward: [  0.14943727   2.65251916  18.93339714] 1.54067967205e-32\n",
      "positions (x,y,z), reward: [  0.35356151   3.38095999  17.90411727] 7.37519244133e-34\n",
      "positions (x,y,z), reward: [  2.52795138   5.33993824  13.63897873] 3.19523820691e-23\n",
      "positions (x,y,z), reward: [  2.86676321   5.45392442  13.48133754] 2.10417652125e-22\n",
      "positions (x,y,z), reward: [  6.27667399   5.4238235   13.43054047] 8.78691081406e-09\n",
      "positions (x,y,z), reward: [  7.25361315   5.09849146  13.42983699] 1.71677326886e-20\n",
      "positions (x,y,z), reward: [ 11.08325698   3.48248428  12.77489521] 4.38090941147e-23\n",
      "positions (x,y,z), reward: [ 24.56419356  -1.60066734   8.34608401] 7.36679239932e-35\n",
      "Episode =  319, score =   0.026 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  7.17530781e-04   8.22666238e-02   2.05985182e+01] 3.59499739902e-08\n",
      "positions (x,y,z), reward: [  9.85313486e-04   1.05052884e-01   2.07769133e+01] 2.7839980919e-08\n",
      "positions (x,y,z), reward: [ -0.21933032  -0.14703344  20.08358514] 7.16600423646e-24\n",
      "positions (x,y,z), reward: [ -0.74867365  -0.23090946  18.25350912] 6.89308468791e-34\n",
      "positions (x,y,z), reward: [-5.77131881 -0.4221913   8.44061063] 6.52424504623e-37\n",
      "positions (x,y,z), reward: [-8.62088959 -0.48933114  4.57868754] 6.63731307742e-38\n",
      "Episode =  320, score =   0.031 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -9.51849218e-03   1.20269393e+00   2.01520107e+01] 6.6989346011e-23\n",
      "positions (x,y,z), reward: [ -0.96090953   5.14191719  14.45070666] 2.06082835995e-35\n",
      "positions (x,y,z), reward: [ -1.2750646    5.66442906  13.19081034] 1.03522498549e-35\n",
      "positions (x,y,z), reward: [ -1.51000038   5.95554093  12.16526054] 2.01184711466e-36\n",
      "positions (x,y,z), reward: [-2.11526475  6.69808529  9.81066091] 3.09681427841e-37\n",
      "positions (x,y,z), reward: [-2.26349673  6.86528327  9.19975016] 2.7812869777e-37\n",
      "Episode =  321, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -2.95048741e-09   4.08099717e-03   2.00201154e+01] 0.789207878714\n",
      "positions (x,y,z), reward: [  0.25256306   3.1415093   18.24244468] 1.05008269325e-33\n",
      "positions (x,y,z), reward: [  0.45975892   3.81106857  17.25237977] 2.02213760129e-33\n",
      "positions (x,y,z), reward: [  0.7089898    4.24636063  16.25997926] 6.31759110682e-35\n",
      "positions (x,y,z), reward: [  1.09749598   4.89623812  15.00238514] 6.56863771991e-35\n",
      "positions (x,y,z), reward: [  1.52574008   5.39212454  13.65843213] 1.80424512103e-35\n",
      "positions (x,y,z), reward: [  1.86246225   5.76061487  12.80321832] 1.64830993511e-35\n",
      "positions (x,y,z), reward: [ 17.01890849   2.7959667    0.63228846] 2.90228049691e-28\n",
      "Episode =  322, score =   0.031 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.41743823e-04   1.69683743e-01   2.02297096e+01] 2.8928026509e-10\n",
      "positions (x,y,z), reward: [  5.27760112e-04   4.37007452e-01   2.01680774e+01] 7.7246988742e-22\n",
      "positions (x,y,z), reward: [  4.59090165  10.35731625   1.57935311] 6.67410942447e-30\n",
      "Episode =  323, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00534443] 0.893014658646\n",
      "positions (x,y,z), reward: [  0.93629266   5.69474548  13.09045417] 2.75206127099e-35\n",
      "positions (x,y,z), reward: [  1.59469675   6.62979817  10.29195993] 3.14368355436e-36\n",
      "positions (x,y,z), reward: [ 2.20988815  7.28248625  7.93081458] 6.00193691156e-34\n",
      "positions (x,y,z), reward: [ 3.51913432  8.68928398  4.44816251] 2.39163120145e-25\n",
      "positions (x,y,z), reward: [  4.66089256  10.01579487   3.24051388] 4.40854889836e-22\n",
      "Episode =  324, score =   0.031 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  5.58767036e-03   1.10414198e+00   2.01721670e+01] 3.96363613777e-22\n",
      "positions (x,y,z), reward: [  0.27350144   4.31182874  16.38221589] 1.24231756051e-34\n",
      "positions (x,y,z), reward: [  0.42391262   5.06013315  14.71521315] 1.15969104959e-35\n",
      "positions (x,y,z), reward: [  0.44144149   5.14931052  14.48494875] 1.15146932068e-35\n",
      "positions (x,y,z), reward: [ 0.76607723  6.85136731  9.53726675] 2.59968328445e-37\n",
      "Episode =  325, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.07695919e-03   1.99012057e+00   1.96777441e+01] 1.32934285651e-31\n",
      "positions (x,y,z), reward: [ -0.05388131   4.33663655  16.27372973] 1.0689090799e-34\n",
      "positions (x,y,z), reward: [ -0.18684374   5.49465356  13.69018796] 3.27796384508e-35\n",
      "positions (x,y,z), reward: [-1.68461802  9.57857744  3.11238857] 5.27378324753e-30\n",
      "Episode =  326, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  9.43616540e-06   6.02789301e-02   2.01061698e+01] 0.00975735757336\n",
      "positions (x,y,z), reward: [  4.88720627e-04   2.18023040e-01   2.02344159e+01] 7.06730787902e-16\n",
      "positions (x,y,z), reward: [  1.18504513   6.62100378  10.35550289] 3.20226052705e-36\n",
      "positions (x,y,z), reward: [  3.11996629  12.40227008   1.09805779] 1.76126566813e-25\n",
      "Episode =  327, score =   0.036 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.43241017   3.80024515  17.50280153] 1.92387693595e-33\n",
      "positions (x,y,z), reward: [ -2.66462575   6.07782011  11.87799532] 3.12900629921e-36\n",
      "positions (x,y,z), reward: [-10.25860013   8.58469875   2.33204033] 3.08950334333e-38\n",
      "Episode =  328, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.98419832e-07   1.82902535e-02   2.00413227e+01] 0.417902036126\n",
      "positions (x,y,z), reward: [ -1.79233658e-04   1.75957887e-01   2.02272629e+01] 3.05100067712e-10\n",
      "positions (x,y,z), reward: [ -1.47512393e-03   6.60390272e-01   2.01250043e+01] 7.66441727139e-22\n",
      "positions (x,y,z), reward: [ -0.03706426   3.65462269  17.57099244] 1.66372629005e-33\n",
      "positions (x,y,z), reward: [ -0.04541509   4.61116353  15.78069015] 2.10497972379e-34\n",
      "positions (x,y,z), reward: [ 0.06760078  7.2550681   8.20926862] 2.33742585825e-37\n",
      "positions (x,y,z), reward: [ 0.10941246  7.72667769  6.70420999] 1.73442669083e-37\n",
      "Episode =  329, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  6.73289458e-04   2.17008954e-01   2.02350748e+01] 7.18358168902e-16\n",
      "positions (x,y,z), reward: [  1.21268853e-02   1.11153062e+00   2.01312859e+01] 3.40712819938e-22\n",
      "positions (x,y,z), reward: [  0.19781859   2.85530129  18.76955909] 2.06774489487e-32\n",
      "positions (x,y,z), reward: [  0.30818218   3.20292666  18.20283228] 6.7464815406e-34\n",
      "positions (x,y,z), reward: [  1.02312939   4.81336926  15.35098287] 1.61720060857e-34\n",
      "positions (x,y,z), reward: [  1.45638767   5.37743658  13.83647906] 2.1003838332e-35\n",
      "positions (x,y,z), reward: [ 5.89747313  5.10377442  0.63149762] 7.22420339094e-31\n",
      "Episode =  330, score =   0.039 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  6.86295090e-03   3.11834777e+00   1.84487242e+01] 1.30375546889e-33\n",
      "positions (x,y,z), reward: [  0.06877853   3.86443192  17.37811514] 1.66320935741e-33\n",
      "positions (x,y,z), reward: [  0.72666917   5.92955966  12.43704129] 2.16524297296e-36\n",
      "positions (x,y,z), reward: [  3.65821515  11.48497417   1.86781441] 5.23171078816e-27\n",
      "positions (x,y,z), reward: [  4.67259229  14.09392565   0.11873021] 1.45152561346e-24\n",
      "Episode =  331, score =   0.036 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  3.49006064e-04   6.42899138e-01   2.01629386e+01] 1.13235070737e-21\n",
      "positions (x,y,z), reward: [  1.22320793e-03   1.69332551e+00   1.98507828e+01] 1.57988075593e-31\n",
      "positions (x,y,z), reward: [  6.65588819e-04   1.88891864e+00   1.97823007e+01] 2.19126286714e-31\n",
      "positions (x,y,z), reward: [ -0.12138417   3.7597878   17.57259505] 2.85095970806e-33\n",
      "positions (x,y,z), reward: [-4.71879223  8.89399812  1.40094362] 1.12176608622e-38\n",
      "positions (x,y,z), reward: [-5.22398257  9.17903689  0.31331352] 1.59825498452e-38\n",
      "Episode =  332, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  8.35755355e-06   5.82928994e-02   2.01069293e+01] 0.00986028523634\n",
      "positions (x,y,z), reward: [  1.20036665e-04   8.53948738e-01   2.01761149e+01] 3.62625387559e-10\n",
      "positions (x,y,z), reward: [ -3.24732895e-03   1.57677774e+00   1.99095350e+01] 1.09548118886e-31\n",
      "positions (x,y,z), reward: [ -6.70340326e-03   1.88020530e+00   1.97992988e+01] 2.48213271509e-31\n",
      "positions (x,y,z), reward: [ -0.06754255   3.07936814  18.53215115] 1.424417997e-33\n",
      "positions (x,y,z), reward: [ -0.14171844   3.74200916  17.60592916] 3.08321334249e-33\n",
      "positions (x,y,z), reward: [ -0.20453544   4.00771961  17.02224883] 1.65127782031e-34\n",
      "positions (x,y,z), reward: [-1.57283314  6.94685224  9.07780006] 2.42245678228e-37\n",
      "positions (x,y,z), reward: [-2.17782025  7.69488454  6.33148851] 3.69496218291e-38\n",
      "Episode =  333, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -5.98306417e-05   8.89948692e-02   2.01580689e+01] 3.14818332694e-05\n",
      "positions (x,y,z), reward: [  0.03127772   2.97707279  18.72914578] 7.45065528567e-33\n",
      "positions (x,y,z), reward: [  0.12975398   4.03758969  16.97008713] 1.64343726269e-34\n",
      "positions (x,y,z), reward: [  0.34219627   5.13527451  14.52330599] 1.31397381e-35\n",
      "positions (x,y,z), reward: [  0.48840953   5.70782259  13.24557968] 2.15929534413e-35\n",
      "positions (x,y,z), reward: [  0.73278518   6.38018491  11.20597161] 4.77618802115e-36\n",
      "positions (x,y,z), reward: [ 1.52904008  7.92871696  5.51553774] 3.17991164754e-38\n",
      "positions (x,y,z), reward: [ 1.63026714  8.1349183   4.83434726] 5.95255042537e-38\n",
      "positions (x,y,z), reward: [ 1.68182698  8.23723349  4.50147961] 7.60563978549e-38\n",
      "Episode =  334, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -0.10007046   2.03307725  19.68490072] 6.89499686851e-32\n",
      "positions (x,y,z), reward: [ -2.42586644   5.40922729  13.88725162] 4.06524510096e-35\n",
      "positions (x,y,z), reward: [ -2.83696067   5.66003036  13.27177615] 2.21787026784e-35\n",
      "positions (x,y,z), reward: [ -3.13836688   5.78612754  12.8110476 ] 5.4023818284e-36\n",
      "positions (x,y,z), reward: [-5.47420226  6.74093467  9.73601739] 6.01264307657e-37\n",
      "Episode =  335, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  3.35440146e-06   8.72278947e-02   2.01593773e+01] 3.18614160675e-05\n",
      "positions (x,y,z), reward: [ -4.77466232e-04   6.41307470e-01   2.01591063e+01] 1.09009087718e-21\n",
      "positions (x,y,z), reward: [ -0.03586517   2.31300839  19.32931964] 5.45433249305e-33\n",
      "positions (x,y,z), reward: [ -0.07633687   2.96256162  18.71142208] 6.85033891711e-33\n",
      "positions (x,y,z), reward: [ -0.87339827   5.67827678  13.21409829] 1.98326189758e-35\n",
      "positions (x,y,z), reward: [ -0.92495764   5.74229019  12.98671194] 8.98070815491e-36\n",
      "positions (x,y,z), reward: [-3.35902409  8.1758357   4.51414181] 9.23871406297e-38\n",
      "positions (x,y,z), reward: [-4.91419998  9.16843005  0.17198403] 1.25262043057e-38\n",
      "Episode =  336, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  6.80819751e-06   6.22494559e-02   2.01050081e+01] 0.0095945881682\n",
      "positions (x,y,z), reward: [  5.13474193e-04   1.05871044e+00   2.01018941e+01] 1.39910949767e-17\n",
      "positions (x,y,z), reward: [  3.85964011e-03   1.93552693e+00   1.96189344e+01] 1.53554153375e-31\n",
      "positions (x,y,z), reward: [  0.07901324   3.54357258  17.62864904] 9.79708191595e-34\n",
      "positions (x,y,z), reward: [  0.17734191   4.39301444  16.04430022] 8.16495536774e-35\n",
      "positions (x,y,z), reward: [ 1.23964842  7.86076237  5.92759691] 1.08740626359e-32\n",
      "Episode =  337, score =   0.038 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -4.58274627e-05   6.00660567e-02   2.01064132e+01] 0.00981121976363\n",
      "positions (x,y,z), reward: [ -4.58739750e-03   4.38537131e-01   2.01820900e+01] 1.00754353725e-21\n",
      "positions (x,y,z), reward: [ -0.09531156   1.81386083  19.74550141] 1.76015729988e-31\n",
      "positions (x,y,z), reward: [-8.66317887  7.30160365  7.88226543] 1.38649833961e-36\n",
      "positions (x,y,z), reward: [-11.30758216   7.86598364   5.46292359] 1.8145855453e-37\n",
      "Episode =  338, score =   0.037 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.10785940e-03   3.51102087e-01   2.02042768e+01] 1.92850522867e-21\n",
      "positions (x,y,z), reward: [  0.05377338   1.99022979  19.65621737] 1.24828566827e-31\n",
      "positions (x,y,z), reward: [  0.17199432   2.85594984  18.78239725] 2.00926620366e-32\n",
      "positions (x,y,z), reward: [  0.57273117   4.00307992  16.96936439] 1.08019939586e-31\n",
      "positions (x,y,z), reward: [ 3.2386694   6.36944506  7.08328894] 2.50638329725e-31\n",
      "positions (x,y,z), reward: [ 5.14389586  8.74885528  2.2922205 ] 2.25382176699e-29\n",
      "positions (x,y,z), reward: [ 6.12130985  9.9702522   0.69563022] 4.07259126152e-28\n",
      "Episode =  339, score =   0.044 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  0.04113513   1.81489056  19.75059826] 1.87407083027e-31\n",
      "positions (x,y,z), reward: [  0.09811333   2.34226254  19.2670148 ] 5.13521829333e-33\n",
      "positions (x,y,z), reward: [  0.2624277    3.20098559  18.24895079] 6.91769653764e-34\n",
      "positions (x,y,z), reward: [  0.42510163   3.79602019  17.43554277] 2.40558903494e-33\n",
      "positions (x,y,z), reward: [  0.94559545   4.80876241  15.42307655] 1.69696604578e-34\n",
      "positions (x,y,z), reward: [  2.63329613   6.48516559  10.74244524] 6.25548866023e-29\n",
      "positions (x,y,z), reward: [ 4.20966574  8.08486629  6.88549077] 5.62717377876e-30\n",
      "positions (x,y,z), reward: [ 4.54336863  8.43725208  6.02272893] 3.10671614893e-30\n",
      "positions (x,y,z), reward: [ 5.65402858  9.7459534   3.29225348] 2.31842322926e-30\n",
      "Episode =  340, score =   0.040 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  7.68546868e-05   8.96420983e-02   2.01586564e+01] 3.16754049531e-05\n",
      "positions (x,y,z), reward: [  2.92990713e-03   6.44493856e-01   2.01331966e+01] 7.72542401463e-22\n",
      "positions (x,y,z), reward: [  4.79583579e-03   8.62223005e-01   2.01246577e+01] 1.08001087679e-14\n",
      "positions (x,y,z), reward: [  1.31283481e-02   1.23546707e+00   2.00580442e+01] 5.00712658899e-23\n",
      "positions (x,y,z), reward: [  0.19160354   3.06065359  18.45114758] 2.44752768542e-33\n",
      "positions (x,y,z), reward: [  0.21061828   3.12510402  18.32069984] 1.09356716764e-33\n",
      "positions (x,y,z), reward: [  0.38485507   3.79331501  17.34834274] 2.17891855825e-33\n",
      "positions (x,y,z), reward: [  2.4842409    6.27160514  11.05062438] 5.90298942181e-27\n",
      "Episode =  341, score =   0.040 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [  1.77831860e-03  -8.68261486e-01   2.07884418e+01] 0.942558263542\n",
      "positions (x,y,z), reward: [  0.02717816  -3.94223685  20.29016901] 3.87445693134e-15\n",
      "positions (x,y,z), reward: [ 0.61222277 -5.41648691  9.92737917] 4.08320714205e-25\n",
      "positions (x,y,z), reward: [  9.00581457 -26.95763213   6.16038181] 2.0787206372e-30\n",
      "positions (x,y,z), reward: [  9.2747053  -30.35992765   3.5060446 ] 2.01477870132e-33\n",
      "Episode =  342, score =   0.134 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -3.29099021e-04   1.39817996e+00   2.00398863e+01] 1.55810637384e-14\n",
      "positions (x,y,z), reward: [ -0.16600734   5.9491894   14.90253231] 5.59070934621e-26\n",
      "positions (x,y,z), reward: [ -0.88323069  12.01656409  12.48341122] 4.70473133416e-21\n",
      "positions (x,y,z), reward: [ -3.23037313  15.98405323  12.40003401] 2.57787589266e-20\n",
      "positions (x,y,z), reward: [ -7.32652699  15.01756081  10.69313262] 1.82877534531e-24\n",
      "positions (x,y,z), reward: [-10.84818069  13.48528174   8.00430832] 6.74069367114e-27\n",
      "Episode =  343, score =   0.036 (best =   1.727), noise_scale = 0.1positions (x,y,z), reward: [ -1.05543877e-02  -3.01200701e-03   2.29756534e+01] 0.999999909685\n",
      "positions (x,y,z), reward: [ -0.29074833  -0.0659127   32.909289  ] 0.999999999995\n",
      "positions (x,y,z), reward: [ -0.85796066  -0.13729666  42.0701343 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.98524364  -0.14680578  43.67038179] 1.0\n",
      "positions (x,y,z), reward: [ -1.59356572  -0.16502833  50.18800801] 1.0\n",
      "positions (x,y,z), reward: [ -3.61570999e+00   3.13506230e-02   6.52339132e+01] 1.0\n",
      "positions (x,y,z), reward: [ -5.18045529   0.36401286  73.73158691] 1.0\n",
      "positions (x,y,z), reward: [ -9.10357375   1.55367355  89.89246178] 1.0\n",
      "positions (x,y,z), reward: [ -17.70237203    4.31844412  113.12580749] 1.0\n",
      "positions (x,y,z), reward: [ -18.24469346    4.47326417  114.2518758 ] 1.0\n",
      "positions (x,y,z), reward: [ -18.52051254    4.55100095  114.8126918 ] 1.0\n",
      "positions (x,y,z), reward: [ -19.94681011    4.94254648  117.59277477] 1.0\n",
      "positions (x,y,z), reward: [ -27.9028366     6.8648577   130.21650756] 1.0\n",
      "Episode =  344, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.47020877e-03   4.17733762e-04   2.14929431e+01] 0.999995997004\n",
      "positions (x,y,z), reward: [ -1.01800287e-01   2.21438407e-03   2.88084722e+01] 0.999999999939\n",
      "positions (x,y,z), reward: [ -1.13570569e-01   2.15326595e-03   2.92420264e+01] 0.999999999956\n",
      "positions (x,y,z), reward: [ -1.00216164  -0.11376073  45.30277599] 1.0\n",
      "positions (x,y,z), reward: [ -2.58267893  -0.59555373  59.64519076] 1.0\n",
      "positions (x,y,z), reward: [ -4.17709478  -1.32597678  69.71842554] 1.0\n",
      "positions (x,y,z), reward: [ -6.02696892  -2.48648619  79.21981948] 1.0\n",
      "positions (x,y,z), reward: [ -8.54551286  -4.44503958  90.25234477] 1.0\n",
      "positions (x,y,z), reward: [ -9.22595112  -5.01664846  92.97375723] 1.0\n",
      "positions (x,y,z), reward: [ -11.55461744   -7.01151446  101.57503906] 1.0\n",
      "positions (x,y,z), reward: [ -18.04850136  -12.17695283  120.43889559] 1.0\n",
      "positions (x,y,z), reward: [ -29.220342    -19.21974574  142.39364717] 1.0\n",
      "Episode =  345, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.10971622e-05   7.58812300e-06   2.03790831e+01] 0.999381026185\n",
      "positions (x,y,z), reward: [ -4.26829524e-03  -5.35083232e-05   2.29749643e+01] 0.9999999095\n",
      "positions (x,y,z), reward: [ -1.90502607e-02   2.34077287e-02   2.88008367e+01] 0.999999999938\n",
      "positions (x,y,z), reward: [ -1.2388353    0.86135211  63.58483553] 1.0\n",
      "positions (x,y,z), reward: [ -3.17291852   1.92932354  81.05708469] 1.0\n",
      "positions (x,y,z), reward: [ -6.76937596   3.831395    99.12360043] 1.0\n",
      "positions (x,y,z), reward: [  -7.64896362    4.29787399  102.49455714] 1.0\n",
      "positions (x,y,z), reward: [ -12.99986405    7.2254828   119.2236601 ] 1.0\n",
      "positions (x,y,z), reward: [ -13.415175     7.4572799  120.3292204] 1.0\n",
      "positions (x,y,z), reward: [ -24.00034211   13.19274568  142.55175177] 1.0\n",
      "positions (x,y,z), reward: [ -25.59443095   14.00186835  145.17901786] 1.0\n",
      "Episode =  346, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.48859387e-05  -4.18968673e-05   2.02790134e+01] 0.998686072018\n",
      "positions (x,y,z), reward: [  6.65968082e-04  -1.76932119e-03   2.19355949e+01] 0.999998930236\n",
      "positions (x,y,z), reward: [  8.27751072e-03  -5.68553640e-03   2.75442418e+01] 0.999999999823\n",
      "positions (x,y,z), reward: [  1.08909597e-01   3.00440414e-02   4.10172942e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.20749108   0.08151885  46.92409015] 1.0\n",
      "positions (x,y,z), reward: [  1.59513188   1.55910376  82.2393086 ] 1.0\n",
      "positions (x,y,z), reward: [  2.84669892   3.19797971  99.70867487] 1.0\n",
      "positions (x,y,z), reward: [   4.4160074     5.81463572  117.32867362] 1.0\n",
      "positions (x,y,z), reward: [   6.63367897   11.19778995  139.28246873] 1.0\n",
      "positions (x,y,z), reward: [   7.60952132   13.7621752   147.36317975] 1.0\n",
      "Episode =  347, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.73063747e-02  -1.21855940e-02   2.55993815e+01] 0.999999998597\n",
      "positions (x,y,z), reward: [  0.08603934  -0.13383308  37.89373919] 1.0\n",
      "positions (x,y,z), reward: [ -0.2126651   -1.08765184  61.93962371] 1.0\n",
      "positions (x,y,z), reward: [ -0.43284379  -1.44804999  66.456781  ] 1.0\n",
      "positions (x,y,z), reward: [ -0.71720262  -1.89413068  70.98622871] 1.0\n",
      "positions (x,y,z), reward: [ -0.83939997  -2.08621908  72.68593788] 1.0\n",
      "positions (x,y,z), reward: [ -1.78034954  -3.69020688  83.43528341] 1.0\n",
      "positions (x,y,z), reward: [ -2.06900918  -4.25143232  86.25412276] 1.0\n",
      "positions (x,y,z), reward: [ -3.47669132  -7.81326292  98.53936961] 1.0\n",
      "positions (x,y,z), reward: [  -4.26860268  -10.82843019  105.03913938] 1.0\n",
      "positions (x,y,z), reward: [  -4.64658421  -12.69671958  108.17667004] 1.0\n",
      "positions (x,y,z), reward: [  -5.17040143  -15.99110155  112.66939043] 1.0\n",
      "positions (x,y,z), reward: [  -5.48003801  -18.52954525  115.47691583] 1.0\n",
      "positions (x,y,z), reward: [  -6.53238408  -43.69475493  128.43856492] 1.0\n",
      "Episode =  348, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.29244556e-07   8.09589375e-08   2.00699601e+01] 0.987007365477\n",
      "positions (x,y,z), reward: [ -2.83283871e-02  -1.29120516e-01   3.14962488e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [ -0.1103813   -0.48884643  42.08041926] 1.0\n",
      "positions (x,y,z), reward: [ -5.35992298e-02  -3.10594503e+00   8.55410582e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.10688623  -3.5731845   94.63745078] 1.0\n",
      "positions (x,y,z), reward: [  0.15350373  -3.67837302  96.91691651] 1.0\n",
      "positions (x,y,z), reward: [   0.27977996   -3.91910161  102.62310703] 1.0\n",
      "positions (x,y,z), reward: [   0.40366276   -4.10807038  107.76350179] 1.0\n",
      "positions (x,y,z), reward: [   0.80247869   -4.50062275  122.02377589] 1.0\n",
      "positions (x,y,z), reward: [   0.85970069   -4.535228    123.73136029] 1.0\n",
      "positions (x,y,z), reward: [   0.98395766   -4.59737967  127.14386059] 1.0\n",
      "Episode =  349, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.23005170e-05   8.56785785e-05   2.04944472e+01] 0.999707960892\n",
      "positions (x,y,z), reward: [ -2.16538770e-03   6.09494318e-03   2.24311787e+01] 0.999999699633\n",
      "positions (x,y,z), reward: [ -5.78381250e-03   1.71335747e-02   2.38809011e+01] 0.999999983345\n",
      "positions (x,y,z), reward: [ -0.1316308    0.23757034  37.89318437] 1.0\n",
      "positions (x,y,z), reward: [ -0.15677151   0.26968354  39.96963023] 1.0\n",
      "positions (x,y,z), reward: [ -0.19436022   0.31266776  43.14774065] 1.0\n",
      "positions (x,y,z), reward: [ -0.26449612   0.37368892  50.21335331] 1.0\n",
      "positions (x,y,z), reward: [ -0.28749941   0.30590374  63.04002979] 1.0\n",
      "positions (x,y,z), reward: [ -0.28414953   0.29580379  63.60324113] 1.0\n",
      "positions (x,y,z), reward: [ -0.19705647   0.09445729  70.9546503 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.64387943e-02  -1.55722058e-01   7.66411897e+01] 1.0\n",
      "positions (x,y,z), reward: [   2.11605524   -3.23581753  115.66919495] 1.0\n",
      "positions (x,y,z), reward: [   2.30861151   -3.48918309  118.48711192] 1.0\n",
      "positions (x,y,z), reward: [   2.86916059   -4.2960761   127.53695246] 1.0\n",
      "positions (x,y,z), reward: [   3.22589476   -4.98941937  135.51053023] 1.0\n",
      "Episode =  350, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.01703664e-02  -6.68908083e-03   2.32677073e+01] 0.999999949903\n",
      "positions (x,y,z), reward: [ -0.13171603  -0.07357259  28.80810811] 0.999999999939\n",
      "positions (x,y,z), reward: [ -0.30003231  -0.18541575  33.88403024] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.49111974  -0.31143127  38.41204677] 1.0\n",
      "positions (x,y,z), reward: [ -0.6161973   -0.39071746  41.02292289] 1.0\n",
      "positions (x,y,z), reward: [ -0.69717988  -0.44026528  42.61349445] 1.0\n",
      "positions (x,y,z), reward: [ -1.36638232  -0.79488753  54.05917352] 1.0\n",
      "positions (x,y,z), reward: [ -1.7355262   -0.94990039  59.61758946] 1.0\n",
      "positions (x,y,z), reward: [ -1.97001194  -1.03291287  62.9708381 ] 1.0\n",
      "positions (x,y,z), reward: [ -2.42484063  -1.1578774   69.14536781] 1.0\n",
      "positions (x,y,z), reward: [ -2.59831604  -1.19286739  71.39787984] 1.0\n",
      "positions (x,y,z), reward: [ -2.77623259  -1.22164206  73.65372353] 1.0\n",
      "positions (x,y,z), reward: [ -4.17396852  -1.22035987  89.51544616] 1.0\n",
      "positions (x,y,z), reward: [ -4.23007931  -1.21272847  90.08411181] 1.0\n",
      "positions (x,y,z), reward: [  -5.47773508   -0.92936847  101.48399407] 1.0\n",
      "positions (x,y,z), reward: [ -10.40084984    0.87194461  128.776228  ] 1.0\n",
      "positions (x,y,z), reward: [ -10.55500668    0.92629295  129.33726874] 1.0\n",
      "positions (x,y,z), reward: [ -10.71226163    0.98128201  129.8977384 ] 1.0\n",
      "positions (x,y,z), reward: [ -11.03636243    1.09315743  131.01686091] 1.0\n",
      "positions (x,y,z), reward: [ -15.34557529    2.40435128  142.55136211] 1.0\n",
      "Episode =  351, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.48883069   0.16215188  36.88050429] 1.0\n",
      "positions (x,y,z), reward: [ -1.96664209   0.54178767  50.22940488] 1.0\n",
      "positions (x,y,z), reward: [ -2.82446419   0.72466782  55.19883249] 1.0\n",
      "positions (x,y,z), reward: [ -8.0273063    1.45677683  74.52573804] 1.0\n",
      "positions (x,y,z), reward: [-12.44507148   1.58691228  85.30698119] 1.0\n",
      "positions (x,y,z), reward: [ -21.26514101    0.88148328  100.6459027 ] 1.0\n",
      "positions (x,y,z), reward: [ -22.98369326    0.63762428  103.06193637] 1.0\n",
      "positions (x,y,z), reward: [ -27.7471505    -0.173332    109.11231392] 1.0\n",
      "positions (x,y,z), reward: [ -37.09531583   -2.15055447  118.89860761] 1.0\n",
      "positions (x,y,z), reward: [ -47.44151965   -4.55731582  127.40419628] 1.0\n",
      "positions (x,y,z), reward: [ -48.38648548   -4.77820376  128.08224282] 1.0\n",
      "positions (x,y,z), reward: [ -54.72063151   -6.24563545  132.25561256] 1.0\n",
      "Episode =  352, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.11132056e-03  -1.89412964e-04   2.12909754e+01] 0.999992054842\n",
      "positions (x,y,z), reward: [  1.78908036e-02  -8.27167699e-04   2.38834317e+01] 0.999999983579\n",
      "positions (x,y,z), reward: [  1.31880128e-01   1.39133505e-04   2.96838705e+01] 0.999999999968\n",
      "positions (x,y,z), reward: [  8.91291061e-01   1.86042941e-03   4.47645585e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.99241438e+00   3.12073171e-02   5.79569795e+01] 1.0\n",
      "positions (x,y,z), reward: [  4.49481218   0.43430676  80.33652333] 1.0\n",
      "positions (x,y,z), reward: [  5.1661045    0.62671891  85.39004086] 1.0\n",
      "positions (x,y,z), reward: [   8.49842156    1.97447938  105.67180657] 1.0\n",
      "positions (x,y,z), reward: [   9.07414116    2.25067684  108.49842047] 1.0\n",
      "Episode =  353, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.05032194  -0.12553836  29.23768975] 0.999999999955\n",
      "positions (x,y,z), reward: [ -0.99401428  -2.3780007   50.21801992] 1.0\n",
      "positions (x,y,z), reward: [ -2.00551445  -4.96902403  60.14915697] 1.0\n",
      "positions (x,y,z), reward: [ -2.07511088  -5.14899934  60.69870737] 1.0\n",
      "positions (x,y,z), reward: [ -2.52385655  -6.30990551  63.98046241] 1.0\n",
      "positions (x,y,z), reward: [ -4.41527996 -11.13276596  74.60823836] 1.0\n",
      "positions (x,y,z), reward: [ -5.21851357 -13.12992979  78.17314419] 1.0\n",
      "positions (x,y,z), reward: [ -7.48454386 -18.51593437  86.42772797] 1.0\n",
      "positions (x,y,z), reward: [-10.46130044 -24.87535159  94.52287048] 1.0\n",
      "positions (x,y,z), reward: [-10.83699903 -25.61639481  95.38138556] 1.0\n",
      "positions (x,y,z), reward: [ -13.54241964  -30.58191186  100.75979105] 1.0\n",
      "positions (x,y,z), reward: [ -33.60764481  -59.25694027  121.72751248] 1.0\n",
      "positions (x,y,z), reward: [ -36.52568663  -63.31382998  123.77112835] 1.0\n",
      "Episode =  354, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.55757107e-04   3.06838551e-03   2.14920425e+01] 0.999995962461\n",
      "positions (x,y,z), reward: [  3.61975185  -1.56646473  79.38046783] 1.0\n",
      "positions (x,y,z), reward: [   6.11080918   -6.30198945  100.73231669] 1.0\n",
      "positions (x,y,z), reward: [   6.17901733   -6.48550994  101.28522355] 1.0\n",
      "positions (x,y,z), reward: [   6.45231271   -7.25412937  103.4884109 ] 1.0\n",
      "positions (x,y,z), reward: [   6.93230733   -8.73599123  107.30654609] 1.0\n",
      "positions (x,y,z), reward: [   9.30364157  -18.3708776   124.82015263] 1.0\n",
      "positions (x,y,z), reward: [   9.44509336  -19.0500513   125.78309792] 1.0\n",
      "positions (x,y,z), reward: [  10.7166494   -25.6216128   134.07162185] 1.0\n",
      "positions (x,y,z), reward: [  11.75662927  -31.64418302  140.4627361 ] 1.0\n",
      "Episode =  355, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777738] 0.941460844308\n",
      "positions (x,y,z), reward: [ -8.19316324e-04   2.00621346e-03   2.12903929e+01] 0.999991985071\n",
      "positions (x,y,z), reward: [ -0.08772265   0.23843444  32.43375723] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.09868819   0.27879001  33.39205863] 0.999999999996\n",
      "positions (x,y,z), reward: [ -0.12173895   0.37116551  35.35741819] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.20992575   0.82341083  42.61132392] 1.0\n",
      "positions (x,y,z), reward: [ -0.33768435   1.67772534  51.89091763] 1.0\n",
      "positions (x,y,z), reward: [ -0.34681351   1.73977065  52.44736667] 1.0\n",
      "positions (x,y,z), reward: [ -0.37590403   1.93437199  54.12262904] 1.0\n",
      "positions (x,y,z), reward: [ -0.41934351   2.21417629  56.36972265] 1.0\n",
      "positions (x,y,z), reward: [ -0.74307148   3.89419335  67.25583908] 1.0\n",
      "positions (x,y,z), reward: [ -2.4681171    8.69766412  87.99357245] 1.0\n",
      "positions (x,y,z), reward: [  -8.01728009   16.16576335  112.52801955] 1.0\n",
      "positions (x,y,z), reward: [ -13.09058199   20.71377079  128.08929157] 1.0\n",
      "positions (x,y,z), reward: [ -13.75747745   21.25972569  130.07003265] 1.0\n",
      "positions (x,y,z), reward: [ -27.63567076   33.81970008  181.0695959 ] 1.0\n",
      "positions (x,y,z), reward: [ -28.75820953   35.30755262  187.12738195] 1.0\n",
      "Episode =  356, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.70549164e-05   9.69272706e-05   2.03795901e+01] 0.999385369602\n",
      "positions (x,y,z), reward: [  1.24137137e-03   2.72040681e-02   2.42086033e+01] 0.999999990332\n",
      "positions (x,y,z), reward: [ -4.09818045e-03   4.07179536e-01   3.68815172e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.11907729   1.5949721   55.19554518] 1.0\n",
      "positions (x,y,z), reward: [ -0.15279082   2.35009111  63.01950369] 1.0\n",
      "positions (x,y,z), reward: [ -6.49743070e-03   4.49500024e+00   7.88864583e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.73793558e-02   4.68486886e+00   8.00275006e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.36442484   6.78918821  90.95135289] 1.0\n",
      "positions (x,y,z), reward: [  0.66487926   8.17083607  96.82910103] 1.0\n",
      "positions (x,y,z), reward: [   1.19623038   10.18396214  104.13663568] 1.0\n",
      "positions (x,y,z), reward: [   1.9149343    12.46591334  111.2131696 ] 1.0\n",
      "positions (x,y,z), reward: [   3.25576707   16.08638046  120.98745152] 1.0\n",
      "positions (x,y,z), reward: [   4.88288699   19.9394345   130.41244512] 1.0\n",
      "positions (x,y,z), reward: [  10.0202145    30.88501006  156.57199665] 1.0\n",
      "positions (x,y,z), reward: [  11.09912719   33.18382336  162.35853069] 1.0\n",
      "Episode =  357, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.33703882e-03   2.20729619e-02   2.75427511e+01] 0.999999999823\n",
      "positions (x,y,z), reward: [  0.03820753   0.07092013  34.86197688] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.09787182   0.12845457  40.4967748 ] 1.0\n",
      "positions (x,y,z), reward: [  0.11229473   0.1427492   41.55331575] 1.0\n",
      "positions (x,y,z), reward: [  0.13606258   0.1671489   43.15208715] 1.0\n",
      "positions (x,y,z), reward: [  0.85669146   1.20858424  67.67296275] 1.0\n",
      "positions (x,y,z), reward: [  0.94451524   1.34504525  69.39841908] 1.0\n",
      "positions (x,y,z), reward: [  1.17845191   1.705553    73.45255313] 1.0\n",
      "positions (x,y,z), reward: [  1.78731881   2.61497167  81.68374456] 1.0\n",
      "positions (x,y,z), reward: [  2.48065331   3.59992469  88.86226956] 1.0\n",
      "positions (x,y,z), reward: [  3.44323473   4.88805237  96.76786475] 1.0\n",
      "positions (x,y,z), reward: [   5.66486205    7.6031229   110.46016037] 1.0\n",
      "positions (x,y,z), reward: [  10.05634933   12.39099921  130.21239653] 1.0\n",
      "positions (x,y,z), reward: [  10.55295564   12.8976894   132.13904442] 1.0\n",
      "positions (x,y,z), reward: [  13.415999     15.68038059  142.46296812] 1.0\n",
      "positions (x,y,z), reward: [  16.88524329   18.72897688  153.62089075] 1.0\n",
      "positions (x,y,z), reward: [  17.10362514   18.90962674  154.28774522] 1.0\n",
      "positions (x,y,z), reward: [  17.32360226   19.09035298  154.95614714] 1.0\n",
      "Episode =  358, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.51886518e-06   2.15690404e-06   2.00699379e+01] 0.986999188616\n",
      "positions (x,y,z), reward: [ -3.45209141e-03   4.14718107e-03   2.17072768e+01] 0.999997942013\n",
      "positions (x,y,z), reward: [ -1.53864732e-02   1.67946921e-02   2.35685423e+01] 0.999999971404\n",
      "positions (x,y,z), reward: [ -0.28457507   0.23490744  40.50154483] 1.0\n",
      "positions (x,y,z), reward: [ -0.72321758   0.58279477  59.0895966 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.79142141   1.10301968  79.48107763] 1.0\n",
      "positions (x,y,z), reward: [ -0.59895958   1.27707729  87.54110375] 1.0\n",
      "positions (x,y,z), reward: [   0.16765798    1.55096052  103.15812006] 1.0\n",
      "positions (x,y,z), reward: [   1.65633948    1.70818727  120.90168913] 1.0\n",
      "positions (x,y,z), reward: [   2.30612807    1.6858826   127.12532464] 1.0\n",
      "Episode =  359, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778417] 0.941498337799\n",
      "positions (x,y,z), reward: [ -3.22304599e-07   8.20155614e-07   2.01243809e+01] 0.993969259315\n",
      "positions (x,y,z), reward: [ -0.13855708  -0.05239714  33.40004111] 0.999999999996\n",
      "positions (x,y,z), reward: [ -0.60056404  -0.2495806   50.76510345] 1.0\n",
      "positions (x,y,z), reward: [ -2.25081405  -0.70192904  72.59750562] 1.0\n",
      "positions (x,y,z), reward: [ -4.4038166   -0.98700776  85.59031144] 1.0\n",
      "positions (x,y,z), reward: [ -5.63039324  -1.07569344  90.66165669] 1.0\n",
      "positions (x,y,z), reward: [ -8.53511975  -1.17174339  99.59980887] 1.0\n",
      "positions (x,y,z), reward: [ -11.67842152   -1.18999145  106.70459094] 1.0\n",
      "positions (x,y,z), reward: [ -16.57751693   -1.1677945   115.11018739] 1.0\n",
      "positions (x,y,z), reward: [ -18.70285583   -1.15792761  118.13762367] 1.0\n",
      "positions (x,y,z), reward: [ -31.83633272   -1.25283104  132.5252228 ] 1.0\n",
      "positions (x,y,z), reward: [ -36.20905584   -1.36304703  136.28140189] 1.0\n",
      "Episode =  360, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.39439445e-03  -1.52211477e-03   2.19359791e+01] 0.999998936206\n",
      "positions (x,y,z), reward: [  2.53038123e-03  -2.59412619e-03   2.24316958e+01] 0.999999701342\n",
      "positions (x,y,z), reward: [  3.31904130e-03  -3.29845468e-03   2.26983016e+01] 0.999999838024\n",
      "positions (x,y,z), reward: [  5.45703864e-03  -5.12216638e-03   2.32674252e+01] 0.999999949996\n",
      "positions (x,y,z), reward: [  0.31364134  -0.18618168  36.37018006] 1.0\n",
      "positions (x,y,z), reward: [  0.33819535  -0.19794315  36.87767014] 1.0\n",
      "positions (x,y,z), reward: [  1.89608248  -0.73196033  54.26777015] 1.0\n",
      "positions (x,y,z), reward: [ 10.09638715  -1.48136171  91.63724353] 1.0\n",
      "positions (x,y,z), reward: [  13.97536518   -1.18602995  103.82470564] 1.0\n",
      "positions (x,y,z), reward: [  26.0111106     1.41387696  138.0780327 ] 1.0\n",
      "positions (x,y,z), reward: [  32.18789183    4.15664142  156.75668424] 1.0\n",
      "positions (x,y,z), reward: [  34.06210266    5.35035488  163.14425917] 1.0\n",
      "Episode =  361, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.03785093  -0.0297342   25.60091768] 0.999999998608\n",
      "positions (x,y,z), reward: [ -0.17028142  -0.18330068  32.4375446 ] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.31149593  -1.72479951  53.58316101] 1.0\n",
      "positions (x,y,z), reward: [  6.11383116e-03  -3.02836052e+00   6.32343007e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.55274063  -4.58053234  71.38762325] 1.0\n",
      "positions (x,y,z), reward: [  0.88713063  -5.43496413  74.93162092] 1.0\n",
      "positions (x,y,z), reward: [  1.1482253   -6.07995325  77.30741805] 1.0\n",
      "positions (x,y,z), reward: [  1.29085035  -6.42660699  78.49862058] 1.0\n",
      "positions (x,y,z), reward: [  3.32159693 -11.16289985  91.07826824] 1.0\n",
      "positions (x,y,z), reward: [   8.55885963  -23.19405927  110.31882401] 1.0\n",
      "positions (x,y,z), reward: [  11.18576742  -29.28528396  117.13853001] 1.0\n",
      "Episode =  362, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  5.89925946e-03  -8.26043294e-02   2.92365700e+01] 0.999999999955\n",
      "positions (x,y,z), reward: [  2.82421056e-03  -1.66741767e-01   3.24334314e+01] 0.999999999993\n",
      "positions (x,y,z), reward: [ -1.92398303e-02  -4.82685132e-01   3.99673461e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.58731341  -2.39912163  62.46652245] 1.0\n",
      "positions (x,y,z), reward: [ -0.74470393  -2.67224156  64.71780374] 1.0\n",
      "positions (x,y,z), reward: [ -2.37214846  -4.52345135  77.71980021] 1.0\n",
      "positions (x,y,z), reward: [ -2.4780738   -4.61397769  78.28507204] 1.0\n",
      "positions (x,y,z), reward: [ -2.93743617  -4.98374366  80.54373089] 1.0\n",
      "positions (x,y,z), reward: [ -5.05411483  -6.36797466  88.38802612] 1.0\n",
      "positions (x,y,z), reward: [ -17.51683427  -11.08595163  109.90178127] 1.0\n",
      "positions (x,y,z), reward: [ -20.12384019  -11.78260884  112.4979341 ] 1.0\n",
      "positions (x,y,z), reward: [ -30.86655333  -14.05338904  120.08343689] 1.0\n",
      "positions (x,y,z), reward: [ -53.14692199  -15.7761001   126.44284559] 1.0\n",
      "Episode =  363, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.60065529e-09   6.44069313e-09   2.00311173e+01] 0.972227489199\n",
      "positions (x,y,z), reward: [  1.29093431e-07  -1.91422780e-07   2.00699863e+01] 0.98702105704\n",
      "positions (x,y,z), reward: [  8.82430272e-07  -3.67419962e-06   2.01941095e+01] 0.997192266652\n",
      "positions (x,y,z), reward: [ -3.23484108e-02   1.39483286e-02   2.45418324e+01] 0.999999994195\n",
      "positions (x,y,z), reward: [ -1.21852811   0.74120465  45.84248089] 1.0\n",
      "positions (x,y,z), reward: [ -1.26237842   0.77716057  46.38537495] 1.0\n",
      "positions (x,y,z), reward: [ -2.36325112   1.90332579  59.13241364] 1.0\n",
      "positions (x,y,z), reward: [  -5.92857448   10.47836331  102.45743441] 1.0\n",
      "positions (x,y,z), reward: [  -6.17839242   11.8111356   106.71752031] 1.0\n",
      "positions (x,y,z), reward: [  -6.98002159   18.7280178   125.48141156] 1.0\n",
      "positions (x,y,z), reward: [  -7.02142731   19.29953834  126.87751672] 1.0\n",
      "positions (x,y,z), reward: [  -7.11872663   20.77992851  130.44684402] 1.0\n",
      "positions (x,y,z), reward: [  -7.190765     22.01383078  133.39171216] 1.0\n",
      "positions (x,y,z), reward: [  -7.51822132   30.18924767  153.46260742] 1.0\n",
      "Episode =  364, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.81526365e-07   4.67802979e-07   2.01241885e+01] 0.993936293594\n",
      "positions (x,y,z), reward: [ -2.72812642e-02   1.77287236e-01   3.14888877e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [ -1.75877649e-02   3.37381143e-01   3.53518382e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [ -9.47200208e-03   4.12810376e-01   3.68626048e+01] 1.0\n",
      "positions (x,y,z), reward: [  5.49506976e-03   5.25942764e-01   3.89178752e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.92698315   3.39366301  71.3435987 ] 1.0\n",
      "positions (x,y,z), reward: [  1.2065734    3.96307599  76.95850333] 1.0\n",
      "positions (x,y,z), reward: [  1.32532453   4.17898804  79.21162502] 1.0\n",
      "positions (x,y,z), reward: [  1.38591243   4.28323143  80.34003325] 1.0\n",
      "positions (x,y,z), reward: [  1.69727506   4.75438979  86.0032197 ] 1.0\n",
      "positions (x,y,z), reward: [  1.82386412   4.91266744  88.27969863] 1.0\n",
      "positions (x,y,z), reward: [   2.74376881    5.12033292  105.59997479] 1.0\n",
      "positions (x,y,z), reward: [   3.49656943    2.46380445  123.11480559] 1.0\n",
      "positions (x,y,z), reward: [   3.84619316   -0.61338421  132.2174431 ] 1.0\n",
      "positions (x,y,z), reward: [   4.05564315   -2.89965511  137.1550277 ] 1.0\n",
      "Episode =  365, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.58857237e-03   3.91306366e-03   2.17080719e+01] 0.99999795301\n",
      "positions (x,y,z), reward: [  0.6218139    0.74968791  54.62628403] 1.0\n",
      "positions (x,y,z), reward: [  2.03115144   1.51266223  79.32402436] 1.0\n",
      "positions (x,y,z), reward: [  3.51240364   1.84242181  94.03841722] 1.0\n",
      "positions (x,y,z), reward: [   6.26622204    1.95764486  112.66537041] 1.0\n",
      "positions (x,y,z), reward: [   7.44482136    1.92965975  118.8459032 ] 1.0\n",
      "Episode =  366, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.07570561   0.62924624  50.79335264] 1.0\n",
      "positions (x,y,z), reward: [ -3.03194655   0.90556222  55.79010182] 1.0\n",
      "positions (x,y,z), reward: [ -3.54320877   1.04891088  58.02243544] 1.0\n",
      "positions (x,y,z), reward: [ -4.26574805   1.24658515  60.81720987] 1.0\n",
      "positions (x,y,z), reward: [ -4.58261128   1.33142595  61.93537327] 1.0\n",
      "positions (x,y,z), reward: [ -7.53768429   2.06608031  70.27822227] 1.0\n",
      "positions (x,y,z), reward: [ -9.30974737   2.45775015  74.10719613] 1.0\n",
      "positions (x,y,z), reward: [-14.04056076   3.3409988   82.02848053] 1.0\n",
      "positions (x,y,z), reward: [ -38.71842424    5.55180699  104.15725891] 1.0\n",
      "positions (x,y,z), reward: [ -42.73125066    5.6595391   106.3441808 ] 1.0\n",
      "positions (x,y,z), reward: [ -46.25657422    5.71127294  108.06010881] 1.0\n",
      "Episode =  367, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.72027725e-03  -1.47172294e-03   2.19353463e+01] 0.999998930433\n",
      "positions (x,y,z), reward: [ -2.11318249e-03  -2.01368185e-03   2.21767369e+01] 0.999999437274\n",
      "positions (x,y,z), reward: [ -9.57301920e-03  -1.86785815e-02   2.52355160e+01] 0.999999997775\n",
      "positions (x,y,z), reward: [ -1.72695670e-02  -3.88397990e-02   2.71386149e+01] 0.999999999741\n",
      "positions (x,y,z), reward: [ -0.08840839  -0.2063021   34.86178982] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.10338491  -0.23918098  35.85949226] 0.999999999998\n",
      "positions (x,y,z), reward: [ -1.85413223  -2.97325337  62.06191534] 1.0\n",
      "positions (x,y,z), reward: [ -1.94886471  -3.09824923  62.62870745] 1.0\n",
      "positions (x,y,z), reward: [ -3.12706547  -4.56894499  68.27254226] 1.0\n",
      "positions (x,y,z), reward: [ -4.58957641  -6.2435363   73.2587953 ] 1.0\n",
      "positions (x,y,z), reward: [-10.57435002 -12.18848985  85.56773139] 1.0\n",
      "positions (x,y,z), reward: [-15.86722516 -16.68818786  92.1664939 ] 1.0\n",
      "positions (x,y,z), reward: [-25.76489796 -23.60469999  99.92029618] 1.0\n",
      "positions (x,y,z), reward: [ -41.45148432  -30.62987762  105.85334329] 1.0\n",
      "positions (x,y,z), reward: [ -43.42234972  -31.16962761  106.23227167] 1.0\n",
      "positions (x,y,z), reward: [ -45.43087848  -31.64336386  106.54814244] 1.0\n",
      "positions (x,y,z), reward: [ -49.54566467  -32.37782949  106.98145556] 1.0\n",
      "positions (x,y,z), reward: [ -56.60718417  -32.92370345  107.07440892] 1.0\n",
      "Episode =  368, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.61192451e-04   2.10055605e-04   2.06247542e+01] 0.999860845164\n",
      "positions (x,y,z), reward: [  1.43612305e-02   1.50947978e-01   2.92396496e+01] 0.999999999956\n",
      "positions (x,y,z), reward: [  0.04750676   0.28290517  32.43707436] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.06762262   0.3543846   33.88120404] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.25100495   0.8836682   42.08127929] 1.0\n",
      "positions (x,y,z), reward: [  0.60087063   1.64821065  50.76418038] 1.0\n",
      "positions (x,y,z), reward: [  0.78152329   1.99315001  54.08366871] 1.0\n",
      "positions (x,y,z), reward: [  5.78709556   8.67354544  95.29096047] 1.0\n",
      "positions (x,y,z), reward: [   9.8687374    13.00630765  112.21901311] 1.0\n",
      "positions (x,y,z), reward: [  14.91114775   18.34644744  127.96499781] 1.0\n",
      "Episode =  369, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.09878267e-02   2.26029090e-03   2.29735907e+01] 0.999999908654\n",
      "positions (x,y,z), reward: [ -1.52217179e-01   9.32201191e-03   3.05667357e+01] 0.999999999981\n",
      "positions (x,y,z), reward: [ -7.22299681e-01  -2.75189793e-02   4.47400855e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.92271232  -0.89614248  66.42493193] 1.0\n",
      "positions (x,y,z), reward: [ -2.87939369  -4.90564054  85.84069526] 1.0\n",
      "positions (x,y,z), reward: [  -0.48200416  -42.18079509  120.46953481] 1.0\n",
      "positions (x,y,z), reward: [  -0.38466543  -42.87954048  120.65106379] 1.0\n",
      "positions (x,y,z), reward: [   0.23713218  -47.18824634  121.56931695] 1.0\n",
      "Episode =  370, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  6.28563993e-07  -1.30700703e-05   2.01940680e+01] 0.997190154421\n",
      "positions (x,y,z), reward: [ -1.45999996e-04  -2.94958785e-04   2.07700005e+01] 0.999933274348\n",
      "positions (x,y,z), reward: [ -2.59155989e-03  -2.66659695e-03   2.24325757e+01] 0.999999702361\n",
      "positions (x,y,z), reward: [ -0.03053538  -0.03334711  29.24492544] 0.999999999956\n",
      "positions (x,y,z), reward: [ -0.03593095  -0.0431845   30.58337013] 0.999999999982\n",
      "positions (x,y,z), reward: [ -0.03920875  -0.05046017  31.50382539] 0.999999999989\n",
      "positions (x,y,z), reward: [ -0.04919663  -0.10498608  37.39167335] 1.0\n",
      "positions (x,y,z), reward: [ -0.04863567  -0.1160344   38.41977417] 1.0\n",
      "positions (x,y,z), reward: [ -2.95557337e-02  -1.90166860e-01   4.42307922e+01] 1.0\n",
      "positions (x,y,z), reward: [  6.03262579e-03  -2.61140049e-01   4.85747380e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.20695579e-02  -2.71147847e-01   4.91226239e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.20909096  -0.51830637  59.66526709] 1.0\n",
      "positions (x,y,z), reward: [  0.2895847   -0.60569882  62.46836984] 1.0\n",
      "positions (x,y,z), reward: [  2.95288925  -3.90879643  99.91152838] 1.0\n",
      "positions (x,y,z), reward: [   5.13485785   -7.4272993   114.03064155] 1.0\n",
      "positions (x,y,z), reward: [   5.34969238   -7.7962673   115.1439048 ] 1.0\n",
      "positions (x,y,z), reward: [   7.45717778  -11.56254666  124.40683535] 1.0\n",
      "positions (x,y,z), reward: [   9.77473189  -15.92959214  132.106768  ] 1.0\n",
      "positions (x,y,z), reward: [  13.79656285  -23.77654492  141.66175164] 1.0\n",
      "Episode =  371, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.00259799e-04   1.42919282e-04   2.11021092e+01] 0.999983876118\n",
      "positions (x,y,z), reward: [ -1.91661874  -1.18277293  64.76929443] 1.0\n",
      "positions (x,y,z), reward: [ -4.4390045   -2.49312236  79.94451708] 1.0\n",
      "positions (x,y,z), reward: [ -5.57701015  -3.00836703  84.95571037] 1.0\n",
      "positions (x,y,z), reward: [ -6.8841262   -3.55603683  89.93139398] 1.0\n",
      "positions (x,y,z), reward: [ -8.19745634  -4.06980837  94.31709924] 1.0\n",
      "positions (x,y,z), reward: [ -13.55126704   -5.88584379  108.24031657] 1.0\n",
      "positions (x,y,z), reward: [ -14.2895591    -6.10685572  109.80599517] 1.0\n",
      "positions (x,y,z), reward: [ -31.32761046  -10.00525214  133.68447028] 1.0\n",
      "Episode =  372, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.03188468   0.02669791  25.60122456] 0.999999998606\n",
      "positions (x,y,z), reward: [  0.07494406   0.05017474  28.80666885] 0.999999999939\n",
      "positions (x,y,z), reward: [  0.16635031   0.08987354  33.88176731] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.2209647    0.11021354  36.36611794] 1.0\n",
      "positions (x,y,z), reward: [  0.32701533   0.1437772   40.49643868] 1.0\n",
      "positions (x,y,z), reward: [  0.61734673   0.21524842  49.11244683] 1.0\n",
      "positions (x,y,z), reward: [  0.80561645   0.26033113  53.52099414] 1.0\n",
      "positions (x,y,z), reward: [  2.17040603   0.73599489  75.36003711] 1.0\n",
      "positions (x,y,z), reward: [  2.21573791   0.75723956  75.92395232] 1.0\n",
      "positions (x,y,z), reward: [  3.65845318   1.64165432  91.78853637] 1.0\n",
      "positions (x,y,z), reward: [   7.17983755    5.93355173  124.84576797] 1.0\n",
      "positions (x,y,z), reward: [   8.02902703    7.52600133  132.60824799] 1.0\n",
      "positions (x,y,z), reward: [   9.20095401   10.18812709  143.60344275] 1.0\n",
      "Episode =  373, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  9.02273086e-04   1.81312718e-03   2.14923097e+01] 0.999995975386\n",
      "positions (x,y,z), reward: [  8.10186338e-03   1.42050471e-02   2.38813909e+01] 0.999999983377\n",
      "positions (x,y,z), reward: [  0.04409535   0.05715607  28.37784776] 0.999999999914\n",
      "positions (x,y,z), reward: [  0.09167432   0.09415994  31.49542437] 0.999999999989\n",
      "positions (x,y,z), reward: [  0.24804089   0.16977407  37.38194659] 1.0\n",
      "positions (x,y,z), reward: [  0.32593887   0.19623753  39.4497094 ] 1.0\n",
      "positions (x,y,z), reward: [  1.74118911   0.32824052  59.18531922] 1.0\n",
      "positions (x,y,z), reward: [  2.59270573   0.26812778  66.5420734 ] 1.0\n",
      "positions (x,y,z), reward: [  3.81598284   0.07872222  75.07731841] 1.0\n",
      "positions (x,y,z), reward: [  5.10738247  -0.22287398  82.49835162] 1.0\n",
      "positions (x,y,z), reward: [  6.89715584  -0.77150566  91.0737177 ] 1.0\n",
      "positions (x,y,z), reward: [  7.02859275  -0.8165671   91.64519968] 1.0\n",
      "positions (x,y,z), reward: [  12.40128672   -3.09046805  110.81423447] 1.0\n",
      "positions (x,y,z), reward: [  12.5853084    -3.18238603  111.36444607] 1.0\n",
      "positions (x,y,z), reward: [  14.50613091   -4.20247419  116.8101477 ] 1.0\n",
      "positions (x,y,z), reward: [  20.1280263    -7.91551217  130.48461157] 1.0\n",
      "positions (x,y,z), reward: [  21.99474913   -9.41852703  134.55536849] 1.0\n",
      "positions (x,y,z), reward: [  26.70509755  -14.12331793  144.51257828] 1.0\n",
      "Episode =  374, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.15118422e-06  -3.54791570e-06   2.01243311e+01] 0.99396169281\n",
      "positions (x,y,z), reward: [  6.77080875e-04  -7.51801081e-04   2.11033804e+01] 0.999984056272\n",
      "positions (x,y,z), reward: [  8.79163823e-04  -1.03252698e-03   2.12912889e+01] 0.999992066515\n",
      "positions (x,y,z), reward: [ -7.04178798e-03  -2.96194965e-03   3.10430806e+01] 0.999999999986\n",
      "positions (x,y,z), reward: [ -0.15292258   0.18041956  44.78238716] 1.0\n",
      "positions (x,y,z), reward: [ -0.2827634    0.32385981  50.23967719] 1.0\n",
      "positions (x,y,z), reward: [ -0.3647848    0.41234919  53.00140065] 1.0\n",
      "positions (x,y,z), reward: [ -1.02965573   1.16025095  69.76964966] 1.0\n",
      "positions (x,y,z), reward: [ -1.05454704   1.19107407  70.33116522] 1.0\n",
      "positions (x,y,z), reward: [ -1.22932975   1.41665098  74.26392449] 1.0\n",
      "positions (x,y,z), reward: [ -1.7862647    2.29961435  87.78554329] 1.0\n",
      "positions (x,y,z), reward: [ -1.96471471   2.70537892  93.46105125] 1.0\n",
      "positions (x,y,z), reward: [  -2.13560996    4.06776431  112.57106759] 1.0\n",
      "positions (x,y,z), reward: [  -1.68021902    4.9302482   129.20387997] 1.0\n",
      "positions (x,y,z), reward: [  -1.39639966    5.04892655  134.61434082] 1.0\n",
      "Episode =  375, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.02040165e-03  -7.20397242e-04   2.35712669e+01] 0.999999971616\n",
      "positions (x,y,z), reward: [ -0.12847335   0.10311964  33.88776435] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.14516541   0.12284183  34.87139312] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.57665142   0.75795794  52.43329526] 1.0\n",
      "positions (x,y,z), reward: [ -1.00021844   1.46361647  63.5901286 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.36572235   2.12786732  71.45974176] 1.0\n",
      "positions (x,y,z), reward: [ -2.72337024   4.38256639  91.12251807] 1.0\n",
      "positions (x,y,z), reward: [ -2.83553253   4.53643544  92.24390957] 1.0\n",
      "positions (x,y,z), reward: [  -5.26776171    7.19402235  109.00261556] 1.0\n",
      "positions (x,y,z), reward: [  -5.84729935    7.70656394  111.77730599] 1.0\n",
      "positions (x,y,z), reward: [  -8.15123634    9.48907649  120.5813382 ] 1.0\n",
      "positions (x,y,z), reward: [ -12.30676901   12.14949533  131.81618602] 1.0\n",
      "positions (x,y,z), reward: [ -17.6457921    15.17693869  142.47515391] 1.0\n",
      "positions (x,y,z), reward: [ -18.20965578   15.48572745  143.45464345] 1.0\n",
      "Episode =  376, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.12849452e-02  -3.45090121e-02   2.63552539e+01] 0.999999999424\n",
      "positions (x,y,z), reward: [ -0.81234006   0.23269035  51.91470391] 1.0\n",
      "positions (x,y,z), reward: [ -2.5591219    2.56727921  79.6246696 ] 1.0\n",
      "positions (x,y,z), reward: [ -2.85613601   3.29313529  84.54455283] 1.0\n",
      "positions (x,y,z), reward: [  -3.75220855    7.38998871  105.27881365] 1.0\n",
      "positions (x,y,z), reward: [  -3.84011152    9.84041279  115.29580893] 1.0\n",
      "positions (x,y,z), reward: [  -3.78291775   11.12550451  120.34154307] 1.0\n",
      "positions (x,y,z), reward: [  -3.46416804   13.73711541  130.58644291] 1.0\n",
      "positions (x,y,z), reward: [   0.61532052   25.21708591  186.72287924] 1.0\n",
      "positions (x,y,z), reward: [   1.79666519   28.11360246  204.56335773] 1.0\n",
      "positions (x,y,z), reward: [   2.05721177   28.82911307  209.08930936] 1.0\n",
      "positions (x,y,z), reward: [   2.60414381   30.48494664  219.63524601] 1.0\n",
      "positions (x,y,z), reward: [   5.50029222   59.98536376  300.        ] 1.0\n",
      "Episode =  377, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.21763634e-06   1.07671710e-06   2.01242205e+01] 0.993947026596\n",
      "positions (x,y,z), reward: [  6.30648699e-03   7.74148620e-03   3.53690855e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [  1.91254752e-02   1.96518486e-02   4.05050769e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.07578388   0.18421203  66.94210434] 1.0\n",
      "positions (x,y,z), reward: [ -0.10552025   0.18900777  68.06928566] 1.0\n",
      "positions (x,y,z), reward: [ -0.5584745    0.18989834  77.14490847] 1.0\n",
      "positions (x,y,z), reward: [ -0.65256651   0.18314231  78.28755362] 1.0\n",
      "positions (x,y,z), reward: [ -3.22866001  -0.13928625  93.24003729] 1.0\n",
      "positions (x,y,z), reward: [ -19.5326401    -1.91677219  118.8746442 ] 1.0\n",
      "positions (x,y,z), reward: [ -20.50334372   -1.99761641  119.69267547] 1.0\n",
      "positions (x,y,z), reward: [ -25.10740844   -2.3509605   123.11703894] 1.0\n",
      "positions (x,y,z), reward: [ -36.4432978    -3.03583924  129.18739125] 1.0\n",
      "positions (x,y,z), reward: [ -44.97957552   -3.40788414  132.20302475] 1.0\n",
      "Episode =  378, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.16504463  -2.91641349  73.03364673] 1.0\n",
      "positions (x,y,z), reward: [  3.71231884  -3.16292975  76.57117978] 1.0\n",
      "positions (x,y,z), reward: [  5.07229862  -3.70027219  84.31384134] 1.0\n",
      "positions (x,y,z), reward: [  5.77927331  -3.95145919  87.91985495] 1.0\n",
      "positions (x,y,z), reward: [  8.04107807  -4.68552893  98.2245853 ] 1.0\n",
      "positions (x,y,z), reward: [   8.62609297   -4.86499881  100.66349523] 1.0\n",
      "positions (x,y,z), reward: [   9.0776194    -5.00176154  102.49557423] 1.0\n",
      "positions (x,y,z), reward: [   9.69654267   -5.18730425  104.94211739] 1.0\n",
      "positions (x,y,z), reward: [  12.35942574   -5.97535838  114.76607331] 1.0\n",
      "positions (x,y,z), reward: [  12.89106192   -6.13323764  116.61378565] 1.0\n",
      "positions (x,y,z), reward: [  13.25101684   -6.24064606  117.84644248] 1.0\n",
      "positions (x,y,z), reward: [  15.70245423   -6.98928296  125.88204375] 1.0\n",
      "positions (x,y,z), reward: [  19.68060057   -8.30129144  137.79416928] 1.0\n",
      "positions (x,y,z), reward: [  21.50226694   -8.95216706  142.90770704] 1.0\n",
      "positions (x,y,z), reward: [  22.20683007   -9.21291856  144.8446837 ] 1.0\n",
      "positions (x,y,z), reward: [  24.38706614  -10.05407997  150.73108757] 1.0\n",
      "Episode =  379, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.74288912e-04  -1.01358283e-03   2.11029792e+01] 0.999983977063\n",
      "positions (x,y,z), reward: [  0.06744182  -0.1639346   35.863472  ] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.07165261  -0.17079841  36.36726989] 1.0\n",
      "positions (x,y,z), reward: [  0.1869729    0.62334418  75.51295646] 1.0\n",
      "positions (x,y,z), reward: [  -3.97415427    5.18316171  108.11134816] 1.0\n",
      "positions (x,y,z), reward: [  -7.6071983     7.8847987   122.86511229] 1.0\n",
      "positions (x,y,z), reward: [ -11.38193017   10.39407327  137.00926456] 1.0\n",
      "positions (x,y,z), reward: [ -23.46414153   21.5473536   199.35059217] 1.0\n",
      "positions (x,y,z), reward: [ -24.07378351   22.61715834  204.514383  ] 1.0\n",
      "positions (x,y,z), reward: [ -29.70268827   47.07684997  296.83044335] 1.0\n",
      "Episode =  380, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.08893348e-06  -2.91006967e-07   2.00699874e+01] 0.987026028252\n",
      "positions (x,y,z), reward: [  1.27224503e-03  -3.70914410e-01   4.05053843e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.28240449e-02  -6.03453606e-01   4.58534158e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.83516000e-02  -1.09060529e+00   5.40913578e+01] 1.0\n",
      "positions (x,y,z), reward: [  1.10987989e-03  -1.43087575e+00   5.85446992e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.80086178  -5.04833344  84.42683479] 1.0\n",
      "positions (x,y,z), reward: [ -0.8758173   -5.29649674  85.55174149] 1.0\n",
      "positions (x,y,z), reward: [  -4.96761663  -18.58451189  117.18126419] 1.0\n",
      "positions (x,y,z), reward: [  -5.35851676  -19.98544602  119.10231873] 1.0\n",
      "positions (x,y,z), reward: [  -5.65863577  -21.07996687  120.5137744 ] 1.0\n",
      "positions (x,y,z), reward: [  -8.58056288  -32.43835402  131.94375178] 1.0\n",
      "Episode =  381, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.37943719e-04  -1.26994837e-03   2.09287852e+01] 0.999967320929\n",
      "positions (x,y,z), reward: [  2.55034945e-03  -5.06844233e-03   2.17068170e+01] 0.999997930134\n",
      "positions (x,y,z), reward: [  0.12835708  -0.26125123  31.02529608] 0.999999999986\n",
      "positions (x,y,z), reward: [  4.18556782  -4.28930472  81.38319635] 1.0\n",
      "positions (x,y,z), reward: [  5.33392578  -4.94337404  87.86878605] 1.0\n",
      "positions (x,y,z), reward: [  7.30962135  -6.00967116  97.40901553] 1.0\n",
      "positions (x,y,z), reward: [   8.00185563   -6.38278035  100.41357394] 1.0\n",
      "positions (x,y,z), reward: [   9.97263632   -7.48327274  108.27003246] 1.0\n",
      "positions (x,y,z), reward: [  16.16579634  -11.63542762  128.35136493] 1.0\n",
      "positions (x,y,z), reward: [  16.60526033  -11.97297478  129.57630673] 1.0\n",
      "positions (x,y,z), reward: [  22.8075249   -17.23185269  145.21057338] 1.0\n",
      "positions (x,y,z), reward: [  24.21154202  -18.53605652  148.47659748] 1.0\n",
      "Episode =  382, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.13253914  -0.20559283  37.3908938 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.35021658  -0.53496167  47.49000276] 1.0\n",
      "positions (x,y,z), reward: [ -4.57407635  -1.18670454  80.50616986] 1.0\n",
      "positions (x,y,z), reward: [ -4.75109301  -1.17885302  81.10319139] 1.0\n",
      "positions (x,y,z), reward: [ -4.93358741  -1.17025863  81.70158742] 1.0\n",
      "positions (x,y,z), reward: [ -5.51488838  -1.14028452  83.50531949] 1.0\n",
      "positions (x,y,z), reward: [-11.18279758  -0.85789509  96.57002025] 1.0\n",
      "positions (x,y,z), reward: [ -25.95393551   -1.3119884   119.92389965] 1.0\n",
      "positions (x,y,z), reward: [ -45.18886591    0.71718888  160.44666355] 1.0\n",
      "Episode =  383, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.04029872e-03   3.25679648e-03   2.24331331e+01] 0.999999703013\n",
      "positions (x,y,z), reward: [ -4.11302666e-02   2.42393567e-02   2.52407072e+01] 0.999999997811\n",
      "positions (x,y,z), reward: [ -0.07176585   0.04552795  26.74769026] 0.99999999962\n",
      "positions (x,y,z), reward: [ -0.38458888   0.29564894  34.87243314] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.7949469    0.63918569  41.03466236] 1.0\n",
      "positions (x,y,z), reward: [ -2.52937689   1.98668877  55.79132443] 1.0\n",
      "positions (x,y,z), reward: [ -6.349384     4.61745467  73.25253003] 1.0\n",
      "positions (x,y,z), reward: [ -9.51439033   6.61445905  82.93606861] 1.0\n",
      "positions (x,y,z), reward: [ -23.68897702   14.20007095  111.16358211] 1.0\n",
      "positions (x,y,z), reward: [ -24.4904509    14.59465339  112.49214255] 1.0\n",
      "positions (x,y,z), reward: [ -29.6525292    17.12514438  120.93860404] 1.0\n",
      "positions (x,y,z), reward: [ -33.92972323   19.24984315  128.00442687] 1.0\n",
      "Episode =  384, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.93519123e-05   4.04503508e-05   2.06248628e+01] 0.999860889896\n",
      "positions (x,y,z), reward: [  2.08184033e-03   5.61237380e-04   2.21771051e+01] 0.999999436526\n",
      "positions (x,y,z), reward: [  3.35308109e-02  -7.13853858e-03   2.71404639e+01] 0.999999999744\n",
      "positions (x,y,z), reward: [  0.10124145  -0.03403202  31.49820679] 0.999999999989\n",
      "positions (x,y,z), reward: [  0.13270327  -0.04657332  32.91587689] 0.999999999995\n",
      "positions (x,y,z), reward: [  0.17019445  -0.06131344  34.37326722] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.3655515   -0.1354868   39.97751308] 1.0\n",
      "positions (x,y,z), reward: [  0.7958223   -0.29405922  48.04001032] 1.0\n",
      "positions (x,y,z), reward: [  0.94456301  -0.34971928  50.23937654] 1.0\n",
      "positions (x,y,z), reward: [  1.85233189  -0.69645443  60.8345434 ] 1.0\n",
      "positions (x,y,z), reward: [  5.18320015  -1.81244373  84.58520038] 1.0\n",
      "positions (x,y,z), reward: [  5.72386745  -1.9596869   87.42713374] 1.0\n",
      "positions (x,y,z), reward: [  7.16453111  -2.30554421  94.25197935] 1.0\n",
      "positions (x,y,z), reward: [  8.38340385  -2.55023337  99.36743633] 1.0\n",
      "positions (x,y,z), reward: [  11.71764525   -3.04509112  111.24787544] 1.0\n",
      "positions (x,y,z), reward: [  12.25176464   -3.10615734  112.93331063] 1.0\n",
      "Episode =  385, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.82864856e-03   7.38837326e-04   2.12913935e+01] 0.999992082548\n",
      "positions (x,y,z), reward: [  2.27430900e-02   2.17438781e-01   3.43825144e+01] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.11025834   0.4025965   38.94652643] 1.0\n",
      "positions (x,y,z), reward: [  0.38086125   0.8474464   46.43713272] 1.0\n",
      "positions (x,y,z), reward: [  2.21408034   3.19825084  67.50626147] 1.0\n",
      "positions (x,y,z), reward: [  2.44966568   3.47567517  69.27249993] 1.0\n",
      "positions (x,y,z), reward: [  6.22263165   7.66470831  90.1780416 ] 1.0\n",
      "positions (x,y,z), reward: [  14.58539369   15.90135333  119.04846384] 1.0\n",
      "positions (x,y,z), reward: [  22.57540294   24.32309353  141.78008181] 1.0\n",
      "Episode =  386, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.21203915e-05  -9.65258405e-05   2.04945366e+01] 0.999707856295\n",
      "positions (x,y,z), reward: [  1.74429362e-03   3.81442196e-02   2.79570206e+01] 0.999999999877\n",
      "positions (x,y,z), reward: [  9.78296721e-03   9.57941363e-02   3.14950020e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [  0.19269377   3.17783819  70.03534981] 1.0\n",
      "positions (x,y,z), reward: [ -0.57259346   7.62691445  92.55274576] 1.0\n",
      "positions (x,y,z), reward: [ -0.67552817   7.93493578  93.7822009 ] 1.0\n",
      "positions (x,y,z), reward: [  -3.39683391   13.45467852  113.02793652] 1.0\n",
      "positions (x,y,z), reward: [  -3.6632995    13.87528611  114.37590963] 1.0\n",
      "positions (x,y,z), reward: [  -7.3509032    18.86258491  130.11274101] 1.0\n",
      "positions (x,y,z), reward: [ -16.47822095   29.18935074  164.05356879] 1.0\n",
      "Episode =  387, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.43487382  -0.11888019  39.95708949] 1.0\n",
      "positions (x,y,z), reward: [ -0.97109093  -0.16032528  47.46898879] 1.0\n",
      "positions (x,y,z), reward: [ -2.07781258  -0.20935137  56.87788646] 1.0\n",
      "positions (x,y,z), reward: [ -6.80395747  -0.51215208  77.53876905] 1.0\n",
      "positions (x,y,z), reward: [ -7.93005646  -0.61693489  80.84259189] 1.0\n",
      "positions (x,y,z), reward: [-13.59740291  -1.34103358  93.72593139] 1.0\n",
      "positions (x,y,z), reward: [ -20.192683     -2.56378221  104.31173868] 1.0\n",
      "positions (x,y,z), reward: [ -33.51960046   -6.03981825  118.8021634 ] 1.0\n",
      "positions (x,y,z), reward: [ -35.82675974   -6.74089173  120.6991975 ] 1.0\n",
      "Episode =  388, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777447] 0.941444780529\n",
      "positions (x,y,z), reward: [  0.57258873  -0.07087426  38.4079874 ] 1.0\n",
      "positions (x,y,z), reward: [  1.38958539  -0.18488593  48.57563958] 1.0\n",
      "positions (x,y,z), reward: [  4.16324552  -0.66021299  68.33738103] 1.0\n",
      "positions (x,y,z), reward: [  4.71456322  -0.75210081  71.23420884] 1.0\n",
      "positions (x,y,z), reward: [  5.68196614  -0.90656683  75.90095882] 1.0\n",
      "positions (x,y,z), reward: [  7.78932363  -1.2188803   84.76112824] 1.0\n",
      "positions (x,y,z), reward: [  9.58083815  -1.47271134  91.35035442] 1.0\n",
      "positions (x,y,z), reward: [  9.92894497  -1.52198669  92.55693116] 1.0\n",
      "positions (x,y,z), reward: [ 10.8300799   -1.6504898   95.58661277] 1.0\n",
      "positions (x,y,z), reward: [ 11.20316922  -1.70427517  96.80438906] 1.0\n",
      "positions (x,y,z), reward: [ 11.77674941  -1.78785634  98.63821873] 1.0\n",
      "positions (x,y,z), reward: [  16.04253379   -2.4735041   111.13786014] 1.0\n",
      "positions (x,y,z), reward: [  17.96799745   -2.85021629  116.30255536] 1.0\n",
      "positions (x,y,z), reward: [  25.12839052   -4.90940248  134.04089608] 1.0\n",
      "positions (x,y,z), reward: [  36.00243584  -11.08139817  158.66973355] 1.0\n",
      "Episode =  389, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -9.07370854e-02   1.05137704e-02   3.01228632e+01] 0.999999999976\n",
      "positions (x,y,z), reward: [ -0.73168892   0.38940156  55.18895152] 1.0\n",
      "positions (x,y,z), reward: [ -0.82158332   0.5521548   59.66269076] 1.0\n",
      "positions (x,y,z), reward: [ -0.85264035   1.61231169  79.55692878] 1.0\n",
      "positions (x,y,z), reward: [ -7.01076281e-02   2.73349230e+00   9.68375673e+01] 1.0\n",
      "positions (x,y,z), reward: [   0.23986831    2.95153191  100.61794169] 1.0\n",
      "positions (x,y,z), reward: [   2.85638508    3.79512786  122.12678828] 1.0\n",
      "positions (x,y,z), reward: [   3.34301881    3.87083826  125.27045339] 1.0\n",
      "positions (x,y,z), reward: [   3.47228269    3.88888044  126.07665451] 1.0\n",
      "positions (x,y,z), reward: [   7.5092587     4.25213167  146.9422882 ] 1.0\n",
      "positions (x,y,z), reward: [  10.2171656     4.43563255  158.35998899] 1.0\n",
      "Episode =  390, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.73696497e-03   1.75012177e-02   2.45376548e+01] 0.999999994123\n",
      "positions (x,y,z), reward: [ -2.25360684e-02   8.48783746e-02   2.88039858e+01] 0.999999999938\n",
      "positions (x,y,z), reward: [ -0.1439676    0.25063801  34.36864081] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.19729191   0.31060245  35.86021856] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.49365937   0.60231358  41.55769884] 1.0\n",
      "positions (x,y,z), reward: [ -1.89312067   1.74169075  55.26944604] 1.0\n",
      "positions (x,y,z), reward: [ -9.92175812   6.81806856  86.60677547] 1.0\n",
      "positions (x,y,z), reward: [ -18.94551292   11.41141065  104.35043814] 1.0\n",
      "positions (x,y,z), reward: [ -19.25696606   11.56095626  104.84354068] 1.0\n",
      "positions (x,y,z), reward: [ -22.4894188    13.10123286  109.67064723] 1.0\n",
      "positions (x,y,z), reward: [ -22.82379319   13.25984119  110.1427792 ] 1.0\n",
      "positions (x,y,z), reward: [ -23.16009175   13.4193065   110.61296075] 1.0\n",
      "positions (x,y,z), reward: [ -34.45911695   18.81485805  124.16850991] 1.0\n",
      "positions (x,y,z), reward: [ -35.24241846   19.19397097  124.97088234] 1.0\n",
      "positions (x,y,z), reward: [ -37.22878738   20.1585977   126.93669169] 1.0\n",
      "positions (x,y,z), reward: [ -43.007194     22.98881414  132.13353099] 1.0\n",
      "Episode =  391, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.00661104e-08   8.98297571e-08   2.00311083e+01] 0.972215345292\n",
      "positions (x,y,z), reward: [ -0.36925875  -0.32930802  35.36150572] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.88458397  -0.9084259   43.681514  ] 1.0\n",
      "positions (x,y,z), reward: [ -5.20603124  -6.41046311  75.61933575] 1.0\n",
      "positions (x,y,z), reward: [ -7.04666181  -9.07330864  83.72938831] 1.0\n",
      "positions (x,y,z), reward: [ -7.31606498  -9.48247605  84.79380117] 1.0\n",
      "positions (x,y,z), reward: [-10.35437664 -14.34822033  95.1112865 ] 1.0\n",
      "positions (x,y,z), reward: [-10.8674716  -15.2015581   96.59509075] 1.0\n",
      "positions (x,y,z), reward: [ -15.59324352  -23.16002273  107.64940033] 1.0\n",
      "positions (x,y,z), reward: [ -26.07705057  -39.59185931  121.58660371] 1.0\n",
      "positions (x,y,z), reward: [ -30.20983465  -45.20161834  124.68380046] 1.0\n",
      "Episode =  392, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.70609017e-07  -1.61610567e-07   2.00700076e+01] 0.987027225468\n",
      "positions (x,y,z), reward: [  0.26492487   0.43714626  36.36903759] 1.0\n",
      "positions (x,y,z), reward: [  0.6093144    2.74369251  57.02014911] 1.0\n",
      "positions (x,y,z), reward: [  0.40676987   5.07933063  69.21679957] 1.0\n",
      "positions (x,y,z), reward: [  0.32055131   5.48588235  71.00334067] 1.0\n",
      "positions (x,y,z), reward: [ -5.80711143e-02   6.81922179e+00   7.64336899e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.49274128   7.97149272  80.73094932] 1.0\n",
      "positions (x,y,z), reward: [ -0.64132824   8.31826043  81.97037114] 1.0\n",
      "positions (x,y,z), reward: [ -2.13000438  11.14155601  91.43106687] 1.0\n",
      "positions (x,y,z), reward: [  -4.88747327   14.95973302  103.24370835] 1.0\n",
      "positions (x,y,z), reward: [  -5.07591227   15.18365619  103.92056148] 1.0\n",
      "positions (x,y,z), reward: [  -5.66558507   15.86244135  105.96842927] 1.0\n",
      "positions (x,y,z), reward: [  -5.87040505   16.09100344  106.6572344 ] 1.0\n",
      "positions (x,y,z), reward: [ -10.00926282   20.12546309  118.99536273] 1.0\n",
      "positions (x,y,z), reward: [ -20.44624429   27.8511823   146.83448242] 1.0\n",
      "positions (x,y,z), reward: [ -27.34687256   32.6567311   168.69455957] 1.0\n",
      "positions (x,y,z), reward: [ -33.29058579   38.08465781  195.10171341] 1.0\n",
      "Episode =  393, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.54010155e-03   1.13073956e-02   2.29769666e+01] 0.9999999104\n",
      "positions (x,y,z), reward: [ -0.06992174   0.14174898  30.12667894] 0.999999999976\n",
      "positions (x,y,z), reward: [ -1.86439015   2.13982161  62.43034497] 1.0\n",
      "positions (x,y,z), reward: [ -4.0842121    4.43501851  81.41713955] 1.0\n",
      "positions (x,y,z), reward: [  -8.32012106    8.08517958  102.38570645] 1.0\n",
      "positions (x,y,z), reward: [  -8.46873718    8.1958921   102.92979156] 1.0\n",
      "positions (x,y,z), reward: [  -8.77243027    8.41975333  104.01623518] 1.0\n",
      "positions (x,y,z), reward: [ -16.79249188   13.64582729  125.05295663] 1.0\n",
      "positions (x,y,z), reward: [ -18.57983709   14.71785364  128.54983814] 1.0\n",
      "positions (x,y,z), reward: [ -20.47406923   15.83986828  131.97690271] 1.0\n",
      "Episode =  394, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.47407190e-05  -1.23466282e-04   2.06248346e+01] 0.999860939509\n",
      "positions (x,y,z), reward: [ -7.07478266e-03   1.16113319e-02   2.48809140e+01] 0.99999999638\n",
      "positions (x,y,z), reward: [ -0.11448372   0.20443219  33.87350715] 0.999999999997\n",
      "positions (x,y,z), reward: [ -2.58541618   2.99033588  65.399653  ] 1.0\n",
      "positions (x,y,z), reward: [ -3.31201743   3.58706774  69.38099698] 1.0\n",
      "positions (x,y,z), reward: [ -4.92418294   4.74559597  76.20343336] 1.0\n",
      "positions (x,y,z), reward: [-10.80783104   7.87500277  91.18522625] 1.0\n",
      "positions (x,y,z), reward: [ -23.12896195   11.76173417  106.87074809] 1.0\n",
      "positions (x,y,z), reward: [ -28.78073489   12.80595561  111.40401693] 1.0\n",
      "Episode =  395, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.65149117e-04  -1.27458072e-04   2.11025012e+01] 0.999983906682\n",
      "positions (x,y,z), reward: [ -4.17506478e-02  -1.79409874e-02   2.59698447e+01] 0.9999999991\n",
      "positions (x,y,z), reward: [ -0.10352357  -0.05046596  28.80199163] 0.999999999938\n",
      "positions (x,y,z), reward: [ -0.69464343  -0.34100052  40.487855  ] 1.0\n",
      "positions (x,y,z), reward: [ -3.87805838  -1.13550175  60.7836565 ] 1.0\n",
      "positions (x,y,z), reward: [ -4.49104017  -1.23186932  63.01371914] 1.0\n",
      "positions (x,y,z), reward: [ -5.92674094  -1.42986974  67.45186399] 1.0\n",
      "positions (x,y,z), reward: [ -7.91251432  -1.66374109  72.37472973] 1.0\n",
      "positions (x,y,z), reward: [-31.83600163  -3.32666247  98.15217667] 1.0\n",
      "positions (x,y,z), reward: [ -66.05298322   -3.1842271   104.41437114] 1.0\n",
      "positions (x,y,z), reward: [ -81.74069683   -1.77871025  100.62716029] 1.0\n",
      "Episode =  396, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.77515376e-04   3.71984463e-04   2.12910719e+01] 0.999992039446\n",
      "positions (x,y,z), reward: [ -1.56039689e-01   3.14111143e-03   3.94513791e+01] 1.0\n",
      "positions (x,y,z), reward: [ -2.75579404e-01   3.95481743e-02   5.35338213e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.1806176    0.19275251  64.75840064] 1.0\n",
      "positions (x,y,z), reward: [ -0.15782609   0.21653462  65.89191817] 1.0\n",
      "positions (x,y,z), reward: [  1.39223323   1.46611839  94.58838781] 1.0\n",
      "positions (x,y,z), reward: [   2.38575407    2.22535073  104.35473969] 1.0\n",
      "positions (x,y,z), reward: [   2.58445706    2.37907203  106.06860193] 1.0\n",
      "positions (x,y,z), reward: [   3.00180377    2.70608083  109.48721215] 1.0\n",
      "positions (x,y,z), reward: [   4.39124458    3.86357484  119.68360508] 1.0\n",
      "Episode =  397, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -8.88341708e-08   8.40842684e-08   2.00310895e+01] 0.972189837336\n",
      "positions (x,y,z), reward: [ -3.99703816e-05   4.77190025e-05   2.02789379e+01] 0.998684330603\n",
      "positions (x,y,z), reward: [  1.30603651e-02   6.35421165e-02   2.59721410e+01] 0.999999999106\n",
      "positions (x,y,z), reward: [  0.54507392   0.79723063  40.50527365] 1.0\n",
      "positions (x,y,z), reward: [  8.11573901   6.92415212  83.8714247 ] 1.0\n",
      "positions (x,y,z), reward: [  9.10720011   7.68706634  87.54895375] 1.0\n",
      "positions (x,y,z), reward: [ 10.65127324   8.88899021  93.06438122] 1.0\n",
      "positions (x,y,z), reward: [ 12.61185408  10.43369258  99.77122072] 1.0\n",
      "positions (x,y,z), reward: [  16.55803202   13.5237911   112.34617688] 1.0\n",
      "positions (x,y,z), reward: [  24.72058114   19.16401367  134.05064859] 1.0\n",
      "Episode =  398, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  8.82350362e-03   2.09062548e-02   2.35690734e+01] 0.99999997138\n",
      "positions (x,y,z), reward: [  1.24322134e-02   2.90979008e-02   2.42055058e+01] 0.999999990226\n",
      "positions (x,y,z), reward: [  0.17319891   0.38519406  36.87029602] 1.0\n",
      "positions (x,y,z), reward: [  0.2775498    0.61891213  42.07786157] 1.0\n",
      "positions (x,y,z), reward: [  0.30114402   0.67194802  43.14372002] 1.0\n",
      "positions (x,y,z), reward: [  0.37646874   0.84228824  46.37614415] 1.0\n",
      "positions (x,y,z), reward: [  0.78995097   1.95798367  63.51798871] 1.0\n",
      "positions (x,y,z), reward: [  0.9041723    2.54303412  70.8028169 ] 1.0\n",
      "positions (x,y,z), reward: [  0.92216777   2.83789382  74.17708652] 1.0\n",
      "positions (x,y,z), reward: [  -1.59141418    6.50249662  109.31629739] 1.0\n",
      "positions (x,y,z), reward: [  -2.48430819    7.03180318  114.97487781] 1.0\n",
      "positions (x,y,z), reward: [  -3.77065057    7.59320907  122.32131326] 1.0\n",
      "positions (x,y,z), reward: [  -6.85108342    7.99164606  138.27745249] 1.0\n",
      "Episode =  399, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  9.36100056e-03  -1.38202509e-01   3.01239232e+01] 0.999999999976\n",
      "positions (x,y,z), reward: [  0.0985328   -0.47980135  37.38162326] 1.0\n",
      "positions (x,y,z), reward: [  0.14027342  -0.61314923  39.44804443] 1.0\n",
      "positions (x,y,z), reward: [  1.6028331   -6.32419663  75.76650425] 1.0\n",
      "positions (x,y,z), reward: [  1.84842993  -7.45928422  79.62983937] 1.0\n",
      "positions (x,y,z), reward: [   4.21451653  -17.40528781  103.59280482] 1.0\n",
      "positions (x,y,z), reward: [   5.3600253   -21.68116646  111.13930377] 1.0\n",
      "positions (x,y,z), reward: [   6.89683724  -27.06408666  119.36559026] 1.0\n",
      "positions (x,y,z), reward: [   7.60105825  -29.43964954  122.63277033] 1.0\n",
      "positions (x,y,z), reward: [   8.23589439  -31.54681485  125.36968878] 1.0\n",
      "Episode =  400, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.23642742e-07   1.60187357e-07   2.00310887e+01] 0.972188515908\n",
      "positions (x,y,z), reward: [ -1.50118141e-02  -1.30553467e-02   2.26965296e+01] 0.99999983496\n",
      "positions (x,y,z), reward: [ -0.09396927  -0.1026629   26.73622621] 0.999999999603\n",
      "positions (x,y,z), reward: [ -0.10502869  -0.11628105  27.13317315] 0.999999999733\n",
      "positions (x,y,z), reward: [ -0.34935537  -0.44338187  33.37563583] 0.999999999995\n",
      "positions (x,y,z), reward: [ -1.11045795  -1.61176534  44.70882364] 1.0\n",
      "positions (x,y,z), reward: [ -1.29891808  -1.92948459  46.86783654] 1.0\n",
      "positions (x,y,z), reward: [ -4.23462739  -9.76106682  73.06535646] 1.0\n",
      "positions (x,y,z), reward: [ -5.37489218 -15.96617359  82.7842247 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.17186326 -23.47103904  90.57647799] 1.0\n",
      "positions (x,y,z), reward: [ -6.24645863 -24.48215765  91.4218901 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.67213279 -33.6375715   97.59294361] 1.0\n",
      "positions (x,y,z), reward: [ -6.7527317  -38.32206429  99.94888612] 1.0\n",
      "positions (x,y,z), reward: [  -6.20577973  -69.39373042  107.46748917] 1.0\n",
      "positions (x,y,z), reward: [  -5.88595292  -84.04304131  107.66417518] 1.0\n",
      "positions (x,y,z), reward: [  -5.8862812  -115.08458917  103.15179792] 1.0\n",
      "Episode =  401, score =   1.991 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.99207089e-05  -6.98966485e-06   2.04944845e+01] 0.999707963105\n",
      "positions (x,y,z), reward: [  1.30830727e-01   7.19367166e-03   3.14968587e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [  1.53259312e-01   1.31529224e-02   3.24368013e+01] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.48889947   0.15022681  42.08264067] 1.0\n",
      "positions (x,y,z), reward: [  1.43347901   0.62184704  57.42032323] 1.0\n",
      "positions (x,y,z), reward: [  2.39184607   1.15177886  68.60072304] 1.0\n",
      "positions (x,y,z), reward: [   5.07001479    5.11469705  105.17928735] 1.0\n",
      "positions (x,y,z), reward: [   5.0991813     5.94902863  109.84489321] 1.0\n",
      "positions (x,y,z), reward: [   4.88048778    8.10070927  120.27268806] 1.0\n",
      "positions (x,y,z), reward: [   4.79180918    8.62867632  122.56507277] 1.0\n",
      "positions (x,y,z), reward: [   4.66707453    9.31418004  125.41444585] 1.0\n",
      "positions (x,y,z), reward: [   3.92452556   13.1933249   139.38126821] 1.0\n",
      "Episode =  402, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.22639085e-03  -1.20696630e-02   2.35694950e+01] 0.999999971485\n",
      "positions (x,y,z), reward: [ -2.91802837e-02  -9.80159546e-02   3.10369628e+01] 0.999999999986\n",
      "positions (x,y,z), reward: [ -2.63151189e-02  -5.56919793e-01   4.85715669e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.05712744  -0.85017395  56.30524241] 1.0\n",
      "positions (x,y,z), reward: [  0.18820316  -1.14209683  63.00980057] 1.0\n",
      "positions (x,y,z), reward: [  0.45336392  -1.57914341  71.44877601] 1.0\n",
      "positions (x,y,z), reward: [  0.70667015  -1.93405502  77.10211249] 1.0\n",
      "positions (x,y,z), reward: [  0.9276067   -2.22407501  81.07281517] 1.0\n",
      "positions (x,y,z), reward: [  0.96244827  -2.26889213  81.64108855] 1.0\n",
      "positions (x,y,z), reward: [   5.32991235   -8.26711247  116.26334583] 1.0\n",
      "positions (x,y,z), reward: [   6.08499082   -9.42279549  119.69757478] 1.0\n",
      "positions (x,y,z), reward: [   7.93905068  -12.37154425  126.96702927] 1.0\n",
      "positions (x,y,z), reward: [   8.89263835  -13.93742003  130.21536452] 1.0\n",
      "positions (x,y,z), reward: [  13.3102713   -21.44108183  142.35006278] 1.0\n",
      "Episode =  403, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.18521271e-06  -1.19921469e-05   2.01939458e+01] 0.997184923111\n",
      "positions (x,y,z), reward: [ -3.32383712e-05  -7.84706981e-05   2.03792022e+01] 0.999382587016\n",
      "positions (x,y,z), reward: [ -0.18217101  -0.41564237  38.40780382] 1.0\n",
      "positions (x,y,z), reward: [ -0.6613293   -2.52527015  58.56920364] 1.0\n",
      "positions (x,y,z), reward: [ -0.68524824  -2.7230725   59.68967164] 1.0\n",
      "positions (x,y,z), reward: [ -0.72913539  -3.15051875  61.93345946] 1.0\n",
      "positions (x,y,z), reward: [ -0.73413009 -10.05195731  83.60623366] 1.0\n",
      "positions (x,y,z), reward: [ -0.57205738 -12.8175722   88.92386405] 1.0\n",
      "positions (x,y,z), reward: [ -0.13566519 -18.26506645  96.96768325] 1.0\n",
      "positions (x,y,z), reward: [ -0.10036681 -18.64860572  97.44628569] 1.0\n",
      "positions (x,y,z), reward: [   0.3563653   -23.20028693  102.48322557] 1.0\n",
      "positions (x,y,z), reward: [   0.83250701  -27.3757976   106.25452142] 1.0\n",
      "Episode =  404, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.50878514e-04  -1.90740589e-04   2.12903234e+01] 0.999991988611\n",
      "positions (x,y,z), reward: [ -1.35241284e-03  -3.51378106e-04   2.17069474e+01] 0.999997934072\n",
      "positions (x,y,z), reward: [ -6.46765992e-02   2.43462111e-02   3.68728963e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.12923143   0.06704921  42.6180972 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.17436588   0.0955883   45.3060371 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.32538889   0.18144562  51.32704528] 1.0\n",
      "positions (x,y,z), reward: [ -0.52085488   0.27718112  56.32710343] 1.0\n",
      "positions (x,y,z), reward: [ -4.81713447   1.75073505  88.05427859] 1.0\n",
      "positions (x,y,z), reward: [ -7.91506535   2.67112761  98.1842696 ] 1.0\n",
      "positions (x,y,z), reward: [ -16.89338458    4.87883384  115.91821253] 1.0\n",
      "positions (x,y,z), reward: [ -17.58913113    5.02517345  116.93087463] 1.0\n",
      "positions (x,y,z), reward: [ -29.75636441    7.07267351  130.29851579] 1.0\n",
      "Episode =  405, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.53732328e-03  -6.05558682e-04   2.21784302e+01] 0.999999441495\n",
      "positions (x,y,z), reward: [ -0.43911418   0.06138257  44.76433092] 1.0\n",
      "positions (x,y,z), reward: [ -0.47319337   0.049313    45.84684714] 1.0\n",
      "positions (x,y,z), reward: [ -2.83071415  -5.4541391   85.23547527] 1.0\n",
      "positions (x,y,z), reward: [ -2.97203332  -5.8524539   86.34954826] 1.0\n",
      "positions (x,y,z), reward: [ -3.04532896  -6.05800582  86.90481919] 1.0\n",
      "positions (x,y,z), reward: [ -3.35697807  -6.92323837  89.11291484] 1.0\n",
      "positions (x,y,z), reward: [ -4.60030515 -10.21483491  96.1101284 ] 1.0\n",
      "positions (x,y,z), reward: [ -15.7008383   -31.6307926   121.47924627] 1.0\n",
      "positions (x,y,z), reward: [ -17.27611594  -33.83731016  123.17940437] 1.0\n",
      "positions (x,y,z), reward: [ -18.28530101  -35.16727069  124.15132747] 1.0\n",
      "positions (x,y,z), reward: [ -22.8388454   -40.46629802  127.65404338] 1.0\n",
      "positions (x,y,z), reward: [ -25.90293944  -43.47962872  129.39230795] 1.0\n",
      "Episode =  406, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -6.64324398e-08   2.14541606e-08   2.00311209e+01] 0.972232324955\n",
      "positions (x,y,z), reward: [ -1.39079267e-03   1.03165165e-03   2.12915035e+01] 0.999992080665\n",
      "positions (x,y,z), reward: [ -2.46450596e-02   2.30546587e-02   2.59769461e+01] 0.99999999912\n",
      "positions (x,y,z), reward: [ -0.03125818   0.03123881  27.14588564] 0.999999999746\n",
      "positions (x,y,z), reward: [ -0.04390712   0.08412558  34.38188613] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.04232506   0.0872767   34.87582984] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.03803012   0.09325937  35.87448863] 0.999999999998\n",
      "positions (x,y,z), reward: [  3.26701274e-02   1.14883047e-01   4.26371672e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.18167735   0.08739821  49.15416833] 1.0\n",
      "positions (x,y,z), reward: [  0.2163812    0.07596184  50.25761568] 1.0\n",
      "positions (x,y,z), reward: [  4.39903951e-01  -1.98624330e-02   5.58319910e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.52463309  -0.06293727  57.52088015] 1.0\n",
      "positions (x,y,z), reward: [  0.83367244  -0.23874475  62.62873841] 1.0\n",
      "positions (x,y,z), reward: [  1.09013856  -0.39914668  66.06825775] 1.0\n",
      "positions (x,y,z), reward: [  2.36823417  -1.25651234  78.36413428] 1.0\n",
      "positions (x,y,z), reward: [  11.95019446   -8.06627083  128.11923404] 1.0\n",
      "positions (x,y,z), reward: [  12.41896215   -8.43046994  130.20214949] 1.0\n",
      "positions (x,y,z), reward: [  15.08584977  -10.65169427  142.41719063] 1.0\n",
      "Episode =  407, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.12414679e-02  -5.52645008e-02   2.83791043e+01] 0.999999999914\n",
      "positions (x,y,z), reward: [  0.0413467   -0.18950654  35.3606914 ] 0.999999999998\n",
      "positions (x,y,z), reward: [  5.08734570e-02  -8.82331203e-01   5.13196301e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.62888751  -5.09015227  89.35994807] 1.0\n",
      "positions (x,y,z), reward: [ -0.80511844  -5.69028257  93.8907656 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.02128092  -6.28044286  98.47604878] 1.0\n",
      "positions (x,y,z), reward: [  -1.14980842   -6.57004459  100.79535469] 1.0\n",
      "positions (x,y,z), reward: [  -5.86648038  -10.38343125  135.08719653] 1.0\n",
      "Episode =  408, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.80265353e-03  -1.92654529e-02   2.42028609e+01] 0.999999990156\n",
      "positions (x,y,z), reward: [ -0.1002514   -0.9609306   57.44169501] 1.0\n",
      "positions (x,y,z), reward: [ -0.46601813  -1.26290577  63.63661471] 1.0\n",
      "positions (x,y,z), reward: [ -0.55568798  -1.31977202  64.76834913] 1.0\n",
      "positions (x,y,z), reward: [ -3.45754828  -2.31141259  85.19929756] 1.0\n",
      "positions (x,y,z), reward: [ -4.18522685  -2.44807336  88.60334048] 1.0\n",
      "positions (x,y,z), reward: [ -6.49987575  -2.74021703  97.68890382] 1.0\n",
      "positions (x,y,z), reward: [ -6.82827491  -2.76922839  98.82396293] 1.0\n",
      "positions (x,y,z), reward: [ -7.16520725  -2.79668217  99.95821635] 1.0\n",
      "positions (x,y,z), reward: [  -7.86423656   -2.84709607  102.2233346 ] 1.0\n",
      "positions (x,y,z), reward: [ -10.76782465   -2.98799505  110.64627786] 1.0\n",
      "positions (x,y,z), reward: [ -12.04295554   -3.02498574  113.96884328] 1.0\n",
      "positions (x,y,z), reward: [ -12.9253152    -3.04376374  116.16521049] 1.0\n",
      "positions (x,y,z), reward: [ -25.6178744    -2.88626902  141.67959897] 1.0\n",
      "positions (x,y,z), reward: [ -26.21272704   -2.86482391  142.66703613] 1.0\n",
      "positions (x,y,z), reward: [ -28.03721959   -2.79296199  145.60474167] 1.0\n",
      "Episode =  409, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.37911541  -0.04767875  33.39366132] 0.999999999996\n",
      "positions (x,y,z), reward: [ -0.92756519  -0.0990619   39.96555101] 1.0\n",
      "positions (x,y,z), reward: [ -2.54248146  -0.16544201  51.83153206] 1.0\n",
      "positions (x,y,z), reward: [ -2.93827863  -0.165627    54.03542371] 1.0\n",
      "positions (x,y,z), reward: [-13.35721763   0.8265365   85.73399386] 1.0\n",
      "positions (x,y,z), reward: [-21.36275954   1.75463388  99.35744021] 1.0\n",
      "positions (x,y,z), reward: [ -27.21287977    2.25330724  107.17828148] 1.0\n",
      "positions (x,y,z), reward: [ -31.53420444    2.50280997  112.15280808] 1.0\n",
      "positions (x,y,z), reward: [ -42.68465568    2.70055001  122.52459072] 1.0\n",
      "positions (x,y,z), reward: [ -50.25811155    2.52501841  127.86456666] 1.0\n",
      "positions (x,y,z), reward: [ -62.61743182    1.86239717  134.09882695] 1.0\n",
      "Episode =  410, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.94389693e-08   1.89983327e-08   2.00311020e+01] 0.97220679469\n",
      "positions (x,y,z), reward: [  0.1677481   -0.03852558  29.68478696] 0.999999999968\n",
      "positions (x,y,z), reward: [  1.04238734  -0.38910744  45.3061331 ] 1.0\n",
      "positions (x,y,z), reward: [  2.51693177  -1.1244483   59.68723251] 1.0\n",
      "positions (x,y,z), reward: [  3.05552542  -1.40759423  63.63565753] 1.0\n",
      "positions (x,y,z), reward: [  4.90084072  -2.42850087  74.50756818] 1.0\n",
      "positions (x,y,z), reward: [  6.27755779  -3.24955545  80.93206658] 1.0\n",
      "positions (x,y,z), reward: [ 11.07723056  -6.59703957  97.78120685] 1.0\n",
      "positions (x,y,z), reward: [  20.18110173  -15.04486804  119.27445167] 1.0\n",
      "positions (x,y,z), reward: [  25.49462873  -21.1756977   128.87199553] 1.0\n",
      "positions (x,y,z), reward: [  35.00412419  -34.27835884  142.39787216] 1.0\n",
      "positions (x,y,z), reward: [  39.93661943  -41.74227338  147.39341817] 1.0\n",
      "Episode =  411, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.26563384e-02   1.04991700e-02   2.52360436e+01] 0.999999997792\n",
      "positions (x,y,z), reward: [ -1.61449350e-02   2.45104873e-02   2.71399439e+01] 0.999999999743\n",
      "positions (x,y,z), reward: [ -2.48931033e-02   2.65682176e-01   3.78991322e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.101986     0.92700823  49.70396342] 1.0\n",
      "positions (x,y,z), reward: [ -1.88806063   5.71397854  84.07448839] 1.0\n",
      "positions (x,y,z), reward: [  -4.87148774   10.65990453  104.14158126] 1.0\n",
      "Episode =  412, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.99098555  -0.76458966  65.80508387] 1.0\n",
      "positions (x,y,z), reward: [-10.5145154   -0.76366664  80.67504233] 1.0\n",
      "positions (x,y,z), reward: [-13.85382422  -0.68368587  87.05652458] 1.0\n",
      "positions (x,y,z), reward: [-17.79245573  -0.57673921  93.19340574] 1.0\n",
      "positions (x,y,z), reward: [-21.16843467  -0.49508495  97.58094991] 1.0\n",
      "positions (x,y,z), reward: [-23.20421149  -0.45528898  99.92227228] 1.0\n",
      "positions (x,y,z), reward: [ -29.5009014    -0.39419081  106.04653134] 1.0\n",
      "positions (x,y,z), reward: [ -37.14177706   -0.4676316   111.80051417] 1.0\n",
      "positions (x,y,z), reward: [ -46.71424438   -0.80671289  117.22079388] 1.0\n",
      "positions (x,y,z), reward: [ -53.89992403   -1.23619296  120.33428035] 1.0\n",
      "positions (x,y,z), reward: [ -57.58651848   -1.50865719  121.67220944] 1.0\n",
      "positions (x,y,z), reward: [ -66.99195872   -2.34268914  124.38256292] 1.0\n",
      "Episode =  413, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -9.98377425e-04  -7.92865352e-05   2.09292780e+01] 0.999967540439\n",
      "positions (x,y,z), reward: [ -1.60391522e-02  -7.75067420e-04   2.32676551e+01] 0.999999949622\n",
      "positions (x,y,z), reward: [ -8.37714147e-02  -1.05822305e-02   2.67425261e+01] 0.99999999961\n",
      "positions (x,y,z), reward: [ -0.32785491  -0.073869    32.43144525] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.59499549  -0.15756997  36.35560043] 1.0\n",
      "positions (x,y,z), reward: [ -0.86031334  -0.24726908  39.43504823] 1.0\n",
      "positions (x,y,z), reward: [ -1.24246126  -0.38584139  43.13122307] 1.0\n",
      "positions (x,y,z), reward: [ -2.25320562  -0.79114258  50.72994315] 1.0\n",
      "positions (x,y,z), reward: [ -2.4262586   -0.86470552  51.82937685] 1.0\n",
      "positions (x,y,z), reward: [ -5.66152817  -2.33354933  66.78233429] 1.0\n",
      "positions (x,y,z), reward: [ -6.31533621  -2.63844043  68.99169842] 1.0\n",
      "positions (x,y,z), reward: [ -7.20693117  -3.05486593  71.74081153] 1.0\n",
      "positions (x,y,z), reward: [ -8.59820255  -3.70542735  75.55631272] 1.0\n",
      "positions (x,y,z), reward: [-14.08153145  -6.32041719  87.13666247] 1.0\n",
      "positions (x,y,z), reward: [-14.66537979  -6.60620591  88.14761749] 1.0\n",
      "positions (x,y,z), reward: [-15.26399253  -6.90048208  89.14997411] 1.0\n",
      "positions (x,y,z), reward: [-18.82847605  -8.66933593  94.49035414] 1.0\n",
      "positions (x,y,z), reward: [-20.24230424  -9.37338251  96.35061372] 1.0\n",
      "positions (x,y,z), reward: [ -45.37296155  -20.58888855  115.54706143] 1.0\n",
      "positions (x,y,z), reward: [ -45.93702753  -20.79642664  115.78093414] 1.0\n",
      "positions (x,y,z), reward: [ -51.74948106  -22.79885441  117.85185711] 1.0\n",
      "positions (x,y,z), reward: [ -56.60686417  -24.28102888  119.15540393] 1.0\n",
      "positions (x,y,z), reward: [ -60.35387596  -25.30932993  119.92753262] 1.0\n",
      "positions (x,y,z), reward: [ -60.98596875  -25.47335281  120.03924093] 1.0\n",
      "Episode =  414, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.19640314e-02  -4.25374889e-03   2.38818087e+01] 0.999999983407\n",
      "positions (x,y,z), reward: [ -0.94677491   0.23688384  50.21507958] 1.0\n",
      "positions (x,y,z), reward: [ -1.96014803   1.5020997   72.69249316] 1.0\n",
      "positions (x,y,z), reward: [ -2.21829601   2.01109673  78.35884674] 1.0\n",
      "positions (x,y,z), reward: [ -2.29969879   2.17772346  80.05578536] 1.0\n",
      "positions (x,y,z), reward: [ -2.87136892   3.30573021  90.20402637] 1.0\n",
      "positions (x,y,z), reward: [  -3.76363466    4.71418757  100.87501579] 1.0\n",
      "positions (x,y,z), reward: [  -6.66361821    7.4232823   119.39639627] 1.0\n",
      "positions (x,y,z), reward: [  -7.05474256    7.66101061  121.08171324] 1.0\n",
      "positions (x,y,z), reward: [  -7.62152069    7.96949308  123.32854831] 1.0\n",
      "positions (x,y,z), reward: [ -10.51098034    9.04850262  132.28404493] 1.0\n",
      "positions (x,y,z), reward: [ -15.28713961    9.79172149  142.09728926] 1.0\n",
      "Episode =  415, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.49097905e-05  -9.52985791e-06   2.01939665e+01] 0.997183778407\n",
      "positions (x,y,z), reward: [ -2.28539674e-04  -2.63889773e-04   2.06245762e+01] 0.999860465646\n",
      "positions (x,y,z), reward: [ -2.76561908e-03  -4.07919226e-03   2.19355284e+01] 0.99999893351\n",
      "positions (x,y,z), reward: [ -3.56944564e-03  -5.35599830e-03   2.21769809e+01] 0.999999438743\n",
      "positions (x,y,z), reward: [ -0.03577041  -0.36352086  35.35663147] 0.999999999998\n",
      "positions (x,y,z), reward: [  6.98703063e-04  -5.98279509e-01   3.99636656e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.24664224  -1.65515864  55.15647882] 1.0\n",
      "positions (x,y,z), reward: [  0.41900962  -2.58490036  65.73831794] 1.0\n",
      "positions (x,y,z), reward: [  0.35553452  -3.79131028  78.70969556] 1.0\n",
      "positions (x,y,z), reward: [  0.13899846  -4.24101624  83.87792678] 1.0\n",
      "positions (x,y,z), reward: [ -0.32032373  -4.69851977  89.73206013] 1.0\n",
      "positions (x,y,z), reward: [ -22.00039287   -6.75274648  161.16480244] 1.0\n",
      "positions (x,y,z), reward: [ -24.64619646   -6.72579656  169.57084594] 1.0\n",
      "positions (x,y,z), reward: [ -30.74651366   -6.14720817  192.62107981] 1.0\n",
      "positions (x,y,z), reward: [ -32.12801434   -5.84550884  198.91500446] 1.0\n",
      "positions (x,y,z), reward: [ -32.84358806   -5.65041627  202.39514654] 1.0\n",
      "Episode =  416, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.03476323e-04   1.52494298e-03   2.24311834e+01] 0.99999969969\n",
      "positions (x,y,z), reward: [ -2.51405343e-02   1.03380038e-01   2.96802764e+01] 0.999999999968\n",
      "positions (x,y,z), reward: [ -0.04433671   0.17994559  31.96723667] 0.999999999992\n",
      "positions (x,y,z), reward: [ -0.1391414    0.55662903  38.94189476] 1.0\n",
      "positions (x,y,z), reward: [ -0.5936497    2.62397462  57.10777992] 1.0\n",
      "positions (x,y,z), reward: [ -0.62994496   2.81084765  58.25883186] 1.0\n",
      "positions (x,y,z), reward: [ -0.80068545   3.7458001   63.5003568 ] 1.0\n",
      "positions (x,y,z), reward: [ -1.34042916   7.82781719  81.10069639] 1.0\n",
      "positions (x,y,z), reward: [ -1.39023342   8.34794576  82.99727543] 1.0\n",
      "positions (x,y,z), reward: [ -1.40652079   8.52564557  83.63352889] 1.0\n",
      "positions (x,y,z), reward: [ -1.5764541   10.62893     90.78891421] 1.0\n",
      "positions (x,y,z), reward: [ -1.73655181  13.04196533  98.32995957] 1.0\n",
      "positions (x,y,z), reward: [  -2.15650322   20.57738296  118.43722878] 1.0\n",
      "positions (x,y,z), reward: [  -2.17845537   20.98098684  119.3881284 ] 1.0\n",
      "positions (x,y,z), reward: [  -2.50551187   26.92152718  132.35942252] 1.0\n",
      "positions (x,y,z), reward: [  -3.72122636   54.3075295   179.96779068] 1.0\n",
      "Episode =  417, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.86650050e-03   4.85903680e-04   2.17079935e+01] 0.999997951841\n",
      "positions (x,y,z), reward: [ -2.98452379e-03   1.34456451e-03   2.21780733e+01] 0.999999441448\n",
      "positions (x,y,z), reward: [ -9.39816942e-03   9.12228442e-03   2.42065372e+01] 0.999999990292\n",
      "positions (x,y,z), reward: [ -0.25202293   0.2430116   46.39707342] 1.0\n",
      "positions (x,y,z), reward: [ -0.98433015   0.68337001  70.30592101] 1.0\n",
      "positions (x,y,z), reward: [ -1.31585345   0.90622222  80.44085851] 1.0\n",
      "positions (x,y,z), reward: [  -1.60060869    1.80526656  101.63011094] 1.0\n",
      "Episode =  418, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.25778498e-03   1.78140105e-03   2.17090947e+01] 0.999997966361\n",
      "positions (x,y,z), reward: [ -3.87633049e-03   2.59329845e-02   2.71455275e+01] 0.999999999744\n",
      "positions (x,y,z), reward: [ -3.37515043e-03   2.85915712e-02   2.75510347e+01] 0.999999999825\n",
      "positions (x,y,z), reward: [  2.78748911e-02   1.07142380e-01   3.58679113e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.04041819   0.13407567  37.90107653] 1.0\n",
      "positions (x,y,z), reward: [  0.12741812   0.47955941  55.192076  ] 1.0\n",
      "positions (x,y,z), reward: [ -5.77428241e-03   7.73775043e-01   6.58314044e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.18888472   0.91906569  70.91622552] 1.0\n",
      "positions (x,y,z), reward: [ -0.30430381   0.98282119  73.18304745] 1.0\n",
      "positions (x,y,z), reward: [ -2.41348465   1.44855259  92.53261563] 1.0\n",
      "positions (x,y,z), reward: [ -11.22198008    0.76226139  120.49919939] 1.0\n",
      "positions (x,y,z), reward: [ -1.52638982e+01  -1.93721114e-02   1.27278432e+02] 1.0\n",
      "positions (x,y,z), reward: [ -26.95497526   -2.40215078  140.02853166] 1.0\n",
      "Episode =  419, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.10572812e-03  -2.49658173e-02   2.52377305e+01] 0.999999997783\n",
      "positions (x,y,z), reward: [ -2.03475111e-02  -2.03418173e-01   3.33951227e+01] 0.999999999996\n",
      "positions (x,y,z), reward: [ -2.56928444e-02  -2.19717007e-01   3.38807289e+01] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.17925482  -0.53675114  41.02673737] 1.0\n",
      "positions (x,y,z), reward: [ -5.06756955  -8.76527145  84.08395542] 1.0\n",
      "positions (x,y,z), reward: [ -6.67776855 -12.319121    92.57815924] 1.0\n",
      "positions (x,y,z), reward: [ -7.70877694 -14.88874044  97.79673659] 1.0\n",
      "positions (x,y,z), reward: [  -9.0665736   -18.65194608  104.58537671] 1.0\n",
      "positions (x,y,z), reward: [  -9.1717037   -18.96279588  105.1130815 ] 1.0\n",
      "positions (x,y,z), reward: [ -14.81193007  -40.42400828  137.89645498] 1.0\n",
      "Episode =  420, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.95954516e-04  -2.07227920e-03   2.19371137e+01] 0.999998942933\n",
      "positions (x,y,z), reward: [  0.40440796  -2.28847423  49.15802722] 1.0\n",
      "positions (x,y,z), reward: [  0.92378135  -4.93266835  58.54720051] 1.0\n",
      "positions (x,y,z), reward: [  1.23957955  -6.4705515   62.37443695] 1.0\n",
      "positions (x,y,z), reward: [  2.14991589 -10.74101579  70.28394714] 1.0\n",
      "positions (x,y,z), reward: [  2.69024054 -13.19047767  73.76629396] 1.0\n",
      "positions (x,y,z), reward: [  5.09485037 -23.5441654   84.2779089 ] 1.0\n",
      "positions (x,y,z), reward: [  8.43481468 -36.92563533  92.42956839] 1.0\n",
      "positions (x,y,z), reward: [  9.66962643 -41.69714205  94.3828588 ] 1.0\n",
      "positions (x,y,z), reward: [ 12.19550343 -51.32915461  97.10055187] 1.0\n",
      "positions (x,y,z), reward: [ 21.15591235 -87.06989617  95.35610761] 1.0\n",
      "Episode =  421, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.01750564e-03  -9.18145849e-05   2.12907147e+01] 0.999992021439\n",
      "positions (x,y,z), reward: [ -0.09090899   0.14729768  39.4519406 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.08310178   0.1848723   42.08699907] 1.0\n",
      "positions (x,y,z), reward: [  0.15949421   0.46815714  56.89097516] 1.0\n",
      "positions (x,y,z), reward: [  0.50272429   0.7470841   65.8897024 ] 1.0\n",
      "positions (x,y,z), reward: [  0.80704965   0.98057563  71.55420212] 1.0\n",
      "positions (x,y,z), reward: [  2.1500294    1.92804076  88.07269774] 1.0\n",
      "positions (x,y,z), reward: [  3.31536122   2.7203409   97.80310045] 1.0\n",
      "positions (x,y,z), reward: [   5.47790285    4.21463142  111.07897047] 1.0\n",
      "positions (x,y,z), reward: [   7.19106034    5.40440746  119.25033456] 1.0\n",
      "positions (x,y,z), reward: [   9.75540772    7.17555113  129.3615611 ] 1.0\n",
      "positions (x,y,z), reward: [  11.55001932    8.40759396  135.47839975] 1.0\n",
      "positions (x,y,z), reward: [  13.57687084    9.79694278  141.78493025] 1.0\n",
      "positions (x,y,z), reward: [  15.60491413   11.19117992  147.67867956] 1.0\n",
      "Episode =  422, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.82144289e-04  -9.37965862e-04   2.17078347e+01] 0.99999794797\n",
      "positions (x,y,z), reward: [  1.22670618e-02  -5.23657689e-02   2.75476748e+01] 0.999999999825\n",
      "positions (x,y,z), reward: [  2.90320079e-02  -1.01448878e-01   3.01275135e+01] 0.999999999976\n",
      "positions (x,y,z), reward: [  0.04515419  -0.14617134  31.9671638 ] 0.999999999992\n",
      "positions (x,y,z), reward: [  0.1323608   -0.36305082  38.41393272] 1.0\n",
      "positions (x,y,z), reward: [  0.22122887  -0.553154    42.6192016 ] 1.0\n",
      "positions (x,y,z), reward: [  0.32804503  -0.75641394  46.3910479 ] 1.0\n",
      "positions (x,y,z), reward: [  0.56324851  -1.15008173  52.43489633] 1.0\n",
      "positions (x,y,z), reward: [  1.70502485  -2.64088198  68.78029577] 1.0\n",
      "positions (x,y,z), reward: [  3.03677581  -3.99223148  80.30772987] 1.0\n",
      "positions (x,y,z), reward: [   6.59998293   -6.65812563  100.89182989] 1.0\n",
      "positions (x,y,z), reward: [   6.72619506   -6.73684334  101.48578911] 1.0\n",
      "positions (x,y,z), reward: [   8.20599474   -7.60789166  108.03087011] 1.0\n",
      "positions (x,y,z), reward: [  13.33844357  -10.09700982  126.52058608] 1.0\n",
      "positions (x,y,z), reward: [  17.62479093  -11.7221364   138.5938909 ] 1.0\n",
      "positions (x,y,z), reward: [  21.77952601  -13.06901072  148.42871391] 1.0\n",
      "Episode =  423, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.41955188e-04   8.58357914e-04   2.17068371e+01] 0.999997931366\n",
      "positions (x,y,z), reward: [ -1.28741670e-02   1.18621925e-02   2.83748079e+01] 0.999999999914\n",
      "positions (x,y,z), reward: [  2.89036155  -0.29107128  75.29114216] 1.0\n",
      "positions (x,y,z), reward: [  5.11084047  -0.2605261   87.95643036] 1.0\n",
      "positions (x,y,z), reward: [  5.65640941  -0.2185169   90.61126094] 1.0\n",
      "positions (x,y,z), reward: [  5.94284828  -0.19150177  91.95709113] 1.0\n",
      "positions (x,y,z), reward: [  6.85885647e+00  -8.29543027e-02   9.60758733e+01] 1.0\n",
      "positions (x,y,z), reward: [  7.18382799e+00  -3.65097344e-02   9.74783887e+01] 1.0\n",
      "positions (x,y,z), reward: [  21.81268079    7.1351473   152.8812449 ] 1.0\n",
      "positions (x,y,z), reward: [  23.99807923    9.54809572  162.0294103 ] 1.0\n",
      "positions (x,y,z), reward: [  24.3841866    10.03302208  163.70659672] 1.0\n",
      "Episode =  424, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  5.46887270e-06   3.00406557e-06   2.02792951e+01] 0.998692464639\n",
      "positions (x,y,z), reward: [  0.52175196   0.34819437  40.51304367] 1.0\n",
      "positions (x,y,z), reward: [  0.6169843    0.40280743  42.10208721] 1.0\n",
      "positions (x,y,z), reward: [  0.65092988   0.42175678  42.63559248] 1.0\n",
      "positions (x,y,z), reward: [  0.87867626   0.54283368  45.87138332] 1.0\n",
      "positions (x,y,z), reward: [  1.00855326   0.60792648  47.50872337] 1.0\n",
      "positions (x,y,z), reward: [  1.52204245   0.84579665  53.04014283] 1.0\n",
      "positions (x,y,z), reward: [  5.99768067   2.47963519  81.07867941] 1.0\n",
      "positions (x,y,z), reward: [  8.84276033   3.39390223  92.75873902] 1.0\n",
      "positions (x,y,z), reward: [  11.06991489    4.0644833   100.46316522] 1.0\n",
      "Episode =  425, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.05569551e-06   1.96537760e-06   2.01243806e+01] 0.993968933083\n",
      "positions (x,y,z), reward: [  8.91073782e-05   2.48936777e-04   2.09297274e+01] 0.999967558867\n",
      "positions (x,y,z), reward: [  9.02035605e-03   1.06635833e-03   2.38827050e+01] 0.999999983452\n",
      "positions (x,y,z), reward: [  5.79772535  -1.57572164  80.77335659] 1.0\n",
      "positions (x,y,z), reward: [  9.32428647  -3.53625636  94.12622666] 1.0\n",
      "positions (x,y,z), reward: [  9.72062163  -3.79574487  95.43408382] 1.0\n",
      "positions (x,y,z), reward: [  19.1110743   -12.11249178  120.83570037] 1.0\n",
      "positions (x,y,z), reward: [  39.50214495  -60.68168416  179.07860669] 1.0\n",
      "Episode =  426, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.58375891e-08  -3.88056419e-07   2.00699491e+01] 0.987003049988\n",
      "positions (x,y,z), reward: [  7.04913505e-06  -3.50716303e-05   2.02790415e+01] 0.998686453097\n",
      "positions (x,y,z), reward: [ -8.13218825e-03  -1.12863713e-01   2.79588493e+01] 0.999999999877\n",
      "positions (x,y,z), reward: [ -1.46489643e-02  -1.56967309e-01   2.92390908e+01] 0.999999999955\n",
      "positions (x,y,z), reward: [ -1.73776208e-02  -1.73777261e-01   2.96788195e+01] 0.999999999967\n",
      "positions (x,y,z), reward: [ -0.30428885  -1.23503024  44.75054288] 1.0\n",
      "positions (x,y,z), reward: [ -0.34237759  -1.34765322  45.83096042] 1.0\n",
      "positions (x,y,z), reward: [ -5.6813575 -12.0237017  88.1518947] 1.0\n",
      "positions (x,y,z), reward: [ -10.94058802  -19.84573194  103.19087443] 1.0\n",
      "positions (x,y,z), reward: [ -15.09879968  -25.58528154  111.82898965] 1.0\n",
      "positions (x,y,z), reward: [ -15.33177077  -25.90278981  112.26330822] 1.0\n",
      "positions (x,y,z), reward: [ -29.51963388  -44.96507324  132.29231824] 1.0\n",
      "Episode =  427, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.94810854e-03   1.44225177e-03   2.14922180e+01] 0.999995965218\n",
      "positions (x,y,z), reward: [  3.43660494e-02   2.43099765e-02   2.59712134e+01] 0.999999999106\n",
      "positions (x,y,z), reward: [  0.05353294   0.03916391  27.54462743] 0.999999999824\n",
      "positions (x,y,z), reward: [  0.20285862   0.17076647  35.36078801] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.69337396   0.70175377  49.12441028] 1.0\n",
      "positions (x,y,z), reward: [  1.60740525   1.70447129  63.09633096] 1.0\n",
      "positions (x,y,z), reward: [  4.56792908   4.84023906  87.57913729] 1.0\n",
      "positions (x,y,z), reward: [  4.66109864   4.93715198  88.14931923] 1.0\n",
      "positions (x,y,z), reward: [   8.27850176    8.62445387  105.86335876] 1.0\n",
      "positions (x,y,z), reward: [   9.31636631    9.65746208  109.8705077 ] 1.0\n",
      "positions (x,y,z), reward: [  10.43970943   10.76662133  113.87034017] 1.0\n",
      "positions (x,y,z), reward: [  10.60717063   10.93130533  114.44080204] 1.0\n",
      "positions (x,y,z), reward: [  11.64872561   11.95229627  117.85712966] 1.0\n",
      "Episode =  428, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  2.94811248e-04   2.14143997e-05   2.06250620e+01] 0.999861316909\n",
      "positions (x,y,z), reward: [  0.24909781   0.10054302  35.35756631] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.29938792   0.12132183  36.86825916] 1.0\n",
      "positions (x,y,z), reward: [  0.41703111   0.17017149  39.96595415] 1.0\n",
      "positions (x,y,z), reward: [  0.98224437   0.40875966  50.7562121 ] 1.0\n",
      "positions (x,y,z), reward: [  2.59254247   1.1682112   69.74488677] 1.0\n",
      "positions (x,y,z), reward: [  2.77655967   1.26827345  71.43707646] 1.0\n",
      "positions (x,y,z), reward: [  3.66663051   1.80101529  78.81802214] 1.0\n",
      "positions (x,y,z), reward: [  3.97387194   2.00317942  81.11158976] 1.0\n",
      "positions (x,y,z), reward: [  5.00103515   2.73922164  88.08513536] 1.0\n",
      "positions (x,y,z), reward: [  13.6648736    10.50429449  129.82644437] 1.0\n",
      "positions (x,y,z), reward: [  15.70396954   12.27156955  137.77249605] 1.0\n",
      "positions (x,y,z), reward: [  18.26374133   14.34776627  147.52631339] 1.0\n",
      "positions (x,y,z), reward: [  19.28918871   15.14041339  151.44445864] 1.0\n",
      "Episode =  429, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.30671120e-05   8.24770527e-05   2.02792155e+01] 0.998688847921\n",
      "positions (x,y,z), reward: [  0.02547739   0.04078788  25.2371816 ] 0.999999997782\n",
      "positions (x,y,z), reward: [  0.31552624   0.83209916  46.93626121] 1.0\n",
      "positions (x,y,z), reward: [  0.31599802   0.94011965  48.58031126] 1.0\n",
      "positions (x,y,z), reward: [  0.24416925   1.52361426  55.81910833] 1.0\n",
      "positions (x,y,z), reward: [ -8.11853927e-04   2.38917863e+00   6.37887285e+01] 1.0\n",
      "positions (x,y,z), reward: [  -4.95410137   10.79067421  105.30685573] 1.0\n",
      "positions (x,y,z), reward: [  -5.33233268   11.28181744  107.08890256] 1.0\n",
      "positions (x,y,z), reward: [  -5.59289296   11.6142522   108.27449172] 1.0\n",
      "positions (x,y,z), reward: [  -7.61534888   14.0564312   116.51863364] 1.0\n",
      "positions (x,y,z), reward: [  -8.42849825   14.98026728  119.44294664] 1.0\n",
      "positions (x,y,z), reward: [  -9.29432458   15.93297159  122.35961297] 1.0\n",
      "positions (x,y,z), reward: [ -14.72730194   21.33968641  137.43322968] 1.0\n",
      "Episode =  430, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.16679101e-02   1.22130974e-02   2.52377871e+01] 0.99999999778\n",
      "positions (x,y,z), reward: [  5.44356663e-02   1.45623048e-02   2.59731254e+01] 0.999999999102\n",
      "positions (x,y,z), reward: [  8.71892374e-02   1.91111181e-02   2.75461078e+01] 0.999999999823\n",
      "positions (x,y,z), reward: [  2.97699328e-01   2.40798524e-02   3.38798598e+01] 0.999999999997\n",
      "positions (x,y,z), reward: [  7.32532039e-01   9.77747751e-04   4.15530035e+01] 1.0\n",
      "positions (x,y,z), reward: [  8.89299069e-01  -8.82890686e-03   4.36884826e+01] 1.0\n",
      "positions (x,y,z), reward: [  5.31056845  -0.21963247  77.07184721] 1.0\n",
      "positions (x,y,z), reward: [  8.06743212  -0.26102006  89.89800013] 1.0\n",
      "positions (x,y,z), reward: [ 10.36684995  -0.25882176  98.72636064] 1.0\n",
      "positions (x,y,z), reward: [  17.44384089   -0.46397126  120.34543617] 1.0\n",
      "positions (x,y,z), reward: [  19.93875882   -0.71040005  126.72495859] 1.0\n",
      "positions (x,y,z), reward: [  23.09039844   -1.20965347  134.10697983] 1.0\n",
      "positions (x,y,z), reward: [  27.28769889   -2.26134693  142.96365049] 1.0\n",
      "positions (x,y,z), reward: [  28.07177444   -2.5115708   144.51144566] 1.0\n",
      "Episode =  431, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.15374980e-06  -6.50394592e-05   2.03794830e+01] 0.99938547178\n",
      "positions (x,y,z), reward: [  2.13251720e-04  -4.19845933e-04   2.11037221e+01] 0.999984125772\n",
      "positions (x,y,z), reward: [  1.25419105e-02   9.00328249e-03   2.48878672e+01] 0.999999996477\n",
      "positions (x,y,z), reward: [  2.09497302e-02   1.77395221e-02   2.59779905e+01] 0.999999999118\n",
      "positions (x,y,z), reward: [  0.06026518   0.06332296  29.24649656] 0.999999999956\n",
      "positions (x,y,z), reward: [  0.26449254   0.37619997  38.42170579] 1.0\n",
      "positions (x,y,z), reward: [  0.32755429   0.49024546  40.5103315 ] 1.0\n",
      "positions (x,y,z), reward: [  0.37952213   0.58835158  42.10019531] 1.0\n",
      "positions (x,y,z), reward: [  2.68787551   5.1516279   76.0915816 ] 1.0\n",
      "positions (x,y,z), reward: [  3.72342864   6.89891738  83.85028302] 1.0\n",
      "positions (x,y,z), reward: [  4.7180229    8.45767418  89.92998909] 1.0\n",
      "positions (x,y,z), reward: [   6.8729461    11.54772964  100.55096404] 1.0\n",
      "positions (x,y,z), reward: [  16.47667244   22.44841616  133.70951709] 1.0\n",
      "positions (x,y,z), reward: [  21.4879512    26.89149555  149.09646014] 1.0\n",
      "Episode =  432, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.08096357   0.03900406  26.74555344] 0.999999999616\n",
      "positions (x,y,z), reward: [ -0.0920401    0.04463048  27.14323512] 0.999999999742\n",
      "positions (x,y,z), reward: [ -0.24129097   0.12888793  31.03677221] 0.999999999986\n",
      "positions (x,y,z), reward: [ -1.41738777   0.97355042  45.32171818] 1.0\n",
      "positions (x,y,z), reward: [ -1.98384895   1.41104797  49.71032021] 1.0\n",
      "positions (x,y,z), reward: [ -3.58073301   2.67297905  59.28159639] 1.0\n",
      "positions (x,y,z), reward: [ -6.22031555   4.81037088  70.97748781] 1.0\n",
      "positions (x,y,z), reward: [ -6.53132419   5.06532024  72.17747214] 1.0\n",
      "positions (x,y,z), reward: [-10.87468434   8.65915005  87.08741648] 1.0\n",
      "positions (x,y,z), reward: [-14.5408441  11.6404015  98.290906 ] 1.0\n",
      "positions (x,y,z), reward: [ -18.15932767   14.45922486  108.83518968] 1.0\n",
      "positions (x,y,z), reward: [ -18.93186951   15.04627254  111.05739039] 1.0\n",
      "positions (x,y,z), reward: [ -26.19344623   20.42856547  132.31680292] 1.0\n",
      "positions (x,y,z), reward: [ -27.52385503   21.41011425  136.44004755] 1.0\n",
      "positions (x,y,z), reward: [ -32.25543643   24.96571786  152.4604631 ] 1.0\n",
      "positions (x,y,z), reward: [ -41.5901559    33.42049342  199.85987786] 1.0\n",
      "Episode =  433, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.3631975    0.18950246  42.08993878] 1.0\n",
      "positions (x,y,z), reward: [  0.79568699   0.38604178  50.25018388] 1.0\n",
      "positions (x,y,z), reward: [  1.42802346   0.6436662   58.1045368 ] 1.0\n",
      "positions (x,y,z), reward: [  1.78100988   0.77395989  61.53539332] 1.0\n",
      "positions (x,y,z), reward: [  1.84518586   0.79667099  62.11136072] 1.0\n",
      "positions (x,y,z), reward: [  2.92482705   1.13454066  70.32635539] 1.0\n",
      "positions (x,y,z), reward: [  4.41164591   1.46627105  78.92970872] 1.0\n",
      "positions (x,y,z), reward: [  8.7210372    1.83060908  96.75715668] 1.0\n",
      "positions (x,y,z), reward: [  10.86303314    1.80748074  103.87732076] 1.0\n",
      "positions (x,y,z), reward: [  11.94866533    1.75529464  107.27864776] 1.0\n",
      "positions (x,y,z), reward: [  19.71390168    0.50016977  130.18716483] 1.0\n",
      "Episode =  434, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.52856309e-04  -7.44729126e-05   2.06247313e+01] 0.9998606141\n",
      "positions (x,y,z), reward: [  7.50982816e-03  -8.50222577e-03   2.45374785e+01] 0.999999994111\n",
      "positions (x,y,z), reward: [  9.64959504e-03  -1.20227796e-02   2.52351686e+01] 0.999999997779\n",
      "positions (x,y,z), reward: [  1.77453571e-02  -2.91722056e-02   2.75437589e+01] 0.999999999823\n",
      "positions (x,y,z), reward: [  2.83985416e-02  -5.95822558e-02   3.01230256e+01] 0.999999999976\n",
      "positions (x,y,z), reward: [  0.04004693  -0.09820574  32.43509794] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.1322778   -0.39528488  41.55616706] 1.0\n",
      "positions (x,y,z), reward: [  0.30669452  -0.92383853  49.14827068] 1.0\n",
      "positions (x,y,z), reward: [  0.32411255  -0.97675919  49.70086941] 1.0\n",
      "positions (x,y,z), reward: [  0.79397061  -2.44176245  59.79995585] 1.0\n",
      "positions (x,y,z), reward: [  0.830223    -2.55758035  60.36650777] 1.0\n",
      "positions (x,y,z), reward: [  0.90636141  -2.80180588  61.50014731] 1.0\n",
      "positions (x,y,z), reward: [  1.11866154  -3.48863717  64.33424927] 1.0\n",
      "positions (x,y,z), reward: [  2.08518768  -6.68884197  73.86190578] 1.0\n",
      "positions (x,y,z), reward: [  2.98872012  -9.76510601  80.34599474] 1.0\n",
      "positions (x,y,z), reward: [  6.97447445 -24.19447716  98.73802024] 1.0\n",
      "positions (x,y,z), reward: [  11.10994072  -39.5102275   109.41085096] 1.0\n",
      "positions (x,y,z), reward: [  16.55488284  -59.4045656   116.74463076] 1.0\n",
      "positions (x,y,z), reward: [  18.16846384  -65.45440639  117.87033402] 1.0\n",
      "Episode =  435, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.32805222e-08   7.02807194e-08   2.00311254e+01] 0.972238433601\n",
      "positions (x,y,z), reward: [ -0.12965721   0.10765034  29.68539544] 0.999999999968\n",
      "positions (x,y,z), reward: [ -0.85788589   0.45773945  42.09230354] 1.0\n",
      "positions (x,y,z), reward: [ -3.42030962   0.9918606   58.56135022] 1.0\n",
      "positions (x,y,z), reward: [ -4.55891244   1.14523719  63.01492483] 1.0\n",
      "positions (x,y,z), reward: [ -7.06049896   1.4325996   70.73977665] 1.0\n",
      "positions (x,y,z), reward: [ -8.77525092   1.6109692   75.08121393] 1.0\n",
      "positions (x,y,z), reward: [-10.94961759   1.82772296  79.87795389] 1.0\n",
      "positions (x,y,z), reward: [-14.83920872   2.20779151  87.11345295] 1.0\n",
      "positions (x,y,z), reward: [-21.76355563   2.89527352  97.3483194 ] 1.0\n",
      "positions (x,y,z), reward: [ -23.97474392    3.12019781  100.12070698] 1.0\n",
      "positions (x,y,z), reward: [ -24.73478413    3.19805244  101.02882921] 1.0\n",
      "positions (x,y,z), reward: [ -29.11951789    3.65101941  105.87301567] 1.0\n",
      "positions (x,y,z), reward: [ -32.52848142    4.00439449  109.22610522] 1.0\n",
      "positions (x,y,z), reward: [ -35.211666      4.27964906  111.63834232] 1.0\n",
      "positions (x,y,z), reward: [ -41.41360651    4.88930072  116.52808439] 1.0\n",
      "positions (x,y,z), reward: [ -43.94280867    5.12115456  118.27321967] 1.0\n",
      "positions (x,y,z), reward: [ -52.00851469    5.76121636  122.98841102] 1.0\n",
      "Episode =  436, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.01869204e-02  -1.20845837e-03   2.24325783e+01] 0.999999701014\n",
      "positions (x,y,z), reward: [  1.17236191e-01  -1.77844643e-02   2.75477608e+01] 0.999999999825\n",
      "positions (x,y,z), reward: [  1.95523882e-01  -2.64321654e-02   2.96818442e+01] 0.999999999968\n",
      "positions (x,y,z), reward: [  2.18523493e+00  -2.21784256e-02   5.46241664e+01] 1.0\n",
      "positions (x,y,z), reward: [  2.52566844e+00  -2.66193884e-02   5.74048669e+01] 1.0\n",
      "positions (x,y,z), reward: [  4.19137071  -0.10681252  68.63387921] 1.0\n",
      "positions (x,y,z), reward: [  4.38770613  -0.12303452  69.76537747] 1.0\n",
      "positions (x,y,z), reward: [  6.4422318   -0.37527041  80.02942099] 1.0\n",
      "positions (x,y,z), reward: [  7.82876279  -0.61646531  85.79750473] 1.0\n",
      "positions (x,y,z), reward: [ 10.98085737  -1.32426746  96.86277909] 1.0\n",
      "positions (x,y,z), reward: [ 11.7330841   -1.52142758  99.20574837] 1.0\n",
      "positions (x,y,z), reward: [  12.12127537   -1.62702774  100.37911593] 1.0\n",
      "positions (x,y,z), reward: [  34.62206192  -12.34359203  148.12670925] 1.0\n",
      "Episode =  437, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.05401834e-02  -1.44355469e-02   2.59716083e+01] 0.999999999107\n",
      "positions (x,y,z), reward: [  1.95075008e-02  -4.55509140e-02   2.88048289e+01] 0.999999999939\n",
      "positions (x,y,z), reward: [  0.04346438  -0.11611339  32.43579295] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.19072638  -0.47851049  41.55404597] 1.0\n",
      "positions (x,y,z), reward: [  0.68279208  -2.19213734  56.92776048] 1.0\n",
      "positions (x,y,z), reward: [  0.72561857  -2.39981511  58.04947032] 1.0\n",
      "positions (x,y,z), reward: [  0.76873501  -2.62137146  59.17219554] 1.0\n",
      "positions (x,y,z), reward: [  1.22542859  -6.44488854  72.58668635] 1.0\n",
      "positions (x,y,z), reward: [  1.25862368 -14.30445288  88.56822055] 1.0\n",
      "positions (x,y,z), reward: [  1.24543188 -14.61772669  89.07611221] 1.0\n",
      "positions (x,y,z), reward: [  -2.02219625  -58.87784687  130.79288807] 1.0\n",
      "Episode =  438, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.21191293e-06  -2.00594617e-06   2.01242103e+01] 0.993945291745\n",
      "positions (x,y,z), reward: [ -4.32168817e-05  -4.62428969e-05   2.03790862e+01] 0.999381211944\n",
      "positions (x,y,z), reward: [ -6.98263246e-03  -6.14951137e-03   2.29747652e+01] 0.999999909456\n",
      "positions (x,y,z), reward: [ -8.65206791e-03  -7.46288373e-03   2.32649020e+01] 0.9999999492\n",
      "positions (x,y,z), reward: [ -0.06768637  -0.04591608  27.95292343] 0.999999999876\n",
      "positions (x,y,z), reward: [ -0.19978095  -0.12465326  32.42854939] 0.999999999993\n",
      "positions (x,y,z), reward: [ -1.72968744  -0.87335122  48.59251124] 1.0\n",
      "positions (x,y,z), reward: [ -2.70021333  -1.26322883  53.56989091] 1.0\n",
      "positions (x,y,z), reward: [ -3.23622024  -1.4593523   55.79229517] 1.0\n",
      "positions (x,y,z), reward: [ -3.38110464  -1.51035755  56.34802769] 1.0\n",
      "positions (x,y,z), reward: [ -9.18147402  -3.11356817  71.06121867] 1.0\n",
      "positions (x,y,z), reward: [-16.92921952  -4.61139531  81.88671215] 1.0\n",
      "positions (x,y,z), reward: [-20.83947194  -5.23941199  85.8131939 ] 1.0\n",
      "positions (x,y,z), reward: [-26.09853886  -6.00420209  90.15057394] 1.0\n",
      "positions (x,y,z), reward: [-30.73543716  -6.62175973  93.30269949] 1.0\n",
      "positions (x,y,z), reward: [-35.07981224  -7.158635    95.79241872] 1.0\n",
      "positions (x,y,z), reward: [ -49.17697229   -8.62047097  101.39224971] 1.0\n",
      "positions (x,y,z), reward: [ -54.15683059   -9.02936553  102.61441183] 1.0\n",
      "positions (x,y,z), reward: [ -68.88046643   -9.95192197  104.40078624] 1.0\n",
      "positions (x,y,z), reward: [ -72.76679079  -10.13771312  104.46845682] 1.0\n",
      "Episode =  439, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.05577211  -0.11497591  31.03521128] 0.999999999986\n",
      "positions (x,y,z), reward: [ -0.52415978  -0.51391224  45.30930211] 1.0\n",
      "positions (x,y,z), reward: [ -0.773674    -0.65519712  49.12979865] 1.0\n",
      "positions (x,y,z), reward: [ -1.33105354  -0.90513981  55.2275318 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.58838864  -2.15929339  80.43417558] 1.0\n",
      "positions (x,y,z), reward: [ -8.12040046  -2.42025885  84.82900092] 1.0\n",
      "positions (x,y,z), reward: [-11.5330495   -2.98779656  92.89771107] 1.0\n",
      "positions (x,y,z), reward: [ -17.74757441   -4.22679339  104.20511796] 1.0\n",
      "positions (x,y,z), reward: [ -34.31471994  -10.52697493  123.91192414] 1.0\n",
      "positions (x,y,z), reward: [ -35.66222207  -11.21344837  125.02633671] 1.0\n",
      "positions (x,y,z), reward: [ -38.92193541  -12.94231229  127.46708632] 1.0\n",
      "positions (x,y,z), reward: [ -43.3538353   -15.40494248  130.24643539] 1.0\n",
      "Episode =  440, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  6.24614440e-04   6.01455316e-04   2.12898216e+01] 0.99999197027\n",
      "positions (x,y,z), reward: [  2.45266520e-03   2.96026820e-03   2.26963097e+01] 0.999999836204\n",
      "positions (x,y,z), reward: [  3.62999615e-03   4.36637347e-03   2.32649759e+01] 0.999999949439\n",
      "positions (x,y,z), reward: [  1.63016914   2.14404948  73.29324055] 1.0\n",
      "positions (x,y,z), reward: [  1.75301859   3.8051567   86.98717596] 1.0\n",
      "positions (x,y,z), reward: [   0.24506254    7.05921224  106.38868688] 1.0\n",
      "positions (x,y,z), reward: [  -0.29505838    7.74607502  109.78382099] 1.0\n",
      "positions (x,y,z), reward: [  -0.39417956    7.86410663  110.3481868 ] 1.0\n",
      "Episode =  441, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.90907942e-04  -3.52430990e-04   2.14931423e+01] 0.999995998411\n",
      "positions (x,y,z), reward: [ -1.00920357e-02   2.76792142e-03   2.45412487e+01] 0.999999994161\n",
      "positions (x,y,z), reward: [ -0.0552669    0.04826012  30.12768978] 0.999999999976\n",
      "positions (x,y,z), reward: [ -0.85074704   1.10061996  54.66624813] 1.0\n",
      "positions (x,y,z), reward: [ -1.31399252   1.64470691  61.38303481] 1.0\n",
      "positions (x,y,z), reward: [ -1.71208177   2.07343088  65.88571934] 1.0\n",
      "positions (x,y,z), reward: [ -3.89915873   4.14259415  82.74763449] 1.0\n",
      "positions (x,y,z), reward: [ -5.38296183   5.46926178  91.09733192] 1.0\n",
      "positions (x,y,z), reward: [ -5.81802477   5.8612762   93.31237656] 1.0\n",
      "positions (x,y,z), reward: [ -5.92927199   5.96197184  93.86536891] 1.0\n",
      "positions (x,y,z), reward: [ -6.04150438   6.06376712  94.41805484] 1.0\n",
      "positions (x,y,z), reward: [ -6.15471961   6.16667404  94.97043608] 1.0\n",
      "positions (x,y,z), reward: [ -6.61735537   6.58963701  97.17687709] 1.0\n",
      "positions (x,y,z), reward: [  -9.03011242    8.86739609  107.58891913] 1.0\n",
      "positions (x,y,z), reward: [ -10.59915684   10.41272827  113.56412787] 1.0\n",
      "positions (x,y,z), reward: [ -16.17163073   16.18156089  131.15304932] 1.0\n",
      "positions (x,y,z), reward: [ -16.75514293   16.79321758  132.71474874] 1.0\n",
      "positions (x,y,z), reward: [ -16.9531727    17.00033964  133.2334751 ] 1.0\n",
      "positions (x,y,z), reward: [ -19.71389363   19.83893009  139.88199977] 1.0\n",
      "positions (x,y,z), reward: [ -19.94259706   20.06835641  140.3852866 ] 1.0\n",
      "positions (x,y,z), reward: [ -22.12742935   22.20126898  144.85277416] 1.0\n",
      "Episode =  442, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.13610897   0.09028855  31.49642117] 0.999999999989\n",
      "positions (x,y,z), reward: [ -0.14651048   0.09950028  31.96407687] 0.999999999992\n",
      "positions (x,y,z), reward: [ -0.25607315   0.21048194  36.36568676] 1.0\n",
      "positions (x,y,z), reward: [ -0.26992853   0.22609539  36.8726833 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.32840141   0.2953195   38.92887728] 1.0\n",
      "positions (x,y,z), reward: [ -0.54653529   0.59461578  45.8435494 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.95002628   1.25894969  56.85144617] 1.0\n",
      "positions (x,y,z), reward: [ -1.50563947   2.16407265  68.57347538] 1.0\n",
      "positions (x,y,z), reward: [ -1.66585058   2.40158369  71.37261351] 1.0\n",
      "positions (x,y,z), reward: [ -2.21769001   3.13039168  79.78073182] 1.0\n",
      "positions (x,y,z), reward: [ -2.2990043    3.22621138  80.90350483] 1.0\n",
      "positions (x,y,z), reward: [ -2.90899919   3.84282523  88.7885318 ] 1.0\n",
      "positions (x,y,z), reward: [ -3.27748516   4.10797987  93.33114803] 1.0\n",
      "positions (x,y,z), reward: [ -3.73347101   4.2691606   99.07610428] 1.0\n",
      "positions (x,y,z), reward: [  -4.19037784    4.11370048  105.50618786] 1.0\n",
      "positions (x,y,z), reward: [  -4.61970665    3.18236815  113.86048053] 1.0\n",
      "positions (x,y,z), reward: [  -4.58585135   -1.10913897  128.32714597] 1.0\n",
      "Episode =  443, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.29558019e-07   1.76861554e-06   2.00699585e+01] 0.98701188914\n",
      "positions (x,y,z), reward: [ -7.33775602e-06   2.32577346e-05   2.01940578e+01] 0.997191722824\n",
      "positions (x,y,z), reward: [ -6.01447448e-03  -4.59549866e-04   2.32675339e+01] 0.999999949595\n",
      "positions (x,y,z), reward: [ -1.58373728e-02  -7.32805373e-03   2.59724943e+01] 0.999999999105\n",
      "positions (x,y,z), reward: [ -1.31372038e-02  -9.39701283e-02   3.68727244e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.38779141  -0.51832215  61.88003593] 1.0\n",
      "positions (x,y,z), reward: [  1.54310141  -0.77704247  84.00499751] 1.0\n",
      "positions (x,y,z), reward: [  1.9124265   -0.74138045  88.08097366] 1.0\n",
      "positions (x,y,z), reward: [  2.09281192  -0.71257283  89.84485595] 1.0\n",
      "positions (x,y,z), reward: [  15.1669586     3.44820576  143.06179892] 1.0\n",
      "positions (x,y,z), reward: [  23.7388499     5.15614788  166.01085621] 1.0\n",
      "Episode =  444, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  8.10255528e-06   6.47432804e-06   2.03792570e+01] 0.999382499237\n",
      "positions (x,y,z), reward: [  2.29218872e-04  -6.24853108e-04   2.17068034e+01] 0.999997928386\n",
      "positions (x,y,z), reward: [ -0.04026771  -0.08094889  30.57247749] 0.999999999982\n",
      "positions (x,y,z), reward: [ -0.0533229   -0.0947622   31.49216349] 0.999999999989\n",
      "positions (x,y,z), reward: [ -0.16316504  -0.17285513  36.360617  ] 1.0\n",
      "positions (x,y,z), reward: [ -0.47155663  -0.27839033  43.1518223 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.85784888  -0.34202664  48.04211713] 1.0\n",
      "positions (x,y,z), reward: [ -1.52801882  -0.39333148  53.59042554] 1.0\n",
      "positions (x,y,z), reward: [ -2.29401046  -0.41140681  58.08358994] 1.0\n",
      "positions (x,y,z), reward: [ -5.4501528   -0.32460699  69.9182904 ] 1.0\n",
      "positions (x,y,z), reward: [ -7.09403347  -0.23925285  74.37533991] 1.0\n",
      "positions (x,y,z), reward: [ -1.05067832e+01  -2.95288746e-02   8.20278944e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.13198115e+01   2.45271918e-02   8.36392959e+01] 1.0\n",
      "positions (x,y,z), reward: [-17.40829487   0.46470023  94.14225886] 1.0\n",
      "positions (x,y,z), reward: [ -31.90060355    1.70663215  113.35352637] 1.0\n",
      "positions (x,y,z), reward: [ -35.40833428    2.04069748  117.32851866] 1.0\n",
      "positions (x,y,z), reward: [ -61.30107736    5.10638833  141.58797977] 1.0\n",
      "Episode =  445, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.60242007e-02  -2.35476422e-02   2.63545347e+01] 0.999999999418\n",
      "positions (x,y,z), reward: [ -0.04100302  -0.02714468  26.74396789] 0.999999999615\n",
      "positions (x,y,z), reward: [ -0.38874628  -0.19316163  38.40952929] 1.0\n",
      "positions (x,y,z), reward: [ -4.54323767   0.30338083  80.89724562] 1.0\n",
      "positions (x,y,z), reward: [  -7.69393355    2.40695344  101.70466897] 1.0\n",
      "positions (x,y,z), reward: [ -10.09070361    4.50003701  116.62475203] 1.0\n",
      "positions (x,y,z), reward: [ -11.95519545    6.14933908  128.51974789] 1.0\n",
      "positions (x,y,z), reward: [ -15.31014714    8.69663721  152.83984284] 1.0\n",
      "positions (x,y,z), reward: [ -15.58954303    8.85892943  155.20097725] 1.0\n",
      "Episode =  446, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.18244727e-03   2.47047341e-03   2.17079565e+01] 0.999997939262\n",
      "positions (x,y,z), reward: [ -0.32378447   0.18201362  34.36510066] 0.999999999997\n",
      "positions (x,y,z), reward: [ -0.36744764   0.20630491  35.35523201] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.41388232   0.23226096  36.35911229] 1.0\n",
      "positions (x,y,z), reward: [ -0.62516141   0.35271699  40.48708033] 1.0\n",
      "positions (x,y,z), reward: [ -1.88004838   1.14499048  59.58905126] 1.0\n",
      "positions (x,y,z), reward: [ -1.96098176   1.19903402  60.70276053] 1.0\n",
      "positions (x,y,z), reward: [ -2.04214793   1.25351732  61.81766956] 1.0\n",
      "positions (x,y,z), reward: [ -2.08278428   1.28091124  62.37556078] 1.0\n",
      "positions (x,y,z), reward: [ -2.44794979   1.53151367  67.40879836] 1.0\n",
      "positions (x,y,z), reward: [ -2.68818096   1.7026266   70.77603873] 1.0\n",
      "positions (x,y,z), reward: [ -2.84545281   1.81919749  73.0263031 ] 1.0\n",
      "positions (x,y,z), reward: [ -4.1911367    3.43085151  97.66207876] 1.0\n",
      "positions (x,y,z), reward: [  -4.71875829    5.96010037  122.26802637] 1.0\n",
      "positions (x,y,z), reward: [  -4.70290902    7.8153331   136.11319067] 1.0\n",
      "Episode =  447, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.07304686e-04  -8.82910433e-05   2.07691486e+01] 0.99993257244\n",
      "positions (x,y,z), reward: [ -5.67929348e-04  -2.07908249e-04   2.11020353e+01] 0.999983857851\n",
      "positions (x,y,z), reward: [ -1.28944638e-03  -4.48500132e-04   2.14911664e+01] 0.99999594553\n",
      "positions (x,y,z), reward: [ -4.09487504e-02  -1.56267578e-02   2.59683283e+01] 0.999999999095\n",
      "positions (x,y,z), reward: [ -0.63935792  -0.20122413  39.43779091] 1.0\n",
      "positions (x,y,z), reward: [ -1.03565829  -0.28923289  44.20864518] 1.0\n",
      "positions (x,y,z), reward: [ -3.81282012  -0.61604068  63.52198237] 1.0\n",
      "positions (x,y,z), reward: [ -30.38595979   -1.92564732  104.19822613] 1.0\n",
      "positions (x,y,z), reward: [ -38.76244032   -2.00354891  107.88816309] 1.0\n",
      "positions (x,y,z), reward: [ -39.39127332   -2.00047964  108.09607051] 1.0\n",
      "positions (x,y,z), reward: [ -42.58606222   -1.96510783  109.02064692] 1.0\n",
      "positions (x,y,z), reward: [ -56.66861705   -1.40354712  110.77282689] 1.0\n",
      "positions (x,y,z), reward: [ -58.04353661   -1.31243941  110.76002171] 1.0\n",
      "positions (x,y,z), reward: [ -68.38871907   -0.40912911  109.6912882 ] 1.0\n",
      "Episode =  448, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.29373516e-06   1.22177363e-05   2.01940195e+01] 0.997187804766\n",
      "positions (x,y,z), reward: [ -3.63435207   0.90913582  57.35390689] 1.0\n",
      "positions (x,y,z), reward: [ -5.93500867   1.76073727  68.43845059] 1.0\n",
      "positions (x,y,z), reward: [ -6.93515949   2.18860406  72.86952688] 1.0\n",
      "positions (x,y,z), reward: [ -7.4478529    2.42324118  75.08666329] 1.0\n",
      "positions (x,y,z), reward: [ -7.5772186    2.48417962  75.64131008] 1.0\n",
      "positions (x,y,z), reward: [ -14.71700351    7.18810577  104.57475288] 1.0\n",
      "positions (x,y,z), reward: [ -15.6322097     8.01909615  108.1346878 ] 1.0\n",
      "positions (x,y,z), reward: [ -26.08812292   19.65362449  143.0096867 ] 1.0\n",
      "Episode =  449, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.41773828e-02  -1.83464372e-03   2.55985182e+01] 0.999999998598\n",
      "positions (x,y,z), reward: [  0.13761349  -0.15685804  40.48986348] 1.0\n",
      "positions (x,y,z), reward: [  0.34073112  -0.86789918  56.86864242] 1.0\n",
      "positions (x,y,z), reward: [   8.0794171   -25.82305619  112.5090019 ] 1.0\n",
      "positions (x,y,z), reward: [  11.02375421  -34.42563518  117.4735015 ] 1.0\n",
      "positions (x,y,z), reward: [  14.16092364  -43.2494979   120.57467156] 1.0\n",
      "positions (x,y,z), reward: [  15.96631242  -48.17054824  121.57090512] 1.0\n",
      "positions (x,y,z), reward: [  18.33929111  -54.46011149  122.14418535] 1.0\n",
      "Episode =  450, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.74421461e-03   3.42464290e-04   2.17062887e+01] 0.999997920688\n",
      "positions (x,y,z), reward: [  0.26484393   0.0375748   33.38785879] 0.999999999996\n",
      "positions (x,y,z), reward: [  0.36301798   0.06883329  35.85365097] 0.999999999998\n",
      "positions (x,y,z), reward: [  1.19869278   0.59325636  50.79467359] 1.0\n",
      "positions (x,y,z), reward: [  1.75479777   1.12367504  58.1119282 ] 1.0\n",
      "positions (x,y,z), reward: [  1.94837949   1.33232818  60.40126391] 1.0\n",
      "positions (x,y,z), reward: [  2.15310753   1.56447611  62.70971715] 1.0\n",
      "positions (x,y,z), reward: [  2.36942369   1.82135417  65.03865011] 1.0\n",
      "positions (x,y,z), reward: [  2.90068836   2.49542224  70.36148909] 1.0\n",
      "positions (x,y,z), reward: [  3.85378258   3.83865877  78.92637322] 1.0\n",
      "positions (x,y,z), reward: [   6.80429339    9.55062441  104.01705454] 1.0\n",
      "positions (x,y,z), reward: [   8.42824272   38.63271062  214.17869898] 1.0\n",
      "Episode =  451, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.11392718   0.12923922  38.4117332 ] 1.0\n",
      "positions (x,y,z), reward: [  3.78042603e-02   1.00174843e+00   5.92363629e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.17442605   1.55996377  65.58887085] 1.0\n",
      "positions (x,y,z), reward: [  0.25538338   1.87460288  68.53081598] 1.0\n",
      "positions (x,y,z), reward: [  0.56163791   2.98072173  76.98451718] 1.0\n",
      "positions (x,y,z), reward: [  0.90973024   4.09198043  83.8824408 ] 1.0\n",
      "positions (x,y,z), reward: [  1.48039273   5.66305524  92.36113858] 1.0\n",
      "positions (x,y,z), reward: [  1.74896594   6.32673186  95.71728566] 1.0\n",
      "positions (x,y,z), reward: [  2.04464561   7.01410058  99.12538934] 1.0\n",
      "positions (x,y,z), reward: [   7.88921608   15.32290596  150.6878222 ] 1.0\n",
      "positions (x,y,z), reward: [   8.10489231   15.4867387   152.72029151] 1.0\n",
      "positions (x,y,z), reward: [   9.35183009   16.21033478  166.32575391] 1.0\n",
      "positions (x,y,z), reward: [   9.73132643   16.32348308  171.59098303] 1.0\n",
      "positions (x,y,z), reward: [   9.82176639   16.33851132  172.98385897] 1.0\n",
      "positions (x,y,z), reward: [   9.99637297   16.35021171  175.87498453] 1.0\n",
      "positions (x,y,z), reward: [  10.31632274   16.28770944  182.14705164] 1.0\n",
      "Episode =  452, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.00081772e-06   2.85702045e-05   2.03792377e+01] 0.999382575914\n",
      "positions (x,y,z), reward: [ -2.12321798e-03   1.12872775e-03   2.21768619e+01] 0.999999437825\n",
      "positions (x,y,z), reward: [ -1.60787508e-02   5.52691174e-03   2.55995011e+01] 0.999999998607\n",
      "positions (x,y,z), reward: [ -2.71046339e-02   9.64033485e-03   2.75451874e+01] 0.999999999824\n",
      "positions (x,y,z), reward: [  0.09446578   0.18146534  48.04220789] 1.0\n",
      "positions (x,y,z), reward: [  0.12733426   0.20018862  49.14413978] 1.0\n",
      "positions (x,y,z), reward: [  3.82844679   1.00456833  83.39579341] 1.0\n",
      "positions (x,y,z), reward: [   9.17015473    2.15927374  106.21712177] 1.0\n",
      "positions (x,y,z), reward: [  13.38547629    3.75284728  121.35943594] 1.0\n",
      "positions (x,y,z), reward: [  16.97682313    5.69815752  133.69531709] 1.0\n",
      "positions (x,y,z), reward: [  21.8913509     9.18179051  149.75124262] 1.0\n",
      "Episode =  453, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.30018056   0.04676022  32.44508247] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.51831687   0.08345485  36.37313243] 1.0\n",
      "positions (x,y,z), reward: [ -1.48207405   0.22697645  48.01505701] 1.0\n",
      "positions (x,y,z), reward: [ -5.30283662   0.58930803  72.42026127] 1.0\n",
      "positions (x,y,z), reward: [ -6.09411433   0.61567935  75.75947584] 1.0\n",
      "positions (x,y,z), reward: [ -1.42458520e+01  -9.75923795e-03   9.97819726e+01] 1.0\n",
      "positions (x,y,z), reward: [ -17.2984854    -0.69147551  106.66746352] 1.0\n",
      "positions (x,y,z), reward: [ -25.58728626   -4.02971817  122.90451377] 1.0\n",
      "positions (x,y,z), reward: [ -28.60580098   -5.70450135  128.12685722] 1.0\n",
      "positions (x,y,z), reward: [ -31.83953755   -7.66388291  133.36158419] 1.0\n",
      "Episode =  454, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.81031233e-04  -7.79369801e-04   2.11031366e+01] 0.999983995432\n",
      "positions (x,y,z), reward: [ -0.26438092  -0.74701079  43.69014724] 1.0\n",
      "positions (x,y,z), reward: [ -0.54088829  -2.01771277  57.41677301] 1.0\n",
      "positions (x,y,z), reward: [ -0.65720595  -2.76334501  62.99768794] 1.0\n",
      "positions (x,y,z), reward: [ -0.77563112  -3.68262178  68.59387281] 1.0\n",
      "positions (x,y,z), reward: [ -1.88623844 -13.3646782   97.14436041] 1.0\n",
      "positions (x,y,z), reward: [ -2.0700431  -14.62537649  99.19789435] 1.0\n",
      "positions (x,y,z), reward: [  -4.71451294  -28.33566451  113.26467824] 1.0\n",
      "positions (x,y,z), reward: [  -6.58515771  -35.62379961  117.14887961] 1.0\n",
      "positions (x,y,z), reward: [  -6.75129794  -36.21640101  117.39185676] 1.0\n",
      "positions (x,y,z), reward: [ -10.06234771  -46.78506123  120.1959122 ] 1.0\n",
      "positions (x,y,z), reward: [ -14.5474307   -58.47377384  120.30451665] 1.0\n",
      "Episode =  455, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  5.79052097e-04  -5.11358036e-04   2.07696495e+01] 0.999933091937\n",
      "positions (x,y,z), reward: [  1.31309408e-03  -1.01716418e-03   2.11028783e+01] 0.999984007558\n",
      "positions (x,y,z), reward: [  3.71345786e-02  -1.27088766e-02   2.56020977e+01] 0.999999998621\n",
      "positions (x,y,z), reward: [  0.17728782  -0.69059985  51.36047658] 1.0\n",
      "positions (x,y,z), reward: [ -0.37281872  -1.97913202  64.86084577] 1.0\n",
      "positions (x,y,z), reward: [ -1.16159872  -3.06175877  72.27003856] 1.0\n",
      "positions (x,y,z), reward: [ -1.51480704  -3.4545506   74.55398758] 1.0\n",
      "positions (x,y,z), reward: [ -2.16675354  -4.09787602  77.9750644 ] 1.0\n",
      "positions (x,y,z), reward: [ -7.22048929  -7.59282303  92.39945731] 1.0\n",
      "positions (x,y,z), reward: [ -26.21532616  -14.52472261  111.93865176] 1.0\n",
      "positions (x,y,z), reward: [ -27.91334196  -14.94112209  112.82113536] 1.0\n",
      "positions (x,y,z), reward: [ -30.24617281  -15.48392128  113.89510027] 1.0\n",
      "positions (x,y,z), reward: [ -36.38683274  -16.78572494  116.03936499] 1.0\n",
      "positions (x,y,z), reward: [ -43.56256153  -18.15130985  117.43817804] 1.0\n",
      "Episode =  456, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.50069571e-03  -1.12616656e-03   2.26989945e+01] 0.999999838196\n",
      "positions (x,y,z), reward: [ -4.48160024e-02  -2.51373169e-02   2.79625201e+01] 0.999999999879\n",
      "positions (x,y,z), reward: [ -0.0938929   -0.06651349  31.50286731] 0.999999999989\n",
      "positions (x,y,z), reward: [ -0.10988663  -0.08204827  32.44361325] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.24711084  -0.25343873  38.94084927] 1.0\n",
      "positions (x,y,z), reward: [ -0.48132616  -0.71108799  47.50364831] 1.0\n",
      "positions (x,y,z), reward: [ -0.69349378  -1.31673359  54.13473062] 1.0\n",
      "positions (x,y,z), reward: [ -0.73115216  -1.44345846  55.24962719] 1.0\n",
      "positions (x,y,z), reward: [ -1.98070584  -8.43192811  87.53968968] 1.0\n",
      "positions (x,y,z), reward: [  -2.49202616  -14.39787125  102.5641989 ] 1.0\n",
      "positions (x,y,z), reward: [  -2.91826315  -20.83709323  114.26453866] 1.0\n",
      "positions (x,y,z), reward: [  -3.35431073  -26.20769466  121.92953228] 1.0\n",
      "positions (x,y,z), reward: [  -4.71095129  -36.15153954  132.92036763] 1.0\n",
      "positions (x,y,z), reward: [  -4.79159849  -36.58928444  133.3303966 ] 1.0\n",
      "positions (x,y,z), reward: [  -5.23228086  -38.8233793   135.34087136] 1.0\n",
      "Episode =  457, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -6.20303958e-07  -3.85442895e-07   2.00699359e+01] 0.986999944158\n",
      "positions (x,y,z), reward: [ -1.42423663e-03  -7.05638837e-04   2.12909230e+01] 0.999992042561\n",
      "positions (x,y,z), reward: [ -1.05479953e-02  -3.94631734e-03   2.32678964e+01] 0.999999950032\n",
      "positions (x,y,z), reward: [ -0.23172668  -0.04692331  35.36916706] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.49156417  -0.05856937  41.56359777] 1.0\n",
      "positions (x,y,z), reward: [ -1.70263215e+00  -4.16091857e-02   5.41501034e+01] 1.0\n",
      "positions (x,y,z), reward: [ -2.17117939e+00  -2.91683270e-02   5.69541997e+01] 1.0\n",
      "positions (x,y,z), reward: [ -5.17371632   0.07154142  68.19630917] 1.0\n",
      "positions (x,y,z), reward: [ -8.33431246   0.18934686  75.31645321] 1.0\n",
      "positions (x,y,z), reward: [ -9.84313564   0.24151682  77.96132617] 1.0\n",
      "positions (x,y,z), reward: [-20.44818492   0.39955367  90.21453228] 1.0\n",
      "positions (x,y,z), reward: [ -2.97631804e+01   6.40123688e-02   9.62438943e+01] 1.0\n",
      "positions (x,y,z), reward: [ -58.86995001   -5.3917916   102.76802057] 1.0\n",
      "positions (x,y,z), reward: [ -71.57553314  -10.23901979  101.89470509] 1.0\n",
      "Episode =  458, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -3.34391038e-04   1.55984925e-03   2.17072947e+01] 0.999997933429\n",
      "positions (x,y,z), reward: [ -5.38232194e-04   3.58073892e-03   2.24309923e+01] 0.999999698383\n",
      "positions (x,y,z), reward: [ -2.61942496e-03   2.27357997e-02   2.63507370e+01] 0.999999999413\n",
      "positions (x,y,z), reward: [  5.07371655e-04   6.87216764e-02   3.58563494e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [  6.07968865e-02  -4.83430739e-03   5.62983416e+01] 1.0\n",
      "positions (x,y,z), reward: [  6.55940109e-02  -1.89771622e-02   5.74120737e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.18785128  -0.41856515  75.91847637] 1.0\n",
      "positions (x,y,z), reward: [  0.22016357  -0.49464773  78.73306737] 1.0\n",
      "positions (x,y,z), reward: [  0.23449083  -0.52510821  79.85927189] 1.0\n",
      "positions (x,y,z), reward: [  0.38978816  -0.7714005   89.4409843 ] 1.0\n",
      "positions (x,y,z), reward: [   0.90608737   -1.09718625  108.66314586] 1.0\n",
      "positions (x,y,z), reward: [   3.04597429   -0.48503807  140.21443309] 1.0\n",
      "positions (x,y,z), reward: [  3.73154198e+00  -1.15141182e-01   1.46569831e+02] 1.0\n",
      "Episode =  459, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.64933323e-03   8.60569236e-04   2.14927134e+01] 0.999995994805\n",
      "positions (x,y,z), reward: [ -0.05954836   0.0334722   27.96461339] 0.99999999988\n",
      "positions (x,y,z), reward: [ -0.29477849   0.09351782  39.46373434] 1.0\n",
      "positions (x,y,z), reward: [ -0.43344238   0.10377974  45.3191439 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.58438028   0.07850679  51.8870667 ] 1.0\n",
      "positions (x,y,z), reward: [ -6.44369351e-01   4.96620570e-02   5.46581455e+01] 1.0\n",
      "positions (x,y,z), reward: [   0.3895317    -4.16913043  108.5269411 ] 1.0\n",
      "positions (x,y,z), reward: [   0.49198103   -4.3530431   109.72408373] 1.0\n",
      "positions (x,y,z), reward: [   1.32864431   -5.76330878  118.19878599] 1.0\n",
      "positions (x,y,z), reward: [   5.80980762  -12.56201283  150.66881999] 1.0\n",
      "Episode =  460, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.03141979e-04   2.94129423e-04   2.09285240e+01] 0.99996721906\n",
      "positions (x,y,z), reward: [  2.94148017e-04   6.63168185e-04   2.14912563e+01] 0.999995946307\n",
      "positions (x,y,z), reward: [  1.07381186e-02   5.64698269e-03   2.63512444e+01] 0.999999999419\n",
      "positions (x,y,z), reward: [  6.10643157   3.76060752  95.81902866] 1.0\n",
      "positions (x,y,z), reward: [  6.52296546   4.12068322  98.16463167] 1.0\n",
      "Episode =  461, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.03084489e-03  -1.94877429e-03   2.21771649e+01] 0.999999437666\n",
      "positions (x,y,z), reward: [ -2.29411313e-02  -4.93377020e-03   2.42044961e+01] 0.999999990185\n",
      "positions (x,y,z), reward: [ -7.14661060e-02  -6.75525402e-03   2.71394336e+01] 0.999999999741\n",
      "positions (x,y,z), reward: [ -1.45879482e-01  -4.29078078e-03   3.01234675e+01] 0.999999999976\n",
      "positions (x,y,z), reward: [ -2.03535818e-01  -7.23086424e-04   3.19621928e+01] 0.999999999992\n",
      "positions (x,y,z), reward: [ -4.24256297e-01   1.46592846e-02   3.73774634e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.42821945e+00   2.31698162e-03   5.18513471e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.93750699e+00  -5.00022736e-02   5.68428236e+01] 1.0\n",
      "positions (x,y,z), reward: [ -3.86461667  -0.39624423  70.28121008] 1.0\n",
      "positions (x,y,z), reward: [ -4.3967245   -0.51236682  73.08655303] 1.0\n",
      "positions (x,y,z), reward: [-10.78329871  -2.05773526  95.20946   ] 1.0\n",
      "positions (x,y,z), reward: [ -14.91028611   -3.0193252   104.21850138] 1.0\n",
      "positions (x,y,z), reward: [ -39.96973301   -7.51871935  131.2585738 ] 1.0\n",
      "positions (x,y,z), reward: [ -43.76577124   -8.03779483  133.382609  ] 1.0\n",
      "Episode =  462, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777988] 0.941474597521\n",
      "positions (x,y,z), reward: [  0.12850247  -0.32462648  64.20006901] 1.0\n",
      "positions (x,y,z), reward: [  0.72007887  -0.81084941  76.21457884] 1.0\n",
      "positions (x,y,z), reward: [  1.58651802  -1.73474877  86.66058226] 1.0\n",
      "positions (x,y,z), reward: [   7.72143079  -11.7828557   120.02923974] 1.0\n",
      "positions (x,y,z), reward: [   7.87186346  -12.08389931  120.54248366] 1.0\n",
      "positions (x,y,z), reward: [   9.12420899  -14.6959677   124.52968576] 1.0\n",
      "positions (x,y,z), reward: [  14.6663757   -28.93458346  137.60969358] 1.0\n",
      "Episode =  463, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  5.32145572e-02  -1.63842837e-02   2.71421532e+01] 0.999999999743\n",
      "positions (x,y,z), reward: [  1.56134793  -0.54225708  65.2339036 ] 1.0\n",
      "positions (x,y,z), reward: [   6.13738938   -6.732542    123.4450958 ] 1.0\n",
      "Episode =  464, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.99034062e-04   1.12981172e-03   2.14930286e+01] 0.999996008977\n",
      "positions (x,y,z), reward: [  2.83602266e-04   3.58178776e-03   2.29785209e+01] 0.999999911331\n",
      "positions (x,y,z), reward: [  1.76448793e-02  -9.09276900e-03   3.15060141e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [  3.22218328e-02  -8.67244669e-02   3.89443926e+01] 1.0\n",
      "positions (x,y,z), reward: [  3.22012658e-02  -9.48859814e-02   3.94651838e+01] 1.0\n",
      "positions (x,y,z), reward: [  2.57574017e-02  -1.77216271e-01   4.37055859e+01] 1.0\n",
      "positions (x,y,z), reward: [ -5.08680791e-02  -6.08165117e-01   5.57833526e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.91346864  -6.72450493  91.34554053] 1.0\n",
      "positions (x,y,z), reward: [ -1.10381328  -7.82253056  94.11097367] 1.0\n",
      "positions (x,y,z), reward: [  -4.71264027  -23.8130329   116.72519175] 1.0\n",
      "Episode =  465, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.06421183e-09   2.63479892e-07   2.00310966e+01] 0.97219937157\n",
      "positions (x,y,z), reward: [ -3.02940004e-05  -1.26564555e-04   2.03791190e+01] 0.999380938605\n",
      "positions (x,y,z), reward: [ -6.16034112e-04  -1.39856858e-03   2.11021938e+01] 0.999983887164\n",
      "positions (x,y,z), reward: [ -0.0292561   -0.02651772  25.59747995] 0.999999998597\n",
      "positions (x,y,z), reward: [ -0.18920482  -0.09139095  32.43260984] 0.999999999993\n",
      "positions (x,y,z), reward: [ -0.39253061  -0.1443263   36.86837308] 1.0\n",
      "positions (x,y,z), reward: [ -0.48241953  -0.16487248  38.40684038] 1.0\n",
      "positions (x,y,z), reward: [ -2.85722382  -0.62303474  60.73628963] 1.0\n",
      "positions (x,y,z), reward: [ -3.03270455  -0.65257356  61.85068217] 1.0\n",
      "positions (x,y,z), reward: [ -6.1370677   -1.0846566   76.88950783] 1.0\n",
      "positions (x,y,z), reward: [ -6.73801082  -1.15400536  79.10581495] 1.0\n",
      "positions (x,y,z), reward: [ -28.58252069   -3.75163559  117.69150828] 1.0\n",
      "positions (x,y,z), reward: [ -43.54748651   -6.08043587  129.20083007] 1.0\n",
      "positions (x,y,z), reward: [ -45.14376826   -6.33838862  130.12175493] 1.0\n",
      "Episode =  466, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.00598376e-07  -2.57607505e-07   2.00699533e+01] 0.98700429314\n",
      "positions (x,y,z), reward: [ -0.05008355  -0.03715484  26.73757452] 0.999999999607\n",
      "positions (x,y,z), reward: [ -0.38951954  -0.47048975  38.39407428] 1.0\n",
      "positions (x,y,z), reward: [ -1.89776737  -3.18901789  61.28907363] 1.0\n",
      "positions (x,y,z), reward: [ -2.50175846  -4.45563985  67.41041783] 1.0\n",
      "positions (x,y,z), reward: [ -4.59347451  -9.05512225  83.31809156] 1.0\n",
      "positions (x,y,z), reward: [ -4.8577919   -9.63355073  84.9308529 ] 1.0\n",
      "positions (x,y,z), reward: [ -10.33938093  -19.82693436  107.08246318] 1.0\n",
      "positions (x,y,z), reward: [ -14.10715045  -24.92651026  115.69532078] 1.0\n",
      "positions (x,y,z), reward: [ -23.11696297  -34.30650186  128.78735861] 1.0\n",
      "positions (x,y,z), reward: [ -25.71095898  -36.70705684  131.5860803 ] 1.0\n",
      "Episode =  467, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777456] 0.941445361607\n",
      "positions (x,y,z), reward: [ -1.45311803e-05  -9.69108136e-06   2.01939844e+01] 0.99718763619\n",
      "positions (x,y,z), reward: [ -1.80531359e-04  -9.74757915e-05   2.04946156e+01] 0.999708659829\n",
      "positions (x,y,z), reward: [ -5.46686521e-04  -2.59561633e-04   2.07697817e+01] 0.999933121585\n",
      "positions (x,y,z), reward: [ -1.81624258e-02  -5.85432320e-03   2.35691612e+01] 0.999999971353\n",
      "positions (x,y,z), reward: [ -0.07504477  -0.03573517  27.54639345] 0.999999999824\n",
      "positions (x,y,z), reward: [ -0.34826456  -0.35726514  39.45005396] 1.0\n",
      "positions (x,y,z), reward: [ -0.71236017  -0.8748817   49.11446705] 1.0\n",
      "positions (x,y,z), reward: [ -1.26448486  -1.55818596  57.97834809] 1.0\n",
      "positions (x,y,z), reward: [ -1.50143742  -1.81877198  60.77536457] 1.0\n",
      "positions (x,y,z), reward: [ -2.02212638  -2.35179044  65.82769352] 1.0\n",
      "positions (x,y,z), reward: [ -6.47647614  -6.26416734  89.81574639] 1.0\n",
      "positions (x,y,z), reward: [ -6.91410176  -6.6285086   91.45480813] 1.0\n",
      "positions (x,y,z), reward: [  -9.52139953   -8.78824412  100.06938917] 1.0\n",
      "positions (x,y,z), reward: [ -16.03933957  -14.28712368  116.49520768] 1.0\n",
      "positions (x,y,z), reward: [ -19.90966479  -17.75141327  124.20803147] 1.0\n",
      "positions (x,y,z), reward: [ -20.42100281  -18.22616436  125.14406275] 1.0\n",
      "positions (x,y,z), reward: [ -27.31408296  -25.037711    136.20982045] 1.0\n",
      "Episode =  468, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.03255965  -0.04142427  27.96385169] 0.999999999879\n",
      "positions (x,y,z), reward: [  0.11114044  -0.08864574  32.4435972 ] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.31137738  -0.13153612  38.4211985 ] 1.0\n",
      "positions (x,y,z), reward: [  0.5595544   -0.1287284   43.17389094] 1.0\n",
      "positions (x,y,z), reward: [  2.54126257   0.28647918  62.33741135] 1.0\n",
      "positions (x,y,z), reward: [  3.11408952   0.43513355  65.91480346] 1.0\n",
      "positions (x,y,z), reward: [  8.60094041   1.77578968  89.65384468] 1.0\n",
      "positions (x,y,z), reward: [  9.24731417   1.91160451  91.90074473] 1.0\n",
      "positions (x,y,z), reward: [  15.12735675    2.76632554  110.77150891] 1.0\n",
      "positions (x,y,z), reward: [  19.96714718    2.63960149  125.24680189] 1.0\n",
      "positions (x,y,z), reward: [  29.94361956   -0.5765986   152.87877291] 1.0\n",
      "positions (x,y,z), reward: [  33.54107739   -2.59859742  162.35398877] 1.0\n",
      "Episode =  469, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -6.64121760e-02  -2.67337709e-03   2.83849739e+01] 0.999999999915\n",
      "positions (x,y,z), reward: [ -1.97971898e-01  -3.20873910e-02   3.53714317e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.24459013  -0.03878725  37.39343199] 1.0\n",
      "positions (x,y,z), reward: [ -6.11025881e-01   1.62110732e-03   4.96778859e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.77758178   0.06328066  54.09791574] 1.0\n",
      "positions (x,y,z), reward: [ -1.08292528   0.23859808  61.36234811] 1.0\n",
      "positions (x,y,z), reward: [ -1.15764453   0.29425315  63.04974415] 1.0\n",
      "positions (x,y,z), reward: [ -1.99561769   1.57185021  84.1652226 ] 1.0\n",
      "positions (x,y,z), reward: [  -1.82134891    5.19334688  110.76776949] 1.0\n",
      "positions (x,y,z), reward: [  -1.76107116    5.43960169  112.0521964 ] 1.0\n",
      "positions (x,y,z), reward: [  -1.38356675    6.80893377  118.60462896] 1.0\n",
      "positions (x,y,z), reward: [  1.31602494e-01   1.14866487e+01   1.36208526e+02] 1.0\n",
      "positions (x,y,z), reward: [   0.36791372   12.20152202  138.4760964 ] 1.0\n",
      "positions (x,y,z), reward: [   1.32034728   15.1990243   147.18374653] 1.0\n",
      "positions (x,y,z), reward: [   1.60054676   16.13637513  149.68528811] 1.0\n",
      "positions (x,y,z), reward: [   1.79139662   16.79458438  151.38845371] 1.0\n",
      "Episode =  470, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.98500974   1.90647786  87.7481193 ] 1.0\n",
      "positions (x,y,z), reward: [ -11.13521662    2.48671863  104.23377659] 1.0\n",
      "positions (x,y,z), reward: [ -19.41325337    2.9542998   121.49094904] 1.0\n",
      "Episode =  471, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778106] 0.941481133673\n",
      "positions (x,y,z), reward: [  0.0463929   -0.1322343   34.87381145] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.08823791  -0.35077458  42.09684129] 1.0\n",
      "positions (x,y,z), reward: [  0.1206173   -0.77482008  50.78676364] 1.0\n",
      "positions (x,y,z), reward: [  2.61093578e-02  -2.08832938e+00   6.47681176e+01] 1.0\n",
      "positions (x,y,z), reward: [ -0.15522477  -3.89306051  74.94715553] 1.0\n",
      "positions (x,y,z), reward: [ -0.24313055  -4.86530945  78.89463992] 1.0\n",
      "positions (x,y,z), reward: [ -0.2962032   -5.49709987  81.14047516] 1.0\n",
      "positions (x,y,z), reward: [  -0.76313687  -13.69200333  100.62963846] 1.0\n",
      "positions (x,y,z), reward: [  -0.7953124   -14.56806132  102.17066693] 1.0\n",
      "positions (x,y,z), reward: [  -0.8057431   -14.86636124  102.68085127] 1.0\n",
      "positions (x,y,z), reward: [  -0.87470719  -17.04209973  106.20090674] 1.0\n",
      "positions (x,y,z), reward: [  -0.97715245  -21.13835937  112.00926632] 1.0\n",
      "positions (x,y,z), reward: [  -1.10856501  -28.6475357   120.49985623] 1.0\n",
      "positions (x,y,z), reward: [  -1.12716886  -29.95631522  121.74487977] 1.0\n",
      "positions (x,y,z), reward: [  -1.24398883  -40.14793818  129.49993847] 1.0\n",
      "Episode =  472, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  6.82126062e-03   4.06794981e-02   2.79609460e+01] 0.999999999879\n",
      "positions (x,y,z), reward: [ -0.06680492   0.16406302  39.97899747] 1.0\n",
      "positions (x,y,z), reward: [ -0.25106534   0.20366697  50.778946  ] 1.0\n",
      "positions (x,y,z), reward: [ -1.11084004   0.24580711  69.23916431] 1.0\n",
      "positions (x,y,z), reward: [ -1.92910562   0.39496424  77.75799673] 1.0\n",
      "positions (x,y,z), reward: [ -2.13502545   0.44108697  79.46893404] 1.0\n",
      "positions (x,y,z), reward: [ -2.35625819   0.49328794  81.18201678] 1.0\n",
      "positions (x,y,z), reward: [  -6.9629137     1.8964476   104.28136458] 1.0\n",
      "positions (x,y,z), reward: [ -15.60057328    4.79169892  128.81054576] 1.0\n",
      "positions (x,y,z), reward: [ -23.43428028    7.01776316  145.58832661] 1.0\n",
      "Episode =  473, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  9.67905045e-03  -4.24501703e-03   2.35666310e+01] 0.999999971088\n",
      "positions (x,y,z), reward: [  3.01346741e-02  -1.88423008e-02   2.71371451e+01] 0.999999999741\n",
      "positions (x,y,z), reward: [  0.06618652  -0.06784312  31.49393896] 0.999999999989\n",
      "positions (x,y,z), reward: [  0.10810051  -0.13985239  34.86300205] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.17165314  -0.25426248  38.41320259] 1.0\n",
      "positions (x,y,z), reward: [  0.36890762  -0.61057512  45.32286256] 1.0\n",
      "positions (x,y,z), reward: [  1.82008014  -3.08099151  66.58873295] 1.0\n",
      "positions (x,y,z), reward: [  2.00304871  -3.38568026  68.29739159] 1.0\n",
      "positions (x,y,z), reward: [  2.13157984  -3.59922736  69.43781828] 1.0\n",
      "positions (x,y,z), reward: [  2.55011804  -4.29211506  72.86491901] 1.0\n",
      "positions (x,y,z), reward: [  12.98900572  -22.14250642  116.02556661] 1.0\n",
      "positions (x,y,z), reward: [  14.94860638  -25.81686093  121.15567979] 1.0\n",
      "positions (x,y,z), reward: [  17.60241751  -31.02274036  127.55454403] 1.0\n",
      "Episode =  474, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.07012303  -0.06180318  35.87006141] 0.999999999998\n",
      "positions (x,y,z), reward: [ -0.14881168  -0.1056839   41.5601617 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.22716042  -0.14375002  45.84923569] 1.0\n",
      "positions (x,y,z), reward: [ -0.53566308  -0.31533107  57.97205651] 1.0\n",
      "positions (x,y,z), reward: [ -1.20836605  -1.03675095  74.27972588] 1.0\n",
      "positions (x,y,z), reward: [ -1.74700903  -1.90007477  83.34432661] 1.0\n",
      "positions (x,y,z), reward: [ -2.18046304  -2.76115403  89.57557852] 1.0\n",
      "positions (x,y,z), reward: [  -3.39824829   -6.01795847  104.75312041] 1.0\n",
      "positions (x,y,z), reward: [  -3.80072443   -7.36450368  109.18744663] 1.0\n",
      "Episode =  475, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.02838735  -0.05736397  25.5989837 ] 0.999999998598\n",
      "positions (x,y,z), reward: [  0.0945306   -0.20554758  30.57461521] 0.999999999982\n",
      "positions (x,y,z), reward: [  2.6331047   -3.5162176   73.65548082] 1.0\n",
      "positions (x,y,z), reward: [  3.77468898  -4.62825017  82.23190087] 1.0\n",
      "positions (x,y,z), reward: [  4.97017427  -5.74848038  89.25071075] 1.0\n",
      "positions (x,y,z), reward: [  5.81732949  -6.53021647  93.446719  ] 1.0\n",
      "positions (x,y,z), reward: [  18.67719892  -19.97723216  133.46361462] 1.0\n",
      "Episode =  476, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -4.14132281e-07   2.74675447e-08   2.00310991e+01] 0.972202724352\n",
      "positions (x,y,z), reward: [ -4.13753605e-04  -1.10871283e-04   2.04946217e+01] 0.999708356817\n",
      "positions (x,y,z), reward: [ -1.61610133e-03  -5.14385523e-04   2.09291816e+01] 0.999967445493\n",
      "positions (x,y,z), reward: [ -1.19088825e-02  -3.80243201e-03   2.24321344e+01] 0.999999702067\n",
      "positions (x,y,z), reward: [ -0.21936175  -0.06716599  30.58166971] 0.999999999982\n",
      "positions (x,y,z), reward: [ -5.33362493  -2.5202721   73.49036467] 1.0\n",
      "positions (x,y,z), reward: [ -7.45668182  -4.10009957  84.00900917] 1.0\n",
      "positions (x,y,z), reward: [ -9.17913934  -5.69201377  91.70320094] 1.0\n",
      "positions (x,y,z), reward: [-11.02877231  -7.66252196  99.30662811] 1.0\n",
      "positions (x,y,z), reward: [ -12.56935376   -9.46923445  105.19410822] 1.0\n",
      "positions (x,y,z), reward: [ -15.57900933  -13.30178532  115.64676002] 1.0\n",
      "positions (x,y,z), reward: [ -15.73701756  -13.51086999  116.15974129] 1.0\n",
      "positions (x,y,z), reward: [ -16.53819861  -14.57981717  118.71020117] 1.0\n",
      "positions (x,y,z), reward: [ -24.79069532  -26.14921051  141.20409588] 1.0\n",
      "Episode =  477, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -5.21163335e-03   3.38511614e-03   2.24323720e+01] 0.999999700703\n",
      "positions (x,y,z), reward: [ -6.61147371e-03   4.36243816e-03   2.26989240e+01] 0.999999837512\n",
      "positions (x,y,z), reward: [ -0.05696615   0.0390925   27.14148965] 0.999999999741\n",
      "positions (x,y,z), reward: [ -0.3938231    0.21489753  36.87560899] 1.0\n",
      "positions (x,y,z), reward: [ -3.62723168   1.26002541  61.391033  ] 1.0\n",
      "positions (x,y,z), reward: [-14.89115482   4.87588861  91.41549723] 1.0\n",
      "positions (x,y,z), reward: [-18.58858307   5.97915805  98.03669272] 1.0\n",
      "positions (x,y,z), reward: [ -33.91291677   10.17823502  123.484815  ] 1.0\n",
      "positions (x,y,z), reward: [ -54.5425169    25.76394903  178.64604776] 1.0\n",
      "positions (x,y,z), reward: [ -55.63040527   28.32810836  184.34266294] 1.0\n",
      "positions (x,y,z), reward: [ -59.65425794   53.73625358  225.57282966] 1.0\n",
      "Episode =  478, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.88209930e-07   1.05457364e-07   2.00699956e+01] 0.987022489298\n",
      "positions (x,y,z), reward: [  2.93115192e-03   3.64559464e-02   2.88068715e+01] 0.999999999939\n",
      "positions (x,y,z), reward: [ -2.88152539e-03   6.52772185e-02   3.10358588e+01] 0.999999999986\n",
      "positions (x,y,z), reward: [ -4.35112347e-03   7.23932779e-02   3.14985730e+01] 0.999999999989\n",
      "positions (x,y,z), reward: [ -2.75415109e-02   2.61136357e-01   3.94524958e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.12233796   1.12961939  56.34270124] 1.0\n",
      "positions (x,y,z), reward: [  0.37906231   1.81973754  64.79108209] 1.0\n",
      "positions (x,y,z), reward: [  2.77118456   5.69193248  93.76420586] 1.0\n",
      "positions (x,y,z), reward: [  3.19289374   6.2511578   96.77805151] 1.0\n",
      "positions (x,y,z), reward: [  3.28249981   6.36809861  97.38523151] 1.0\n",
      "positions (x,y,z), reward: [   3.75865082    6.98054558  100.44595382] 1.0\n",
      "positions (x,y,z), reward: [   4.06818657    7.37186638  102.30430424] 1.0\n",
      "positions (x,y,z), reward: [   7.85963494   11.97474787  120.08037577] 1.0\n",
      "Episode =  479, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.87099820e-02  -5.09207457e-02   2.75488994e+01] 0.999999999826\n",
      "positions (x,y,z), reward: [ -0.30881958  -0.56208369  48.57785535] 1.0\n",
      "positions (x,y,z), reward: [ -0.33179953  -0.60238494  49.67416772] 1.0\n",
      "positions (x,y,z), reward: [ -0.68949896  -2.35544254  79.916752  ] 1.0\n",
      "positions (x,y,z), reward: [ -0.30213781  -4.02084506  98.65411621] 1.0\n",
      "positions (x,y,z), reward: [   3.61940183   -8.48645849  137.43386661] 1.0\n",
      "Episode =  480, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.40143389e-04  -8.56908836e-04   2.11030066e+01] 0.999983941569\n",
      "positions (x,y,z), reward: [  0.14215693  -0.09373316  29.23463247] 0.999999999955\n",
      "positions (x,y,z), reward: [  0.55387029  -0.32517817  36.86652159] 1.0\n",
      "positions (x,y,z), reward: [  1.49251119  -0.75092265  46.4217774 ] 1.0\n",
      "positions (x,y,z), reward: [  2.02222979  -0.95156928  50.30999597] 1.0\n",
      "positions (x,y,z), reward: [  2.2805041   -1.04224878  52.00208209] 1.0\n",
      "positions (x,y,z), reward: [  4.81175238  -1.75745433  64.90851327] 1.0\n",
      "positions (x,y,z), reward: [  6.54847926  -2.10871012  71.75319052] 1.0\n",
      "positions (x,y,z), reward: [ 11.06514232  -2.63274409  86.49135185] 1.0\n",
      "positions (x,y,z), reward: [ 13.66381615  -2.69691176  93.81768448] 1.0\n",
      "positions (x,y,z), reward: [  16.06717391   -2.6181331   100.06588845] 1.0\n",
      "positions (x,y,z), reward: [  18.81745175   -2.39355618  106.73680713] 1.0\n",
      "positions (x,y,z), reward: [  25.72642596   -1.38380872  121.7920601 ] 1.0\n",
      "positions (x,y,z), reward: [  39.17744263    1.26234934  147.41501913] 1.0\n",
      "positions (x,y,z), reward: [  56.07423977    3.93902076  180.43867829] 1.0\n",
      "positions (x,y,z), reward: [  72.74074211    4.88329433  232.16215093] 1.0\n",
      "Episode =  481, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -7.93224203e-06   8.21921702e-06   2.02790780e+01] 0.998686200109\n",
      "positions (x,y,z), reward: [  1.39364634e-03  -1.04658317e-02   2.55982482e+01] 0.999999998599\n",
      "positions (x,y,z), reward: [  3.87571517e-03  -1.24715236e-02   2.63513917e+01] 0.999999999416\n",
      "positions (x,y,z), reward: [  1.03469284e-01   8.10538478e-03   3.43699037e+01] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.1819419    0.04686419  37.38470447] 1.0\n",
      "positions (x,y,z), reward: [  0.19764575   0.05565785  37.89823552] 1.0\n",
      "positions (x,y,z), reward: [  5.54977716   5.7738703   91.74563534] 1.0\n",
      "positions (x,y,z), reward: [  10.00043829   10.7741459   113.95620452] 1.0\n",
      "positions (x,y,z), reward: [  11.60014397   12.50107635  120.79470917] 1.0\n",
      "positions (x,y,z), reward: [  12.05554691   12.98374337  122.65898393] 1.0\n",
      "positions (x,y,z), reward: [  18.0496615    18.92681529  144.301531  ] 1.0\n",
      "positions (x,y,z), reward: [  18.24274374   19.10604795  144.91928218] 1.0\n",
      "positions (x,y,z), reward: [  19.83956978   20.56114311  149.87055324] 1.0\n",
      "Episode =  482, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  0.99994573   0.16782502  51.9740984 ] 1.0\n",
      "positions (x,y,z), reward: [  1.55391325   0.22333414  57.66666416] 1.0\n",
      "positions (x,y,z), reward: [  1.61847469   0.22823972  58.24407113] 1.0\n",
      "positions (x,y,z), reward: [  3.64425506   0.2969631   72.03179547] 1.0\n",
      "positions (x,y,z), reward: [  4.24469875   0.30494874  75.1964212 ] 1.0\n",
      "positions (x,y,z), reward: [  5.82059895   0.33930429  82.47014513] 1.0\n",
      "positions (x,y,z), reward: [  8.64123334   0.51549667  93.33306222] 1.0\n",
      "positions (x,y,z), reward: [  11.54901968    0.87279651  103.1717984 ] 1.0\n",
      "positions (x,y,z), reward: [  14.53275101    1.39913611  112.60099539] 1.0\n",
      "positions (x,y,z), reward: [  15.9211764     1.68921147  116.83143872] 1.0\n",
      "positions (x,y,z), reward: [  25.24956423    4.13140905  143.66313264] 1.0\n",
      "positions (x,y,z), reward: [  25.9487428     4.33527005  145.59154968] 1.0\n",
      "Episode =  483, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.09801072e-04  -1.10397601e-04   2.03791245e+01] 0.999381371407\n",
      "positions (x,y,z), reward: [  2.35215789e-03  -2.12611437e-03   2.14914810e+01] 0.999995949517\n",
      "positions (x,y,z), reward: [  2.87670340e-02  -2.37384935e-02   2.48794836e+01] 0.999999996373\n",
      "positions (x,y,z), reward: [  0.06696338  -0.06054247  27.54033955] 0.999999999822\n",
      "positions (x,y,z), reward: [  0.10537593  -0.10205308  29.67260748] 0.999999999967\n",
      "positions (x,y,z), reward: [  0.23005104  -0.25293601  35.35290896] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.28037449  -0.31769993  37.37330056] 1.0\n",
      "positions (x,y,z), reward: [  0.40946638  -0.48574578  42.07101434] 1.0\n",
      "positions (x,y,z), reward: [  0.79015926  -0.93488434  52.94799297] 1.0\n",
      "positions (x,y,z), reward: [  1.12850097  -1.26909855  60.17189605] 1.0\n",
      "positions (x,y,z), reward: [  1.2503297   -1.37868585  62.40667091] 1.0\n",
      "positions (x,y,z), reward: [  1.9627951   -1.93792161  73.06681042] 1.0\n",
      "positions (x,y,z), reward: [  2.75716184  -2.4465986   82.07459393] 1.0\n",
      "positions (x,y,z), reward: [  2.92786923  -2.54516093  83.76435844] 1.0\n",
      "positions (x,y,z), reward: [  3.62063222  -2.91424043  89.96354264] 1.0\n",
      "positions (x,y,z), reward: [  3.97442967  -3.08512211  92.78540215] 1.0\n",
      "positions (x,y,z), reward: [   5.60742106   -3.72439273  103.59324062] 1.0\n",
      "positions (x,y,z), reward: [   6.35300941   -3.94202947  107.63744531] 1.0\n",
      "positions (x,y,z), reward: [   8.69604789   -4.41922481  118.23837442] 1.0\n",
      "positions (x,y,z), reward: [  14.12613703   -4.92072033  136.89172939] 1.0\n",
      "Episode =  484, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.99195803e-02  -1.34778239e-02   2.38819405e+01] 0.999999983405\n",
      "positions (x,y,z), reward: [  0.11497835  -0.0842364   29.23924512] 0.999999999956\n",
      "positions (x,y,z), reward: [  0.41263107  -0.45776777  40.49415231] 1.0\n",
      "positions (x,y,z), reward: [  0.50025085  -0.61743196  43.68190731] 1.0\n",
      "positions (x,y,z), reward: [  0.88929353  -2.00032163  60.77506729] 1.0\n",
      "positions (x,y,z), reward: [  0.95020974  -2.43382183  64.14521257] 1.0\n",
      "positions (x,y,z), reward: [  1.06526993  -3.54989529  70.90693538] 1.0\n",
      "positions (x,y,z), reward: [  1.07480752  -3.66000769  71.47076748] 1.0\n",
      "positions (x,y,z), reward: [  1.24210677  -5.83327534  80.46242844] 1.0\n",
      "positions (x,y,z), reward: [  1.77139772 -12.57943817  97.3457364 ] 1.0\n",
      "Episode =  485, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.33329446e-03   1.06416207e-03   2.12907252e+01] 0.999992046253\n",
      "positions (x,y,z), reward: [  1.97624834e-02   1.75201115e-02   2.42058736e+01] 0.999999990247\n",
      "positions (x,y,z), reward: [  0.23696566   0.19049354  33.88360553] 0.999999999997\n",
      "positions (x,y,z), reward: [  0.33345901   0.26190299  36.36833472] 1.0\n",
      "positions (x,y,z), reward: [  0.79607778   0.59030509  44.76974731] 1.0\n",
      "positions (x,y,z), reward: [  4.20935509   2.72755333  72.49704115] 1.0\n",
      "positions (x,y,z), reward: [  4.66376804   2.99825934  74.86865778] 1.0\n",
      "positions (x,y,z), reward: [  6.08983526   3.84861041  81.50995207] 1.0\n",
      "positions (x,y,z), reward: [  14.10349986    8.85640685  108.90187444] 1.0\n",
      "positions (x,y,z), reward: [  40.36610468   20.55821116  170.07249665] 1.0\n",
      "positions (x,y,z), reward: [  46.33575481   21.71153796  181.7346187 ] 1.0\n",
      "Episode =  486, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  2.34809008e-06  -2.46330095e-06   2.01242526e+01] 0.993949129841\n",
      "positions (x,y,z), reward: [  2.64939213e-03  -3.05050392e-04   2.19350390e+01] 0.999998929348\n",
      "positions (x,y,z), reward: [  0.33101538   0.06473697  44.22426306] 1.0\n",
      "positions (x,y,z), reward: [  3.21373501  -0.73403986  81.99355901] 1.0\n",
      "positions (x,y,z), reward: [  3.3821287   -0.81883853  83.16686378] 1.0\n",
      "positions (x,y,z), reward: [  28.01879492  -22.32367096  167.02644899] 1.0\n",
      "positions (x,y,z), reward: [  29.09454141  -23.52133511  170.30410943] 1.0\n",
      "positions (x,y,z), reward: [  32.84821021  -27.77433117  181.90906775] 1.0\n",
      "Episode =  487, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -6.22212205e-05   2.95771563e-05   2.02790802e+01] 0.99868807358\n",
      "positions (x,y,z), reward: [ -5.95146487e-03   3.50192146e-03   2.21779538e+01] 0.999999439546\n",
      "positions (x,y,z), reward: [ -0.45232248   0.21116853  37.8923262 ] 1.0\n",
      "positions (x,y,z), reward: [ -0.76163558   0.34998153  43.14579294] 1.0\n",
      "positions (x,y,z), reward: [ -0.95125306   0.43991488  45.83922245] 1.0\n",
      "positions (x,y,z), reward: [ -1.07659612   0.50107775  47.47069016] 1.0\n",
      "positions (x,y,z), reward: [ -1.25754314   0.59141867  49.66055905] 1.0\n",
      "positions (x,y,z), reward: [ -2.61526785   1.31821566  62.44253896] 1.0\n",
      "positions (x,y,z), reward: [ -2.68706171   1.35814268  63.00221256] 1.0\n",
      "positions (x,y,z), reward: [ -3.90406636   2.04259461  71.40548553] 1.0\n",
      "positions (x,y,z), reward: [ -5.40737649   2.89138896  79.7907922 ] 1.0\n",
      "positions (x,y,z), reward: [ -8.24042298   4.45475762  91.98557696] 1.0\n",
      "positions (x,y,z), reward: [ -9.17790495   4.95580033  95.28345068] 1.0\n",
      "Episode =  488, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -0.03592039  -0.08149734  31.95891131] 0.999999999992\n",
      "positions (x,y,z), reward: [ -0.03673572  -0.08856526  34.36476708] 0.999999999997\n",
      "positions (x,y,z), reward: [ -3.53408159e-02  -8.81555553e-02   3.53553428e+01] 0.999999999998\n",
      "positions (x,y,z), reward: [ -3.28143511e-02  -8.55943609e-02   3.63599106e+01] 1.0\n",
      "positions (x,y,z), reward: [  6.93035988e-04  -3.53887720e-02   4.15522850e+01] 1.0\n",
      "positions (x,y,z), reward: [  0.08259707   0.08764278  46.95018322] 1.0\n",
      "positions (x,y,z), reward: [  0.64173639   0.79724094  61.01559068] 1.0\n",
      "positions (x,y,z), reward: [  2.08961465   2.38507839  76.93590236] 1.0\n",
      "positions (x,y,z), reward: [   6.54948892    6.99470371  103.50998486] 1.0\n",
      "positions (x,y,z), reward: [   8.01389759    8.54865588  110.01545759] 1.0\n",
      "positions (x,y,z), reward: [   8.16915731    8.71657201  110.67540457] 1.0\n",
      "positions (x,y,z), reward: [  13.80363482   15.51088437  132.85368785] 1.0\n",
      "positions (x,y,z), reward: [  16.03255656   18.68056492  141.15849748] 1.0\n",
      "Episode =  489, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.22854746e-02  -9.78434992e-03   2.42046216e+01] 0.999999990197\n",
      "positions (x,y,z), reward: [ -0.99903082  -0.39901785  46.38750025] 1.0\n",
      "positions (x,y,z), reward: [ -2.46522087  -1.22359628  60.22407875] 1.0\n",
      "positions (x,y,z), reward: [ -2.7943811   -1.41383275  62.46432243] 1.0\n",
      "positions (x,y,z), reward: [ -9.52408705  -5.03605486  89.04059809] 1.0\n",
      "positions (x,y,z), reward: [ -9.72238433  -5.13781241  89.57812635] 1.0\n",
      "positions (x,y,z), reward: [ -14.76468896   -7.6585017   101.11736918] 1.0\n",
      "positions (x,y,z), reward: [ -23.77705876  -11.968631    115.12512171] 1.0\n",
      "positions (x,y,z), reward: [ -34.98341495  -17.20606323  126.05528294] 1.0\n",
      "positions (x,y,z), reward: [ -39.78312405  -19.45265893  129.36251449] 1.0\n",
      "positions (x,y,z), reward: [ -43.83354644  -21.35318333  131.67027242] 1.0\n",
      "Episode =  490, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.63071204e-05   3.59031786e-05   2.03792198e+01] 0.999382431824\n",
      "positions (x,y,z), reward: [  9.61118120e-04   1.05823323e-04   2.12902935e+01] 0.999991984263\n",
      "positions (x,y,z), reward: [  1.49678242e-02   2.18714001e-03   2.45368532e+01] 0.999999994089\n",
      "positions (x,y,z), reward: [  9.07377596e-02   1.92255268e-02   3.05732792e+01] 0.999999999982\n",
      "positions (x,y,z), reward: [  1.56231626  -0.10888908  56.97415452] 1.0\n",
      "positions (x,y,z), reward: [  1.93778375  -0.16782443  60.39548939] 1.0\n",
      "positions (x,y,z), reward: [  2.68948164  -0.28229216  66.18887293] 1.0\n",
      "positions (x,y,z), reward: [  4.16236697  -0.48052274  75.15791845] 1.0\n",
      "positions (x,y,z), reward: [  4.63927616  -0.53582536  77.62851409] 1.0\n",
      "positions (x,y,z), reward: [  12.27554462   -0.92034971  106.60251159] 1.0\n",
      "positions (x,y,z), reward: [  17.5591717    -0.83326471  123.50427061] 1.0\n",
      "positions (x,y,z), reward: [  19.70542      -0.79853583  130.39146492] 1.0\n",
      "positions (x,y,z), reward: [  33.18939554   -2.78420657  174.79803066] 1.0\n",
      "Episode =  491, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.57131412e-06   4.96575005e-04   2.24308956e+01] 0.999999699217\n",
      "positions (x,y,z), reward: [  7.64023607e-06   8.62917689e-04   2.29758478e+01] 0.999999909932\n",
      "positions (x,y,z), reward: [ -0.12110518   0.06631137  39.97288232] 1.0\n",
      "positions (x,y,z), reward: [ -0.34845153   0.06171372  50.76432633] 1.0\n",
      "positions (x,y,z), reward: [ -7.23102376e-01  -5.06724953e-02   6.18857701e+01] 1.0\n",
      "positions (x,y,z), reward: [ -1.2741173   -0.28227001  73.67187255] 1.0\n",
      "positions (x,y,z), reward: [ -1.36088829  -0.3227279   75.3581557 ] 1.0\n",
      "positions (x,y,z), reward: [  -2.44056198   -1.18382647  125.1742697 ] 1.0\n",
      "positions (x,y,z), reward: [  -2.39853231   -1.16139146  126.41068868] 1.0\n",
      "positions (x,y,z), reward: [  -2.07098624   -0.9591444   133.33736402] 1.0\n",
      "positions (x,y,z), reward: [  -1.81427487   -0.78541396  137.21800337] 1.0\n",
      "positions (x,y,z), reward: [  -1.49327852   -0.56137286  141.18239304] 1.0\n",
      "positions (x,y,z), reward: [  -1.43298877   -0.51891733  141.8519037 ] 1.0\n",
      "Episode =  492, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  4.32669688e-02   1.41564710e-02   2.55995034e+01] 0.999999998606\n",
      "positions (x,y,z), reward: [  0.12897633   0.04040979  30.12428015] 0.999999999976\n",
      "positions (x,y,z), reward: [  0.14983969   0.04762235  31.03326313] 0.999999999986\n",
      "positions (x,y,z), reward: [  0.18403513   0.06020238  32.4358887 ] 0.999999999993\n",
      "positions (x,y,z), reward: [  0.72685798   0.35816659  48.55810062] 1.0\n",
      "positions (x,y,z), reward: [  1.30201703   0.76189013  60.18440705] 1.0\n",
      "positions (x,y,z), reward: [  1.57295568   0.96094207  64.65825719] 1.0\n",
      "positions (x,y,z), reward: [  2.49327622   1.6105737   76.47267397] 1.0\n",
      "positions (x,y,z), reward: [  2.95204992   1.90440706  81.00916878] 1.0\n",
      "positions (x,y,z), reward: [  5.09791428   2.98475692  96.56573921] 1.0\n",
      "positions (x,y,z), reward: [  12.22006013    4.13125898  126.73219147] 1.0\n",
      "positions (x,y,z), reward: [  12.61779996    4.10527645  127.99275612] 1.0\n",
      "positions (x,y,z), reward: [  15.72288576    3.65831816  137.00255979] 1.0\n",
      "positions (x,y,z), reward: [  19.18519019    2.74992552  145.77358442] 1.0\n",
      "positions (x,y,z), reward: [  19.77759609    2.55878504  147.17212788] 1.0\n",
      "Episode =  493, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -6.81428653e-03   2.03369155e-03   2.26974929e+01] 0.999999836262\n",
      "positions (x,y,z), reward: [ -1.69346800e-02   7.59755728e-03   2.38805245e+01] 0.999999983262\n",
      "positions (x,y,z), reward: [ -0.70331315   0.52211324  37.88821565] 1.0\n",
      "positions (x,y,z), reward: [ -2.43614064   1.65225399  49.70416746] 1.0\n",
      "positions (x,y,z), reward: [ -3.21532129   2.08307217  53.03709222] 1.0\n",
      "positions (x,y,z), reward: [ -4.53403471   2.73170579  57.50453873] 1.0\n",
      "positions (x,y,z), reward: [ -5.54136355   3.17330547  60.29165622] 1.0\n",
      "positions (x,y,z), reward: [-22.18616291   7.34509021  83.48626256] 1.0\n",
      "positions (x,y,z), reward: [-24.21331029   7.62294766  85.14367495] 1.0\n",
      "positions (x,y,z), reward: [-30.14593986   8.25810813  89.32462846] 1.0\n",
      "positions (x,y,z), reward: [-32.41434153   8.44072911  90.70569217] 1.0\n",
      "positions (x,y,z), reward: [-44.99512279   9.00581734  96.74455518] 1.0\n",
      "positions (x,y,z), reward: [-50.6063283    9.08105073  98.72951563] 1.0\n",
      "positions (x,y,z), reward: [ -59.45112845    9.06435737  101.13277568] 1.0\n",
      "positions (x,y,z), reward: [ -65.80318013    8.98784704  102.35728353] 1.0\n",
      "positions (x,y,z), reward: [ -82.27984387    8.70377592  103.69667523] 1.0\n",
      "Episode =  494, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -2.60208015e-02  -5.71681603e-02   3.05769085e+01] 0.999999999982\n",
      "positions (x,y,z), reward: [ -0.13835259  -0.09500561  37.38323804] 1.0\n",
      "positions (x,y,z), reward: [ -1.08247312e+00  -2.12997509e-02   5.41360266e+01] 1.0\n",
      "positions (x,y,z), reward: [ -3.06094976   0.37392246  66.64140441] 1.0\n",
      "positions (x,y,z), reward: [ -4.58232004   0.69327629  72.41720086] 1.0\n",
      "positions (x,y,z), reward: [ -8.88985861   1.48997677  83.44310655] 1.0\n",
      "positions (x,y,z), reward: [ -9.46029875   1.58141078  84.60530478] 1.0\n",
      "positions (x,y,z), reward: [-12.65218011   2.03184833  90.425789  ] 1.0\n",
      "positions (x,y,z), reward: [ -24.41864662    2.83684114  107.09299045] 1.0\n",
      "positions (x,y,z), reward: [ -52.65034447    0.41792188  145.26550419] 1.0\n",
      "positions (x,y,z), reward: [ -59.73202878   -0.84135714  158.26525866] 1.0\n",
      "Episode =  495, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  8.33619607e-05   5.01582794e-05   2.03794167e+01] 0.999383902166\n",
      "positions (x,y,z), reward: [  0.0837107    0.06514181  27.95988269] 0.999999999878\n",
      "positions (x,y,z), reward: [  0.27247023   0.24029037  35.86258735] 0.999999999998\n",
      "positions (x,y,z), reward: [  0.49529354   0.43485916  43.14762893] 1.0\n",
      "positions (x,y,z), reward: [  0.55105414   0.47760303  44.75836634] 1.0\n",
      "positions (x,y,z), reward: [  0.60998658   0.52030158  46.38130253] 1.0\n",
      "positions (x,y,z), reward: [  0.88261836   0.6896061   52.96304517] 1.0\n",
      "positions (x,y,z), reward: [  1.04457838   0.77189789  56.29156   ] 1.0\n",
      "positions (x,y,z), reward: [  1.19431544   0.83853514  59.07823232] 1.0\n",
      "positions (x,y,z), reward: [  2.839401     1.27313903  80.43218616] 1.0\n",
      "positions (x,y,z), reward: [  4.7318913    1.34218383  95.71553957] 1.0\n",
      "positions (x,y,z), reward: [   6.39031032    1.01125776  105.43102504] 1.0\n",
      "positions (x,y,z), reward: [   6.61568239    0.94186883  106.57972045] 1.0\n",
      "positions (x,y,z), reward: [   9.27887684   -0.20114107  118.10479434] 1.0\n",
      "positions (x,y,z), reward: [  10.07390967   -0.63241513  120.99054848] 1.0\n",
      "positions (x,y,z), reward: [  11.8465614    -1.70027226  126.76451103] 1.0\n",
      "positions (x,y,z), reward: [  12.23241252   -1.94878532  127.91954511] 1.0\n",
      "positions (x,y,z), reward: [  14.10552216   -3.21952423  133.11612573] 1.0\n",
      "positions (x,y,z), reward: [  18.27216379   -6.32961946  142.92818282] 1.0\n",
      "Episode =  496, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  1.16287364e-04  -2.22870575e-04   2.09295952e+01] 0.999967520547\n",
      "positions (x,y,z), reward: [  2.28341517e-03  -2.37867754e-03   2.24324663e+01] 0.999999701536\n",
      "positions (x,y,z), reward: [  0.22469493  -0.05879505  36.88362701] 1.0\n",
      "positions (x,y,z), reward: [  1.58431365  -0.30526633  58.65310827] 1.0\n",
      "positions (x,y,z), reward: [  3.5204802   -0.45704031  73.67026658] 1.0\n",
      "positions (x,y,z), reward: [  12.71132558    0.4650152   112.71056191] 1.0\n",
      "positions (x,y,z), reward: [  15.11007406    0.9491309   120.64748559] 1.0\n",
      "positions (x,y,z), reward: [  22.78287091    2.64449643  146.19892065] 1.0\n",
      "positions (x,y,z), reward: [  26.2753203     3.14145399  158.63999917] 1.0\n",
      "Episode =  497, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  7.91497932e-03   1.38614053e-03   2.24320718e+01] 0.999999701097\n",
      "positions (x,y,z), reward: [  1.8614437    0.1926834   53.54192419] 1.0\n",
      "positions (x,y,z), reward: [  2.17839397   0.23823882  56.32296165] 1.0\n",
      "positions (x,y,z), reward: [  3.12955887   0.39814225  63.60210511] 1.0\n",
      "positions (x,y,z), reward: [  4.97054712   0.82346835  74.87965927] 1.0\n",
      "positions (x,y,z), reward: [  9.33890817   2.33309649  94.73596163] 1.0\n",
      "positions (x,y,z), reward: [  11.77931889    3.40925456  103.83414817] 1.0\n",
      "positions (x,y,z), reward: [  12.42308211    3.71965039  106.10783645] 1.0\n",
      "positions (x,y,z), reward: [  12.74918253    3.88142236  107.24466151] 1.0\n",
      "positions (x,y,z), reward: [  13.2430721     4.13259128  108.95011742] 1.0\n",
      "positions (x,y,z), reward: [  18.13035871    7.16930963  125.51615002] 1.0\n",
      "positions (x,y,z), reward: [  18.62780492    7.55523267  127.24415704] 1.0\n",
      "positions (x,y,z), reward: [  18.79251449    7.68729176  127.82110008] 1.0\n",
      "positions (x,y,z), reward: [  19.60583948    8.37453858  130.71422083] 1.0\n",
      "positions (x,y,z), reward: [  20.55290098    9.26216872  134.20793207] 1.0\n",
      "positions (x,y,z), reward: [  23.32273907   12.79745156  146.10444174] 1.0\n",
      "Episode =  498, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [  3.84027233e-07  -3.00404675e-07   2.00699127e+01] 0.986988818875\n",
      "positions (x,y,z), reward: [  1.77176225e-02  -1.39888340e-02   2.42045526e+01] 0.999999990236\n",
      "positions (x,y,z), reward: [  0.06345825  -0.04446475  27.1402956 ] 0.999999999741\n",
      "positions (x,y,z), reward: [  0.4448952   -0.249071    36.36757811] 1.0\n",
      "positions (x,y,z), reward: [  7.68678242  -3.92603458  74.95191053] 1.0\n",
      "positions (x,y,z), reward: [  27.62057588  -15.17656512  113.43315422] 1.0\n",
      "Episode =  499, score =   1.999 (best =   1.999), noise_scale = 0.1positions (x,y,z), reward: [ -1.51246758e-02   1.27656476e-02   2.38821162e+01] 0.999999983491\n",
      "positions (x,y,z), reward: [ -2.11552383e-02   1.74753463e-02   2.45399215e+01] 0.999999994177\n",
      "positions (x,y,z), reward: [ -0.14331574   0.11708747  31.50019816] 0.999999999989\n",
      "positions (x,y,z), reward: [ -1.30481772   1.14346847  55.19023306] 1.0\n",
      "positions (x,y,z), reward: [ -4.00864032   3.45593671  85.90936418] 1.0\n",
      "positions (x,y,z), reward: [ -4.19047372   3.58384655  87.59005913] 1.0\n",
      "positions (x,y,z), reward: [ -5.46845266   4.39404609  98.22368136] 1.0\n",
      "positions (x,y,z), reward: [  -6.16076782    4.78046971  103.25183825] 1.0\n",
      "positions (x,y,z), reward: [  -6.83142095    5.12190697  107.71725306] 1.0\n",
      "positions (x,y,z), reward: [ -10.06407841    6.32716399  124.98177832] 1.0\n",
      "positions (x,y,z), reward: [ -11.34937616    6.65024678  130.52281716] 1.0\n",
      "positions (x,y,z), reward: [ -11.75799894    6.73941956  132.18086682] 1.0\n",
      "positions (x,y,z), reward: [ -14.26936081    7.16188038  141.53653342] 1.0\n",
      "positions (x,y,z), reward: [ -14.58653692    7.20039049  142.63293981] 1.0\n",
      "positions (x,y,z), reward: [ -14.74683842    7.21859745  143.18082319] 1.0\n",
      "positions (x,y,z), reward: [ -14.90828296    7.23608268  143.72849126] 1.0\n",
      "positions (x,y,z), reward: [ -15.90101922    7.32476315  147.00984329] 1.0\n",
      "Episode =  500, score =   1.999 (best =   1.999), noise_scale = 0.1"
     ]
    }
   ],
   "source": [
    "## TODO: Train your agent here.\n",
    "import sys\n",
    "import pandas as pd\n",
    "from agents.agent import DDPG\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 500\n",
    "\n",
    "''' \n",
    "target = takeoff (go z up a little bit)\n",
    "#x = 0, y = 0, z = 10\n",
    "'''\n",
    "\n",
    "init_pos = np.array([0., 0., 20.,0., 0., 0.])\n",
    "target_pos = np.array([0., 0., 100.])\n",
    "\n",
    "task = Task(init_pose=init_pos, target_pos=target_pos)\n",
    "agent = DDPG(task) \n",
    "agent_scores = []\n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            agent_scores.append(agent.score)\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\\\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final position: [ -15.90101922    7.32476315  147.00984329]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final position:\", task.sim.pose[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the Rewards\n",
    "\n",
    "Once you are satisfied with your performance, plot the episode rewards, either from a single run, or averaged over multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X18VOWd9/HPL5OE8CCIEJWCCFq2K2JEiIiCaBcFqi3s1vpC2wra+sLbqrR3u3dX212g2L37YK21L2kt22Ztbx/A1Vqxyxat1sUqVgJFhOID4gMRtiAoz4Ek87v/OCeTyZCHIZlkknO+7xfzypzrnDNznTD5nWt+5zrXZe6OiIjER0G+KyAiIp1LgV9EJGYU+EVEYkaBX0QkZhT4RURiRoFfRCRmFPhFRGJGgV9EJGYU+EVEYqYw3xVoysCBA33YsGH5roaISLexZs2a9929NJttu2TgHzZsGJWVlfmuhohIt2Fm72S7rVI9IiIxo8AvIhIzCvwiIjHTJXP8TampqaGqqorq6up8V0VypKSkhCFDhlBUVJTvqojESquB38xOAX4FnAwkgcXufnfGNgbcDVwGHASudfe14brZwD+Hm37b3X/ZlopWVVVx3HHHMWzYMIK3k+7M3dm1axdVVVUMHz4839URiZVsUj21wNfc/QxgPHCTmY3M2OYTwIjwMQf4KYCZnQDMB84DxgHzzax/WypaXV3NgAEDFPQjwswYMGCAvsGJ5EGrgd/dt9e33t19H7AJGJyx2QzgVx54ETjezAYBU4Gn3H23u38APAVMa2tlFfSjRf+fIvlxTDl+MxsGnAP8KWPVYGBr2nJVWNZcuYh0QZVv72bl6zvzXQ0APnJ8T3YdOMLhmrp8V6XT9OpRyP+66PQOf5+sA7+Z9QEeBb7i7nszVzexi7dQ3tTrzyFIEzF06NBsq9WlzZs3j0mTJnHJJZe063X69OnD/v37c1SrjnfxxRfzgx/8gPLy8nxXRY7RD596nRfe3EW+v4ylTwWe77p0poF9enSdwG9mRQRB/wF3/3UTm1QBp6QtDwG2heUXZ5Q/29R7uPtiYDFAeXl5JGaAX7hwYb6rQF1dHYlEosNev7a2lsLCbtM5TFpRm3TOG34CS284P6/1OFxbxzcf28ClI09i6pkn57UuUdRqjj/ssfMLYJO7/7CZzZYBsywwHtjj7tuBFcAUM+sfXtSdEpZ1S/fffz/jxo1j9OjR3HDDDdTVBV9B+/Tpw9e+9jXGjBnD5MmT2bkz+Kp87bXX8sgjjwBw6623MnLkSMrKyvjHf/xHAN555x0mT55MWVkZkydP5t133wXgrbfe4vzzz+fcc8/lX/7lXxrV4Y477uDcc8+lrKyM+fPnN1nPPn36MG/ePM477zxWrVrFmjVruOiiixg7dixTp05l+/bt7Nixg7FjxwLw8ssvY2ap9z/99NM5ePAgTzzxBOeddx7nnHMOl1xyCX/9618BWLBgAXPmzGHKlCnMmjWLQ4cOcdVVV1FWVsbMmTM5dOgQEJx0rr32WkaNGsVZZ53FXXfdlbP/C+kgXaTJ1aMwwQ+uPFtBv4Nk01SbAFwDvGJm68KybwBDAdz9XmA5QVfOzQTdOa8L1+02s9uB1eF+C919d3sr/a0nNvKXbZnZpvYZ+ZG+zP/Umc2u37RpE0uXLuX555+nqKiIL33pSzzwwAPMmjWLAwcOMGbMGO68804WLlzIt771Le65557Uvrt37+axxx7j1Vdfxcz48MMPAbj55puZNWsWs2fPpqKigrlz5/Kb3/yGL3/5y9x4443MmjWLRYsWpV7nySef5I033uCll17C3Zk+fTorV65k0qRJjep64MABRo0axcKFC6mpqeGiiy7i8ccfp7S0lKVLl/LNb36TiooKqqur2bt3L8899xzl5eU899xzTJw4kRNPPJFevXoxceJEXnzxRcyMn//853z/+9/nzjvvBGDNmjX88Y9/pGfPnvzwhz+kV69erF+/nvXr1zNmzBgA1q1bx3vvvceGDRsAUsctXZfjFMQptxJTrQZ+d/8jTefq07dx4KZm1lUAFW2qXRfy9NNPs2bNGs4991wADh06xIknnghAQUEBM2fOBODzn/88n/70pxvt27dvX0pKSrj++uu5/PLL+eQnPwnAqlWr+PWvg8zZNddcw9e//nUAnn/+eR599NFU+T/90z8BQeB/8sknOeeccwDYv38/b7zxxlGBP5FIcMUVVwDw2muvsWHDBi699FIgaIUPGjQIgAsuuIDnn3+elStX8o1vfIPf/e53uDsXXnghENw7MXPmTLZv386RI0ca9befPn06PXv2BGDlypXMnTsXgLKyMsrKygA47bTT2LJlC7fccguXX345U6ZMadPvXjqXtfznLhHQLZOzLbXMO4q7M3v2bL7zne+0um1mN8XCwkJeeuklnn76aZYsWcI999zDM8880+J+TXV1dHduu+02brjhhhbfv6SkJJXXd3fOPPNMVq1addR2F154Ic899xzvvPMOM2bM4Hvf+x5mljox3XLLLXz1q19l+vTpPPvssyxYsCC1b+/evVs8ZoD+/fvz8ssvs2LFChYtWsTDDz9MRUW3bwNEmnu8LqbGlcbqydLkyZN55JFH2LFjBxCkb955JxgFNZlMpnL5Dz74IBMnTmy07/79+9mzZw+XXXYZP/rRj1i3LsiYXXDBBSxZsgSABx54ILXfhAkTGpXXmzp1KhUVFakePu+9916qPs352Mc+xs6dO1OBv6amho0bNwIwadIk7r//fkaMGEFBQQEnnHACy5cvZ8KECQDs2bOHwYOD3re//GXzN1xPmjQpVc8NGzawfv16AN5//32SySRXXHEFt99+O2vXrm2xrpJ/jgJ/HHTLFn8+jBw5km9/+9tMmTKFZDJJUVERixYt4tRTT6V3795s3LiRsWPH0q9fP5YuXdpo33379jFjxgyqq6tx99RFzh//+Md84Qtf4I477qC0tJR///d/B+Duu+/ms5/9LHfffXcqZQMwZcoUNm3axPnnBz0u+vTpw/33359KOTWluLiYRx55hLlz57Jnzx5qa2v5yle+wplnnkn9ZDf1qaKJEydSVVVF//7BzdULFizgyiuvZPDgwYwfP5633nqryfe48cYbue666ygrK2P06NGMGzcOCE5M1113HclkEiCrb0uSX+5d5OqudCjriv/R5eXlnjkRy6ZNmzjjjDPyVKOWdbd+9l1JV/5/jaN/+Mnz9C4u5P7rz8t3VeQYmdkad8/q5hmlekSkEaV6ok+BPwfU2peo6IIJAOkA3Srwd8W0lLSd/j+7nuDirpr8UddtAn9JSQm7du1SsIiI+vH4S0pK8l0VSae/r1joNr16hgwZQlVVVWo4BOn+6mfgkq6juZEVJVq6TeAvKirSTE0inUCZnujrNqkeEel47mrxx4ECv4ikOK6LuzGgwC8iKbq2Gw8K/CKSolRPPCjwi0gjyvREnwK/iKQEmR5F/qhrtTunmVUAnwR2uPuoJtb/H+Bzaa93BlAazr71NrAPqANqsx1ASETyw93V4o+BbFr89wHTmlvp7ne4+2h3Hw3cBvx3xvSKHw/XK+iLiHQBrQZ+d18JZDtP7tXAQ+2qkYjkjS7uxkPOcvxm1ovgm8GjacUOPGlma8xsTq7eS0Q6jlI90ZfLIRs+BTyfkeaZ4O7bzOxE4CkzezX8BnGU8MQwB2Do0KE5rJaIZMtxTbYeA7ns1XMVGWked98W/twBPAaMa25nd1/s7uXuXl5aWprDaolItjTZejzkJPCbWT/gIuDxtLLeZnZc/XNgCrAhF+8nIh1DN+7GQzbdOR8CLgYGmlkVMB8oAnD3e8PN/gF40t0PpO16EvBYOO5HIfCgu/8ud1UXkVxTd854aDXwu/vVWWxzH0G3z/SyLcDZba2YiOSHcvzRpzt3RSTFQf05Y0CBX0QaqB9/LCjwi0iKJluPBwV+EUlxDcgfCwr8ItKI2vvRp8AvIilBqifftZCOpsAvIikapC0eFPhFJEWTrceDAr+IpOjabjwo8ItII2rvR58Cv4ikuKPIHwMK/CLSiMbqiT4FfhFJ0eic8aDALyIpurYbDwr8ItKIGvzRp8AvIimaejEeWg38ZlZhZjvMrMlpE83sYjPbY2brwse8tHXTzOw1M9tsZrfmsuIiknuabD0esmnx3wdMa2Wb59x9dPhYCGBmCWAR8AlgJHC1mY1sT2VFpGOpxR8PrQZ+d18J7G7Da48DNrv7Fnc/AiwBZrThdUSkk+jibjzkKsd/vpm9bGb/ZWZnhmWDga1p21SFZSLShanFH32tTraehbXAqe6+38wuA34DjKDpzgHNNijMbA4wB2Do0KE5qJaIHCvXpLux0O4Wv7vvdff94fPlQJGZDSRo4Z+StukQYFsLr7PY3cvdvby0tLS91RKRNtENXHHQ7sBvZidbOI6rmY0LX3MXsBoYYWbDzawYuApY1t73E5GOo/H446HVVI+ZPQRcDAw0sypgPlAE4O73Ap8BbjSzWuAQcJUHE3fWmtnNwAogAVS4+8YOOQoRyQld3I2HVgO/u1/dyvp7gHuaWbccWN62qolIZ9NYPfGgO3dFpBHdwBV9CvwikqLJ1uNBgV9EUnRxNx4U+EUkxTXpbiwo8ItISpDqUZs/6hT4RURiRoFfRBpodM5YUOAXkRRH3TnjQIFfRFJ0A1c8KPCLSIr69MSDAr+INKIGf/Qp8ItIiqZejAcFfhFJcVz9+GNAgV9EUjRkQzwo8ItIii7uxoMCv4g0piZ/5LUa+M2swsx2mNmGZtZ/zszWh48XzOzstHVvm9krZrbOzCpzWXER6QCuG7jiIJsW/33AtBbWvwVc5O5lwO3A4oz1H3f30e5e3rYqikhncU22HgvZTL240syGtbD+hbTFF4Eh7a+WiOSDLu7GQ65z/F8E/itt2YEnzWyNmc1paUczm2NmlWZWuXPnzhxXS0SyoYu78dBqiz9bZvZxgsA/Ma14grtvM7MTgafM7FV3X9nU/u6+mDBNVF5ers+fSJ4o1RN9OWnxm1kZ8HNghrvvqi93923hzx3AY8C4XLyfiHQMd9fF3Rhod+A3s6HAr4Fr3P31tPLeZnZc/XNgCtBkzyAR6Ro02Xo8tJrqMbOHgIuBgWZWBcwHigDc/V5gHjAA+El4q3dt2IPnJOCxsKwQeNDdf9cBxyAiOaKLu/GQTa+eq1tZfz1wfRPlW4Czj95DRETySXfuikhjyvVEngK/iADBhV1QqicOFPhFBAjy+6AGfxwo8IsI0HDzlrpzRp8Cv4gADakeiT4FfhFpRKme6FPgFxEgPdUjUafALyKALu7GiQK/iADBWPyAJluPAQV+EQEaWvwSfQr8IiIxo8AvIo0o0xN9CvwiAqRd3FW/nshT4BcRIP3ibp4rIh1OgV9EgPQWv0RdVoHfzCrMbIeZNTmDlgV+bGabzWy9mY1JWzfbzN4IH7NzVXEREWmbbFv89wHTWlj/CWBE+JgD/BTAzE4gmLHrPIL5duebWf+2VlZEOk7qzl01+SMvq8Dv7iuB3S1sMgP4lQdeBI43s0HAVOApd9/t7h8AT9HyCURE8qRhPH5F/qjLVY5/MLA1bbkqLGuuXES6GLX44yNXgb+pj4q3UH70C5jNMbNKM6vcuXNnjqolItnSnbvxkavAXwWckrY8BNjWQvlR3H2xu5e7e3lpaWmOqiUiIplyFfiXAbPC3j3jgT3uvh1YAUwxs/7hRd0pYZmIdDWp0TmV64m6wmw2MrOHgIuBgWZWRdBTpwjA3e8FlgOXAZuBg8B14brdZnY7sDp8qYXu3tJFYhHJk9QNXHmuh3S8rAK/u1/dynoHbmpmXQVQcexVE5HOpPH440N37ooIoBm44kSBX0QkZhT4RQRIu4FLuZ7IU+AXEUA3cMWJAr+IABqdM04U+EUEaOjOqSZ/9Cnwi0hAQzbEhgK/iDSi9n70KfCLCKCLu3GiwC8igCZbjxMFfhEBNNl6nCjwiwig8fjjRIFfRBpRgz/6FPhFBNDF3ThR4BcRQJOtx4kCv4gAaTl+xf3Iyyrwm9k0M3vNzDab2a1NrL/LzNaFj9fN7MO0dXVp65blsvIiknuK+9HX6gxcZpYAFgGXEkyevtrMlrn7X+q3cff/nbb9LcA5aS9xyN1H567KIiLSHtm0+McBm919i7sfAZYAM1rY/mrgoVxUTkQ6j2uy9djIJvAPBramLVeFZUcxs1OB4cAzacUlZlZpZi+a2d+3uaYi0qE02Xp8ZDPZelOfg+Zu9bgKeMTd69LKhrr7NjM7DXjGzF5x9zePehOzOcAcgKFDh2ZRLRHJJU22Hh/ZtPirgFPSlocA25rZ9ioy0jzuvi38uQV4lsb5//TtFrt7ubuXl5aWZlEtEckl9eOPj2wC/2pghJkNN7NiguB+VO8cM/sY0B9YlVbW38x6hM8HAhOAv2TuKyIinafVVI+715rZzcAKIAFUuPtGM1sIVLp7/UngamCJe6MRP84AfmZmSYKTzHfTewOJSNehG7jiI5scP+6+HFieUTYvY3lBE/u9AJzVjvqJSCdRqic+dOeuiAAanTNOFPhFJFQ/Hr+a/FGnwC8iEjMK/CICpE+9KFGnwC8igC7uxokCv4gAmmw9ThT4RQTQZOtxosAvIhIzCvwiAujibpwo8IsIoNE540SBX0SAhhy/2vzRp8AvIoBa/HGiwC8iEjMK/CLSiBr80afALyKAJluPEwV+EQE02XqcZBX4zWyamb1mZpvN7NYm1l9rZjvNbF34uD5t3WwzeyN8zM5l5UUkd3RxNz5anYHLzBLAIuBSgonXV5vZsiamUFzq7jdn7HsCMB8oJxgDak247wc5qb2IiByzbFr844DN7r7F3Y8AS4AZWb7+VOApd98dBvungGltq6qIdCSNzhkf2QT+wcDWtOWqsCzTFWa23sweMbNTjnFfzGyOmVWaWeXOnTuzqJaI5JImW4+PbAJ/U5+CzNk5nwCGuXsZ8Hvgl8ewb1Dovtjdy929vLS0NItqiUgupf4wFfcjL5vAXwWckrY8BNiWvoG773L3w+HivwFjs923I9XUJTlcW9dZbyfSrWmQtvjIJvCvBkaY2XAzKwauApalb2Bmg9IWpwObwucrgClm1t/M+gNTwrJOMfNnqxj3r0931tuJRIL68Udfq4Hf3WuBmwkC9ibgYXffaGYLzWx6uNlcM9toZi8Dc4Frw313A7cTnDxWAwvDsg73n+u3s/bdD9lzqIZfvvB2Z7ylSDfXZBZWIqjV7pwA7r4cWJ5RNi/t+W3Abc3sWwFUtKOObXLTg2tTz+cv28iV5UPoVZzV4YrEklI98RGbO3cPHFauX6Ql6s4ZH5EN/IUFRq/iBBecPgCAQ0cU+EVaosnW4yOygb8oUcDnx5/KNeNPBeBgTW2eayTSPajFH32RDfx1SSdRYPQsTgBwUC1+kRbV38Al0RfZwF+bTIbpnuCC7kHl+EVapIkX4yOSgd/dSToUWJDnBzh4RKkekZa4In9sRDLw1yWDT3BhWqrnUI1a/CItaRiPX5E/6iIZ+GvDwJ9IGL3rUz3K8YtkRRd3oy+Sgb+pFr8Cv0grdG03NiIZ+FMt/oKCVI7/UI5z/Gve+YAjtcmcvqZIPinFHx+RDPz1Lf6EBf35ixLWphb/C2++z1+27T2qfPOOfVzx0xf4v8s3NbGXSPekydbjI5KD16QCfyI4r/UsSrQp8H/23/4EwNvfvbxR+QcHawCaPCmIdFepi7uK+5EX6RZ/YUHwCe5VXKjunCKt0CBt8RHJwF+bDHLviTDw9yxOUF2T+3y862qYiHRDkQz8mS3+wgJLnQxySXe4S5RodM74iGTgb+jVEwb+RAE1dbmL0vq7kChy3bobG1kFfjObZmavmdlmM7u1ifVfNbO/mNl6M3vazE5NW1dnZuvCx7LMfTtCXUbgL0oYtXW5a/GroS9RpBZ/fLTaq8fMEsAi4FKCydNXm9kyd/9L2mZ/Bsrd/aCZ3Qh8H5gZrjvk7qNzXO8WNZ3qyV24rglPIjoBSKTo4m5sZNPiHwdsdvct7n4EWALMSN/A3f/g7gfDxReBIbmt5rGpS7uBC+pTPblr8dfl8CQiItLZsgn8g4GtactVYVlzvgj8V9pyiZlVmtmLZvb3ze1kZnPC7Sp37tyZRbWaV5vR4g9SPccWrFsam7z+tTR+uURJQz9+tfmjLpsbuJr6FDQZ8czs80A5cFFa8VB332ZmpwHPmNkr7v7mUS/ovhhYDFBeXt6uiFoX9uApSKV6CtifPLYbuFq6GKxUj0SR+vHHRzYt/irglLTlIcC2zI3M7BLgm8B0dz9cX+7u28KfW4BngXPaUd+s1LfI01v8NVmOq3PHilf57fptLXb/VKpHoqhhyIb81kM6XjaBfzUwwsyGm1kxcBXQqHeOmZ0D/Iwg6O9IK+9vZj3C5wOBCUD6ReEOUecZ3TkLCrLux7/oD29y84N/brnFr8AvEdTQmVORP+paTfW4e62Z3QysABJAhbtvNLOFQKW7LwPuAPoA/xHmB9919+nAGcDPzCxJcJL5bkZvoA5xVK+eNuT4W+r+Wb9OKX4R6Y6yGqTN3ZcDyzPK5qU9v6SZ/V4AzmpPBdsi8wauokQBNcd4525LLf7Uxd021k+kK6rvrKBUT/RF8s7durrMVM+xt/hb6v6Zy3sCRLoKfarjI5KB/6gWf2F2QzakX7RtKbinrhco1yMRoou78RHJwJ/0+hx/cHhFWQ7Slj6jVks5/lyO+yPSdWiy9biIZOBvapC25lI9B4/UUvVBcNNxeuBPD+7JjNZ/Lsf9Eelq1OKPvkgG/vobuNJ79TSXs//CfauZ+L0/AHC4ruEmr/TtMy8M159Y1O6XKFF7Jj4iGfhrMy7uFhUUNJuzf3HLbiBo7TdK9STT0z6ZLf76IRtyV2eRfLvpwbWAWvxxEMnAnzksc2HCqEv6USmbdAcO1zab6jkq8IcnBd3BK1FxuLbh265y/NEXzcCfurjb0I8fjk7ZpNtXXcuR9PROFqmejpjVSyQf9hyqST1Xiz/6ohn4M1v84c+W+vLvO1zD4bR5eQ8daWgBHZ3qSbb6eiLdyd5DtannivvRl9Wdu91NwyBtDePxp5c3ZX91bWo0T4ADRxr+EDIvDNengY71bmCRriq9xS/RF+0Wf6JhdE5oOVDvz8jx769uCPyZF4brUzw1tWrxSzTsVaonVqLZ4q8P/NYwOie0kuqprqUg7RO/Nz3wZ7T465Tjl4jZW53e4lfkj7pItviTmcMy17f4mwngAPsO13I4vcV/uCHwX3rXSu7974a5Y1KpHuX4JSJ0cTdeIhn4m5qIBY5O2aSnc/Zn9Or59dqqRtv+9NmGwN9wcVctfun+9hys4b0PD6WWj2Q5aZF0X5FL9ax55wPu+v3rQMPUi0Wpi7uNP9DpX2//ureahyu3pi0fbrTtoH4lVH1wkJP7lqRa+geO1PHPv3mFfdW1XHLGSfzxjfepTTqJguDbRoEZhQVGnTuG8eGhGr776bPo3aMQd2fRHzazfU81xYUFJMwoKAh6UJsZtXVJ6txJmJH0IK1UU+fU1iXp3aOQXsUJnOAmMscJ/zXL3Y+64ay+ZZc+x2qjxl79+rTS+k3dw9ckONHuOVRD356FqZNte+dtzcV8xu19iVx9nzNo1HEAGh9fZj290XaZ65rfb2CfYg4cqWNQvxKGntCLte9+yNbdBzGgZ3GCpAdDlJzUt4Rk0ilMFFCcMJZWbm30ed+X1iCSaMoq8JvZNOBugolYfu7u381Y3wP4FTAW2AXMdPe3w3W3EUzAXgfMdfcVOat9ExY+sRGAc4f1T5XV5/gzUzPb91Snnt/3wtup5z/53Bi+9MDaRttu3X0wNbRDuocrq+iRKODxdQ2zUZ7Utwd1ySDlVJd0zODgkTqO1Ca5cuwQJv1NKdv3VPODJ1+nd3GCAjOS7iQ92McJvq0kLDhpFJhRmDAKCwooShj7qmuprqnDLAzKBgXW/I03TvAa1qgs/OmNtyOjvNFvrIkTR4EZBQZ9exaxr7o2qH94MmrvjUC5SDm09yVycQJzgv/XzN9H5ktnvlPmex9Vk7SCmrok1TXNt9T79yqiLukUJQrYc6iG4sJg/KqaZBJ3GD6wN/uqa3h//xEG9++Z1bFJ99Vq4DezBLAIuJRg/t3VZrYsYyatLwIfuPtHzewq4HvATDMbSTBV45nAR4Dfm9nfuPuxzXyepbqk89pf9/GFCcOZ96mRqfKGVE/jP4w3d+4H4PtXlPH1R9enys8/bQC/vWUiNz+4lrd3BQO4HTjSuMpDT+jFVy4ZwZih/enbs4j/fGU7pX160LekkAs+OvCouu3cd5hz//X3vLlzP5P+ppTNO4L3/sW15zL+tAE5OHqJs8q3d/OZe1cB0Ks4wYUjBvK3J/fFDC454yRGDe4HBAMOJt1TXZwhODnVn2Rq65KN1kk0ZdPiHwdsDidLx8yWADNoPHfuDGBB+PwR4B4LPkkzgCXh5Otvmdnm8PVW5ab6jb27+yDVNUn+9uTjGpXXf5AzL+5u2bmfHoUFzDjnI40Cf3FhAaMG9+Nn15Qz9UcrOblvCf+zt5rjehRy2VmDWFq5lf69ivj0mCGpfa4Zf2qLdRvYp5i+JYWpk0194P/oiX3afsAiofTP0YYFU49KLdUrKDAKjvrm0bCsoB8P2QT+wcDWtOUq4Lzmtgnn6N0DDAjLX8zYd3Cba9uC6po6rl4cvNXHMgJ/UfhHMPehdfQqTqTK/2dPNcMH9qZHYaLR9sWFBanXeXn+FB5f9x7zHt/IqMH9GDWkH0srt3Ksw/SYGaef2IfH1r7Hqjd3sevAEY7vVcSA3sXHeqgiRzm+V8PnqLmgL1Ivm8Df1KcoM+w1t002+wYvYDYHmAMwdOjQLKrVWElRgvNPH8CIk/pwVvi1tt6oIf24cuyQRnfjAow4qQ/TRg0C4NEbL+Ct9w9QWGCpi8EA/XoWMePswSSTzqfO/gjFhQUcPFzL5DNOOuY63jDpdJ54eVvqtzL+tAHtziGL1LvzyrMZ0EcNCWmdtdZ7wszOBxa4+9Rw+TYAd/9O2jYrwm1WmVkh8D9AKXBr+rbp27VWxfHoAAAElUlEQVT0nuXl5V5ZWdnmgxIRiRszW+Pu5dlsm01CbzUwwsyGm1kxwcXaZRnbLANmh88/AzzjwRllGXCVmfUws+HACOClbComIiIdo9VUT5izvxlYQdCds8LdN5rZQqDS3ZcBvwD+X3jxdjfByYFwu4cJLgTXAjd1VI8eERHJTqupnnxQqkdE5NjkOtUjIiIRosAvIhIzCvwiIjGjwC8iEjMK/CIiMdMle/WY2U7gnTbuPhB4P4fV6Q50zPGgY46Hth7zqe5ems2GXTLwt4eZVWbbpSkqdMzxoGOOh844ZqV6RERiRoFfRCRmohj4F+e7AnmgY44HHXM8dPgxRy7HLyIiLYtii19ERFoQmcBvZtPM7DUz22xmt+a7PrliZhVmtsPMNqSVnWBmT5nZG+HP/mG5mdmPw9/BejMbk7+at52ZnWJmfzCzTWa20cy+HJZH9rjNrMTMXjKzl8Nj/lZYPtzM/hQe89JwaHTCoc6Xhsf8JzMbls/6t4eZJczsz2b223A50sdsZm+b2Stmts7MKsOyTv1sRyLwp00I/wlgJHB1ONF7FNwHTMsouxV42t1HAE+HyxAc/4jwMQf4aSfVMddqga+5+xnAeOCm8P8zysd9GPg7dz8bGA1MM7PxwPeAu8Jj/gD4Yrj9F4EP3P2jwF3hdt3Vl4FNactxOOaPu/votG6bnfvZdvdu/wDOB1akLd8G3JbveuXw+IYBG9KWXwMGhc8HAa+Fz38GXN3Udt35ATwOXBqX4wZ6AWsJ5rZ+HygMy1Ofc4L5Mc4PnxeG21m+696GYx1CEOj+DvgtwcSkUT/mt4GBGWWd+tmORIufpieE75BJ3buIk9x9O0D488SwPHK/h/Dr/DnAn4j4cYcpj3XADuAp4E3gQ3evnyw6/bhSxxyu3wMM6Nwa58SPgK8DyXB5ANE/ZgeeNLM14Vzj0Mmf7WwmW+8Osp7UPeIi9Xswsz7Ao8BX3H1vCxPTR+K4PZidbrSZHQ88BpzR1Gbhz25/zGb2SWCHu68xs4vri5vYNDLHHJrg7tvM7ETgKTN7tYVtO+SYo9LirwJOSVseAmzLU106w1/NbBBA+HNHWB6Z34OZFREE/Qfc/ddhceSPG8DdPwSeJbi+cbyZ1TfQ0o8rdczh+n4E0552JxOA6Wb2NrCEIN3zI6J9zLj7tvDnDoIT/Dg6+bMdlcCfzYTwUZI+uf1sghx4ffmssCfAeGBP/dfH7sSCpv0vgE3u/sO0VZE9bjMrDVv6mFlP4BKCC55/AD4TbpZ5zPW/i88Az3iYBO4u3P02dx/i7sMI/mafcffPEeFjNrPeZnZc/XNgCrCBzv5s5/tCRw4vmFwGvE6QF/1mvuuTw+N6CNgO1BCc/b9IkNd8Gngj/HlCuK0R9G56E3gFKM93/dt4zBMJvs6uB9aFj8uifNxAGfDn8Jg3APPC8tOAl4DNwH8APcLyknB5c7j+tHwfQzuP/2Lgt1E/5vDYXg4fG+tjVWd/tnXnrohIzEQl1SMiIllS4BcRiRkFfhGRmFHgFxGJGQV+EZGYUeAXEYkZBX4RkZhR4BcRiZn/D7lftqeH6gaQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94bb57a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multiple runs\n",
    "\n",
    "plt.plot(range(len(agent_scores)), agent_scores, label='episode rewards')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single run - latest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900.09978550955657, 899.18400043608551, 900.18349133434253, 900.24018132025617]\n",
      "[900.50072458144814, 899.20810355704134, 900.25540713700207, 899.9749011918243]\n",
      "[900.61168400488066, 899.33002672279792, 900.33154880962854, 900.23824973965952]\n",
      "[900.61181454061125, 899.00470942946254, 900.47561461979546, 900.47703423542214]\n",
      "[900.02514477976422, 899.02686207969066, 901.20460549918766, 900.4284931361874]\n",
      "[900.06089924287835, 899.15050935672605, 901.30621862594626, 900.38610859294431]\n",
      "positions (x,y,z), reward: [  1.21709420e-03  -6.65727390e-05   2.09292413e+01] 0.999967477569\n",
      "[900.31531922932174, 898.93190521473957, 901.13548424254827, 900.14605177833892]\n",
      "[899.66148743497081, 899.55515619352241, 900.83697109670061, 900.2667755305755]\n",
      "[899.77954268434587, 899.93702862840678, 900.54667081910975, 900.13464035190873]\n",
      "[899.93747805147996, 900.17922373982924, 900.68253260989479, 900.3690682796979]\n",
      "[900.2579590247426, 900.10647309424553, 900.87448603287407, 900.11110436929971]\n",
      "[900.26656568243027, 900.00450013193051, 901.16932407113234, 900.22717933888509]\n",
      "[900.33167870421778, 900.30961190580786, 900.58617014396987, 900.02557900188629]\n",
      "[899.70055183058662, 900.25176348196624, 900.49772891346333, 900.24033390155489]\n",
      "[899.67005884773289, 900.43953312887834, 900.69147971812117, 900.14892927999631]\n",
      "[899.42989933536728, 900.28282861430398, 900.62732918695349, 899.8790302123623]\n",
      "[899.59980261691487, 900.4298876420894, 900.87590350459925, 900.12824922893014]\n",
      "[899.83878553720865, 900.0529664463786, 900.24043841859816, 900.24120789981555]\n",
      "[899.78790770387775, 899.84289408137317, 899.80863754331574, 900.34212913126453]\n",
      "[899.59128219505124, 900.18110754126428, 899.9076182709091, 900.23267822351625]\n",
      "[900.02245998046726, 900.52622692257171, 899.78794168731133, 899.70346533017812]\n",
      "[899.95223589622663, 900.55563580636215, 899.77839907742305, 899.39632251534499]\n",
      "[899.61624805563542, 900.64725261984154, 899.78397508622049, 899.34054195800331]\n",
      "[900.11695741526046, 900.07934074628031, 899.30174333671414, 899.4389220765853]\n",
      "positions (x,y,z), reward: [  0.35701333  -0.13827371  33.88200753] 0.999999999996\n",
      "[900.41623050764179, 899.77262313458573, 899.3992337122445, 899.43827122413859]\n",
      "[900.56514585123148, 900.07110837214952, 899.58443648916148, 899.50877227032652]\n",
      "[900.22431495139233, 900.16378854847733, 899.88455052731956, 899.06994860222483]\n",
      "[900.42283931898328, 900.07873049565592, 899.75586441453618, 899.17922183707196]\n",
      "[900.00082983994605, 899.51011274152324, 900.00329659893418, 899.05193367970253]\n",
      "[899.79229008129744, 899.7926248524559, 900.12656510344755, 899.11691677071417]\n",
      "[899.49676357488192, 899.74124788508686, 900.14430940999932, 898.90096924089846]\n",
      "[899.15947418041935, 900.1740762007712, 900.19247799898346, 899.21437512403941]\n",
      "[899.37850606105633, 899.91236251818441, 900.11819003620087, 899.46815842612261]\n",
      "[900.1077776841629, 900.10304888071983, 900.13167045912189, 899.73105165793379]\n",
      "[899.9313019893242, 900.84704408966945, 900.25579988869004, 900.33436966779902]\n",
      "[900.07429780702535, 901.00297958305191, 900.29786285403679, 900.13491807039054]\n",
      "[900.07287173370469, 901.13827146266885, 899.84020540608867, 899.9205940991103]\n",
      "[899.53519886487209, 900.55873308403864, 899.35071727649927, 899.94580294872617]\n",
      "[899.29974378921986, 900.00023537371453, 899.4772811812046, 899.56002614462182]\n",
      "positions (x,y,z), reward: [  1.30552106  -0.80278757  49.64881495] 1.0\n",
      "[899.70484521647131, 899.93742973777466, 899.53288750571744, 899.37642866353394]\n",
      "[899.67834349710233, 899.99806861765353, 899.06964804418499, 899.62242218988047]\n",
      "[900.05597777417904, 899.68082538671376, 899.83560344884313, 900.21860026386048]\n",
      "[899.93152846107785, 900.09817125089592, 900.07993350574748, 900.64464035209221]\n",
      "[900.03811573975793, 900.24614429922997, 899.9497026623111, 900.47160954187245]\n",
      "[899.80204807689529, 900.3574619489309, 900.30657821455452, 900.25475768421063]\n",
      "[899.9199954846174, 900.41795617224307, 899.45194769593775, 899.8203505988547]\n",
      "[900.28599146154261, 900.59595788405613, 899.75525589585141, 900.00835384959885]\n",
      "positions (x,y,z), reward: [  2.06685812  -1.5679057   59.06214569] 1.0\n",
      "[899.67271905770951, 900.51430486519484, 899.26260206333177, 899.96232161747014]\n",
      "[899.76169125338345, 900.50594679268806, 899.47360324652323, 899.96085312977698]\n",
      "[899.64055650741602, 900.001208549745, 900.09186286386375, 900.2699539149869]\n",
      "[899.32001391767312, 899.50020009053219, 900.1527821173554, 900.59482529989384]\n",
      "[900.00765430653792, 899.73339165807204, 900.35238853075487, 900.90169398768091]\n",
      "[900.15188396956114, 900.32276418089862, 900.67185899930291, 900.41925829164381]\n",
      "[899.65956714360982, 900.10367792482953, 900.78090872849623, 900.4883625118016]\n",
      "[899.59928759896434, 900.57078176882715, 900.7351276979291, 900.55784931688277]\n",
      "[900.32441515478729, 900.6053719577767, 900.72244266429584, 900.7367480098012]\n",
      "[900.60931102936888, 900.75138721809958, 900.58507521261811, 900.3942265336832]\n",
      "[901.3677915347962, 900.81559578444535, 900.00529658866628, 900.36001973671262]\n",
      "[900.87394282508353, 900.85568745349917, 899.93966352815755, 899.81804876538376]\n",
      "[900.83181962738047, 900.7355400387903, 899.84141337458766, 900.1568405170334]\n",
      "[900.8119670707141, 900.24622059548415, 900.03521899116572, 899.76674866466215]\n",
      "[900.6730827790318, 901.03662085152575, 900.2184238723753, 900.07771707212157]\n",
      "[900.45233040452456, 900.63187202493157, 899.72568733579999, 899.90952349992563]\n",
      "[899.99565322855733, 900.11953210633715, 899.88715651309451, 900.05835681630947]\n",
      "positions (x,y,z), reward: [  3.86756468  -4.23604891  77.51029233] 1.0\n",
      "[900.18895264012258, 900.96855176596296, 899.54286187040248, 900.10551375622981]\n",
      "[900.11231006688695, 900.3293048226252, 899.67003056529143, 899.89538740562625]\n",
      "[900.07948440897121, 900.29759392618632, 899.49873010902024, 900.12208609299853]\n",
      "[900.45613472157777, 899.92764435192294, 899.57074608531684, 900.07084180199274]\n",
      "[900.69691785431473, 900.21311444605328, 899.92075957453039, 899.95663859890033]\n",
      "[900.24540400867943, 900.13373863667107, 899.98269758407116, 899.96003580440549]\n",
      "positions (x,y,z), reward: [  4.62888862  -5.79344749  84.74787687] 1.0\n",
      "[900.14337484331054, 900.26689762112574, 899.95487920489211, 899.94253025862974]\n",
      "[900.317830252102, 900.38906608440618, 899.95632882504151, 900.5767658795869]\n",
      "[900.33287015080236, 900.12734613292446, 899.95409586354424, 900.1016051549268]\n",
      "[900.43570511419841, 900.24004491357516, 899.79981100873806, 900.08099429626429]\n",
      "[900.52141321112447, 900.01087497114304, 899.44526619382896, 900.389755209584]\n",
      "[900.67615915030046, 900.00197961886147, 899.31026722584568, 900.49727661555642]\n",
      "[900.60427308745238, 899.74438662887087, 899.5591363602266, 900.51884111661764]\n",
      "[900.8729573376844, 900.02850398285182, 899.82054988835466, 900.39452528654192]\n",
      "[900.89954173965589, 900.54021081137819, 899.19015101253319, 900.93691466122903]\n",
      "[900.83022585772756, 900.29527706558486, 899.09272901413476, 900.87887896117354]\n",
      "[900.81394642314228, 899.54834188047005, 899.21793707320398, 900.6132329939436]\n",
      "[901.06474490533776, 899.64396906396087, 899.31713314166961, 900.64290636076555]\n",
      "[900.99118875071417, 899.66970018710799, 899.23642612940012, 900.13698019663445]\n",
      "[900.39913929663282, 899.75548148258645, 899.45909665503291, 899.73262301803572]\n",
      "[900.60372040516211, 899.91606818576997, 899.53533228574145, 899.60741079487184]\n",
      "[900.85962610305648, 900.20161661522695, 900.01432999902283, 899.6964671667007]\n",
      "[900.71931924683679, 900.77975765330052, 900.47707636275243, 899.38994942232284]\n",
      "[900.45949334925285, 900.38702671325655, 900.22464114619424, 898.96922121222542]\n",
      "[899.38260846382741, 900.43007105629601, 900.60795915765777, 899.22489922885461]\n",
      "[899.10159542638087, 900.87988358121095, 900.61831757825803, 899.53468124667347]\n",
      "[899.49031640245789, 900.78931420268725, 900.00273683679654, 898.94523256607818]\n",
      "[899.60538113432597, 900.65920382567708, 900.50373456012937, 899.6891159578031]\n",
      "[899.09267465305084, 900.50900886235024, 900.60407425904657, 899.67990733201952]\n",
      "[899.6748509290411, 900.06714604819081, 901.20019666016572, 899.7075172532758]\n",
      "[899.52810830749377, 899.79606706006598, 901.42619275856032, 899.72683807891292]\n",
      "[899.49675351010592, 899.8413186404581, 900.78489460602418, 899.38851229543104]\n",
      "[899.61333514341982, 899.37428013041347, 900.83302522809208, 899.48470150027845]\n",
      "positions (x,y,z), reward: [   7.41209316  -15.32511298  113.5218654 ] 1.0\n",
      "[900.04752545045312, 899.76177907603005, 900.76154743770132, 899.80933576884047]\n",
      "[900.24452648336637, 900.08829104536699, 900.48296513496939, 900.0393361799679]\n",
      "[899.97948084890254, 900.21775724703741, 900.62707157643194, 900.24133653530851]\n",
      "[900.02523262513716, 900.50125708657527, 900.67664434479957, 899.88073308357707]\n",
      "[899.87739243379508, 900.64823077620144, 900.71759010336348, 899.82867450084518]\n",
      "[899.79738221763057, 900.60331694195895, 900.41864608134347, 899.48711841886529]\n",
      "[899.97644354574129, 900.56355772385598, 900.38924361479712, 899.68749466943666]\n",
      "[899.68826438287704, 901.09866590341244, 900.3071729756806, 899.60769582876787]\n",
      "[899.32361053113345, 900.87410663816604, 900.54177479242765, 900.12987587219959]\n",
      "[899.00054312500777, 900.83616164543275, 900.93163899164483, 899.77911833872554]\n",
      "[899.20806033342626, 901.01188941114685, 901.03687543124136, 899.89122323022912]\n",
      "[899.32424468320744, 900.80834836398265, 900.60792372501339, 900.11128203644523]\n",
      "[899.51535683963414, 901.05574735016273, 900.50770653826885, 899.89359467957138]\n",
      "[899.66063247078932, 900.56175946010217, 900.5491038910402, 899.72096931293936]\n",
      "[900.23252929972807, 899.86493960239238, 900.56803579613711, 899.35476743435891]\n",
      "[900.74990450887003, 899.85390697362539, 900.40499403442084, 899.46836423717821]\n",
      "[900.68200353915017, 899.5767839984004, 899.99744114476357, 899.48829971498958]\n",
      "[900.52910153286973, 899.51591673114797, 899.93920469610282, 899.58729150042336]\n",
      "[900.21442362481582, 899.15296624443317, 899.53870969357854, 899.44053304472072]\n",
      "[900.42510482652324, 898.55283581450703, 899.02912040397234, 899.49889457893141]\n",
      "[900.18909357530879, 898.79134603571356, 898.89316151929165, 899.59608221664507]\n",
      "positions (x,y,z), reward: [   8.96121705  -26.59416097  135.5076321 ] 1.0\n",
      "[900.33471187924454, 899.01475663966755, 898.98183511770765, 899.60556781590105]\n",
      "[900.30723464354821, 898.67971018342769, 898.98519250240406, 899.28443055874106]\n",
      "[900.52795720806603, 898.55816203515508, 898.81655672917066, 900.12075469808633]\n",
      "[900.78195407451892, 898.88507110139983, 898.87417996152021, 900.26673514718618]\n",
      "[900.61933886647773, 899.76180250166919, 899.19191648385231, 900.20265181316836]\n",
      "[900.02922760522245, 898.98352517487842, 899.56167656845776, 900.12335412366792]\n",
      "[900.15720573639771, 899.03588561020058, 899.76133786147136, 900.31604185318452]\n",
      "[900.21446514991351, 898.73624033159547, 899.73095220604182, 900.31622029897846]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4','reward']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "\n",
    "state = agent.reset_episode() # start a new episode\n",
    "while True:\n",
    "    action = agent.act(state)\n",
    "    print(action)\n",
    "    #action = [500.,500.,500.,500.]\n",
    "    next_state, reward, done = agent.task.step(action*np.ones(4))\n",
    "    agent.step(action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    to_write = [agent.task.sim.time] + list(agent.task.sim.pose) + list(agent.task.sim.v) + list(agent.task.sim.angular_v) + list(rotor_speeds) + list([reward])\n",
    "    for ii in range(len(labels)):\n",
    "        results[labels[ii]].append(to_write[ii])\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99912154968\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFkpJREFUeJzt3X+QXHW55/H3k8lgIMCSJSMCkQys4AYDSGokZJGIV4wI7HUrFlWmFhEKRUsXcbl4ubAs1FX/0CqLgltbhRUFU3jZXLcU1OWXF7xQUQsJCQkQSGAp4a6zIAkJkIQQku5+9o/pxBCmuyfzqzPffr+qppLpc/qc50yKzzw8/e3TkZlIkjrHpHYXIEkaXwa/JHUYg1+SOozBL0kdxuCXpA5j8EtShzH4JanDGPyS1GEMfknqMJPbXcBgpk+fnr29ve0uQ5ImjJUrV76amT1D2Xe/DP7e3l5WrFjR7jIkacKIiH8d6r6OeiSpwxj8ktRhDH5J6jAGvyR1GINfkjpMy+CPiPdHxEMRsTYino6IKwbZJyLiHyLi+Yh4MiLm7LHtCxHxf+pfXxjtC5Ak7ZuhLOesAH+TmY9HxCHAyoh4IDOf2WOfTwPH17/mArcAcyPi3wI3AH1A1p/7q8x8bVSvQpI0ZC2DPzNfBl6u/31LRKwFjgb2DP7PALfnwOc4/iEiDouII4GzgAcycxNARDwAnAMsHdWr2EfbdlR44dU3eeHVN9n05g6276zy9s4atYRaJu/6MEo/nlLSODjoPZP5ysf+3ZifZ5/ewBURvcCpwKN7bToa+NMe3/fXH2v0+GDHvgy4DOCYY47Zl7KGbEelxv946Hluefh5dlb3LcwjxqQkSdpt+sHv2b+CPyIOBn4OfCMzN++9eZCnZJPH3/1g5mJgMUBfX9+ot9jPvbKFy//nKp59ZQuf+fBRfOpD7+PY6VPpOeQ9TOnu4oCuSUyeFERAmPKSCjak4I+IbgZC/47MvHOQXfqB9+/x/QzgpfrjZ+31+MPDKXSk/vsv1rBh69vc+oU+PjHriHaUIEn7haGs6gngVmBtZt7YYLdfARfVV/ecDrxRf23g18CCiJgWEdOABfXHxtX6zdtZ/uImLpo309CX1PGG0vGfAXweeCoiVtcfuxY4BiAzfwDcC5wLPA9sAy6pb9sUEd8GHqs/71u7XugdT79++s9kwrknHTnep5ak/c5QVvX8jsFn9Xvuk8DXGmy7DbhtWNWNknueepkPvPdgTjjikHaWIUn7heLfubthy9ssf2ET585+X7tLkaT9QvHB/+un/0wt4dyTHfNIEnRA8N/71MscN30qH3TMI0lA4cG/ZftO/vDHjZwz+32uzZekuqKDf8OWt6klHH/Ewe0uRZL2G0UH/2vbdgJw2EEHtLkSSdp/FB38b7y1A4DDDuxucyWStP8oOvhft+OXpHfpiOCfdpAdvyTtUnjw7yACDpli8EvSLmUH/1s7OXRKN12TXMopSbuUHfzbdnKYYx5Jeoeyg/+tnb6wK0l7KTv4t+1wKack7aXw4HfUI0l7Kzz4dzDNUY8kvUOxwV+p1ti8vcK/cdQjSe9QbPBv3l4BcNQjSXspNvhf31a/T4/BL0nvUG7wv+V9eiRpMOUG/zbvzClJgyk4+O34JWkw5Qe/Hb8kvUO5wf/WTiLgUINfkt6h3ODftsM7c0rSIAoOfm/XIEmDKTf4vTOnJA2q2OB/wztzStKgig3+1xz1SNKgig1+78UvSYMrMvirtWTz9oozfkkaRJHBv3n3fXrs+CVpb0UG/2vemVOSGioy+HffmfNARz2StLcig/+NbY56JKmRIoP/9bd2jXrs+CVpby2DPyJui4j1EbGmwfZpEXFXRDwZEcsjYvYe2/5rRDwdEWsiYmlETBnN4ht57U3vzClJjQyl418CnNNk+7XA6sw8GbgIuBkgIo4Gvg70ZeZsoAv43IiqHaJdM37vzClJ79Yy+DNzGbCpyS4nAr+p77sO6I2II+rbJgMHRsRk4CDgpZGVOzRvV6q8Z/Ik78wpSYMYjRn/E8BCgIg4DZgJzMjM/wd8H/i/wMvAG5n5z6Nwvpaq1WSyoS9JgxqN4P8uMC0iVgOXA6uASkRMAz4DHAscBUyNiAsbHSQiLouIFRGxYsOGDSMqqFJLu31JamDEwZ+ZmzPzksz8MAMz/h7gBeBs4IXM3JCZO4E7gf/Q5DiLM7MvM/t6enpGVFO1lkzuKnLBkiSN2IjTMSIOi4hd6ya/CCzLzM0MjHhOj4iDIiKATwBrR3q+obDjl6TGJrfaISKWAmcB0yOiH7gB6AbIzB8As4DbI6IKPANcWt/2aET8DHgcqDAwAlo8BtfwLpVqzRm/JDXQMvgzc1GL7Y8AxzfYdgMDvyjGVdWOX5IaKnIQXqm5qkeSGiky+O34JamxIoO/UqsxeVKRlyZJI1ZkOtrxS1JjRQZ/pZZ0dxn8kjSYIoPfjl+SGisy+CvVdMYvSQ0UmY52/JLUWJHBX6nVmOyMX5IGVWTw2/FLUmNFBr/v3JWkxooMfjt+SWqsyOAf6PiLvDRJGrEi09GOX5IaKzL4B+7VY/BL0mCKDP5q1Y5fkhopMvgrtXQdvyQ1UGTwO+OXpMaKDH5X9UhSY0Wmox2/JDVWZPC7qkeSGisz+F3VI0kNFRf8mem9eiSpieKCv5YDf3b54q4kDaq4dKzUagCu45ekBooL/mq95XfGL0mDKy74K/Xgd8YvSYMrLvirVYNfkpopLvh3dfxdXcVdmiSNiuLSseqoR5KaKi74d63q8cVdSRpcccFvxy9JzRUX/BWXc0pSU8UF/186/uIuTZJGRXHpWKna8UtSM8UFvzN+SWquuODfvarHe/VI0qBaBn9E3BYR6yNiTYPt0yLiroh4MiKWR8TsPbYdFhE/i4h1EbE2IuaNZvGDseOXpOaG0vEvAc5psv1aYHVmngxcBNy8x7abgfsz898DpwBrh1nnkLmqR5Kaaxn8mbkM2NRklxOB39T3XQf0RsQREXEoMB+4tb5tR2a+PvKSm3NVjyQ1Nxrp+ASwECAiTgNmAjOA44ANwI8jYlVE/Cgipo7C+Zqy45ek5kYj+L8LTIuI1cDlwCqgAkwG5gC3ZOapwJvA3zU6SERcFhErImLFhg0bhl1MddcHsRj8kjSoEQd/Zm7OzEsy88MMzPh7gBeAfqA/Mx+t7/ozBn4RNDrO4szsy8y+np6eYdfjOn5Jam7EwV9fuXNA/dsvAsvqvwz+DPwpIj5Y3/YJ4JmRnq+V3TN+l3NK0qAmt9ohIpYCZwHTI6IfuAHoBsjMHwCzgNsjospAsF+6x9MvB+6o/2L4I3DJqFY/CD+BS5Kaaxn8mbmoxfZHgOMbbFsN9A2vtOH5y22ZXdUjSYMpLh0rfvSiJDVVXPBXXc4pSU0VF/zO+CWpueKC345fkporLvh3d/xdxV2aJI2K4tLRd+5KUnPFBb/36pGk5ooL/qrLOSWpqeKC345fkporLvirtaRrUhBh8EvSYIoL/ko9+CVJgysu+Ku1mvN9SWqiuOC345ek5ooL/mot7fglqYnign+g4y/usiRp1BSXkNWqHb8kNVNc8Dvjl6Tmigv+aq3m5+1KUhPFBb8dvyQ1V1zwu6pHkporLvhd1SNJzRWXkHb8ktRcccG/s1pzxi9JTRQX/Hb8ktRcccHvqh5Jaq644K/W0nX8ktREccHvqh5Jaq64hKzWanQ76pGkhooL/krVGb8kNVNc8Dvjl6Tmigx+Z/yS1FhxCVlxHb8kNVVc8Fddxy9JTRUX/JVazY5fkpooLvjt+CWpueKC3xm/JDVXXPBXq67qkaRmWiZkRNwWEesjYk2D7dMi4q6IeDIilkfE7L22d0XEqoi4e7SKbqbiOn5JamoorfES4Jwm268FVmfmycBFwM17bb8CWDus6obBGb8kNdcy+DNzGbCpyS4nAr+p77sO6I2IIwAiYgZwHvCjkZc6NK7qkaTmRmMY/gSwECAiTgNmAjPq224C/haojcJ5WqrVklpixy9JTYxG8H8XmBYRq4HLgVVAJSLOB9Zn5sqhHCQiLouIFRGxYsOGDcMqpJoJYMcvSU1MHukBMnMzcAlARATwQv3rc8BfR8S5wBTg0Ij4x8y8sMFxFgOLAfr6+nI4tVRrA09zVY8kNTbihIyIwyLigPq3XwSWZebmzLwmM2dkZi8DvwT+pVHoj5ZKzY5fklpp2fFHxFLgLGB6RPQDNwDdAJn5A2AWcHtEVIFngEvHrNoWqtVdHb/BL0mNtAz+zFzUYvsjwPEt9nkYeHhfChuOSm3gNWTX8UtSY0UNwys1O35JaqXI4HfGL0mNFRX8f5nxF3VZkjSqikrI3TN+O35Jaqio4N+1jt8XdyWpsaKC3xm/JLVWVPD7zl1Jaq2ohLTjl6TWigr+av3FXdfxS1JjRQV/pWrHL0mtFBX8Vd+5K0ktFRX8FZdzSlJLRQW/q3okqbWiEtJVPZLUWlHB76oeSWqtqOC345ek1ooKflf1SFJrRQX/X9bxF3VZkjSqikrI3R2/yzklqaGigt8ZvyS1VlTwu6pHklorKvjt+CWptaKC31U9ktRaUcG/01U9ktRSUQnpjF+SWisq+J3xS1JrRQV/tZZEwCSDX5IaKir4K7Wk2/m+JDVVVEpWa+l8X5JaKCr4K9V0vi9JLRQV/NVazfv0SFILRQV/pWbHL0mtFBX8zvglqbWign+g4y/qkiRp1BWVknb8ktRaUcHvjF+SWisq+Ku1mh2/JLXQMvgj4raIWB8RaxpsnxYRd0XEkxGxPCJm1x9/f0Q8FBFrI+LpiLhitIvfW6XqqEeSWhlKx78EOKfJ9muB1Zl5MnARcHP98QrwN5k5Czgd+FpEnDiCWluq1pLJruOXpKZaBn9mLgM2NdnlROA39X3XAb0RcURmvpyZj9cf3wKsBY4eecmNVWpJl6t6JKmp0UjJJ4CFABFxGjATmLHnDhHRC5wKPNroIBFxWUSsiIgVGzZsGFYhVV/claSWRiP4vwtMi4jVwOXAKgbGPABExMHAz4FvZObmRgfJzMWZ2ZeZfT09PcMqpOKLu5LU0uSRHqAe5pcAREQAL9S/iIhuBkL/jsy8c6TnaqVaS7q7HPVIE83OnTvp7+9n+/bt7S5lvzdlyhRmzJhBd3f3sI8x4uCPiMOAbZm5A/gisCwzN9d/CdwKrM3MG0d6nqGo1JIp3Xb80kTT39/PIYccQm9vLwPRocFkJhs3bqS/v59jjz122McZynLOpcAjwAcjoj8iLo2Ir0TEV+q7zAKejoh1wKeBXcs2zwA+D/xVRKyuf5077EqHwBm/NDFt376dww8/3NBvISI4/PDDR/x/Ri07/sxc1GL7I8Dxgzz+O2Bc/xUH1vE76pEmIkN/aEbj51RUSlZqNTt+SRNSb28vr7766ricq7DgTz+IRdKIZSa1Wm3Mjl+pVFrvNIaKCn5n/JKG68UXX2TWrFl89atfZc6cOfzkJz9h3rx5zJkzhwsuuICtW7eyfPlyFi5cCMAvf/lLDjzwQHbs2MH27ds57rjjAPjhD3/IRz7yEU455RQ++9nPsm3bNgAuvvhirrzySj7+8Y9z9dVXs3HjRhYsWMCpp57Kl7/8ZTITgDfffJPzzjuPU045hdmzZ/PTn/501K91xKt69ifeq0ea+P7+fz/NMy81fMvPsJx41KHc8B8/1HK/Z599lh//+Md861vfYuHChTz44INMnTqV733ve9x4441ce+21rFq1CoDf/va3zJ49m8cee4xKpcLcuXMBWLhwIV/60pcAuO6667j11lu5/PLLAXjuued48MEH6erq4utf/zof/ehHuf7667nnnntYvHgxAPfffz9HHXUU99xzDwBvvPHGqP4soLDgr9aSbl/clTRMM2fO5PTTT+fuu+/mmWee4YwzzgBgx44dzJs3j8mTJ/OBD3yAtWvXsnz5cq688kqWLVtGtVrlzDPPBGDNmjVcd911vP7662zdupVPfepTu49/wQUX0NXVBcCyZcu4886Btzedd955TJs2DYCTTjqJq666iquvvprzzz9/93FHU1HB74xfmviG0pmPlalTpwIDM/5PfvKTLF269F37nHnmmdx33310d3dz9tlnc/HFF1OtVvn+978PDIx0fvGLX3DKKaewZMkSHn744Xcdf5fBVuiccMIJrFy5knvvvZdrrrmGBQsWcP3114/iVRY343dVj6SRO/300/n973/P888/D8C2bdt47rnnAJg/fz433XQT8+bNo6enh40bN7Ju3To+9KGBX1hbtmzhyCOPZOfOndxxxx0NzzF//vzd2++77z5ee+01AF566SUOOuggLrzwQq666ioef/zxUb++8jp+g1/SCPX09LBkyRIWLVrE22+/DcB3vvMdTjjhBObOncsrr7zC/PnzATj55JN573vfu7t7//a3v83cuXOZOXMmJ510Elu2bBn0HDfccAOLFi1izpw5fOxjH+OYY44B4KmnnuKb3/wmkyZNoru7m1tuuWXUry92vZK8P+nr68sVK1bs8/NOvP5+/vPcY/hv543pbf8ljbK1a9cya9asdpcxYQz284qIlZnZN5TnFzXqWXDiEcw68tB2lyFJ+7WiRj03fe7UdpcgSfu9ojp+SVJrBr+k/cL++Hrj/mg0fk4Gv6S2mzJlChs3bjT8W9h1P/4pU6aM6DhFzfglTUwzZsygv7+f4X7edifZ9QlcI2HwS2q77u7uEX2ilPaNox5J6jAGvyR1GINfkjrMfnnLhojYAPzrPjxlOjA+n1m2//CaO4PX3BlG45pnZmbPUHbcL4N/X0XEiqHeo6IUXnNn8Jo7w3hfs6MeSeowBr8kdZhSgn9xuwtoA6+5M3jNnWFcr7mIGb8kaehK6fglSUM04YM/Is6JiGcj4vmI+Lt21zPWIuK2iFgfEWvaXct4iYj3R8RDEbE2Ip6OiCvaXdNYi4gpEbE8Ip6oX/Pft7um8RARXRGxKiLubnct4yEiXoyIpyJidUTs+8cODve8E3nUExFdwHPAJ4F+4DFgUWY+09bCxlBEzAe2Ardn5ux21zMeIuJI4MjMfDwiDgFWAv+p8H/nAKZm5taI6AZ+B1yRmX9oc2ljKiKuBPqAQzPz/HbXM9Yi4kWgLzPH9X0LE73jPw14PjP/mJk7gH8CPtPmmsZUZi4DNrW7jvGUmS9n5uP1v28B1gJHt7eqsZUDtta/7a5/TdwubQgiYgZwHvCjdtdSuoke/EcDf9rj+34KD4ROFxG9wKnAo+2tZOzVxx6rgfXAA5lZ+jXfBPwtUGt3IeMogX+OiJURcdl4nXSiB38M8ljRXVEni4iDgZ8D38jMze2uZ6xlZjUzPwzMAE6LiGJHexFxPrA+M1e2u5ZxdkZmzgE+DXytPsodcxM9+PuB9+/x/QzgpTbVojFUn3P/HLgjM+9sdz3jKTNfBx4GzmlzKWPpDOCv6zPvfwL+KiL+sb0ljb3MfKn+53rgLgbG12Nuogf/Y8DxEXFsRBwAfA74VZtr0iirv9B5K7A2M29sdz3jISJ6IuKw+t8PBM4G1rW3qrGTmddk5ozM7GXgv+N/ycwL21zWmIqIqfXFCkTEVGABMC6r9SZ08GdmBfgvwK8ZeMHvf2Xm0+2tamxFxFLgEeCDEdEfEZe2u6ZxcAbweQa6wNX1r3PbXdQYOxJ4KCKeZKDBeSAzO2KJYwc5AvhdRDwBLAfuycz7x+PEE3o5pyRp303ojl+StO8MfknqMAa/JHUYg1+SOozBL0kdxuCXpA5j8EtShzH4JanD/H90rj8sVAwiUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94bb6d748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['reward'], label='rewards')\n",
    "plt.legend()\n",
    "_ = plt.ylim()\n",
    "print(agent.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94bad42e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Run the code cell below to visualize how the position of the quadcopter evolved during the simulation.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8XFXd+PHPmS0zSSZ7mmZpmrQN3WmhC1DKTmURqCAgiyiK9oeI8sDPR3GvPPqIoD4+wPNIVfyBgiKCLAUEgVKgUEpb2tJ935KmSZp9mX3O748zSVua0rSZyU1mvm9e53Vnbu7M/V6Sfu+555x7rtJaI4QQIvnZrA5ACCHEwJCEL4QQKUISvhBCpAhJ+EIIkSIk4QshRIqQhC+EEClCEr4QQqSIfid8pZRbKfWBUmqNUmq9UuonsfWVSqllSqmtSqm/KaVc/Q9XCCHEiYpHDT8AnK+1ngJMBS5WSp0O/AL4L611FdAM3BKHfQkhhDhBjv5+gTa36nbE3jpjRQPnAzfE1j8GzAd++0nfVVBQoCsqKvobkhBCpJSVK1ce0FoXHmu7fid8AKWUHVgJjAH+B9gOtGitw7FNqoHSo3x2HjAPoLy8nBUrVsQjJCGESBlKqd192S4unbZa64jWeipQBswExve22VE++zut9XSt9fTCwmOeoIQQQpyguI7S0Vq3AIuB04EcpVT3FUQZsC+e+xJCCHF84jFKp1AplRN77QEuBDYCbwJXxzb7IvB8f/clhBDixMWjDb8YeCzWjm8DntJav6iU2gA8qZT6KbAKeCQO+xJCCHGC4jFK5yPglF7W78C05wshhBgE5E5bIYRIEZLwhRAiRcRlHL4Q/RHVUXxhH12hLnxhH76wD3/Ejz/sJxAJEIwETYkGCUVDhKNhwtEwkWiEsA6jtSaiI2it6fnvkEd3KqVQqJ6lTdmwKzsOmwO7smO3mdcO5cBpd+K0HSxp9jRcdhdp9jRTHGbptrtxO9w4bPJPSAwd8tcq4q4z1EldVx2NvkYauhpo8jf1lJZAC62BVtqD7T2lI9SB7v02jROmUD2v4/3dh3LYHHgcHjx2Dx6nh3RHunl/yOsMZwaZzkzSnelkOjN73me6Msl0ZuJ1efG6vGQ6M7Hb7AmLVQhJ+OK4tQfb2dO2h73te6nuqKamo4bazlpqO2qp66qjM9R5xGfsyk5OWg657lyy07IpySzpSXLdiS/DmWGSpcOD2+HuqUm77C5cdhdOmxOHzXHYsru2blM2bMqGUqqXiOmp/Ud1tOeKIBwNE9ERIjpCKBIirMNmGQ33XE0EI8Geq4xAJGBKONBzBdJ9NeIL+/CFzNVJV7iLtkAbtR21dIW76Ax10hXqIqIjx/x/m+nMJMuVRVZaFlmuLLLTsnuWOWk55KTlkJ2WTa47l9y0XHLduXhdXmxKWmfFsUnCF0flC/vY2ryVTU2b2Nq8le2t29nRsoNGf+Nh2+Wm5VKcWUxldiVnlJxBUXoRhemFFHoKKfAUUOApsDwpHdqcA+DEOaD711oTiAToCHXQGeqkI9RBR9CU9tDBq522YJtZBtpoC7axvWU7bcE2WgIthKPhXr/boRzkuHPId+eT78mnwFPQ87rQU9jzuxiWPox0Z/qAHrcYXCThC8AkpF1tu1hdv5o1DWtYe2At21q2EdVRwNQ8R+WM4qyys6jIqqAiq4IybxkjvCMkifSBUgq3w7T7F3gKjvvzWmu6wl20BFpo8bfQEmihOdBMs9+URn8jTb4mGv2N7GzdSaOvkWA0eMT3eJ1eijKKKEovoiijiGHpwyhKL2J4xnCK0osozigm05UZj0MWg5Ak/BS2t30vS/ctZVntMlbUraDJ3wRAdlo2k/Ince6Ic5mQP4FxeeMoySg5anOJSDylFBnODDKcGZRm9joP4WG01rQF22j0NVLvq6ehq4G6rjrqu+qp76pnf+d+tjRv4YDvwBF9HF6nl+GZwynJKGF4xnBKMksoySihOLOYkowS8j350oQ0REnCTyHhaJhV9atYtGcR79S8w+42M8HesPRhzCqZxfSi6ZxSdAqVWZWS3Ic4pRTZadlkp2UzKmfUUbcLRUM9J4P9nfvZ37m/pz+mtrOWD+s/pD3YfthnXDYXwzOG95wAijOLKc44+Hp4+nCc9oFtMhN9Iwk/yUWiEVbWreTlnS/zxp43aAm04LK5mFk8k+vHXc+ZJWcyMmukJPgU5bQ5TQ0+s+So23QEO6jtrGVfxz72de6jtqO2Z7mkZgkNvobDtlcoCjwFR5wIijNiJbOYLFdWog9N9EISfpLa276X57Y9x/Pbnqeuqw6Pw8N5I85jzsg5zCqZJe3uos8yXZlUuaqoyq3q9efBSLDnymBfx76Drzv3sbFxI4v2LCIUDR3+nc5Mc5WQUUxJZslhr0sySihML5RmowSQhJ9EojrKuzXv8pdNf2FJzRJsysaZJWfyrRnf4pyyc/A4PFaHKJKQy+6iPKuc8qzyXn8e1VGa/E09Vwh1nXXs69hnmo46a1l7YC0tgZbDPuOwOXpOAKWZpZRklFDqLaU005QCT4GcEE6AJPwkEIqGeGXnK/xh7R/Y0bqDAk8Bt025jSurrmR4xnCrwxMpzqZsPcNzTy48uddtukJdPVcIPc1HHfuo6azh7eq3OeA7cNj2LpuLUm8pZZlllGaW9owYK/OWUZZZJlewRyEJfwiLRCO8tPMl/nf1/1LTUUNVbhU/P+vnXDTyIuk0E0NKujOd0TmjGZ0zutef+8N+9nXuo6a9hpoOU6rbzU1/q+pX0RHqOGz7fHc+I7wjDpYssyz3lpOTlpOyfVbq0DlHrDZ9+nQtz7Ttm7er3+ZXK37FjtYdjM8bz21Tb+OcsnNS9g9ZpK7uIajV7dXsbd97RKnvqj9s6KnX6WVE1ghGekdSnlXOyCyzrMiqIDst28IjOXFKqZVa6+nH2k5q+EPMrtZd/GL5L1hSs4SKrAp+dc6vmDNyjiR6kbIOHYI6sWDiET8PRALUtNewu213z0lgT/sePjrwEa/ufrXn5kKAnLQcRmaNpDK70pSsSkbnjKY0szQp5jmSGv4QEYqE+OO6P7LgowWk2dO4dcqt3DDuBmm6EaIfgpEg1R3V7Gnbw+623exq28Wu1l3satt1WL+By+aiMruSMbljqMoxI5ZOyj2JovSiQVHZkhp+EtnYuJHvLfke21q2cUnFJXx75rdP6PZ8IcThXHYXo7JHMSr7yJvT2oJt7GzdyY6WHWxv2c621m2s2L+Cl3a81LNNTloOY3PHMj5/POPzxjOxYCLl3vJBcRLojST8QSyqozy6/lEeXPUgeWl5PHT+Q5wz4hyrwxIiJWS5sphSOIUphVMOW98aaGVbyzY2N21mS/MWNjVt4i8b/9Izd5HX5WVC/gROLjiZyQWTObnwZPI9+VYcwhGkSWeQavI38Z23v8P7te8zZ+QcfnT6j8hx51gdlhCiF6FoiB0tO1jfuJ51B9ax7sA6tjRv6ZkSu9xbztRhU5lWNI1pRdPifhXQ1yYdSfiD0NqGtdy5+E6a/c1877TvcVXVVYP2ElEI0Ttf2MfGxo2saVjDqvpVrK5fTXOgGYBCTyHTh09n5vCZnF58OmXesn7tSxL+ELVw+0J+/N6PGZY+jF+f+2sm5E+wOiQhRBxordnZupMVdStYsX8Fy+uW93QMl2WW8aVJX+Lasdee0HdLp+0Qo7Xmt2t+y2/X/JYZw2fw63N+LU04QiQRpRSjckYxKmcU1469tucE8H7t+7xf+z5OW+JH3EnCHwTC0TA/WfoTntv2HFeMvoL5Z8yX4ZZCJLlDTwA3jL9hQPYpCd9iwUiQu9+5m9d2v8atU27ltim3SXu9ECIhJOFbKBAJcMebd/Buzbv8+/R/5wsTv2B1SEKIJCYJ3yKhSIi7Ft/FezXvMf+M+Xz2pM9aHZIQIsnJhNIWCEVD/Pvb/87b1W/zwzN+KMleCDEgJOEPMK0189+bzxt73uDumXdzzUnXWB2SECJFSMIfYA+uepAXtr/AbVNv48bxN1odjhAihUjCH0BPbX6K36/9PZ+t+iy3nnyr1eEIIVKMJPwB8n7t+/znsv/krNKz+MHpP5Chl0KIAScJfwDsbd/Lt976FpXZldx/zv04bDI4Sggx8CThJ1hXqItvLvomWmseOO8BMpwZVockhEhR/U74SqkRSqk3lVIblVLrlVJ3xNbnKaVeU0ptjS1z+x/u0KK15p7372FH6w7uP+d+RmSNsDokIUQKi0cNPwz8X631eOB04OtKqQnA3cAbWusq4I3Y+5Ty7LZneWnHS3xtyteYVTLL6nCEECmu3wlfa12rtf4w9rod2AiUAnOBx2KbPQZ8pr/7Gkq2NG/hP5f9J6cVn8ZXJ3/V6nCEECK+bfhKqQrgFGAZUKS1rgVzUgCGxXNfg5k/7Ofbb30br8vLvWfdmxRPuxdCDH1xGy6ilMoEngH+TWvd1tdhh0qpecA8gPLy8niFY6kHVj3A9tbtLLhwgTxsXAgxaMSlhq+UcmKS/RNa63/EVtcppYpjPy8G6nv7rNb6d1rr6Vrr6YWFhfEIx1If1H7Anzf8mevGXsesUmm3F0IMHvEYpaOAR4CNWutfH/KjF4Avxl5/EXi+v/sa7NqD7fzg3R8wMmskd0670+pwhBDiMPFo0jkTuAlYq5RaHVv3PeBe4Cml1C3AHiDpZwn7zcrfUNdVx58u+RPpznSrwxFCiMP0O+FrrZcAR2uwv6C/3z9UfFj3IU9teYqbJtzElMIpVocjhBBHkDtt4yAQCTB/6XxKM0u5fertVocjhBC9kkld4uAPa//AztadPHzhw9KUI4QYtKSG30972vbwyNpHuKTyEs4sPdPqcIQQ4qgk4ffTfcvvw2lz8q3p37I6FCGE+ESS8Pvhrb1v8Vb1W3xtytcYlp4yNxILIYYoSfgnKBgJ8ovlv6Ayu1IeVSiEGBKk0/YE/XXTX9nbvpcFFy7AaXdaHY4QQhyT1PBPQIu/hQUfLWB26WyZPkEIMWRIwj8BCz5aQGeok7um3WV1KEII0WeS8I/TnrY9PLn5Sa4ccyVVuVVWhyOEEH0mCf84PbjqQZw2J1+f+nWrQxFCiOMiCf84bG7azCu7XuHz4z9PYfrQn8pZCJFaJOEfhwdXPYjX5eXmSTdbHYoQQhw3Sfh9tKZhDW9Vv8WXJn6JLFeW1eEIIcRxk4TfRw9++CB57jy5yUoIMWRJwu+DlXUrWbZ/GbdMukVmwxRCDFmS8PtgwZoF5LnzuGZs0j+0SwiRxCThH8NHDR+xtHYpN0+8GY/DY3U4QghxwiThH8OCjxaQk5bD58Z+zupQhBCiXyThf4INjRt4u/ptvjDhC9J2L4QY8iThf4JH1j6C1+nlunHXWR2KEEL0myT8o9jTtofX97zOtWOvxevyWh2OEEL0myT8o3hs/WPYlZ3PT/i81aEIIURcSMLvxQHfAZ7b9hxXjL6CAk+B1eEIIURcSMLvxV82/oVQNMTNE2+2OhQhhIgbSfgf0xXq4m+b/8b55edTkV1hdThCCBE3kvA/ZuH2hbQF2/jixC9aHYoQQsSVJPxDRHWUxzc+zqT8SUwtnGp1OEIIEVeS8A+xpGYJu9p2cdOEm1BKWR2OEELElST8Q/xpw58Ylj6MORVzrA5FCCHiThJ+zJbmLSyrXcb1467HaXNaHY4QQsSdJPyYv276K2n2NK6uutrqUIQQIiEk4QNtwTZe2vESl1ZeSo47x+pwhBAiISThA89vex5f2CeTpAkhklrKJ/yojvLkpieZWjiVCfkTrA5HCCESJi4JXyn1R6VUvVJq3SHr8pRSrymltsaWufHYV7y9t+899rTv4fpx11sdihBCJFS8aviPAhd/bN3dwBta6yrgjdj7QefJTU+S785nzkgZiimESG5xSfha67eBpo+tngs8Fnv9GPCZeOwrnmo7anmn5h2uqroKp12GYgohklsi2/CLtNa1ALHlsATu64Q8s/UZtNZcfZIMxRRCJD/LO22VUvOUUiuUUisaGhoGbL+haIh/bP0Hs0tnU5JZMmD7FUIIqyQy4dcppYoBYsv63jbSWv9Oaz1daz29sLAwgeEc7q29b9Hga+DasdcO2D6FEMJKiUz4LwDdcwx/EXg+gfs6bn/f8neK0ouYXTrb6lCEEGJAxGtY5l+BpcBYpVS1UuoW4F5gjlJqKzAn9n5Q2Nu+l/f2vcdnT/osDpvD6nCEEGJAxCXbaa2PNoj9gnh8f7w9u/VZbMrGlWOutDoUIYQYMJZ32g60cDTMc9ueY3bpbIZnDLc6HCGEGDApl/CX1CyhwdfAVVVXWR2KEEIMqJRL+M9sfYZ8dz5nl51tdShCCDGgUirh13fV8071O8wdM1ceciKESDkplfBf2P4CER2R5hwhREpKmYSvtebZrc9y6rBTGZk10upwhBBiwKVMwl9Vv4o97Xu4skqGYgohUlPKJPzntj2Hx+HhUyM/ZXUoQghhiZRI+F2hLl7d9SoXVVxEujPd6nCEEMISKZHw/7X7X3SFu/jMmEE3Jb8QQgyYlEj4z217jnJvOacOO9XqUIQQwjJJn/D3tu9lZd1K5o6Zi1LK6nCEEMIySZ/wF25fiEJxxegrrA5FCCEsldQJP6qjvLD9BWYWz5SJ0oQQKS+pE/6HdR9S01HD3NFzrQ5FCCEsl9QJ/4XtL5DuSOeC8kE5Lb8QQgyopE34vrCPf+3+F3NGzpGx90IIQRIn/EV7FtEZ6mTuGGnOEUIISOKEv3D7QkoySphWNM3qUIQQYlBIyoTf0NXA0tqlfHrUp7GppDxEIYQ4bkmZDV/e+TJRHeXy0ZdbHYoQQgwaSZnwX9j+ApMLJlOZXWl1KEIIMWgkXcLf3LSZLc1bpHYvhBAfk3QJf+H2hTiUg4srLrY6FCGEGFQcVgcQT5FohJd3vszsstnkunOtDkcMYlprAuEogVAUfzhCIBQlEI4QCEcJRqIEw1FCke6iiUQ14agmEo0SjmiiWhPV9Cw/zqbAplTP0mFX2G02HDaFw6Zw2m2xonA5bLgcNtIcdtIcNtxOO26nDY/TjsOedHUyYaGkSvjL9i+jwdcgE6UlsUA4QqsvRJsvRKsvTJvfvG73h2n3h+kIhOjwh2kPhOkMhOkMROgMmtddwQi+YISuYAR/OILuJVEPNk67wu20k+6yk+5ykO6yk+FykJ5mJyPNQYbLLDNjJSPNgdd98H2m24E3zUlGmp1Mt4M0h93qQxIWSqqE/+L2F/E6vZxddrbVoYhj0FrTFYzQ1BmksTNIc2eQps4gzV0Hl82dIVp8QVq6QrT6QrR0hfCFIp/4vXabIsNlx+t2xhKgncw0B8O8aWS4HHhcdjyxBJrmtPfUprtr16ambcNlt+F0mFp4d43cHqud220Km01hVwqlMIWDU29rNGiIdF8F9FwdaMKxK4TuK4dQ7GoiED54hREIRfCHovhDEXwhc4LqCh48YXUGwzR1BtnT1HXYSa0vJzCnXfWcGLqX3SeOdJf5/9V9Yuk+yXhcNjxOs677/58n9vPu1y67TaYfHwKSJuF3hbp4fc/rXFp5KWn2NKvDSUnRqKa5K0hDR4AD7UEOdAQ40BGgoSNAY0eQxo4AjZ1B87ozgD8U7fV7HDZFTrqL3HQnuekuynLTmVzqJCfdSbbHlKxDllluB1luJ5luBx6nPSUTTzSq8YUidATMlU5nIExHd/GHafeH6AxGDvtZZyBMZzBMqy9EbYvPXAXFTjDBcO+/m6Ox2xTpseSfkXbwhGFOJuZE0tuVSPfvzet24HWb32WGy4HNlnq/w4GQNAl/0d5F+MI+Lht1mdWhJJ1gOEpDR4C6Nj/1bX7q2gLUt/tpaA9Q3x6gIVYaO4NEemnQdtoVBZlp5GW4KMhMY0xhJvmZLvIy0sjPcJGX4SIv00V+houcdBdZbkdKJu3+sNlUT229KKv/3xeOROkKHWwC8wUj+ELh2NVGBH/o0PWHX4F0X5F0BiI9VyJdgYg50fThSkQp8KY5yE53kuU+eJI3J3wXOelOctOd5KSbv53cdPO3k+1xyoniGJIm4b+440VKMko4tUgeY9hX0aimqSvI/lY/dbFEvr/NT12rn7p2P/tb/dS3B2jqDB7xWbtNkZ/hYlhWGsO8aUwqyabA62KY101BZhoFmS4KvGkUZKSR5ZEEPtQ47Day7Day3M64fm93U57pbzFXHt39L92vW30h2v0h2mKvW30httZ3mNddIYKR3q8+7DbVU6ko9Jq/y6KsNIqy3BRneyjOdlOS4yE33Zmyf49JkfAP+A6wdN9Sbpl0i0ylEBMMR6mPJe3aWEKvbfX3JPT9bX7q2wJH/ONRCgoy0xie5aYs18O0kbkUZblj/3jcFMaWeRku7FKbEsdJqYNXIiei+4TR3cfT3GX6ew50BGnqNE2JjZ3minNrXTv17YEjrjo9TjtluR5G5qczIi+dyoIMKgsyGFWYSUm2O6lPBkmR8JfULCGqoynTnBOKRHsS+L4WH/ta/Oxv9fUk9NpWPwc6AkdcOnucdoZnuynKSmP6yFyKst0Mz3JTnO2mKMvN8GxTO3fKUEAxSB16wijrw8jraFRzoDPA/lY/+1r81LT4qGn2sbe5i71NXby3vZGu4MGBAOkuO6MLM6kqymRskZexw72ML85imDctKU4ESg+isWnTp0/XK1asOKHP7mrdRUV2RXwDsogvGKGmpYu9zT6qm80faE2LL5bcfdS1+Y8Y++11OyjOdjM820NJLIGX5BxM5MVZHmlaEeJjtNY0tAfYcaCT7Q0dbKs3ZUtdO3VtgZ7tctOdTCjJYmJJNhNLsphcmk1Ffsag6TNQSq3UWk8/5nbJkvCHkkhUU9vqY0+TqWWYpXlf3dzFgY7D28yddkVxtofSHA8lOR5Kc01SL845uMw8wUtkIUTvWrqCbN7fzsbaNjbWtrOhto3N+9t7mkG9aQ4mlWZz8ohsppTlMGVEjmVNQoMm4SulLgb+G7ADf9Ba33u0bZMp4bf7Q4cl9N2NXT3vq5t9hA+potttipIcNyNy003J8zAiL52yXA+lOekM86YNmpqEEKksFImypa6ddTWtfFTdytqaVjbWthGKmH/PBZlpTB2RzdQR5gQwZURO3Du+ezMoEr5Syg5sAeYA1cBy4Hqt9Ybeth9KCb8jEKa2xTS5VLf4qG7uorrpYNtgc1fosO1z0p2U56X3lBF56YyMLYuz3XILvRBDVCAcYVNtOx9Vt7Bqbwtr9rawvaETMIMgRhdmMqUsh6nlOUwty2FcsTfu/WR9TfiJbgeYCWzTWu+IBfUkMBfoNeFbSWuNPxSl1Rfr+Y/dAXqgI9Az3twMXTSdou3+8GGfd9ltlOZ6KMv1MHlyMSM+ltyzPYk/ywshBl6aw95Tm7/pDLOu1Rfio+oWVu9pYfXeFhZvrueZD6tj29uYUJIVawbK5uSyHCoHqD8g0Qm/FNh7yPtq4LR472TLh4tpfet/zBt92ILuK5hDJ7qKRiGsIRy75T0YgUBEEdQ2ItgIYyeMnRB2gtpJVDkpTvNQ4cnA40knvdKLNyuH7Kxs8vPyKMwvID+vAJsnC+yS2IVIddkeJ2dVFXJWVSFg8lB1s481sZPAR9Wt/G35Xh59bxcAmWkObjtvNLedOyahcSU64fd2yjqsDUkpNQ+YB1BeXn5CO/G11FPatuaTg1BmqTAzGSq0WSqN3amxOaPYdQQ7UWw6gk2HsUUP6TyNAB2x0vAJwTjTwZ0NntzDS3o+ZBRAegFkFEJmIWQWmfd26XAVIpkppRgRu9q/7OQSwNzNvK2hw/QFVLdSmZ+R+DgS3IZ/BjBfa31R7P13AbTWP+9t+0HXhq81RMMQDkDYb0rID6EuU4KdEOyAQAcE2iHQBv5W8LeAr7s0QVcTdDVCNNTLTpQ5EWQOB28ReIfHXg+HrBLwFkNWqTlJ2KSdXwhxpMHShr8cqFJKVQI1wHXADQneZ/woZZpo7E5Iy+zfd2ltTgidB6CzATrqobPeLDvqoL0O2muhbr1Zpz82K6TNAd4ScxLIKoHsso+VEeZKQsbZCyGOIqEJX2sdVkrdDryKGZb5R631+kTuc9BSyjT1uLMhf/QnbxuNmJNC2z5zEmjbB201ZtlaA/tWwaYXIfKxOW6cGZAzwiT/nHJTckdCzkjIrZATghApLuGNx1rrl4GXE72fpGKzmyYd7/CjbxONQtcBaK2Olb1m2bLHlJoV4Gs+/DNpWSbx51ZA3ihz4skfY0pGoZwMhEhy0ls4VNlskDnMlNKjzBDqb4udAHZD825o3glNO02z0eaXTf9EN3c25FdB4VgoOAkKx8GwcZBdLn0HQiQJSfjJzJ0FwyeZ8nGRsLkqaNwOjdugcSsc2ALb3oDVTxzczpVpkn/RBCiaZMrwSeYEIYQYUiThpyq7A/IqTam68PCf+ZqhYQvUb4CGTeaKYOOL8OGfDm6TMxKKT4biqaaUnAIZ+QN7DEKI4yIJXxzJkwvlp5nSTWto3w9162D/R1D7kVluXHhwm+xyKD0FSqdB6XQomQquxI8tFkL0jSR80TdKQVaxKVVzDq73t5rkv28V7PsQaj6EDc/HPmM3TUFlM2HEaTBipukwls5hISwhCV/0jzsbKs8ypVvnAahZCdUroPoD+OgpWPGI+VlmkUn+5WfAyDOgaLLcaSzEAJF/aSL+MgrgpItMAXNfQf1G2LsM9rxvysYXzM9cXtN0NHIWjJxt+gIcLutiFyKJScIXiWezHxwtNOMWs661BvYsNWX3e/DGPWa9w2NOABVnQeU55gQgVwBCxIU88UoMDp2NsPtd2LUEdr1jRgiBuQIYOQsqz4ZR58KwCXJfgBAfM1jm0hGibzLyYcIVpoDpB9j1Dux8B3a+BVtfNevTC0ziH3UujD7PzCMkhOgTSfhicMoogIlXmgKmCWjnW7BjsSnrnjbrC06CUefBmAugYrYMAxXiE0iTjhh6tDZNPtvfhO2LTB9A2Ac2pxn5M/oCGHMhFE2UIaAiJQyKZ9oeL0n44oSE/Kbzd/sbsG0R1McmZPWWmJp/1adME5A7y8oohUgYacMXqcPpNu35o8+DT2Gmkd72Bmx7DTa8AKv+bJ4nUH6GSf56K9ywAAASIUlEQVQnXWSagqT2L1KM1PBFcouEYO8HsPVfsPW1g7X/3Ao46WJTRp4pY//FkCZNOkL0pmWPSf5b/mU6gcN+85yA0efD2EvNtBHpeVZHKcRxkYQvxLEEu8yIny3/hC2vmkdNKrsZ9z/2Uhh3qbkSEGKQk4QvxPGIRs0EcJtfgk0vQ8NGs75oMoy/DMZ92jwLQNr9xSAkCV+I/mjcbp4KtuklM/cP2tT2x10G46+Ashlyx68YNCThCxEvHfUm+W980TQBRUOQOdzU/MdfYTp9Zb4fYSFJ+EIkgr/VdPhufB62vm5u+ErPNzX/CXPNnD92p9VRihQjCV+IRAt2wrbXzVj/La9AsMM8LWzcp2HClTDqHEn+YkDIjVdCJJorw9TqJ8w1d/tuf8M87Wv987DqcXDnmGafiVeaqZ4l+QuLScIXIh6cblOzH/dpCAfMHD/rn43d6ft4rOZ/GUy6CirOljZ/YQn5qxMi3hxpMPYSU0L+g8l//bNmmof0fNPZO+kq0+Frs1sdsUgRgz7hh0Ihqqur8fv9VocyoNxuN2VlZTid0gwwpDnd5gaucZdCyGfa/Nc/a57zu/L/mWf8TpgLE68yz/qVoZ4igQZ9p+3OnTvxer3k5+ejUuSmF601jY2NtLe3U1lZaXU4IhGCXeahLuv+YaZ6CPshq9S090+6CkpOlZu8RJ8lTaet3++noqIiZZI9gFKK/Px8GhoarA5FJIor/eADXgLtsPkVWPcMLFsASx8yN3lNvAomfVbm9RdxM+gTPpBSyb5bKh5zykrzwsnXmOJrNnf3rnsG3v1vWPJrKBhrav0Tr4LCk6yOVgxhQyLhC5EyPLlwyudN6TwAG56Ddc/C4nth8c/N3D6TYlcGeaOsjlYMMdJDFCeLFy/msssuO67PPProo+zbty9BEYkhL6MAZnwFvvQS3LURLr4XnB544x544BRYcA4s+Q0077I6UjFESMK3kCR80WdZxXD61+Arr8G/rYNP/RSUDV7/Mfz3FPjdeaYJqGmn1ZGKQUwS/jEsX76ck08+Gb/fT2dnJxMnTmTdunW9btvR0cHVV1/NuHHjuPHGG+keAXXPPfcwY8YMJk2axLx589Ba8/TTT7NixQpuvPFGpk6dis/nG8jDEkNZzgiY9Q2Y9ybcsQYu/AnoKLz2I3hgKiw4G97+JTRssTpSMcgM+mGZGzduZPz48QD8ZOF6Nuxri+s+J5Rk8ePLJ37iNj/4wQ/w+/34fD7Kysr47ne/e8Q2ixcvZu7cuaxfv56SkhLOPPNM7r//fmbPnk1TUxN5eeYpSjfddBPXXnstl19+Oeeeey6//OUvmT6999FUhx67EMfUvMvc2bvxBahebtYVjI3dAXwZlJwi4/yTVNIMyxwMfvSjHzFjxgzcbjcPPPDAUbebOXMmZWVlAEydOpVdu3Yxe/Zs3nzzTe677z66urpoampi4sSJXH755QMVvkgVuRVw5jdNaa2BTS+a0j3ax1tsnuE79hIzq6fTY3XEYoD1K+Erpa4B5gPjgZla6xWH/Oy7wC1ABPim1vrV/uwLOGZNPFGampro6OggFArh9/vJyMjodbu0tLSe13a7nXA4jN/v57bbbmPFihWMGDGC+fPnp9xdw8IC2aVw2v8xpavJ3Ny16aWDd/g602HUuXDSRVD1KcgqsTpiMQD6W8NfB1wFLDh0pVJqAnAdMBEoAV5XSp2ktY70c3+WmDdvHv/xH//Bzp07+c53vsNDDz3U5892J/eCggI6Ojp4+umnufrqqwHwer20t7cnJGYheqTnwZTrTAkHYNc75kavra+aB7sADJ8MY+aY5F82QyZ3S1L9+q1qrTdCrzcJzQWe1FoHgJ1KqW3ATGBpf/ZnhT/96U84HA5uuOEGIpEIs2bNYtGiRZx//vl9+nxOTg5f/epXmTx5MhUVFcyYMaPnZzfffDO33norHo+HpUuX4vHIJbZIMEcajLnQFH0/NGwyD3Df+trBpp+0bBh1ttlm9AWmk1gkhbh02iqlFgPf6m7SUUo9BLyvtX489v4R4J9a66c/6XuO1WmbalL52IUFfC2w823Y9hpsewPaasz6gpNM4h9zAYycZZ4DIAaVuHXaKqVeB4b38qPva62fP9rHelnX65lFKTUPmAdQXl5+rHCEEIniyYEJV5iiNTRsNrN7bl9k2v2X/RbsLjOr55gLYPT55s5fGfkzZBwz4WutLzyB760GDr0OLAN6vcNIa/074HdgavgnsK8BtXbtWm666abD1qWlpbFs2TKLIhIiAZSCYeNMmXW7mdp5z1LY/qY5Abw+35T0Ahh9nkn+o88Hb291QzFYJKpn5gXgL0qpX2M6bauADxK0rwE1efJkVq9ebXUYQgwsp+dgUuc/oH2/Sf47YieAtX832xVNip0ALoDyM8zzAMSg0d9hmVcCDwKFwEtKqdVa64u01uuVUk8BG4Aw8PWhOkJHCNEL73CYer0p0SjUrTPP9N32hpni+b0HweGBitmm+WfMhZA/RqZ5tlh/R+k8Czx7lJ/9DPhZf75fCDEE2GxQfLIps++EYCfsWmKS//Y34JW7zXY55SbxV33K3Pglnb8DTgbbCiHiy5Vhbug66SLzvnmXSf7bXoc1f4MVfzSdvyPPPHjjV/5oS0NOFZLwhRCJlVsBM24xJRwwnb9bXzN3/75ytyn5Y8y0DyddDOWng12e5ZwIMp4qTmQ+fCH6wJFmpnS46Gdw+3L45mq45H7IGQkf/A4euwzuHw1P3wJrnzb3Boi4kRq+hR599FEmTZpESYnMYyJSVF4lnDbPlECHGfWz+Z/m7t91T4PNYZp+xn3alOwyqyMe0oZWwv/n3bB/bXy/c/hkuOTeo/74hz/8IQUFBdxxxx0AfP/736eoqIhvfvObR2zbPR/+unXrmDZtGo8//jhKKe655x4WLlyIz+dj1qxZLFiwgGeeeaZnPnyZWkEIIC0Txl9uSjQC1Stg80uw6WX457dNKZ4K4y+D8XPl+b4nQJp0juGWW27hscceAyAajfLkk09y44039rrtqlWr+M1vfsOGDRvYsWMH7777LgC33347y5cvZ926dfh8Pl588UWuvvpqpk+fzhNPPMHq1asl2QtxKJsdyk+DOffAN1bA7Svgwvmmxr/op/A/M+ChmbDoZ7B/nbkzWBzT0Krhf0JNPFEqKirIz89n1apV1NXVccopp5Cfn9/rtjIfvhAJUlBlhnzOvhPa9pmpnjc8D+/8Et6+D/JGmwe7T/yMuflLxvv3amglfIt85Stf4dFHH2X//v18+ctfPup2Mh++EAMgqwRmftWUjgbzkJcNz8GS/zIngPwqmPRZU6TZ5zDSpNMHV155Ja+88grLly/noosuOq7P9jYffjeZD1+IfsoshOlfgi88D9/aApf9l7kL+K1fmGafh8+Cdx8wVwVCavh94XK5OO+888jJycFutx/XZ2U+fCEGSEYBTP+yKW21sP5ZM8fPaz80D3ivPNs8BGb8FaaDOAUNqYeYWyUajXLqqafy97//naqqqgHb72A4diGGvMbt5tGOHz1p7vp1psOEuTD1Bhg5Oymmd+7rfPhD/0gTbMOGDYwZM4YLLrhgQJO9ECJO8kfDed81N3l9+VWYfI3p9H3scnhgKrx1n3noewqQJp1jmDBhAjt27Oh5L/PhCzFEKWWmbSg/HS6+13T2rnoc3vwZLP65eabvtJvN3D5J+kzf5DyqBJL58IVIAq50OPlaU5p2msS/6nF48nrwlsCpX4BpXzQjgpKINOkIIVJbXiVc8EO4cz187gkommBG+fzXJHjyRtjxVtLc2CU1fCGEANOMM/4yU5p2muf4fvhn0/RTMNbM93PydUN6hI/U8IUQ4uPyKs20DndthM/81jzi8aX/C7+eAK9+34z2GYIk4QshxNE43Wb45rzFcMtrUHUhLHsYHjgF/vZ52L10SDX3SJNOHGVmZtLR0dHn7RcvXozL5WLWrFkJjEoI0W9KwYiZprTWwPI/mCafjQuh5FQ44+sw4TODfnSP1PAttHjxYt577z2rwxBCHI/sUrjwx6aT99O/An8rPHOLGdO/9H8gMHinSxlSd9r+4oNfsKlpU1z3OS5vHN+Z+Z1P3Obhhx/m4YcfBqC1tZWKigrefPPNI7bLzMzkjjvu4MUXX8Tj8fD8889TVFTEwoUL+elPf0owGCQ/P58nnngCn8/H6aefjt1up7CwkAcffJCzzjrrsO+TO22FGAKiUdjyCix9CHa/C2nZZn6f026FrOIBCUHutI2jW2+9ldWrV7N8+XLKysq46667et2us7OT008/nTVr1nD22Wfz+9//HoDZs2fz/vvvs2rVKq677jruu+8+KioquPXWW7nzzjtZvXr1EcleCDFE2Gww7lL40svwlUUw5nx47wH4zWR47utQH99Kan8M7ganjzlWTTzR7rjjDs4///yjzmXvcrl6nms7bdo0XnvtNQCqq6v53Oc+R21tLcFgkMrKygGLWQgxgMqmwTWPmmGd7/+vGda5+nE46RI485tQfoalc/VLDb+PHn30UXbv3s2Pf/zjo27jdDpRsV9m93z4AN/4xje4/fbbWbt2LQsWLJD58IVIdnmVcOn9pp3/3O9B9Qfw/y6BR+bAhhfMIxwtIAm/D1auXMkvf/lLHn/8cWwnMLNea2srpaWlAD2PSwSZD1+IpJeRD+d+B/5tHVz6S+hsgKdugodmwIo/Qsg3oOFIwu+Dhx56iKamJs477zymTp3KV77yleP6/Pz587nmmms466yzKCgo6Fl/+eWX8+yzzzJ16lTeeeedeIcthBgsXOnmCV3f+NA0+biz4cU7zfQNi38BnY0DEsaQGqWTalL52IVIalqbET3vPgBbXwWHB87/Acy6/YS+rq+jdIZUp60QQiQFpaBitin1m8yQzpwRCd+tJPwTcNpppxEIBA5b9+c//5nJkydbFJEQYsgaNg7mPjQgu5KEfwLkYSdCiKFoSHTaDqZ+hoGSiscshEisQZ/w3W43jY2NKZUAtdY0NjbidrutDkUIkUQGfZNOWVkZ1dXVNDQ0WB3KgHK73ZSVlVkdhhAiiQz6hO90OmUqAiGEiINB36QjhBAiPiThCyFEipCEL4QQKWJQTa2glGoAdh/nxwqAAwkIZzCTY04NqXbMqXa8EL9jHqm1LjzWRoMq4Z8IpdSKvswhkUzkmFNDqh1zqh0vDPwxS5OOEEKkCEn4QgiRIpIh4f/O6gAsIMecGlLtmFPteGGAj3nIt+ELIYTom2So4QshhOiDIZvwlVIXK6U2K6W2KaXutjqegaCU+qNSql4ptc7qWAaCUmqEUupNpdRGpdR6pdQdVseUaEopt1LqA6XUmtgx/8TqmAaKUsqulFqllHrR6lgGglJql1JqrVJqtVJqxbE/EYd9DsUmHaWUHdgCzAGqgeXA9VrrDZYGlmBKqbOBDuBPWutJVseTaEqpYqBYa/2hUsoLrAQ+k8y/Z6WUAjK01h1KKSewBLhDa/2+xaElnFLqLmA6kKW1vszqeBJNKbULmK61HrB7D4ZqDX8msE1rvUNrHQSeBOZaHFPCaa3fBpqsjmOgaK1rtdYfxl63AxuBUmujSixtdMTeOmNl6NXKjpNSqgz4NPAHq2NJZkM14ZcCew95X02SJ4JUp5SqAE4Bkv5xY7GmjdVAPfCa1jrpjxn4DfBtIGp1IANIA/9SSq1USs0biB0O1YSvelmX9LWgVKWUygSeAf5Na91mdTyJprWOaK2nAmXATKVUUjffKaUuA+q11iutjmWAnam1PhW4BPh6rMk2oYZqwq8GDn3Eexmwz6JYRALF2rGfAZ7QWv/D6ngGkta6BVgMXGxxKIl2JnBFrE37SeB8pdTj1oaUeFrrfbFlPfAspqk6oYZqwl8OVCmlKpVSLuA64AWLYxJxFuvAfATYqLX+tdXxDASlVKFSKif22gNcCGyyNqrE0lp/V2tdprWuwPxbXqS1/rzFYSWUUiojNhABpVQG8Ckg4aPvhmTC11qHgduBVzEdeU9prddbG1XiKaX+CiwFxiqlqpVSt1gdU4KdCdyEqfGtjpVLrQ4qwYqBN5VSH2EqNq9prVNimGKKKQKWKKXWAB8AL2mtX0n0TofksEwhhBDHb0jW8IUQQhw/SfhCCJEiJOELIUSKkIQvhBApQhK+EEKkCEn4QgiRIiThCyFEipCEL4QQKeL/Az55HueCN9GtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94bae2358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The next code cell visualizes the velocity of the quadcopter.\n",
    "\n",
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94ba65048>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),\n",
    "\n",
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94baad4a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before plotting the velocities (in radians per second) corresponding to each of the Euler angles.\n",
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe94ba7fc50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally, you can use the code cell below to print the agent's choice of actions.\n",
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9.12907694  -31.83633753  143.25550111    5.51209643    0.21470266\n",
      "    0.        ]\n",
      "[  0.0553423  -17.40312154  23.67714087]\n",
      "[-0.23523727 -0.03217826  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflections\n",
    "\n",
    "**Question 1**: Describe the task that you specified in `task.py`.  How did you design the reward function?\n",
    "\n",
    "**Answer**: I specified a take off task. Since there was no floor (if drone hits z=0, the episode ends), I set the start position to x=0,y=0,z=20 and target to x=0,y=0,z=100. \n",
    "\n",
    "For the reward function, at first I tried to apply a penalty relative to the distance between the target position and current position, increasing the z penalty by 1.5. That didn't work, I noticed that the quadcopter was shaking, angle velocities were varying a lot. \n",
    "\n",
    "So I experimented creating penalties using angular velocity and the euler angles. Angular velocity penalty ended working best for stabilizing the quadcopter, but wasn't enough to make it go up, so I added z speed to the reward (so if it was going up, it received a reward bonus the size of z speed, and if it was falling received a penalty).\n",
    "\n",
    "I also created extra bonuses in case z velocity beats certain thresholds (for instance reward += 5 if self.sim.v[2] > 0.3 ).\n",
    "\n",
    "In my last attempts I rewarded the quadcopter if it could decrease its distance to the target relative to its initial distance (if it could be \"more close\" to the target than initially), I hardcoded this in the task but its easy to get this dynamically.\n",
    "\n",
    "The last resort was rewarding the quadcopter in case it reached or passed the z goal. Which  was obvious but I didn't think about in the beginning. For this he received a 100 reward.\n",
    "\n",
    "I felt a little loose designing the reward function, really didn't felt sure what I was doing, I guess there wasn't a concept or lesson about this. So what I did was a lot of trial and error, reshaping the reward function pieces and watching the results.\n",
    "\n",
    "This approach works but only 30% of the time, If run again there's a high risk of not obtaining the same results (perhaps I should freeze the seed next time :/)\n",
    "\n",
    "### Update\n",
    "\n",
    "I did the suggested in the review:\n",
    "* Aim just at the height (z), so I removed x and y from the distance penalty\n",
    "* pass the reward function through an activation function (sigmoid) before returning it to the agent, to reduce its magnitude\n",
    "\n",
    "After this 2 steps the agent was successfull and eventually learned the best actions to take off.\n",
    "\n",
    "Thank you very much, Ill try to use a tanh activation function to compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Discuss your agent briefly, using the following questions as a guide:\n",
    "\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "**Answer**: I used the udacity's provided DDPG agent which uses an off policy approach, didn't try other algorithms as I assumed (maybe incorrectly) the DDPG was the best for this job (continuous state and action spaces).\n",
    "\n",
    " I didn't use any architecture, only provided code.\n",
    " \n",
    " For the actor:\n",
    " \n",
    " 3 dense hidden layers 32 - 64 - 32 with Relu activation function\n",
    " 1 sigmout output layer (1D tensor with len 4), that was scaled to action range\n",
    " Adam Optimizer\n",
    " \n",
    " For the critic:\n",
    " \n",
    " 2 dense hidden layers 32 - 64 with Relu activation for the state pathway\n",
    " 2 dense hidden layers 32 - 64 with Relu activation for the action pathway\n",
    " 1 layers.add() of the paths and a Relu activation\n",
    " 1 final output layer with 1 node and no activation function for the Q values\n",
    " Adam Optimizer\n",
    " \n",
    " I Added Batchnorm and Dropout(.2) between the layers, but that didn't help at all, quadcopter performance went down, so at the end I used the default.\n",
    "\n",
    "Didn't play with the hyperparameters very much, but at the end these was best (obtained via trial and error):\n",
    "\n",
    "* gamma = 0.99\n",
    "* theta = 0.15\n",
    "* sigma = 0.3\n",
    "* tau = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Using the episode rewards plot, discuss how the agent learned over time.\n",
    "\n",
    "- Was it an easy task to learn or hard?\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "**Answer**: Hard task. At first I thought it was an easy task, but my dreams were crushed by gravity and the lesser boundary z.\n",
    "\n",
    "I believed z=0 to be ground, but the quadcopter started every episode already floating. When I finally found out about the lesser boundary from z to be 0 everything became much easier. \n",
    "\n",
    "Turns out that when you set the start position to [0,0,0], the physics sim sets z to 10, the quadcopter quickly falls to 0 and the episode ends.\n",
    "\n",
    "Maybe telling this to the studends should make this exercise easier, or perhaps I should have read the physics_sim before trying to play with the agent.\n",
    "\n",
    "Nothing seemed to work at first, but after solving the above enigma, shaping the reward function and experimenting became easier.\n",
    "\n",
    "The main problem here is that the quadcopter had to became stable to be able to fight gravity and go up, after it learned to keep angular v low and use very close speeds at all 4 propellers, it figured it out.\n",
    "\n",
    "It was a very \"AHA\" moment, as we can see in the rewards plot. It seems that the agent is experimenting with a wide range of actions, so the reward plot kind of reminds me of a electroencephalogram. Maybe because of the exploration sigma ? \n",
    "\n",
    "Overall I say the final performance was good, but need improvements:\n",
    "\n",
    "It was good in the sense that it was able to take off and it kept stable until certain heights. The problem is that the agent became a little insensible, it overcame the target z by 40%, wich is really bad, and started oscilating in X an Z axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Briefly summarize your experience working on this project. You can use the following prompts for ideas.\n",
    "\n",
    "- What was the hardest part of the project? (e.g. getting started, plotting, specifying the task, etc.)\n",
    "- Did you find anything interesting in how the quadcopter or your agent behaved?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "The hardest part was designing the reward function, and working with the scales of the rewards and penalties. I also spent too many time before figuring out about z boundary.\n",
    "\n",
    "The most interesting and sad part is that, as mentionet in question 1, sometimes the agent learns about how to get the best scores (and reach target), but then sort of \"forgets\" how to do it, in the middle of training, and start behaving oddly, even falling to z=0.\n",
    "\n",
    "Another interesting fact is that, if we check the quadcopter actions in the last run (cell after the rewards plot), we can see that the agent understood that it had to use very similar action to all propellers (900)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
